This file is a merged representation of a subset of the codebase, containing specifically included files, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: R/**/*.R, R/**/*.r, *.Rmd, *.rmd, DESCRIPTION, tests/**/*.R, tests/**/*.r
- Files matching patterns in .gitignore are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
R/
  afni.R
  all_generic.R
  ar_utils.R
  autoplot-methods.R
  baseline_model.R
  basis.R
  benchmark_datasets.R
  beta_utils.R
  bootstrap.R
  con_stats.R
  contrast.R
  covariate.R
  data_fmri_benchmark_datasets.R
  design_plot.R
  evaluate-helpers.R
  event_model_helpers.R
  event_model.R
  event_vector.R
  event-classes.R
  fmri_betas.R
  fmri_dataset.R
  fmri_latent_lm.R
  fmri_model.R
  fmrilm.R
  fmrireg.R
  fmrirlm.R
  gen_contrast.R
  globals.R
  hrf_decorators.R
  hrf_smoothing_kernel.R
  hrf-afni.R
  hrf-formula.R
  hrf-functions.R
  hrf.R
  lss.R
  metafuns.R
  mixed_solve.R
  naming-utils.R
  penalty_matrix.R
  RcppExports.R
  reg-constructor.R
  reg-methods.R
  regressor.R
  sampling_frame.R
  simulate.R
  utils-internal.R
  zzz.R
tests/
  testthat/
    helper-naming.R
    test_afni_hrf_aliases.R
    test_afni_hrf.R
    test_ar_args.R
    test_ar_integration.R
    test_ar_whiten.R
    test_baseline.R
    test_benchmark_datasets.R
    test_betas.R
    test_contrast.R
    test_convenience_functions.R
    test_covariate_length.R
    test_dataset.R
    test_estimate_ar.R
    test_estimate_hrf.R
    test_event_model.R
    test_event_vector.R
    test_fmriglm.R
    test_fmrimodel.R
    test_hrf.R
    test_iterators.R
    test_ls_svd_benchmark.R
    test_parse_event_formula.R
    test_parse_term.R
    test_penalty_matrix.R
    test_regressor.R
    test_runwise_ar_fit.R
    test_sampling_frame.R
    test_standardized.R
    test_thread_option.R
    test_trialwise.R
    test-naming-utils.R
    test-regressor.R
  testthat.R
DESCRIPTION
README.rmd
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="R/beta_utils.R">
#' @keywords internal
#' @noRd
build_design_data <- function(bdes) {
  X <- if (is.null(bdes$dmat_fixed)) bdes$dmat_ran else cbind(bdes$dmat_ran, bdes$dmat_fixed)
  Base <- as.matrix(bdes$dmat_base)
  X[is.na(X)] <- 0
  list(Base = Base, X = X)
}

#' @keywords internal
#' @noRd
masked_vectors <- function(dset) {
  neuroim2::vectors(get_data(dset), subset = which(get_mask(dset) > 0))
}

#' Apply a function to voxel vectors with optional progress bar
#'
#' @keywords internal
#' @noRd
map_voxels <- function(vecs, FUN, ..., .progress = TRUE) {
  worker <- function(v) FUN(v, ...)
  if (.progress) {
    with_package("progressr")
    progressr::with_progress({
      p <- progressr::progressor(along = vecs)
      res <- furrr::future_map(vecs, function(v) { p(); worker(v) })
    })
  } else {
    res <- furrr::future_map(vecs, worker)
  }
  do.call(cbind, res)
}
</file>

<file path="R/con_stats.R">
#' @keywords internal
#' @noRd
qr.lm <- getFromNamespace("qr.lm", "stats")

#' Extract basic components from a linear model fit
#'
#' @param lmfit A fitted linear model object.
#' @return A list containing coefficient matrix (`betamat`), residual standard
#'   deviations (`sigma`), and residual degrees of freedom (`dfres`).
#' @keywords internal
#' @noRd
.lm_basic_stats <- function(lmfit) {
  betamat <- as.matrix(coef(lmfit))
  rss     <- colSums(as.matrix(lmfit$residuals^2))
  dfres   <- lmfit$df.residual
  sigma   <- sqrt(rss / dfres)
  list(betamat = betamat, sigma = sigma, dfres = dfres)
}

#' @keywords internal
#' @noRd
fit_Ftests <- function(object) {
  w <- object$weights
  ssr <- if (is.null(w)) {
    apply(object$residuals, 2, function(vals) sum(vals^2))
  } else {
    apply(object$residuals, 2, function(vals) sum((vals^2 *w)))
  }
  
  mss <- if (is.null(w)) {
    apply(object$fitted.values, 2, function(vals) sum(vals^2))
  } else {
    apply(object$fitted.values, 2, function(vals) sum(vals^2 * w))
  }
  
  #if (ssr < 1e-10 * mss) 
  #  warning("ANOVA F-tests on an essentially perfect fit are unreliable")
  
  dfr <- df.residual(object)
  p <- object$rank
  
  p1 <- 1L:p
  #comp <- object$effects[p1]
  asgn <- object$assign[qr.lm(object)$pivot][p1]
  
  
  #nmeffects <- c("(Intercept)", attr(object$terms, "term.labels"))
  #tlabels <- nmeffects[1 + unique(asgn)]
  
  df <- c(lengths(split(asgn, asgn)), dfr)
  
  I.p <- diag(nrow(coefficients(object)))
  nterms <- length(unique(asgn))
  hmat <- lapply(1:nterms, function(i) {
    subs <- which(asgn == i)
    hyp.matrix <- I.p[subs, , drop=FALSE]
    hyp.matrix[!apply(hyp.matrix, 1, function(x) all(x == 0)), , drop = FALSE]
  })
  
  ret <- lapply(seq_along(ssr), function(i) {
    comp <- object$effects[,i]
    ss <- c(unlist(lapply(split(comp^2, asgn), sum)), ssr[i])
    ms <- ss/df
    f <- ms/(ssr[i]/dfr)
    
    P <- pf(f, df, dfr, lower.tail = FALSE)
    list(F = f, P = P)
  })
  
  FMat <- do.call(rbind, lapply(ret, "[[", "F"))
  PMat <- do.call(rbind, lapply(ret, "[[", "P"))
  
  list(F=FMat, P=PMat)
  
}



#' Beta Statistics for Linear Model
#'
#' @description
#' This function calculates beta statistics for a linear model fit.
#'
#' @param lmfit Fitted linear model object.
#' @param varnames Vector of variable names.
#' @param se Logical flag indicating whether to calculate standard errors (default: TRUE).
#'
#' @return A list containing the following elements:
#' \itemize{
#'   \item{\code{estimate}: Estimated beta coefficients.}
#'   \item{\code{stat}: t-statistics of the beta coefficients (if \code{se = TRUE}).}
#'   \item{\code{se}: Standard errors of the beta coefficients (if \code{se = TRUE}).}
#'   \item{\code{prob}: Probabilities associated with the t-statistics (if \code{se = TRUE}).}
#'   \item{\code{stat_type}: Type of the statistics calculated.}
#' }
#' @examples
#' data(mtcars)
#' lm_fit <- lm(mpg ~ wt + qsec + am, data = mtcars)
#' beta_stats(lm_fit, c("Intercept", "wt", "qsec", "am"))
#' @noRd
#' @autoglobal
beta_stats <- function(lmfit, varnames, se = TRUE) {
  basics  <- .lm_basic_stats(lmfit)
  betamat <- t(basics$betamat)
  sigma   <- basics$sigma
  rdf     <- basics$dfres
  colnames(betamat) <- varnames

  if (se) {
    cov.unscaled <- chol2inv(qr.lm(lmfit)$qr)
    coef_se      <- sqrt(diag(cov.unscaled))
    vc           <- outer(sigma, coef_se)
    colnames(vc) <- varnames
    tstat        <- ifelse(abs(vc) < .Machine$double.eps^0.5, 0, betamat / vc)
    prob         <- 2 * pt(-abs(tstat), rdf)

    ret <- dplyr::tibble(
      type        = "beta",
      name        = "parameter_estimates",
      stat_type   = "tstat",
      df.residual = rdf,
      conmat      = list(NULL),
      colind      = list(NULL),
      data        = list(dplyr::tibble(
        estimate = list(betamat),
        se       = list(vc),
        stat     = list(tstat),
        prob     = list(prob),
        sigma    = list(sigma)
      ))
    )
  } else {
    ret <- dplyr::tibble(
      type        = "beta",
      name        = "parameter_estimates",
      stat_type   = "effect",
      df.residual = rdf,
      conmat      = list(NULL),
      colind      = list(NULL),
      data        = list(tibble(
        estimate = list(betamat),
        se       = list(NULL),
        stat     = list(NULL),
        prob     = list(NULL),
        sigma    = list(sigma)
      ))
    )
  }

  ret
}

#' Fit F-contrasts for Linear Model
#'
#' @description
#' This function calculates F-contrasts for a fitted linear model.
#'
#' @param lmfit Fitted linear model object.
#' @param conmat Contrast matrix.
#' @param colind Column indices corresponding to the variables in the contrast matrix.
#'
#' @return A list containing the following elements:
#' \itemize{
#'   \item{\code{estimate}: Estimated contrasts.}
#'   \item{\code{se}: Residual variance.}
#'   \item{\code{stat}: F-statistics for the contrasts.}
#'   \item{\code{prob}: Probabilities associated with the F-statistics.}
#'   \item{\code{stat_type}: Type of the statistics calculated.}
#' }
#' @noRd
#' @keywords internal

fit_Fcontrasts <- function(lmfit, conmat, colind) {
  basics  <- .lm_basic_stats(lmfit)
  betamat <- basics$betamat
  sigma2  <- basics$sigma^2
  rdf     <- basics$dfres

  cov.unscaled <- chol2inv(qr.lm(lmfit)$qr)

  cmat <- matrix(0, nrow(conmat), nrow(betamat))
  if (ncol(conmat) == length(colind)) {
    cmat[, colind] <- conmat
  } else if (nrow(conmat) == length(colind)) {
    cmat[, colind] <- t(conmat)
  } else {
    stop(sprintf(
      "F contrast weight matrix dimensions %d x %d do not match length(colind) %d",
      nrow(conmat), ncol(conmat), length(colind)
    ))
  }

  r  <- nrow(conmat)
  M  <- cmat %*% cov.unscaled %*% t(cmat)
  cm <- tryCatch(solve(M), error = function(e) {
    warning(paste(
      "Singular matrix in F-contrast computation (C(X'X)^-1C'). Details:",
      e$message
    ))
    matrix(NaN, nrow(M), ncol(M))
  })

  estimate <- purrr::map_dbl(1:ncol(betamat), function(i) {
    cb <- cmat %*% betamat[, i]
    drop(t(cb) %*% cm %*% cb) / r
  })

  Fstat <- estimate / sigma2

  structure(list(
    conmat      = conmat,
    estimate    = estimate,
    se          = sigma2,
    df.residual = rdf,
    stat        = Fstat,
    prob        = 1 - pf(Fstat, r, rdf),
    stat_type   = "Fstat"),
    class = c("Fstat", "result_stat")
  )
}

#' @keywords internal
#' @noRd
#' @autoglobal
estimate_contrast.contrast <- function(x, fit, colind, ...) {
  ret <- fit_contrasts(fit, x$weights, colind, se=TRUE)
  
  ## assumes se computed
  tibble(
    type="contrast",
    name=x$name,
    stat_type=ret$stat_type,
    df.residual=ret$df.residual,
    conmat=list(x$weights),
    colind=list(colind),
    data=list(tibble(
      estimate=ret$estimate,
      se=ret$se,
      stat=ret$stat,
      prob=ret$prob,
      sigma=ret$sigma)))
    
}


#' @export
#' @autoglobal
#' @keywords internal
#' @noRd
estimate_contrast.Fcontrast <- function(x, fit, colind, ...) {
  ret <- fit_Fcontrasts(fit, x$weights, colind)
  tibble(
    type="Fcontrast",
    name=x$name,
    stat_type=ret$stat_type,
    df.residual=ret$df.residual,
    conmat=list(x$weights),
    colind=list(colind),
    data=list(tibble(
      estimate=ret$estimate,
      se=ret$se,
      stat=ret$stat,
      prob=ret$prob)))
}

#' Fit Contrasts for Linear Model
#'
#' @description
#' This function calculates contrasts for a fitted linear model.
#'
#' @param lmfit The fitted linear model object.
#' @param conmat The contrast matrix or contrast vector.
#' @param colind The subset column indices in the design associated with the contrast.
#' @param se Whether to compute standard errors, t-statistics, and p-values (default: TRUE).
#'
#' @return A list containing the following elements:
#' \itemize{
#'   \item{\code{conmat}: Contrast matrix.}
#'   \item{\code{sigma}: Residual standard error.}
#'   \item{\code{df.residual}: Degrees of freedom for residuals.}
#'   \item{\code{estimate}: Estimated contrasts.}
#'   \item{\code{se}: Standard errors of the contrasts (if \code{se = TRUE}).}
#'   \item{\code{stat}: t-statistics for the contrasts (if \code{se = TRUE}).}
#'   \item{\code{prob}: Probabilities associated with the t-statistics (if \code{se = TRUE}).}
#'   \item{\code{stat_type}: Type of the statistics calculated.}
#' }
#' @noRd
fit_contrasts <- function(lmfit, conmat, colind, se = TRUE) {

  conmat <- as.matrix(conmat)

  basics  <- .lm_basic_stats(lmfit)
  betamat <- basics$betamat
  sigma   <- basics$sigma
  rdf     <- basics$dfres

  ncoef <- nrow(betamat)
  cmat  <- matrix(0, ncoef, 1)
  cmat[colind, ] <- conmat

  ct <- drop(t(cmat) %*% betamat)

  if (se) {
    cov.unscaled <- chol2inv(qr.lm(lmfit)$qr)
    var_est      <- as.numeric(t(cmat) %*% cov.unscaled %*% cmat)
    se_vec       <- sqrt(var_est) * sigma

    structure(list(
      conmat      = cmat,
      sigma       = sigma,
      df.residual = rdf,
      estimate    = ct,
      se          = se_vec,
      stat        = ct / se_vec,
      prob        = 2 * pt(-abs(ct / se_vec), rdf),
      stat_type   = "tstat"),
      class = c("tstat", "result_stat")
    )
  } else {
    structure(list(
      conmat      = cmat,
      sigma       = sigma,
      df.residual = rdf,
      estimate    = ct,
      stat_type   = "effects"),
      class = c("effect", "result_stat")
    )
  }
}

#' @keywords internal
#' @noRd
#' @autoglobal
.fast_t_contrast  <- function(B, sigma2, XtXinv, l, df) {
  # B:      p x V matrix (betas)
  # sigma2: V-vector (residual variance)
  # XtXinv: p x p matrix (inverse crossproduct of design)
  # l:      1 x p vector/matrix (contrast weights)
  # df:     scalar (residual degrees of freedom)
  
  # Ensure l is a row vector (matrix)
  if (!is.matrix(l)) {
    l <- matrix(l, nrow = 1)
  }
  
  est  <- drop(l %*% B)                # 1 × V  (BLAS GEMV)
  s2   <- as.numeric(l %*% XtXinv %*% t(l)) # scalar Var(est) / sigma2
  
  # Avoid division by zero or NaNs if s2 or sigma2 are zero/negative
  se   <- sqrt(pmax(0, s2 * sigma2))            # 1 × V
  
  tval <- ifelse(se < .Machine$double.eps^0.5, 0, est / se)
  pval <- 2 * pt(-abs(tval), df)

  list(estimate = est,
       se       = se,
       stat     = tval,
       prob     = pval,
       sigma    = sqrt(pmax(0, sigma2)), # Include sigma for potential compatibility
       stat_type = "tstat")
}

#' @keywords internal
#' @noRd
#' @autoglobal
.fast_F_contrast <- function(B, sigma2, XtXinv, L, df) {
  # B:      p x V matrix (betas)
  # sigma2: V-vector (residual variance)
  # XtXinv: p x p matrix
  # L:      r x p matrix (contrast weights)
  # df:     scalar (residual degrees of freedom)
  
  if (!is.matrix(L)) {
      stop(".fast_F_contrast requires L to be a matrix.")
  }
  
  r   <- nrow(L)
  U   <- L %*% B                    # r × V   (BLAS GEMM) : L*beta
  M   <- L %*% XtXinv %*% t(L)      # r × r   : L (X'X)^-1 L'
  
  # Use tryCatch for solve() in case M is singular
  Cinv <- tryCatch(solve(M), error = function(e) {
    warning(paste("Singular matrix in F-contrast computation (L(X'X)^-1 L'). Details:", e$message))
    # Return a matrix of NaNs or zeros? Let's use NaNs.
    matrix(NaN, nrow = r, ncol = r)
  })

  # qf = diag(t(U) %*% Cinv %*% U)
  # Efficient computation: colSums((t(U) %*% Cinv) * t(U))
  # Check if Cinv contains NaNs
  if (any(is.nan(Cinv))) {
      qf <- rep(NaN, ncol(U))
  } else {
      tmp  <- t(U) %*% Cinv           # V x r
      qf  <- colSums(tmp * t(U))      # V-vector, each element is u_v' Cinv u_v
  }
  
  estimate <- qf / r # Numerator mean square: (LB)' (L(X'X)^-1 L')^-1 (LB) / r
  se <- sigma2 # Denominator mean square (residual variance)
  
  # Avoid division by zero/NaNs
  Fval <- ifelse(abs(se) < .Machine$double.eps^0.5 | is.nan(qf), 
                 NaN, 
                 estimate / se)
                 
  pval <- pf(Fval, r, df, lower.tail = FALSE)

  list(estimate = estimate, # Numerator MS
       se       = se,       # Denominator MS (sigma2)
       stat     = Fval,
       prob     = pval,
       stat_type = "Fstat")
}

#' @keywords internal
#' @noRd
#' @autoglobal
fit_lm_contrasts_fast <- function(B, sigma2, XtXinv, conlist, fconlist, df) {
  # B:        p x V matrix (betas)
  # sigma2:   V-vector (residual variance)
  # XtXinv:   p x p matrix
  # conlist:  Named list of simple contrast vectors/matrices (1xp or px1)
  # fconlist: Named list of F contrast matrices (rxp)
  # df:       Scalar residual df

  # ----- simple contrasts (t) -----
  simples <- purrr::imap(conlist, function(l, nm) {
    # Ensure l has colind attribute attached in fmri_lm_fit
    colind <- attr(l, "colind")
    if (is.null(colind)) {
        warning(paste("Missing 'colind' attribute for simple contrast:", nm))
        # Cannot compute contrast without knowing which columns it applies to.
        # Need to decide how to handle this - skip contrast? Error?
        # For now, return NULL, will be filtered out by bind_rows.
        # Return NULL for this specific contrast, imap will handle it.
        return(NULL)
    }
    
    # Create full contrast vector/matrix padded with zeros
    p <- nrow(XtXinv)
    if (is.matrix(l)) { # Should be 1xp or px1
        if (ncol(l) == 1) l <- t(l) # Ensure it's 1xp
        if (ncol(l) != length(colind)) stop(paste("Contrast matrix columns mismatch colind for contrast:", nm))
        full_l <- matrix(0, nrow = 1, ncol = p)
        full_l[, colind] <- l
    } else { # Vector
        if (length(l) != length(colind)) stop(paste("Contrast vector length mismatch colind for contrast:", nm))
        full_l <- matrix(0, nrow = 1, ncol = p)
        full_l[, colind] <- l
    }
    
    res <- .fast_t_contrast(B, sigma2, XtXinv, full_l, df)
    # Package into tibble matching estimate_contrast.contrast output structure
    dplyr::tibble(type      = "contrast",
           name      = nm,
           stat_type = res$stat_type,
           df.residual = df,
           conmat    = list(l), # Store original contrast weights
           colind    = list(colind),
           data      = list(dplyr::tibble(
             estimate = res$estimate, # V-vector -- REMOVE list() wrapper
             se       = res$se,       # V-vector -- REMOVE list() wrapper
             stat     = res$stat,     # V-vector -- REMOVE list() wrapper
             prob     = res$prob,     # V-vector -- REMOVE list() wrapper
             sigma    = res$sigma     # V-vector -- REMOVE list() wrapper
           )))
  })

  # ----- F contrasts -----
  Fcons <- purrr::imap(fconlist, function(L, nm) {
    colind <- attr(L, "colind")
    if (is.null(colind)) {
        warning(paste("Missing 'colind' attribute for F contrast:", nm))
        return(NULL) # Return NULL for this specific contrast
    }
        
    # Create full contrast matrix padded with zeros
    p <- nrow(XtXinv)
    if (!is.matrix(L)) stop("F contrast weights must be a matrix")
    if (ncol(L) != length(colind)) stop(paste("F contrast matrix columns mismatch colind for contrast:", nm))
        
    full_L <- matrix(0, nrow = nrow(L), ncol = p)
    full_L[, colind] <- L
    
    res <- .fast_F_contrast(B, sigma2, XtXinv, full_L, df)
    # Package into tibble matching estimate_contrast.Fcontrast output structure
    dplyr::tibble(type      = "Fcontrast",
           name      = nm,
           stat_type = res$stat_type,
           df.residual = df,
           conmat    = list(L), # Store original contrast weights
           colind    = list(colind),
           data      = list(dplyr::tibble(
             estimate = res$estimate, # V-vector (Num MS) -- REMOVE list() wrapper
             se       = res$se,       # V-vector (Den MS = sigma2) -- REMOVE list() wrapper
             stat     = res$stat,     # V-vector (F stat) -- REMOVE list() wrapper
             prob     = res$prob      # V-vector -- REMOVE list() wrapper
           )))
  })

  # Return a list containing a single tibble, similar to fit_lm_contrasts output?
  # Original fit_lm_contrasts returned list(contrasts=conres, bstats=bstats, fit=fit)
  # The callers (chunkwise_lm, runwise_lm) process this.
  # Let's return just the combined tibble for now, callers need adjustment.
  # Or return a list structure mimicking the original?
  # Mimic structure: list(contrasts = list(combined_tibble), bstats = ..., fit=NULL)
  # For now, return just the tibble of contrasts.
  # Callers will need modification.
  
  # Let's return the structure expected by runwise/chunkwise logic if possible.
  # The original `fit_lm_contrasts` returned a list where each element was a contrast result (tibble).
  # Let's try returning a list of tibbles, one per contrast.
  # Combine the lists of tibbles, filtering out any NULLs from failed contrasts
  all_cons_list <- c(Filter(Negate(is.null), simples), Filter(Negate(is.null), Fcons))
  
  # Ensure the list is named correctly
  names(all_cons_list) <- unlist(lapply(all_cons_list, function(x) x$name[1]))
  
  # Return the list of tibbles
  all_cons_list
}

#' @keywords internal
#' @noRd
#' @autoglobal
beta_stats_matrix <- function(Betas, XtXinv, sigma, dfres, varnames) {
  # Betas:    p x V matrix
  # XtXinv:   p x p matrix
  # sigma:    V-vector (residual std dev)
  # dfres:    Scalar residual df
  # varnames: p-vector of coefficient names
  
  p <- nrow(Betas)
  V <- ncol(Betas)
  sigma2 <- sigma^2 # V-vector
  
  # Compute SE for each beta, each voxel
  # se(beta_i) = sqrt( [XtXinv]_ii * sigma2 )
  diag_XtXinv <- diag(XtXinv)
  if (any(diag_XtXinv < 0)) {
      # Handle potential numerical issues if diagonal is negative
      warning("Negative diagonal elements found in XtXinv during beta SE calculation.")
      diag_XtXinv[diag_XtXinv < 0] <- NaN
  }
  se_scaling <- sqrt(diag_XtXinv) # p-vector
  
  # Outer product: V-vector sigma with p-vector se_scaling -> V x p matrix
  vc <- outer(sigma, se_scaling) # SEs for all betas (rows=voxels, cols=betas)
  
  betamat <- t(Betas) # V x p matrix (voxels x betas)
  colnames(betamat) <- varnames
  colnames(vc) <- varnames
  
  # Compute t-stats: element-wise division
  # Avoid division by zero
  tstat <- ifelse(abs(vc) < .Machine$double.eps^0.5, 0, betamat / vc)
  
  # Compute p-values
  prob <- 2 * pt(-abs(tstat), dfres)
  
  # Package into the same tibble structure as beta_stats
  ret <- dplyr::tibble(
    type = "beta",
    name = "parameter_estimates",
    stat_type = "tstat",
    df.residual = dfres,
    conmat = list(NULL), # Keep consistent structure
    colind = list(NULL),
    data = list(dplyr::tibble(
      estimate = list(betamat), # V x p matrix
      se = list(vc),       # V x p matrix
      stat = list(tstat),    # V x p matrix
      prob = list(prob),     # V x p matrix
      sigma = list(sigma)    # V-vector
    ))
  )
  
  return(ret)
}
</file>

<file path="R/design_plot.R">
#' Design Plot for fMRI Model
#'
#' @description
#' Generates an interactive Shiny app that plots the design matrix for a given
#' fMRI model. The design matrix is first converted into a long-format tibble and
#' then plotted over time, faceted by block. Several customization options allow
#' you to adjust the title, axis labels, line thickness, color palette, and more.
#'
#' @param fmrimod An \code{fmri_model} object.
#' @param term_name Optional: Name of the term to plot. If \code{NULL} (the default),
#'   the first term is used.
#' @param longnames Logical; if TRUE, use long condition names in the legend. Default is FALSE.
#' @param plot_title Optional plot title. If \code{NULL}, a default title is generated.
#' @param x_label Label for the x-axis. Default is "Time".
#' @param y_label Label for the y-axis. Default is "Value".
#' @param line_size Numeric; line thickness for the plot. Default is 1.
#' @param color_palette Character; name of a ColorBrewer palette to use (e.g., "Set1"). Default is "Set1".
#' @param facet_ncol Number of columns for facet_wrap. Default is 1.
#' @param theme_custom A ggplot2 theme to apply. Default is \code{theme_bw(base_size = 14)}.
#' @param legend_threshold Numeric; if the number of unique conditions exceeds this value,
#'   the legend is hidden. Default is 25.
#' @param ... Additional arguments passed to ggplot2::geom_line().
#'
#' @return A Shiny app that displays the design plot.
#'
#' @importFrom ggplot2 ggplot aes_string geom_line facet_wrap labs theme_bw scale_color_brewer guides theme_minimal
#' @importFrom tidyr pivot_longer
#' @export
#'
#' @examples
#' if (interactive()) {
#'   ## --- Construct a sampling frame ---
#'   sframe <- sampling_frame(blocklens = c(100, 100), TR = 2, precision = 0.5)
#'
#'   ## --- Create a dummy event table ---
#'   set.seed(123)
#'   event_table <- data.frame(
#'     onset = seq(10, 190, length.out = 20),
#'     x = rnorm(20),
#'     y = rnorm(20),
#'     run = rep(1:2, each = 10)
#'   )
#'
#'   ## --- Construct a baseline model ---
#'   base_mod <- baseline_model(basis = "bs", degree = 3, sframe = sframe, intercept = "runwise")
#'
#'   ## --- Construct an event model using a formula ---
#'   ev_mod <- event_model(x = onset ~ hrf(x) + hrf(y), data = event_table,
#'                         block = ~ run, sampling_frame = sframe,
#'                         drop_empty = TRUE, durations = rep(0, nrow(event_table)))
#'
#'   ## --- Combine into an fMRI model ---
#'   fmri_mod <- fmri_model(ev_mod, base_mod)
#'
#'   ## --- Launch the interactive design plot ---
#'   design_plot(fmrimod = fmri_mod,
#'               term_name = NULL,
#'               longnames = TRUE,
#'               plot_title = "fMRI Design Matrix",
#'               x_label = "Time (s)",
#'               y_label = "Signal",
#'               line_size = 1.5,
#'               color_palette = "Set2",
#'               facet_ncol = 1)
#' }-------------------------------------------------------------------------
# ---------------------------------------------------------------------------
design_plot <- function(fmrimod, term_name = NULL, longnames = FALSE,
                         plot_title = NULL,
                         x_label = "Time (s)", y_label = "Amplitude",
                         line_size = 1,
                         color_palette = "viridis",      # <- colour‑blind safe
                         facet_ncol   = 2,               # <- sensible default
                         theme_custom = ggplot2::theme_minimal(base_size = 15) +
                                        ggplot2::theme(panel.spacing = ggplot2::unit(1, "lines")),
                         legend_threshold = 30, ...){

  with_package(c("shiny", "plotly", "bslib", "thematic"))
  stopifnot(inherits(fmrimod, "fmri_model"))

  # ── prep ------------------------------------------------------------------
  terms_all  <- terms(fmrimod)
  term_names <- vapply(terms_all, `[[`, character(1), "varname")

  if (is.null(term_name)) term_name <- term_names[1]
  if (!(term_name %in% term_names))
      stop("term_name not found in model: ", term_name)

  sframe <- fmrimod$event_model$sampling_frame
  df_time <- sframe$time
  df_block<- sframe$blockids

  longify <- function(term){
    dm   <- tibble::as_tibble(design_matrix(term), .name_repair = "unique")
    dm$.block <- df_block
    dm$.time  <- df_time

    # pretty column names
    cn <- if (longnames) conditions(term) else shortnames(term)
    if (!is.null(cn) && length(cn)==ncol(dm)-2) names(dm)[1:(ncol(dm)-2)] <- cn

    tidyr::pivot_longer(dm, -c(.time,.block),
                        names_to = "condition", values_to = "value")
  }
  df_long <- lapply(terms_all, longify)
  names(df_long) <- term_names

  # ── shiny UI --------------------------------------------------------------
  ui <- shiny::fluidPage(
    theme = bslib::bs_theme(bg = "#fafafa", fg = "#222", primary = "#4c72b0"),
    bslib::card(
      bslib::card_header("🎨  fmrireg design viewer"),
      bslib::layout_sidebar(
        sidebar = list(
          shiny::selectInput("term",   "Term",      term_names, term_name),
          shiny::selectInput("block",  "Block",     c("all", sort(unique(df_block)))),
          shiny::sliderInput("timer",  "Time‑window",
                             min(df_time), max(df_time),
                             value = range(df_time), step = diff(range(df_time))/200),
          shiny::checkboxInput("zero", "Y‑axis starts at zero", TRUE),
          shiny::hr(),
          shiny::helpText("Drag to zoom, double‑click to reset.")
        ),
        shiny::mainPanel(
          plotly::plotlyOutput("plot", height = "650px", inline = TRUE)
        )
      )
    )
  )

  # ── server ----------------------------------------------------------------
  server <- function(input, output, session){

    reactive_df <- shiny::reactive({
      d <- df_long[[input$term]]
      d <- d[d$.time >= input$timer[1] & d$.time <= input$timer[2], ]
      if (input$block != "all") d <- d[d$.block == input$block, ]
      d
    })

    output$plot <- plotly::renderPlotly({
      d <- reactive_df()
      gg <- ggplot2::ggplot(
              d, ggplot2::aes(.time, value,
                              colour = condition,
                              text = paste0("t = ", round(.time,2),
                                            "<br>cond = ", condition,
                                            "<br>val = ", signif(value,3)))
            ) +
            ggplot2::geom_line(size = line_size, ...) +
            ggplot2::facet_wrap(~ .block, ncol = facet_ncol) +
            ggplot2::labs(title   = plot_title %||% paste("Design:", input$term),
                          x = x_label, y = y_label, colour = "Condition") +
            theme_custom +
            { if (tolower(color_palette) == "viridis")
                  ggplot2::scale_colour_viridis_d(option = "C")
              else ggplot2::scale_colour_brewer(palette = color_palette) } +
            { if (input$zero) ggplot2::expand_limits(y = 0) } +
            { if (length(unique(d$condition)) > legend_threshold)
                  ggplot2:: guides(colour = "none") }

      plotly::ggplotly(gg, tooltip = "text") |>
        plotly::layout(hovermode = "closest") |>
        plotly::config(displaylogo = FALSE, modeBarButtonsToRemove = c("lasso2d"))
    })
  }

  shiny::shinyApp(ui, server)
}
</file>

<file path="R/evaluate-helpers.R">
#' @importFrom memoise memoise
#' @keywords internal
#' @noRd
.memo_hrf <- memoise::memoise(function(hrf, span, dt) {
    times <- seq(0, span, by = dt)
    # Evaluate HRF - ensure it returns a matrix
    val <- evaluate(hrf, times)
    if (is.vector(val)) matrix(val, ncol = 1) else val
})

#' Prepare Inputs for Regressor Evaluation Engines
#' 
#' Internal helper function to perform common setup steps before calling 
#' a specific evaluation engine (fft, conv, loop, Rconv).
#' Handles filtering of events, evaluation/memoization of HRF on fine grid.
#' 
#' @param x A `Reg` object.
#' @param grid The target evaluation time grid (numeric vector).
#' @param precision The precision for internal calculations (numeric scalar).
#' @return A list containing prepared inputs:
#'   * `nb`: Number of basis functions.
#'   * `hrf_span`: The span of the HRF.
#'   * `valid_ons`: Filtered onset times relevant to the grid.
#'   * `valid_durs`: Corresponding durations.
#'   * `valid_amp`: Corresponding amplitudes.
#'   * `grid`: The original target grid.
#'   * `precision`: The precision value.
#'   * `hrf_fine_matrix`: HRF values evaluated on the fine time grid (potentially memoized).
#'   * `fine_grid`: The fine time grid itself (if needed by Rconv/loop).
#'   * `summate`: Logical summation flag from the regressor.
#'   * `hrf`: The original HRF object.
#' @keywords internal
#' @noRd
#' @importFrom stats approx median convolve
prep_reg_inputs <- function(x, grid, precision) {
  
  # Ensure grid is sorted (Correctness 1.4)
  if (is.unsorted(grid)) {
      warning("Input grid is unsorted. Sorting grid for evaluation.")
      grid <- sort(grid)
  }
    
  nb <- nbasis(x$hrf) 
  hrf_span <- x$span 
  
  # Filter events based on grid boundaries and HRF span
  onset_min_bound <- grid[1] - hrf_span
  onset_max_bound <- grid[length(grid)]
  
  # Start with potentially already filtered data from Reg constructor
  keep_indices <- which(x$onsets >= onset_min_bound & x$onsets <= onset_max_bound)
  
  # Note: Amplitude filtering already done in Reg(), no need to repeat here
  valid_ons <- x$onsets[keep_indices]
  valid_durs <- x$duration[keep_indices]
  valid_amp <- x$amplitude[keep_indices]

  if (length(valid_ons) == 0) {
    # Return minimal info needed to signal zero output
    return(list(nb = nb, grid = grid, valid_ons = numeric(0)))
  }
  
  # Prepare/Memoize finely sampled HRF (Efficiency 2.1 / Ticket D-1)
  hrf_fine_matrix <- .memo_hrf(x$hrf, hrf_span, precision)
  
  # Prepare fine grid (needed for Rconv/loop interpolation)
  # Use full range of onsets when constructing the fine grid
  # to handle unsorted event inputs without reordering events
  fine_grid_start <- min(grid[1], min(valid_ons)) - hrf_span
  fine_grid_end <- max(grid[length(grid)], max(valid_ons) + max(valid_durs)) + hrf_span
  fine_grid <- seq(fine_grid_start, fine_grid_end, by = precision)

  return(list(
    nb         = nb,
    hrf_span   = hrf_span,
    valid_ons  = valid_ons,
    valid_durs = valid_durs,
    valid_amp  = valid_amp,
    grid       = grid,
    precision  = precision,
    hrf_fine_matrix = hrf_fine_matrix,
    fine_grid  = fine_grid, 
    summate    = x$summate,
    hrf        = x$hrf
  ))
}

# Internal Evaluation Engines -----

#' FFT-based Regressor Evaluation Engine
#' @param p A list returned by prep_reg_inputs.
#' @param ... Additional arguments.
#' @keywords internal
#' @noRd
eval_fft <- function(p, ...) {
  # Call the unified C++ wrapper
  result <- evaluate_regressor_cpp(
              grid = p$grid,
              onsets = p$valid_ons,
              durations = p$valid_durs,
              amplitudes = p$valid_amp,
              hrf_matrix = p$hrf_fine_matrix,
              hrf_span = p$hrf_span,
              precision = p$precision,
              method = "fft"
            )
  result
}

#' Direct Convolution Regressor Evaluation Engine
#' @param p A list returned by prep_reg_inputs.
#' @param ... Additional arguments.
#' @keywords internal
#' @noRd
eval_conv <- function(p, ...) {
  # Call the unified C++ wrapper
  result <- evaluate_regressor_cpp(
              grid = p$grid,
              onsets = p$valid_ons,
              durations = p$valid_durs,
              amplitudes = p$valid_amp,
              hrf_matrix = p$hrf_fine_matrix,
              hrf_span = p$hrf_span,
              precision = p$precision,
              method = "conv"
            )
  result
}

#' R Convolution Regressor Evaluation Engine
#' @param p A list returned by prep_reg_inputs.
#' @param ... Additional arguments.
#' @keywords internal
#' @noRd
#' @importFrom stats convolve approx
eval_Rconv <- function(p, ...) {
  # Check conditions (moved from evaluate.Reg)
  is_regular_grid <- length(p$grid) > 1 && length(unique(round(diff(p$grid), 8))) == 1
  is_constant_duration <- length(unique(p$valid_durs)) <= 1
  
  if (!is_regular_grid || !is_constant_duration) {
    warning("Method 'Rconv' requires a regular grid and constant event durations. Falling back to 'loop' method.")
    return(eval_loop(p, ...)) # Call the loop engine directly as fallback
  }
  
  # Proceed with R convolution using stats::convolve
  delta <- numeric(length(p$fine_grid))
  onset_indices <- round((p$valid_ons - p$fine_grid[1]) / p$precision) + 1
  valid_onset_indices <- onset_indices >= 1 & onset_indices <= length(p$fine_grid)
  delta[onset_indices[valid_onset_indices]] <- p$valid_amp[valid_onset_indices]
  
  samhrf <- p$hrf_fine_matrix # Already evaluated and potentially memoized
  nb <- p$nb
  
  if (nb > 1) {
    lowres <- matrix(0, length(p$grid), nb)
    for (b in 1:nb) {
      highres_conv <- stats::convolve(delta, rev(samhrf[, b]), type = "open")
      valid_len <- length(p$fine_grid)
      highres_trimmed <- highres_conv[1:valid_len]
      interp_res <- approx(p$fine_grid, highres_trimmed, xout = p$grid, rule = 2)$y
      lowres[, b] <- interp_res
    }
    result <- lowres
  } else {
    highres_conv <- stats::convolve(delta, rev(as.vector(samhrf)), type = "open")
    valid_len <- length(p$fine_grid)
    highres_trimmed <- highres_conv[1:valid_len]
    result <- approx(p$fine_grid, highres_trimmed, xout = p$grid, rule = 2)$y
  }
  result
}

#' R Loop Regressor Evaluation Engine
#' @param p A list returned by prep_reg_inputs.
#' @param ... Additional arguments passed to evaluate.HRF.
#' @keywords internal
#' @noRd
eval_loop <- function(p, ...) {
  # Add check for p$hrf
  if (is.null(p$hrf) || !inherits(p$hrf, "HRF")) {
      stop("Error inside eval_loop: p$hrf is NULL or not an HRF object.")
  }
  
  nb <- p$nb
  hrf_span <- p$hrf_span
  grid <- p$grid
  valid_ons <- p$valid_ons
  valid_durs <- p$valid_durs
  valid_amp <- p$valid_amp
  precision <- p$precision
  summate <- p$summate
  
  dspan <- hrf_span / stats::median(diff(grid), na.rm=TRUE) # Approx span in grid units
  
  # Pre-calculate nearest grid indices for onsets (more robust than RANN for this)
  # Find the index of the grid point *just before or at* each onset
  nidx <- stats::findInterval(valid_ons, grid)
  nidx[nidx == 0] <- 1 
  
  outmat <- matrix(0, length(grid), length(valid_ons) * nb)

  for (i in seq_along(valid_ons)) { 
    start_grid_idx <- nidx[i]
    end_grid_idx <- min(start_grid_idx + ceiling(dspan) + 5, length(grid)) 
    if (start_grid_idx > length(grid)) next 
    grid.idx <- start_grid_idx:end_grid_idx
      
    relOns <- grid[grid.idx] - valid_ons[i]
    valid_rel_idx <- which(relOns >= 0 & relOns <= hrf_span)
      
    if (length(valid_rel_idx) > 0) {
        target_indices_outmat <- grid.idx[valid_rel_idx]
        # Call evaluate S3 generic, should dispatch to evaluate.HRF
        resp <- evaluate(p$hrf, relOns[valid_rel_idx], amplitude=valid_amp[i], 
                         duration=valid_durs[i], 
                         precision=precision,
                         summate=summate, ...)
                           
        if (!is.matrix(resp) && nb > 1) {
            resp <- matrix(resp, ncol=nb)
        }
        if (!is.matrix(resp) && nb == 1) {
            resp <- matrix(resp, ncol=1)
        }

        if (nrow(resp) != length(target_indices_outmat)){
            warning("Dimension mismatch between response and target indices in loop.")
            next
        }
                          
        if (nb > 1) {
            start_col <- (i-1) * nb + 1
            end_col <- i*nb 
            outmat[target_indices_outmat, start_col:end_col] <- resp
        } else {
            outmat[target_indices_outmat, i] <- resp
        }
    }
  }
  
  # Sum contributions across onsets
  if (length(valid_ons) > 1) {
    if (nb == 1) {
      result <- matrix(rowSums(outmat), ncol=1)
    } else {
      result <- do.call(cbind, lapply(1:nb, function(basis_idx) {
        rowSums(outmat[, seq(basis_idx, by=nb, length.out=length(valid_ons)), drop = FALSE])
      }))
    }
  } else { 
    if (nb == 1) {
        result <- matrix(outmat[,1], ncol=1) 
    } else {
        result <- outmat[, 1:nb, drop=FALSE] # Use drop=FALSE
    }
  }
  result
}
</file>

<file path="R/fmrireg.R">
#' fmrireg: regression tools for fMRI data
#'
#' fmrireg provides functions for generating experimental design matrices appropriate for analyzing fMRI data with regression.
#' 
#' 
#' @keywords internal
"_PACKAGE"

#' @useDynLib fmrireg
#' @importFrom Rcpp evalCpp
#' @import assertthat
#' @import stats
NULL


#if(getRversion() >= "2.15.1")  utils::globalVariables(c("."))
</file>

<file path="R/hrf_decorators.R">
#' Lag an HRF Object
#'
#' Creates a new HRF object by applying a temporal lag to an existing HRF object.
#'
#' @param hrf The HRF object (of class `HRF`) to lag.
#' @param lag The time lag in seconds to apply. Positive values shift the response later in time.
#'
#' @return A new HRF object representing the lagged function.
#'
#' @family HRF_decorator_functions
#' @export
#' @examples
#' lagged_spmg1 <- lag_hrf(HRF_SPMG1, 5)
#' # Evaluate at time 10; equivalent to HRF_SPMG1(10 - 5)
#' lagged_spmg1(10)
#' HRF_SPMG1(5)
lag_hrf <- function(hrf, lag) {
  assertthat::assert_that(inherits(hrf, "HRF"), msg = "Input 'hrf' must be an HRF object.")
  assertthat::assert_that(is.numeric(lag) && length(lag) == 1, msg = "'lag' must be a single numeric value.")

  # Original attributes
  orig_name <- attr(hrf, "name")
  orig_span <- attr(hrf, "span")
  orig_nbasis <- nbasis(hrf)
  orig_params <- attr(hrf, "params")

  # Create the lagged function
  lagged_func <- function(t) {
    hrf(t - lag)
  }

  # Create new HRF object using as_hrf
  as_hrf(
    f = lagged_func,
    name = paste0(orig_name, "_lag(", lag, ")"),
    nbasis = orig_nbasis,
    span = orig_span + max(0, lag), # Increase span if lag is positive
    params = c(orig_params, list(.lag = lag)) # Add lag to params for bookkeeping
  )
}


#' Create a Blocked HRF Object
#'
#' Creates a new HRF object representing a response to a sustained (blocked)
#' stimulus by convolving the input HRF with a boxcar function of a given width.
#'
#' @param hrf The HRF object (of class `HRF`) to block.
#' @param width The width of the block in seconds.
#' @param precision The sampling precision in seconds used for the internal convolution (default: 0.1).
#' @param half_life The half-life of an optional exponential decay applied during the block (default: Inf, meaning no decay).
#' @param summate Logical; if TRUE (default), the responses from each time point within the block are summed. If FALSE, the maximum response at each time point is taken.
#' @param normalize Logical; if TRUE, the resulting blocked HRF is scaled so that its peak value is 1 (default: FALSE).
#'
#' @return A new HRF object representing the blocked function.
#'
#' @family HRF_decorator_functions
#' @export
#' @examples
#' blocked_spmg1 <- block_hrf(HRF_SPMG1, width = 5)
#' t_vals <- seq(0, 30, by = 0.5)
#' plot(t_vals, HRF_SPMG1(t_vals), type = 'l', col = "blue", ylab = "Response", xlab = "Time")
#' lines(t_vals, blocked_spmg1(t_vals), col = "red")
#' legend("topright", legend = c("Original", "Blocked (width=5)"), col = c("blue", "red"), lty = 1)
block_hrf <- function(hrf, width, precision = 0.1, half_life = Inf, summate = TRUE, normalize = FALSE) {
  assertthat::assert_that(inherits(hrf, "HRF"), msg = "Input 'hrf' must be an HRF object.")
  assertthat::assert_that(is.numeric(width) && length(width) == 1 && width >= 0, msg = "'width' must be a single non-negative numeric value.")
  assertthat::assert_that(is.numeric(precision) && length(precision) == 1 && precision > 0, msg = "'precision' must be a single positive numeric value.")
  assertthat::assert_that(is.numeric(half_life) && length(half_life) == 1 && half_life > 0, msg = "'half_life' must be a single positive numeric value (use Inf for no decay).")
  assertthat::assert_that(is.logical(summate) && length(summate) == 1, msg = "'summate' must be a single logical value.")
  assertthat::assert_that(is.logical(normalize) && length(normalize) == 1, msg = "'normalize' must be a single logical value.")

  # Original attributes
  orig_name <- attr(hrf, "name")
  orig_span <- attr(hrf, "span")
  orig_nbasis <- nbasis(hrf)
  orig_params <- attr(hrf, "params")

  # Create the blocked function
  blocked_func <- function(t) {
    if (width < precision) {
      # If width is negligible, just return the original hrf value
      res <- hrf(t)
    } else {
      samples <- seq(0, width, by = precision)
      hmat_list <- lapply(samples, function(offset) {
        decay_factor <- if (is.infinite(half_life)) 1 else exp(-log(2) * offset / half_life)
        hrf(t - offset) * decay_factor
      })
      
      # Combine results for each time point t across offsets
      if (orig_nbasis == 1) {
        hmat <- do.call(cbind, hmat_list) # Matrix with rows=time, cols=offsets
        res <- if (summate) {
          rowSums(hmat)
        } else {
          apply(hmat, 1, function(vals) vals[which.max(vals)])
        }
      } else {
         # For multi-basis, sum matrices if summate=TRUE (difficult to define max sensibly)
         if (!summate) {
           warning("'summate = FALSE' is not fully supported for multi-basis HRFs in block_hrf; returning sum.")
         }
         res <- Reduce("+", hmat_list)
      }
    }
    
    # Apply normalization if requested
    if (normalize) {
      if (orig_nbasis == 1) {
        peak_val <- max(abs(res), na.rm = TRUE)
        if (!is.na(peak_val) && peak_val != 0) {
          res <- res / peak_val
        }
      } else {
        # Normalize each basis column independently
        res <- apply(res, 2, function(basis_col) {
           peak_val <- max(abs(basis_col), na.rm = TRUE)
           if (!is.na(peak_val) && peak_val != 0) {
             basis_col / peak_val
           } else {
             basis_col
           }
        })
      }
    }
    return(res)
  }

  # Store parameters used for blocking
  block_params <- list(
      .width = width,
      .precision = precision,
      .half_life = half_life,
      .summate = summate,
      .normalize = normalize
  )
  
  # Create new HRF object using as_hrf
  as_hrf(
    f = blocked_func,
    name = paste0(orig_name, "_block(w=", width, ")"),
    nbasis = orig_nbasis,
    span = orig_span + width, # Span increases by the block width
    params = c(orig_params, block_params) # Add block params for bookkeeping
  )
}


#' Normalise an HRF Object
#'
#' Creates a new HRF object whose output is scaled such that the maximum absolute
#' value of the response is 1.
#'
#' @param hrf The HRF object (of class `HRF`) to normalise.
#'
#' @return A new HRF object representing the normalised function.
#' @details For multi-basis HRFs, each basis function (column) is normalised independently.
#'
#' @family HRF_decorator_functions
#' @export
#' @examples
#' # Create a gaussian HRF with a peak value != 1
#' gauss_unnorm <- as_hrf(function(t) 5 * dnorm(t, 6, 2), name="unnorm_gauss")
#' # Normalise it
#' gauss_norm <- normalise_hrf(gauss_unnorm)
#' t_vals <- seq(0, 20, by = 0.1)
#' max(gauss_unnorm(t_vals)) # Peak is > 1
#' max(gauss_norm(t_vals))   # Peak is 1
normalise_hrf <- function(hrf) {
  assertthat::assert_that(inherits(hrf, "HRF"), msg = "Input 'hrf' must be an HRF object.")

  # Original attributes
  orig_name <- attr(hrf, "name")
  orig_span <- attr(hrf, "span")
  orig_nbasis <- nbasis(hrf)
  orig_params <- attr(hrf, "params")

  # Create the normalised function
  normalised_func <- function(t) {
    res <- hrf(t)
    if (orig_nbasis == 1) {
      peak_val <- max(abs(res), na.rm = TRUE)
      if (!is.na(peak_val) && peak_val != 0) {
        res <- res / peak_val
      }
    } else if (is.matrix(res)) {
      # Normalise each basis column independently
      res <- apply(res, 2, function(basis_col) {
        peak_val <- max(abs(basis_col), na.rm = TRUE)
        if (!is.na(peak_val) && peak_val != 0) {
          basis_col / peak_val
        } else {
          basis_col
        }
      })
    }
    # If it's not numeric or matrix (e.g., NULL or error result), return as is
    return(res)
  }

  # Create new HRF object using as_hrf
  as_hrf(
    f = normalised_func,
    name = paste0(orig_name, "_norm"),
    nbasis = orig_nbasis,
    span = orig_span,
    params = c(orig_params, list(.normalised = TRUE)) # Add flag for bookkeeping
  )
}
</file>

<file path="R/hrf_smoothing_kernel.R">
#' Compute an HRF smoothing kernel
#'
#' This function computes a temporal similarity matrix from a series of hemodynamic response functions.
#'
#' @param len The number of scans.
#' @param TR The repetition time (default is 2 seconds).
#' @param form the `trialwise` formula expression, see examples.
#' @param buffer_scans The number of scans to buffer before and after the event.
#' @param normalise Whether to normalise the kernel.
#' @param method The method to use for computing the kernel.
#' @export
#' @examples
#' form <- onsets ~ trialwise(basis="gaussian")
#' sk <- hrf_smoothing_kernel(100, TR=1.5, form)
#' @return a smoothing matrix
hrf_smoothing_kernel <- function(len, TR = 2,
                                 form  = onset ~ trialwise(),
                                 buffer_scans = 3L,
                                 normalise = TRUE,
                                 method = c("gram", "cosine")) {

  method <- match.arg(method)
  n_buf  <- as.integer(buffer_scans)

  sf   <- sampling_frame(len + 2 * n_buf, TR)
  dfx  <- data.frame(onset = samples(sf), block = 1L)
  em   <- event_model(form, data = dfx, block = ~ block, sampling_frame = sf)
  X    <- as.matrix(design_matrix(em))

  K <- switch(method,
              gram   = X %*% t(X),
              cosine = tcrossprod(scale(X, FALSE, sqrt(colSums(X^2)))))

  if (normalise)
    K <- K / diag(K)                                       # make diag = 1

  keep <- (n_buf + 1):(n_buf + len)
  K[keep, keep, drop = FALSE]
}

#' Design kernel for a given design matrix
#'
#' This internal function calculates a design kernel for the given design matrix (`dmat`). It can also compute the derivative of the design kernel if the `deriv` parameter is set to TRUE.
#' @noRd
#' @param dmat A design matrix.
#' @param deriv A logical value indicating whether to compute the derivative (default is FALSE).
#' @keywords internal
#' @examples
#' onsets <- sort(runif(25, 0, 200))
#' fac <- factor(sample(letters[1:4], length(onsets), replace=TRUE))
#' sframe <- sampling_frame(200, TR=1)
#' des <- data.frame(onsets=onsets, fac=fac, constant = factor(rep(1, length(fac))), block=rep(1, length(fac)))
#' emod <- event_model(onsets ~ hrf(constant) + hrf(fac), data=des, sampling_frame=sframe, block = ~ block)
#' dmat <- design_matrix(emod)
design_kernel <- function(dmat, deriv=FALSE) {
  dd <- rbind(rep(0, ncol(dmat)), apply(dmat, 2, diff))
}
</file>

<file path="R/lss.R">
#' @keywords internal
#' @noRd
lss_fast <- function(dset, bdes, Y=NULL, use_cpp = TRUE) {
  # Data preparation

  if (is.null(Y)) {
    data_matrix <- get_data_matrix(dset)
  } else {
    data_matrix <- Y
  }

  # Check and validate Y dimensions
  if (!is.null(Y)) {
    expected_rows <- nrow(bdes$dmat_ran) # Use design matrix rows as reference
    if (nrow(Y) != expected_rows) {
      stop(sprintf("Y must have %d rows to match design matrix dimensions, but has %d rows", 
                  expected_rows, nrow(Y)))
    }
  }

  n_timepoints <- nrow(data_matrix)
  n_voxels <- ncol(data_matrix)
  
  # Design matrices
  dmat_base <- as.matrix(bdes$dmat_base)
  dmat_fixed <- if (!is.null(bdes$fixed_ind)) as.matrix(bdes$dmat_fixed) else NULL
  dmat_ran <- as.matrix(bdes$dmat_ran)
  
  # Prepare baseline and fixed design matrix
  if (!is.null(dmat_fixed)) {
    X_base_fixed <- cbind(dmat_base, dmat_fixed)
  } else {
    X_base_fixed <- dmat_base
  }
  
  if (use_cpp) {
    ##print("using cpp")
    res <- compute_residuals_cpp(X_base_fixed, data_matrix, dmat_ran)
    beta_matrix <- lss_compute_cpp(res$Q_dmat_ran, res$residual_data)
  } else {
    ##print("using r")
    # Pure R implementation
    P_base_fixed <- MASS::ginv(X_base_fixed)
    Q_base_fixed <- diag(n_timepoints) - X_base_fixed %*% P_base_fixed
    residual_data <- Q_base_fixed %*% data_matrix
    Q_dmat_ran <- Q_base_fixed %*% dmat_ran
    beta_matrix <- lss_compute_r(Q_dmat_ran, residual_data)
  }
  
  return(beta_matrix)
}

#' @keywords internal
#' @noRd
lss_compute_r <- function(Q_dmat_ran, residual_data) {
  n_timepoints <- nrow(Q_dmat_ran)
  n_events <- ncol(Q_dmat_ran)
  n_voxels <- ncol(residual_data)
  
  # Initialize beta matrix
  beta_matrix <- matrix(NA, nrow = n_events, ncol = n_voxels)
  
  # Loop over trials
  for (i in seq_len(n_events)) {
    # Current trial regressor
    c <- Q_dmat_ran[, i, drop = FALSE]
    
    # Skip if current regressor has very low variance
    c_norm <- drop(crossprod(c))
    if (c_norm < 1e-10) {
      beta_matrix[i, ] <- 0
      next
    }
    
    # If there's only one event, we can just do a simple regression
    if (n_events == 1) {
      s <- c / c_norm
      beta_matrix[i, ] <- drop(crossprod(s, residual_data))
      next
    }
    
    # Sum of other trial regressors
    b <- Q_dmat_ran[, -i, drop = FALSE]
    
    # If all other regressors are very close to zero, just use this regressor
    if (ncol(b) == 0 || all(colSums(b^2) < 1e-10)) {
      s <- c / c_norm
      beta_matrix[i, ] <- drop(crossprod(s, residual_data))
      next
    }
    
    # Sum the columns of b
    b_sum <- rowSums(b)
    b <- matrix(b_sum, ncol=1)
    
    # Check if b is essentially zero
    b_norm <- drop(crossprod(b))
    if (b_norm < 1e-10) {
      # If other regressors sum to approximately zero, use this regressor directly
      s <- c / c_norm
      beta_matrix[i, ] <- drop(crossprod(s, residual_data))
      next
    }
    
    # Compute v = c - b(b'b)^(-1)b'c
    bc <- drop(crossprod(b, c))
    v <- c - (bc/b_norm) * b
    
    # Compute cvdot = c'v
    cvdot <- drop(crossprod(c, v))
    
    # Handle numerical stability - only set to zero if truly negligible
    # compared to both c_norm and v_norm
    v_norm <- drop(crossprod(v))
    if (abs(cvdot) < 1e-8 * sqrt(c_norm * v_norm)) {
      # Try direct regression as fallback
      s <- c / c_norm
    } else {
      s <- v / cvdot
    }
    
    # Compute beta for current trial
    beta_matrix[i, ] <- drop(crossprod(s, residual_data))
  }
  
  return(beta_matrix)
}
</file>

<file path="R/metafuns.R">
#' Meta-analysis using Stouffer's method
#'
#' This function performs a meta-analysis on input p-values and standard errors using Stouffer's method.
#' Stouffer's method combines z-scores by weighting them by their inverse variance.
#' 
#' @param pval A numeric vector of p-values from multiple studies or tests.
#' @param se A numeric vector of standard errors corresponding to the p-values.
#' 
#' @return A list containing the following elements:
#' \itemize{
#'   \item{estimate}{A numeric vector of the weighted z-scores obtained using Stouffer's method.}
#'   \item{se}{A numeric vector of the combined standard errors.}
#'   \item{stat}{Same as the estimate, the weighted z-scores.}
#'   \item{prob}{A numeric vector of the combined p-values.}
#'   \item{stat_type}{A character string indicating the type of statistic used, in this case "zfstat".}
#' }
#' 
#' @keywords internal
#' @noRd
meta_stouffer <- function(pval, se) {
  if (any(pval == 0)) {
    pval[pval == 0] <- .Machine$double.eps
  }
  inv_var <- 1/(se^2)
  wts <- inv_var/rowSums(inv_var)
  zscore <- qnorm(1-pval)
  wzscore <- zscore * wts
  wzscore <- rowSums(wzscore)
  
  return(
    list(
      estimate=wzscore,
      se=sqrt(rowSums(wts*wts*(se^2))),
      stat=wzscore,
      prob=1-pnorm(wzscore),
      stat_type="zfstat"
    )
  )
}


#' Fixed-effects meta-analysis
#'
#' This function performs a fixed-effects meta-analysis on input beta estimates and standard errors.
#' It supports two types of weighting schemes: inverse-variance weighting and equal weighting.
#' 
#' @param beta A numeric matrix of beta estimates from multiple studies or tests.
#' @param se A numeric matrix of standard errors corresponding to the beta estimates.
#' @param weighting A character string specifying the weighting scheme to use. 
#'   Options are "inv_var" (default) for inverse-variance weighting and "equal" for equal weighting.
#' 
#' @return A list containing the following elements:
#' \itemize{
#'   \item{estimate}{A numeric vector of the combined beta estimates.}
#'   \item{se}{A numeric vector of the pooled standard errors.}
#'   \item{stat}{A numeric vector of the combined z-scores.}
#'   \item{prob}{A numeric vector of the combined p-values.}
#'   \item{stat_type}{A character string indicating the type of statistic used, in this case "zstat".}
#' }
#' 
#' @keywords internal
#' @examples
#' beta <- matrix(c(0.5, 1, 0.75), nrow=1)
#' se <- matrix(c(0.2, 0.15, 0.25), nrow=1)
#' result <- meta_fixef(beta, se, weighting = "inv_var")
#' print(result)
#' @autoglobal
#' @noRd
meta_fixef <- function(ctab, weighting=c("inv_var", "equal")) {
  weighting <- match.arg(weighting)
  
  # Extract the list-column, then unlist each element before cbind
  se_list <- ctab$data %>% purrr::map(~ .$se)
  beta_list <- ctab$data %>% purrr::map(~ .$estimate)
  
  # Check if the first element is a list (indicative of fast path output)
  # If so, unlist each element. Assume consistency across the list.
  if (length(se_list) > 0 && is.list(se_list[[1]])) {
    se_list <- lapply(se_list, function(x) x[[1]])
  }
  if (length(beta_list) > 0 && is.list(beta_list[[1]])) {
    beta_list <- lapply(beta_list, function(x) x[[1]])
  }
  
  # Now se_list and beta_list should contain numeric vectors/matrices
  se <- do.call(cbind, se_list)
  beta <- do.call(cbind, beta_list)
  
  # Handle cases where cbind might produce a vector if only one contrast/run
  if (is.vector(se)) se <- matrix(se, ncol = 1)
  if (is.vector(beta)) beta <- matrix(beta, ncol = 1)
  
  # Ensure dimensions match if possible (can be tricky if runs have different numbers of voxels)
  # This assumes all runs/contrasts being pooled have the same number of rows (voxels/observations)
  if (nrow(se) != nrow(beta)) {
      stop("Mismatch in number of observations between estimates and standard errors in meta_fixef.")
  }

  ret <- do_fixef(se, beta, weighting)
  
  # Package results
  dplyr::tibble(type=ctab$type[1], name=ctab$name[1], stat_type="meta_zstat", 
                conmat=list(ctab$conmat[[1]]),
         colind=list(ctab$colind[[1]]), data=list(ret)) # ret from do_fixef is already a tibble
  
}


#' @keywords internal
#' @noRd
#' @autoglobal
do_fixef <- function(se, beta, weighting) {
  if (weighting == "inv_var") {
    inv_var <- 1/(se^2)
    wts <- inv_var/rowSums(inv_var)
    wbeta <- beta * wts
    wbeta <- rowSums(wbeta)
    pooledse <- sqrt(rowSums(wts*wts*(se^2)))
  } else {
    wbeta <- rowSums(beta)
    pooledse <- sqrt(rowSums((se^2)))
  }
  
  tibble(estimate=wbeta,
         se=pooledse,
         stat=wbeta/pooledse,
         prob=1-pchisq((wbeta/pooledse)^2,1),
         stat_type="zstat")
}
  
  



#' Meta-analysis of F-contrasts
#'
#' This function performs a meta-analysis on a list of F-contrasts results obtained from different studies or tests.
#'
#' @param fres A list of F-contrast results, where each element of the list contains the results for a particular study or test.
#'
#' @return A list containing meta-analysis results for each contrast. Each element of the list includes:
#' \itemize{
#'   \item{estimate}{A numeric vector of the combined z-scores.}
#'   \item{se}{A numeric vector of the pooled standard errors.}
#'   \item{stat}{A numeric vector of the combined z-scores.}
#'   \item{prob}{A numeric vector of the combined p-values.}
#'   \item{stat_type}{A character string indicating the type of statistic used, in this case "zfstat".}
#' }
#' 
#' @keywords internal
#' @noRd
meta_Fcontrasts <- function(ftab) {
  pval <- do.call(cbind, ftab$data %>% purrr::map(~ .$prob))
  se <- do.call(cbind, ftab$data %>% purrr::map(~ .$se))
  
  ret <- meta_stouffer(pval,se)
  dplyr::tibble(type=ftab$type[1], name=ftab$name[1], stat_type="meta_zfstat", 
         conmat=list(ftab$conmat[[1]]),
         colind=list(ftab$colind[[1]]), data=list(tibble::as_tibble(ret)))
}


#' Meta-analysis of contrasts
#'
#' This function performs a meta-analysis on a list of contrast results obtained from different studies or tests.
#'
#' @param cres A list of contrast results, where each element of the list contains the results for a particular study or test.
#' @param weighting A character string specifying the weighting method to use for the meta-analysis. Options are "inv_var" (inverse variance weighting) or "equal" (equal weighting). Default is "inv_var".
#'
#' @return A list containing meta-analysis results for each contrast, including:
#' \itemize{
#'   \item{estimate}{A matrix of the combined contrast estimates.}
#'   \item{se}{A matrix of the pooled standard errors.}
#'   \item{stat}{A matrix of the combined z-scores.}
#'   \item{prob}{A matrix of the combined p-values.}
#'   \item{stat_type}{A character string indicating the type of statistic used, in this case "zstat".}
#' }
#' 
#' @keywords internal
#' @noRd
#' @global name
meta_contrasts <- function(cres, weighting=c("inv_var", "equal")) {
 
  weighting <- match.arg(weighting)
  ctab <- unlist(cres, recursive=FALSE) %>% dplyr::bind_rows()
  if (nrow(ctab) == 0) {
    return(dplyr::tibble(type="contrast", name="meta_contrast", stat_type="meta_zstat", conmat=list(NULL),
         colind=list(NULL), data=list(tibble(estimate=list(NULL), se=list(NULL), stat=list(NULL), prob=list(NULL)))))
  }

  gsplit <- ctab %>% group_by(name,type) %>% dplyr::group_split()
  
  lapply(gsplit, function(tab) {
    type <- tab$type[1]
    if (type == "Fcontrast") {
      meta_Fcontrasts(tab)
    } else if (type == "contrast") {
      meta_fixef(tab)
    }
  }) %>% dplyr::bind_rows()
  
}


#' @keywords internal
#' @noRd
#' @importFrom dplyr tibble
meta_betas <- function(bstats, colind, weighting=c("inv_var", "equal")) {
  weighting <- match.arg(weighting)

  len <- length(colind)
  
  # Check the dimensions of the first beta matrix to understand the structure
  first_beta <- bstats[[1]]$data[[1]]$estimate[[1]]
  max_col <- ncol(first_beta)
  
  # Filter colind to only include valid column indices
  valid_colind <- colind[colind <= max_col]
  
  if (length(valid_colind) == 0) {
    warning("No valid column indices found in meta_betas. Using all available columns.")
    valid_colind <- 1:max_col
  }
  
  res <- lapply(valid_colind, function(i) {
    beta <- do.call(cbind, lapply(bstats, function(x) x$data[[1]]$estimate[[1]][,i]))
    se <- do.call(cbind, lapply(bstats, function(x) x$data[[1]]$se[[1]][,i]))
    do_fixef(se,beta, weighting)
  })
  
  estimate = do.call(cbind, lapply(res, function(x) x$estimate))
  se=do.call(cbind, lapply(res, function(x) x$se))
  stat=do.call(cbind, lapply(res, function(x) x$stat))
  prob=do.call(cbind, lapply(res, function(x) x$prob))
  stat_type="zstat"
  
  ret <- dplyr::tibble(type="beta", name="parameter_estimates", stat_type="meta_zstat", conmat=list(NULL),
         colind=list(valid_colind), data=list(tibble(
           estimate=list(estimate),
           se=list(se),
           stat=list(stat),
           prob=list(prob))))
  
}
</file>

<file path="R/mixed_solve.R">
#' Mixed Model Solver using Rcpp and roptim
#'
#' This function solves a mixed model using Rcpp and roptim for optimization.
#' It estimates variance components in a mixed model, potentially speeding up computations compared to the pure R implementation.
#'
#' @param y Response vector.
#' @param Z Design matrix for random effects (default: identity matrix of size n).
#' @param K Kinship matrix (default: NULL).
#' @param X Design matrix for fixed effects (default: vector of ones).
#' @param method Optimization method, either "REML" or "ML" (default: "REML").
#' @param bounds Bounds for the optimizer (default: c(1e-9, 1e9)).
#' @param SE Logical, whether to return standard errors (default: FALSE).
#' @param return_Hinv Logical, whether to return the inverse of H (default: FALSE).
#' @return A list containing:
#'   \item{Vu}{Estimated variance component for random effects.}
#'   \item{Ve}{Estimated variance component for residuals.}
#'   \item{beta}{Estimated fixed effects coefficients.}
#'   \item{u}{Estimated random effects coefficients.}
#'   \item{LL}{Log-likelihood of the model.}
#'   \item{beta.SE}{Standard errors of fixed effects coefficients (if SE = TRUE).}
#'   \item{u.SE}{Standard errors of random effects coefficients (if SE = TRUE).}
#'   \item{Hinv}{Inverse of H (if return_Hinv = TRUE).}
#' @examples
#' \dontrun{
#' # Example usage with random data
#' set.seed(123)
#' n <- 100
#' y <- rnorm(n)
#' Z <- matrix(rnorm(n * 5), n, 5)
#' K <- diag(5)
#' X <- matrix(1, n, 1)
#' result <- mixed_solve_cpp(y, Z, K, X)
#' }
#' @export
mixed_solve_cpp <- function(y,
                            Z = NULL,
                            K = NULL,
                            X = NULL,
                            method = "REML",
                            bounds = c(1e-9, 1e9),
                            SE = FALSE,
                            return_Hinv = FALSE) {

  result <- mixed_solve_internal(y, Z, K, X, method, bounds, SE, return_Hinv)
  return(result)
}
</file>

<file path="R/naming-utils.R">
# Naming Utilities for fmrireg Design Matrix Column Names

# Internal helper for zero-padding numbers
#' @keywords internal
#' @noRd
zeropad <- function(i, n_total) {
  # Handle edge case n_total = 0 or 1 gracefully
  #width <- if (n_total <= 1) 1 else ceiling(log10(n_total + 1e-9)) # OLD width calc
  # Calculate width needed based on magnitude of the largest number (n_total)
  log_width <- if (n_total < 1) 1L else ceiling(log10(n_total + 1e-9))
  # Ensure minimum width is 2 if there's more than one item, otherwise use calculated width
  final_width <- if (n_total > 1) max(2L, as.integer(log_width)) else as.integer(log_width) 
  sprintf(paste0("%0", final_width, "d"), i)
}

#' Sanitize Strings for Use in R Names
#'
#' Wraps `make.names` but allows control over dot replacement.
#'
#' @param x A character vector.
#' @param allow_dot Logical, if `FALSE`, dots (`.`) are replaced with underscores (`_`).
#' @return A sanitized character vector.
#' @export
#' @examples
#' sanitize("a.b c")
#' sanitize("a.b c", allow_dot = FALSE)
sanitize <- function(x, allow_dot = TRUE) {
  # Initial sanitization using make.names (handles invalid starting chars, spaces, etc.)
  sanitized <- make.names(x, unique = FALSE)

  if (!allow_dot) {
    # Replace dots introduced by make.names (or pre-existing) with underscores.
    # CRITICAL FIX: Replace sequences of one or more dots/underscores with a single underscore.
    # This prevents ".." becoming "__".
    # First, replace all dots with underscores to normalize separators
    sanitized <- gsub(".", "_", sanitized, fixed = TRUE)
    # Then, replace multiple consecutive underscores with a single one
    sanitized <- gsub("_+", "_", sanitized)
    # Optional: remove leading/trailing underscores that might result
    sanitized <- gsub("^_|_$", "", sanitized)
  }
  sanitized
}

#' Create Basis Function Suffix
#'
#' Generates the `_b##` suffix for HRF basis functions.
#'
#' @param j Integer vector of basis indices (1-based).
#' @param nb Total number of basis functions.
#' @return Character vector of suffixes (e.g., `_b01`, `_b02`).
#' @export
#' @examples
#' basis_suffix(1:3, 5)
#' basis_suffix(1:10, 10)
basis_suffix <- function(j, nb) {
  paste0("_b", zeropad(j, nb))
}

#' Make Tags Unique with Hash Separator
#'
#' Wraps `make.unique` using `#` as the separator.
#'
#' @param tags Character vector of tags.
#' @return Character vector with unique tags (e.g., `tag`, `tag#1`).
#' @keywords internal
#' @noRd
make_unique_tags <- function(tags) {
  make.unique(tags, sep = "#")
}

#' Generate Term Tag
#'
#' Creates a sanitized, unique tag for an event term based on its spec.
#'
#' @param hrfspec The HRF specification list for the term.
#' @param existing_tags Character vector of already assigned term tags.
#' @return A single, unique, sanitized term tag.
#' @importFrom rlang as_label
#' @keywords internal
#' @noRd
make_term_tag <- function(hrfspec, existing_tags = character()) {
  known_generative_bases <- c("Poly", "BSpline") # Add other known bases here, e.g. "Legendre"

  if (!is.null(hrfspec$id)) {
    tag_base <- sanitize(hrfspec$id, allow_dot = FALSE)
  } else if (!is.null(hrfspec$prefix)) {
    # If no explicit id but prefix is provided, use prefix as the term tag
    tag_base <- sanitize(hrfspec$prefix, allow_dot = FALSE)
  } else {
    is_ident_only <- FALSE
    is_known_generative_basis <- FALSE
    parsed_generative_tag_base <- NULL

    if (length(hrfspec$vars) == 1) {
       expr <- rlang::quo_get_expr(hrfspec$vars[[1]])
       target_expr <- if (rlang::is_formula(expr, lhs = FALSE)) rlang::f_rhs(expr) else expr

       if (rlang::is_call(target_expr)) {
          call_nm <- rlang::call_name(target_expr)
          if (!is.null(call_nm)) {
            if (call_nm == "Ident") {
              is_ident_only <- TRUE
            } else if (call_nm %in% known_generative_bases) {
              is_known_generative_basis <- TRUE
              # Attempt to parse: BasisFunction(VarName, ...)
              if (length(rlang::call_args(target_expr)) >= 1) {
                var_expr <- rlang::call_args(target_expr)[[1]]
                var_name_label <- rlang::as_label(var_expr)
                # Sanitize parts separately before combining for clarity
                sanitized_call_nm <- sanitize(call_nm, allow_dot = FALSE)
                sanitized_var_name <- sanitize(var_name_label, allow_dot = FALSE)
                parsed_generative_tag_base <- paste(sanitized_call_nm, sanitized_var_name, sep = "_")
              } else {
                # Fallback if parsing fails, should be rare for Poly(Var,Deg) structure
                is_known_generative_basis <- FALSE # Treat as generic
              }
            }
          }
       }
    }
    
    if (is_ident_only) {
       return(NULL) 
    } else if (is_known_generative_basis && !is.null(parsed_generative_tag_base)) {
        tag_base <- parsed_generative_tag_base
    } else {
       # Default: build tag from variable names/labels in original quosures
       tag_base <- paste(vapply(hrfspec$vars, rlang::as_label, character(1)), collapse = "_")
       tag_base <- sanitize(tag_base, allow_dot = FALSE)
    }
  }
  
  if (tag_base == "") {
      tag_base <- "empty_id_tag" 
  }

  tag <- tag_base 

  all_tags <- c(existing_tags, tag)
  unique_tags <- make_unique_tags(all_tags)
  final_tag <- unique_tags[length(all_tags)]
  return(final_tag)
}

#' Create Factor Level Token
#'
#' Generates the `Var.Level` token.
#'
#' @param var Variable name (character).
#' @param lev Level name (character).
#' @return Sanitized token (e.g., `cond.A`).
#' @keywords internal
#' @noRd
level_token <- function(var, lev) {
  # Sanitize both parts, allowing dots
  s_var <- sanitize(var, allow_dot = TRUE)
  s_lev <- sanitize(lev, allow_dot = TRUE)
  paste0(s_var, ".", s_lev)
}

#' Sanitize Continuous Column Name Token
#'
#' Ensures a pre-formatted continuous column name (like `poly_RT_01`) is a valid R name.
#'
#' @param colname The proposed column name string.
#' @return Sanitized token.
#' @keywords internal
#' @noRd
continuous_token <- function(colname) {
  sanitize(colname, allow_dot = TRUE)
}

#' Combine Tokens into Condition Tag
#'
#' Pastes tokens together with underscores for interaction terms.
#'
#' @param tokens Character vector of tokens (factor levels or continuous names).
#' @return Single string representing the combined condition tag.
#' @keywords internal
#' @noRd
make_cond_tag <- function(tokens) {
  paste(tokens, collapse = "_")
}

#' Add Basis Suffix to Condition Tags
#'
#' Optionally expands condition tags with basis suffixes.
#'
#' @param cond_tags Character vector of condition tags.
#' @param nb Number of basis functions.
#' @return Character vector, expanded with suffixes if `nb > 1`.
#' @keywords internal
#' @noRd
add_basis <- function(cond_tags, nb) {
  if (nb <= 1L) {
    return(cond_tags)
  }
  suffixes <- basis_suffix(seq_len(nb), nb)
  as.vector(outer(cond_tags, suffixes, paste0))
}

#' Compose Final Column Names
#'
#' The single source of truth for creating final design matrix column names.
#'
#' @param term_tag The sanitized, unique term tag.
#' @param cond_tags Character vector of base condition tags (without basis suffix).
#' @param nb Number of basis functions.
#' @return Character vector of final column names `term_tag_condition_tag[_b##]`.
#' @keywords internal
#' @noRd
make_column_names <- function(term_tag, cond_tags, nb) {
  # Internal consistency check: term_tag should not contain double underscores
  # Allow NULL term_tag for Ident()-only direct variables
  if (!is.null(term_tag)) {
    stopifnot(!grepl("__", term_tag))
  }
  
  # Add basis suffix if needed
  full_cond_tags <- add_basis(cond_tags, nb)
  
  # Combine term tag and condition tag, or just use condition tags if term_tag is NULL
  if (is.null(term_tag)) {
    # This is the case for Ident()-only terms where variables become direct column names
    return(full_cond_tags)
  } else {
    # Default case: term_tag_condition_tag[_b##]
    return(paste0(term_tag, "_", full_cond_tags))
  }
}

# Null-coalescing operator (from rlang)
# Avoids direct dependency if only used here, but rlang is needed for as_label anyway
`%||%` <- function(x, y) {
  if (is.null(x)) y else x
}
</file>

<file path="R/regressor.R">
# Constructor functions and deprecated wrappers
# Source: R/reg-constructor.R

# [Content of R/reg-constructor.R moved here]

# Internal utility functions
# Source: R/utils-internal.R

# [Content of R/utils-internal.R moved here]

# Evaluation logic: S3 method and helper functions
# Source: R/reg-evaluate.R & R/evaluate-helpers.R

# [Content of R/evaluate-helpers.R moved here]
# [Content of R/reg-methods.R's evaluate.Reg moved here]

# Other S3 Methods (Print, Shift)
# Source: R/reg-methods.R

# [Content of R/reg-methods.R's print.Reg, print.regressor, shift.Reg moved here]

# Plotting Methods
# Source: R/autoplot-methods.R

# [Content of R/autoplot-methods.R moved here]
</file>

<file path="R/utils-internal.R">
#' Default value for NULL
#' @param a Value to use if not NULL
#' @param b Value to use if a is NULL
#' @keywords internal
#' @noRd
`%||%` <- function(a, b) if (is.null(a)) b else a

###############################################################################
## Helper: how many *rows* (events) does an arbitrary value-object have?    ###
###############################################################################
#' @keywords internal
#' @noRd
n_events <- function(x) UseMethod("n_events")
#' @keywords internal
#' @noRd
n_events.matrix            <- function(x) nrow(x)
#' @keywords internal
#' @noRd
n_events.ParametricBasis   <- function(x) nrow(x$y)
#' @keywords internal
#' @noRd
n_events.default           <- function(x) length(x)         # vector / factor / list

###############################################################################
## recycle a scalar / vector or abort with a clear message                  ###
###############################################################################
#' @keywords internal
#' @noRd
recycle_or_error <- function(x, target, label) {
  if (length(x) == 1L) rep(x, target)
  else if (length(x) != target)
    stop(sprintf("Length mismatch for %s: got %d, expected %d", label, length(x), target),
         call. = FALSE)
  else x
}

#' Sanitize variable names and store original names
#'
#' Uses `make.names` for robust sanitization and ensures uniqueness.
#' Stores original names in the "orig_names" attribute.
#'
#' @param names A character vector of names to sanitize.
#' @param allow_ = TRUE Passed to `make.names`.
#' @return A character vector of sanitized names, with original names attached
#'         as the "orig_names" attribute.
#' @keywords internal
#' @noRd
.sanitizeName <- function(names, allow_ = TRUE) {
  if (length(names) == 0) return(character(0))
  
  # Store original names before sanitizing
  original_names <- names
  
  # Use make.names for robust sanitization and uniqueness
  sanitized <- make.names(names, unique = TRUE, allow_ = allow_)
  
  # Attach original names as an attribute
  attr(sanitized, "orig_names") <- original_names
  
  sanitized
}

###############################################################################
## Helpers for Consistent Naming (Conditions/Levels)                       ###
###############################################################################

#' Generate a formatted label component for an event and specific level/index
#' 
#' @param ev An event object.
#' @param level Optional: The factor level (character) or column index (integer) to use. If NULL, assumes single column.
#' @return A character string label (e.g., "VarName\\[LevelName\\]" or "VarName\\[1\\]").
#' @keywords internal
#' @noRd
.label_component <- function(ev, level = NULL) {
  base_name <- ev$varname # Use original name before potential sanitization
  if (is.null(level)) {
    base_name
  } else {
    # Revert to sprintf format causing invalid names, but descriptive
    sprintf("%s[%s]", base_name, level)
    # Original change using paste:
    # paste(base_name, level, sep = ".")
  }
}

#' Internal helper to get a vector of formatted labels for a single event
#'
#' Returns `Variable[Level]` for each level of a categorical event, 
#' `Variable[Index]` for each column of a multi-column continuous event, 
#' `Variable` for a single-column continuous event, or `character(0)`.
#' Relies on `levels.event`, `is_categorical`, `.label_component`.
#'
#' @param ev An `event` object.
#' @return A character vector of formatted labels.
#' @keywords internal
#' @noRd
.level_vector <- function(ev) {
  lvls <- levels(ev) # Get levels/colnames via levels.event
  
  if (is_categorical(ev)) {
    # Categorical: Use actual levels
    vapply(lvls, \(l) .label_component(ev, l), character(1))
  } else if (is_continuous(ev) && length(lvls) > 1) {
    # Continuous multi-column (matrix/basis): Use index 1:ncol
    vapply(seq_along(lvls), \(k) .label_component(ev, k), character(1))
  } else if (is_continuous(ev) && length(lvls) == 1) {
    # Single continuous variable (vector): Just the variable name
    .label_component(ev) # level = NULL implicit
  } else {
    # Fallback (e.g., categorical with no levels?) -> empty
    character(0)
  }
}

###############################################################################
## The new .checkEVArgs                                                     ###
###############################################################################
#' Validate event arguments using new helpers.
#'
#' @param name The name of the event.
#' @param value The event values.
#' @param onsets Numeric vector of event onsets.
#' @param blockids Numeric vector of block IDs.
#' @param durations Numeric vector of durations (or a scalar, defaults to 0).
#' @return A list of validated event parameters with sanitized varname.
#' @import assertthat
#' @keywords internal
#' @noRd
.checkEVArgs <- function(name, value, onsets, blockids, durations = 0) {

  vname <- .sanitizeName(name)                    # single place

  ## ---- length consistency --------------------------------------------------
  n <- length(onsets)
  if (n_events(value) != n)
    stop(sprintf("Value length for '%s' is %d but onsets length is %d",
                 vname, n_events(value), n), call. = FALSE)

  if (length(blockids) != n)
    stop(sprintf("blockids length for '%s' is %d but onsets length is %d",
                 vname, length(blockids), n), call. = FALSE)

  ## ---- basic sanity checks -------------------------------------------------
  assertthat::assert_that(all(!is.na(onsets)),   msg = sprintf("NA in onsets (%s)", vname))
  assertthat::assert_that(all(!is.na(blockids)), msg = sprintf("NA in blockids (%s)", vname))
  assertthat::assert_that(!is.unsorted(blockids), msg = sprintf("blockids not non-decreasing (%s)", vname))

  ## strictly increasing onsets *within* each block
  tapply(onsets, blockids, function(ons) {
    if (is.unsorted(ons, strictly = TRUE))
      stop(sprintf("Onsets not strictly increasing within block for '%s'", vname), call. = FALSE)
    NULL
  })

  ## ---- durations -----------------------------------------------------------
  durations <- recycle_or_error(durations, n, sprintf("durations for '%s'", vname))

  ## ---- return cleaned bundle ----------------------------------------------
  list(
    varname   = vname,
    value     = value,
    onsets    = onsets,
    durations = durations,
    blockids  = blockids
  )
}
</file>

<file path="tests/testthat/helper-naming.R">
# Helper functions for naming tests

#' Check if a String is a Valid fmrireg Column Heading
#'
#' Based on the agreed grammar, allowing letters, numbers, dot, underscore, and hash.
#' Starts with a letter or dot.
#'
#' @param x Character vector of potential headings.
#' @return Logical vector.
is_valid_heading <- function(x) {
  # Allows letters, numbers, ., _, and # (for unique tags)
  # Must start with a letter or dot.
  grepl("^[A-Za-z\\.][A-Za-z0-9\\._#]*$", x)
}
</file>

<file path="tests/testthat/test_afni_hrf_aliases.R">
context("afni hrf aliases")

test_that("afni_hrf accepts sin/gam aliases", {
  spec_sin <- afni_hrf(x, basis = "sin")
  spec_gam <- afni_hrf(x, basis = "gam")

  expect_equal(attr(spec_sin$hrf, "name"), "SIN")
  expect_equal(attr(spec_gam$hrf, "name"), "GAM")
})
</file>

<file path="tests/testthat/test_baseline.R">
options(mc.cores=2)
test_that("can construct a baseline_model with 1 block and 5th order bspline basis", {
  sframe <- sampling_frame(blocklens=100, TR=2)
  bmodel <- baseline_model(basis="bs", degree=5, sframe=sframe)
  
  ## 5 + 1 for constant term
  expect_equal(ncol(design_matrix(bmodel)),6)
  expect_equal(length(terms(bmodel)), 2)
})

test_that("can construct a baseline_model with 1 block and 5th order bspline basis and nuisance_list", {
  sframe <- sampling_frame(blocklens=100, TR=2)
  nlist <- list(
    poly(samples(sframe), 3)
  )
  
  bmodel <- baseline_model(basis="bs", degree=5, sframe=sframe, nuisance_list=nlist)
  
  ## 5 + 1 for constant term
  expect_equal(ncol(design_matrix(bmodel)),9)
  expect_equal(length(terms(bmodel)), 3)
})

test_that("can construct a baseline_model with 2 blocks and 5th order bspline basis", {
  sframe <- sampling_frame(blocklens=c(100,100), TR=2)
  bmodel <- baseline_model(basis="bs", degree=5, sframe=sframe)
  
  expect_equal(ncol(design_matrix(bmodel)),6*2)
  expect_equal(length(terms(bmodel)), 2)
  #p <- print(bmodel)
  #expect_true(TRUE)
  
})

test_that("can construct a baseline_model with 2 blocks and global intercept", {
  sframe <- sampling_frame(blocklens=c(100,100), TR=2)
  # Use poly basis to avoid degree restrictions of bs/ns
  bmodel <- baseline_model(basis="poly", degree=3, sframe=sframe, intercept="global")
  
  # Expect 3 poly terms per block + 1 global constant term
  expect_equal(ncol(design_matrix(bmodel)), 3*2 + 1)
  # Drift term + Block term (global constant)
  expect_equal(length(terms(bmodel)), 2) 
  # Check term names
  expect_equal(names(terms(bmodel)), c("drift", "block"))
})

test_that("can construct a baseline_model with 2 blocks and nuisance_list", {
  sframe <- sampling_frame(blocklens=c(100,100), TR=2)
  nlist <- list(
    matrix(rnorm(100*2), 100, 2), # 2 nuisance regressors block 1
    matrix(rnorm(100*3), 100, 3)  # 3 nuisance regressors block 2
  )
  
  bmodel <- baseline_model(basis="bs", degree=5, sframe=sframe, nuisance_list=nlist)
  
  # Expect 5 bspline terms per block + 1 constant term per block + 5 nuisance regressors
  # (5*2) + (1*2) + (2+3) = 10 + 2 + 5 = 17
  expect_equal(ncol(design_matrix(bmodel)), 17)
  # Drift term + Block term + Nuisance term
  expect_equal(length(terms(bmodel)), 3) 
  # Check that the expected terms are present, regardless of order
  expect_true(setequal(names(terms(bmodel)), c("block", "drift", "nuisance")))
})

test_that("can construct a baseline_model with basis='constant'", {
  sframe <- sampling_frame(blocklens=c(100,100), TR=2)
  # Intercept option should be ignored/overridden when basis is constant
  bmodel_runwise <- baseline_model(basis="constant", sframe=sframe, intercept="runwise")
  bmodel <- baseline_model(basis="constant", sframe=sframe, intercept="global")
  bmodel_none <- baseline_model(basis="constant", sframe=sframe, intercept="none")
  
  # Expect only 1 column (the constant baseline itself) regardless of intercept 
  # because the baseline IS the constant. Intercept logic is skipped.
  # Update: The current logic *does* add a separate block term if intercept != "none".
  # Let's test the current behavior. If basis='constant', drift term is 1 col per block.
  # If intercept='runwise', block term is 1 col per block. Total = 2*2 = 4? No, drift is global constant if intercept='global'.
  # If basis='constant' & intercept='runwise': drift term is 1 col/block (but value is 1?), block term is 1 col/block? -> This seems redundant.
  # Let's re-read baseline_model carefully for basis='constant'.
  # baseline(): sets degree=1. bfun returns matrix(rep(1, length(x))). 
  # construct.baselinespec(): calculates ret_list. Each element is matrix(1, block_len, 1). 
  # If intercept='global', returns a single column matrix of 1s. Term name 'baseline_constant_1'.
  # If intercept!='global', builds block-diagonal matrix of 1s (1 col per block). Term name 'baseline_constant_1'.
  # baseline_model(): 
  #   drift = construct(...) based on above.
  #   block = NULL because basis='constant'. 
  # So, only the 'drift' term is created.
  
  # Therefore: 
  # basis='constant', intercept='runwise' -> drift term = block-diagonal 1s (1 col per block). Total = 2 cols.
  expect_equal(ncol(design_matrix(bmodel_runwise)), 2)
  expect_equal(length(terms(bmodel_runwise)), 1)
  expect_equal(names(terms(bmodel_runwise)), c("drift"))
  
  # basis='constant', intercept='global' -> drift term = single column of 1s. Total = 1 col.
  expect_equal(ncol(design_matrix(bmodel)), 1)
  expect_equal(length(terms(bmodel)), 1)
  expect_equal(names(terms(bmodel)), c("drift"))

  # Using blockid should subset rows by block
  expect_equal(
    nrow(design_matrix(bmodel, blockid = 2)),
    blocklens(sframe)[2]
  )
  
  # basis='constant', intercept='none' -> treated like 'runwise' by construct.baselinespec? No, intercept is passed.
  # construct.baselinespec doesn't explicitly use intercept='none' for constant basis differently than 'runwise'.
  # Let's assume it behaves like runwise. -> drift term = block-diagonal 1s (1 col per block). Total = 2 cols.
  expect_equal(ncol(design_matrix(bmodel_none)), 2)
  expect_equal(length(terms(bmodel_none)), 1)
  expect_equal(names(terms(bmodel_none)), c("drift"))

})
</file>

<file path="tests/testthat/test_contrast.R">
options(mc.cores=2)

library(testthat)
library(assertthat)
facedes <- read.table(system.file("extdata", "face_design.txt", package = "fmrireg"), header=TRUE)


test_that("a 2-by-2 Fcontrast", {
  F_a <- factor(rep(letters[1:2], 8))
  F_b <- factor(rep(c("V1", "V2"), each=8))
  onsets <- seq(1, length(F_a))
  blockids <- rep(1, length(onsets))
  
  et <- event_term(list(Fa=F_a, Fb=F_b), onsets, blockids)
  expect_true(!is.null(Fcontrasts(et)))
})

test_that("a 2-by-3 Fcontrast", {
  F_a <- factor(rep(letters[1:2], 9))
  F_b <- factor(rep(c("V1", "V2", "V3"), each=6))
 
  onsets <- seq(1, length(F_a))
  blockids <- rep(1, length(onsets))
  
  et <- event_term(list(Fa=F_a, Fb=F_b), onsets, blockids)
  expect_true(!is.null(Fcontrasts(et)))
})


test_that("a 3-by-2 Fcontrast", {
  F_a <- factor(rep(letters[1:2], 8))
  F_b <- factor(rep(c("V1", "V2"), each=8))
  F_c <- factor(rep(c("B3", "B3", "B4", "B4"), 4))
  onsets <- seq(1, length(F_a))
  blockids <- rep(1, length(onsets))
  
  et <- event_term(list(Fa=F_a, Fb=F_b, Fc=F_c), onsets, blockids)
  expect_true(!is.null(Fcontrasts(et)))
})

test_that("a 3-by-3 Fcontrast", {
  F_a <- factor(sample(letters[1:3], 200, replace=TRUE))
  F_b <- factor(sample(c("V1", "V2", "V3"), 200, replace=TRUE))
  F_c <- factor(sample(c("B3", "B3", "B4", "B4", "B5", "B5"),200, replace=TRUE))
  onsets <- seq(1, length(F_a))
  blockids <- rep(1, length(onsets))
  
  et <- event_term(list(Fa=F_a, Fb=F_b, Fc=F_c), onsets, blockids)
  expect_true(!is.null(Fcontrasts(et)))
})




test_that("can build a simple contrast from a convolved term", {
  facedes$repnum <- factor(facedes$rep_num)
  sframe <- sampling_frame(blocklens=rep(436/2,max(facedes$run)), TR=2)
  espec <- event_model(onset ~  hrf(repnum), data=facedes, block=~run, sampling_frame=sframe)
  con <- pair_contrast(~ repnum==-1, ~ repnum==1, name="A_B")
  
  expect_equal(as.vector(contrast_weights(con, terms(espec)[[1]])$weights), c(1,-1,0,0,0))
})

test_that("can build a simple contrast from a convolved term and convert to glt", {
  facedes$repnum <- factor(facedes$rep_num)
  sframe <- sampling_frame(blocklens=rep(436/2,max(facedes$run)), TR=2)
  espec <- event_model(onset ~  hrf(repnum), data=facedes, block=~run, sampling_frame=sframe)
  con <- pair_contrast(~ repnum==-1, ~ repnum==1, name="A_B")
  
  conw <- contrast_weights(con, terms(espec)[[1]])
  glt <- to_glt(conw)
  expect_true(!is.null(glt))
})

test_that("can build a contrast versus the intercept from a convolved term", {
  facedes$repnum <- factor(facedes$rep_num)
  sframe <- sampling_frame(blocklens=rep(436/2,max(facedes$run)), TR=2)
  espec <- event_model(onset ~  hrf(repnum), data=facedes, block=~run, sampling_frame=sframe)
  
  con <- unit_contrast(~ repnum, name="A")

  term <- terms(espec)[[1]]
  expect_equal(as.vector(contrast_weights(con, term)$weights), rep(.2,5))
  
})

test_that("can construct a simple pair_contrast", {
  facedes$repnum <- factor(facedes$rep_num)
  sframe <- sampling_frame(blocklens=rep(436/2,max(facedes$run)), TR=2)
  espec <- event_model(onset ~  hrf(repnum), data=facedes, block=~run, sampling_frame=sframe)
  
  pc <- pair_contrast(~ repnum == 1, ~ repnum ==2, name="B-A")
  cw <- contrast_weights(pc, terms(espec)[[1]])
  expect_equal(as.vector(cw$weights), c(0,1,-1,0,0))
  
})

test_that("can build a linear contrast from repnum and value_map", {
   facedes$repnum <- factor(facedes$rep_num)
   sframe <- sampling_frame(blocklens=rep(436/2,max(facedes$run)), TR=2)
   espec <- event_model(onset ~  hrf(repnum), data=facedes, block=~run, sampling_frame=sframe)
  
   con <- poly_contrast(~ repnum, degree=1, value_map=list("-1"=0, "1"=1, "2"=2, "3"=3, "4"=4), name="linear_repnum")
   term1 <- terms(espec)[[1]]
   cw <- contrast_weights(con, term1)
   expect_equal(as.vector(contrast_weights(con, term1)$weights), as.vector(poly(c(0,1,2,3,4))))
})

test_that("can build a set of pairwise contrasts", {
  facedes$repnum <- factor(facedes$rep_num)
  sframe <- sampling_frame(blocklens=rep(436/2,max(facedes$run)), TR=2)
  espec <- event_model(onset ~  hrf(repnum), data=facedes, block=~run, sampling_frame=sframe)
  levs <- levels(facedes$repnum)
  cset <- pairwise_contrasts(levs, facname = "repnum")
  expect_equal(length(cset), ncol(combn(length(levs),2)))

})

test_that("can build a one_against_all contrast set", {
  facedes$repnum <- factor(facedes$rep_num)
  sframe <- sampling_frame(blocklens=rep(436/2,max(facedes$run)), TR=2)
  espec <- event_model(onset ~  hrf(repnum), data=facedes, block=~run, sampling_frame=sframe)
  levs <- levels(facedes$repnum)
  cset <- one_against_all_contrast(levs, "repnum")
  
  
  expect_equal(length(cset),length(levels(facedes$repnum)))
  
  wtls <- lapply(cset, function(con) {
    contrast_weights(con, terms(espec)[[1]])
  })
  expect_true(!is.null(wtls))
  
})

test_that("can subtract two pairwise contrasts to form an interaction contrast", {
  simple_des <- expand.grid(category=c("face", "scene"), attention=c("attend", "ignored"), replication=c(1,2))
  simple_des$onset <- seq(1,100, length.out=nrow(simple_des))
  simple_des$run <- rep(1,nrow(simple_des))
  sframe <- sampling_frame(blocklens=100, TR=2)
  espec <- event_model(onset ~  hrf(category, attention), data=simple_des, block=~run, sampling_frame=sframe)
  con1 <- pair_contrast(~ category=="face", ~ category == "scene", name="face_scene#attend", where=~ attention == "attend")
  con2 <- pair_contrast(~ category=="face", ~ category == "scene", name="face_scene#ignored", where=~ attention == "ignored")
  con3 <- con1 - con2
  expect_true(!is.null(con3))
})


test_that("can contrast two parametric regressors crossed with a factor", {
  simple_des <- expand.grid(category=c("face", "scene"), attention=c("attend", "ignored"), replication=c(1,2))
  simple_des$onset <- seq(1,100, length.out=nrow(simple_des))
  simple_des$run <- rep(1,nrow(simple_des))
  simple_des$RT <- rnorm(nrow(simple_des))
  
  sframe <- sampling_frame(blocklens=100, TR=2)
  espec <- event_model(onset ~  hrf(category), data=simple_des, block=~run, sampling_frame=sframe)
  con <- pair_contrast(~ category == "face", ~ category == "scene", name="face_vs_scene")
  cwts <- contrast_weights(con, terms(espec)[[1]])
  expect_true(!is.null(cwts))
})

test_that("can contrast two parametric regressors wrapped in Ident for additive regressors", {
  simple_des <- expand.grid(category=c("face", "scene"), attention=c("attend", "ignored"), replication=c(1,2))
  simple_des$onset <- seq(1,100, length.out=nrow(simple_des))
  simple_des$run <- rep(1,nrow(simple_des))
  simple_des$RT1 <- rnorm(nrow(simple_des))
  simple_des$RT2 <- rnorm(nrow(simple_des))
  
  sframe <- sampling_frame(blocklens=100, TR=2)
  espec <- event_model(onset ~  hrf(Ident(RT1,RT2)), data=simple_des, block=~run, sampling_frame=sframe)
  
  # --- Determine actual column names for safety ---
  dm_colnames <- colnames(design_matrix(espec))
  term_of_interest <- terms(espec)[[1]] 
  term_condition_tags <- conditions(term_of_interest, expand_basis=FALSE) 
  term_tag_assigned <- attr(term_of_interest, "term_tag")
  
  # For Ident-only terms, term_tag might be NULL according to new naming scheme
  # In that case, column names should be just the variable names (RT1, RT2)
  if (is.null(term_tag_assigned)) {
    # Ident-only case: column names should be just the variable names
    pattern_A_col <- "^RT1$"
    pattern_B_col <- "^RT2$"
  } else {
    # Regular case with term_tag prefix
    if (length(term_condition_tags) < 2) {
      stop("Could not reliably determine column names for Ident(RT1,RT2) term in test.")
    }
    pattern_A_col <- paste0("^", term_tag_assigned, "_", term_condition_tags[1], "$")
    pattern_B_col <- paste0("^", term_tag_assigned, "_", term_condition_tags[2], "$")
  }
  
  # Ensure these patterns actually match columns in the design_matrix
  expect_true(any(grepl(pattern_A_col, dm_colnames)), 
              info = paste("Pattern A:", pattern_A_col, "did not match any of actual colnames:", paste(dm_colnames, collapse=", ")))
  expect_true(any(grepl(pattern_B_col, dm_colnames)),
              info = paste("Pattern B:", pattern_B_col, "did not match any of actual colnames:", paste(dm_colnames, collapse=", ")))

  con <- column_contrast(pattern_A = pattern_A_col, 
                         pattern_B = pattern_B_col, 
                         name="RT1_vs_RT2_cols")
                         
  cwts <- contrast_weights(con, term_of_interest)
  expect_true(!is.null(cwts))
  
  # More specific checks for the weights vector
  weights_vec <- as.vector(cwts$weights)
  col_A_idx <- grep(pattern_A_col, dm_colnames)
  col_B_idx <- grep(pattern_B_col, dm_colnames)
  
  # Check that only one column matches each pattern
  expect_equal(length(col_A_idx), 1, info = "Pattern A should match exactly one column")
  expect_equal(length(col_B_idx), 1, info = "Pattern B should match exactly one column")
  
  if (length(col_A_idx) == 1 && length(col_B_idx) == 1) {
      expect_equal(weights_vec[col_A_idx], 1)
      expect_equal(weights_vec[col_B_idx], -1)
      # Ensure all other weights are zero
      other_indices <- setdiff(seq_along(weights_vec), c(col_A_idx, col_B_idx))
      if (length(other_indices) > 0) {
        expect_true(all(weights_vec[other_indices] == 0))
      }
      expect_equal(sum(weights_vec), 0) # Overall sum should be zero
  }

})

test_that("can contrast two basis functions from a custom multi-phase hrf", {
  # Create a proper factor with multiple levels to avoid the contrasts error
  simple_des <- expand.grid(trial_type=c("encoding", "retrieval"))
  simple_des <- simple_des[rep(1:nrow(simple_des), length.out=15), , drop=FALSE]
  
  simple_des$onset <- seq(1,300, length.out=nrow(simple_des))
  simple_des$run <- rep(1,nrow(simple_des))
  
  hrf_encode <- gen_hrf(hrf_spmg1, normalize=TRUE)
  hrf_delay <- gen_hrf(hrf_spmg1, lag=3, width=8, normalize=TRUE)
  hrf_probe <-gen_hrf(hrf_spmg1, lag=11, width=3, normalize=TRUE)  
  hrf_trial <<- gen_hrf_set(hrf_encode, hrf_delay, hrf_probe)
  
  sframe <- sampling_frame(blocklens=250, TR=2)
  espec <- event_model(onset ~  hrf(trial_type, basis=hrf_trial), data=simple_des, block=~run, sampling_frame=sframe)
  
  # Updated to use new HRF basis suffix naming scheme: _b01, _b02, etc.
  # Use column_contrast to target specific basis functions
  con <- column_contrast(pattern_A = "_b01$", pattern_B = "_b02$", name="basis1_vs_basis2")
  cwts <- contrast_weights(con, terms(espec)[[1]])
  expect_true(!is.null(cwts))
})

test_that("can form a simple formula contrast", {
  simple_des <- expand.grid(category=c("face", "scene"), attention=c("attend", "ignored"), replication=c(1,2))
  simple_des$onset <- seq(1,100, length.out=nrow(simple_des))
  simple_des$run <- rep(1,nrow(simple_des))
  sframe <- sampling_frame(blocklens=100, TR=2)
  espec <- event_model(onset ~  hrf(category, attention), data=simple_des, block=~run, sampling_frame=sframe)
  
  # Use the new naming scheme: term_tag_condition_tag format
  # The term_tag should be "category_attention" and condition_tags should be "category.face_attention.attend" etc.
  # But for formula contrasts, we still use shortnames which are the old format for backward compatibility
  con1 <- contrast(~ (`face:attend` - `face:ignored`) - (`scene:attend` - `scene:ignored`), name="face_scene")
  cwts <- contrast_weights(con1, terms(espec)[[1]])
  
  # Now the contrast should work correctly with proper weights
  # Order is: face:attend, scene:attend, face:ignored, scene:ignored
  # Formula: (face:attend - face:ignored) - (scene:attend - scene:ignored)
  # Expected: face:attend=1, face:ignored=-1, scene:attend=-1, scene:ignored=1
  expect_equal(as.vector(cwts$weights[,1]), c(1, -1, -1, 1))
  
})

test_that("can form formula contrast with 3 terms", {
  simple_des <- expand.grid(match=c("match", "nonmatch"), condition=c("NOVEL", "REPEAT"), correct=c("correct","incorrect"))
  simple_des$onset <- seq(1,100, length.out=nrow(simple_des))
  simple_des$run <- rep(1,nrow(simple_des))
  sframe <- sampling_frame(blocklens=100, TR=2)
  espec <- event_model(onset ~  hrf(match, condition, correct), data=simple_des, block=~run, sampling_frame=sframe)
  
  # Use the old shortnames format for formula contrasts (backward compatibility)
  con1 <- contrast(
    ~  ((`match:NOVEL:correct` + `match:NOVEL:incorrect`) - (`nonmatch:NOVEL:correct` + `nonmatch:NOVEL:incorrect`)) -
      ((`match:REPEAT:correct` + `match:REPEAT:incorrect`) - (`nonmatch:REPEAT:correct` + `nonmatch:REPEAT:incorrect`)), name="cond_by_match")
  cwts <- contrast_weights(con1, terms(espec)[[1]])
  expect_equal(length(as.vector(cwts$weights[,1])), 8)
  
})

test_that("can form formula contrast with two factor terms and one continuous covariate", {
  simple_des <- expand.grid(match=c("match", "nonmatch"), condition=c("NOVEL", "REPEAT"), correct=c(1,2))
  simple_des$onset <- seq(1,100, length.out=nrow(simple_des))
  simple_des$run <- rep(1,nrow(simple_des))
  simple_des$correct <- as.factor(simple_des$correct)
  sframe <- sampling_frame(blocklens=100, TR=2)
  espec <- event_model(onset ~  hrf(match, condition, correct), data=simple_des, block=~run, sampling_frame=sframe)
  
  # Use the old shortnames format for formula contrasts
  con1 <- contrast(
    ~  `match:NOVEL:1` - `nonmatch:NOVEL:1`, name="cond_by_match")
  cwts <- contrast_weights(con1, terms(espec)[[1]])
  
  # Check that we get the correct contrast weights
  weights_vec <- as.vector(cwts$weights[,1])
  expect_equal(length(weights_vec), 8)
  
  # The contrast should have +1 for match:NOVEL:1 and -1 for nonmatch:NOVEL:1
  # Find the positions of these conditions in shortnames
  short_names <- shortnames(terms(espec)[[1]])
  match_pos <- which(short_names == "match:NOVEL:1")
  nonmatch_pos <- which(short_names == "nonmatch:NOVEL:1")
  
  expect_equal(weights_vec[match_pos], 1)
  expect_equal(weights_vec[nonmatch_pos], -1)
  # All other weights should be 0
  other_pos <- setdiff(1:length(weights_vec), c(match_pos, nonmatch_pos))
  expect_true(all(weights_vec[other_pos] == 0))
  
})



# 
# test_that("can build a contrast versus the intercept and add to hrfspec", {
#   facedes$repnum <- factor(facedes$rep_num)
#   aux_table <- data.frame(run=rep(1:6, each=218))
#   
#   
#   conf <- contrast_formula(~ `2` - !`1`, id="repnum")
#   sframe <- sampling_frame(rep(436/2,max(facedes$run)), TR=2)
#   nuisance <- matrix(rnorm(2*length(sframe$blockids)), length(sframe$blockids), 2)
#   
#   bm <- baseline_model(basis="bs", degree=3, sampling_frame=sframe, nuisance_matrix=nuisance)
#   em <- event_model(onset ~ hrf(repnum, contrasts=con), block = ~ run, data=facedes, sampling_frame=sframe)
#   mod <- fmri_model(em, bm)
#   
#   term <- construct(mspec$varspec[[1]], mspec)
#   expect_equal(as.vector(contrast_weights(con, term)), c(1,0,0,0,0))
# })
#
</file>

<file path="tests/testthat/test_covariate_length.R">
test_that("covariate data length must match sampling frame", {
  sframe <- sampling_frame(blocklens = c(50, 50), TR = 1)

  # create covariate data that is too short
  bad_dat <- data.frame(x = rnorm(75), y = rnorm(75))

  expect_error(
    event_model(onset ~ covariate(x, y, data = bad_dat),
                data = data.frame(onset = seq_len(100), run = rep(1:2, each = 50)),
                block = ~ run, sampling_frame = sframe),
    "sampling_frame expects"
  )
})
</file>

<file path="tests/testthat/test_dataset.R">
test_that("can construct an fmri_dataset", {
  dset <- fmri_dataset(
    scans=c("scan1.nii", "scan2.nii", "scan3.nii"),
    mask="mask.nii",
    run_length=c(100,100,100),
    TR=2
  )
  expect_true(!is.null(dset))
  
})


## design file not found during testing
#test_that("can read a config file to create fmri_dataset", {
  #fname <- system.file("extdata", "config.R", package = "fmrireg")
  #base_path=dirname(fname)
  
  #config <- read_fmri_config(fname, base_path)
  #expect_true(!is.null(config))
#})

test_that("can construct an fmri_mem_dataset", {
  
  facedes <- read.table(system.file("extdata", "face_design.txt", package = "fmrireg"), header=TRUE)
  facedes$repnum <- factor(facedes$rep_num)
  
  scans <- lapply(1:length(unique(facedes$run)), function(i) {
    arr <- array(rnorm(10*10*10*244), c(10,10,10, 244))
    bspace <- neuroim2::NeuroSpace(dim=c(10,10,10,244))
    neuroim2::NeuroVec(arr, bspace)
  })
  
  mask <- neuroim2::LogicalNeuroVol(array(rnorm(10*10*10), c(10,10,10)) > 0, neuroim2::NeuroSpace(dim=c(10,10,10)))
  
  #scans <- list.files("test_data/images_study/epi/", "rscan0.*nii", full.names=TRUE)
  dset <- fmri_mem_dataset(scans=scans, 
                           mask=mask, 
                           TR=1.5, 
                           event_table=tibble::as_tibble(facedes))
  
  expect_true(!is.null(dset))
  
  
})
</file>

<file path="tests/testthat/test_estimate_hrf.R">
# Helper function to generate event table
generate_event_table <- function(onsets, duration=0, level=1) {
  data.frame(
    onset = onsets,
    duration = rep(duration, length(onsets)),
    stem = rep(level, length(onsets)),
    run = rep(1, length(onsets))
  )
}

# Helper function to simulate fMRI data
simulate_fmri_data <- function(onsets, n_voxels, n_timepoints, hrf_means, noise_sd=0.1) {
  timepoints <- seq(0, n_timepoints - 1)
  
  # Generate HRFs for each onset with different means
  hrfs <- lapply(hrf_means, function(mean) {
    h <- gen_hrf(hrf_gaussian, mean=mean)
    reg <- regressor(onsets = onsets, hrf = h, duration = 0, amplitude = 1)
    evaluate(reg, timepoints)
  })
  
  # Generate matrix dataset
  matrix_dataset <- sapply(1:n_voxels, function(i) {
    signal <- hrfs[[i]]
    noise <- rnorm(n_timepoints, mean=0, sd=noise_sd)
    signal + noise
  })
  
  colnames(matrix_dataset) <- paste0("Voxel_", 1:n_voxels)
  rownames(matrix_dataset) <- paste0("Time_", 1:n_timepoints)
  
  matrix_dataset
}

# Helper function to create matrix dataset object
create_matrix_dataset <- function(datamat, TR=1, run_length, event_table, sampling_frame) {
  matrix_dataset(
    datamat = datamat,
    TR = TR,
    run_length = run_length,
    event_table = event_table
  )
}

# Test function for single HRF
test_find_best_hrf <- function(n_voxels = 100, n_timepoints = 100, onsets = seq(10, 100, by=10), hrf_fun = hrf_gaussian, hrflib=NULL) {
  # Generate event table
  event_table <- generate_event_table(onsets)
  
  # Simulate fMRI data
  hrf_means <- rep(5, n_voxels)  # All voxels have the same HRF mean for test 1
  datamat <- simulate_fmri_data(onsets, n_voxels, n_timepoints, hrf_means)
  
  # Create sampling frame
  sampling_frame <- sampling_frame(blocklens=c(n_timepoints), TR=1)
  
  # Combine into a dataset
  dataset <- create_matrix_dataset(datamat, TR=1, run_length=n_timepoints, event_table=event_table, sampling_frame=sampling_frame)
  
  # Run the find_best_hrf function
  result <- find_best_hrf.matrix_dataset(dataset, fac_var="stem", onset_var="onset", hrflib=hrflib, block=~run)
  
  expect_true(!is.null(result))
}

# Test function for multiple HRFs
test_find_best_hrf_multiple_means <- function(n_voxels = 100, n_timepoints = 100, onsets = seq(10, 100, by=10), 
                                              hrf_means = c(5, 6, 7), hrflib=NULL) {
  # Generate event table
  event_table <- generate_event_table(onsets)
  
  # Adjust hrf_means to ensure 33, 33, 34 distribution
  hrf_means <- rep(hrf_means, length.out=n_voxels)
  
  # Simulate fMRI data
  datamat <- simulate_fmri_data(onsets, n_voxels, n_timepoints, hrf_means)
  
  # Create sampling frame
  sampling_frame <- sampling_frame(blocklens=c(n_timepoints), TR=1)
  
  # Combine into a dataset
  dataset <- create_matrix_dataset(datamat, TR=1, run_length=n_timepoints, event_table=event_table, sampling_frame=sampling_frame)
  
  # Run the find_best_hrf function
  result <- find_best_hrf.matrix_dataset(dataset, fac_var="stem", onset_var="onset", hrflib=hrflib, block=~run)
  
  expect_true(!is.null(result))
}

# Define tests
test_that("find_best_hrf.matrix_dataset works with a single HRF", {
  result <- test_find_best_hrf()
  expect_true(!is.null(result))
})

test_that("find_best_hrf.matrix_dataset works with multiple HRFs", {
  result <- test_find_best_hrf_multiple_means()
  expect_true(!is.null(result))
})
</file>

<file path="tests/testthat/test_event_model.R">
library(testthat)
testthat::local_edition(3)
#library(fmrireg)
library(rlang)

# Helper function to create consistent test data
create_test_data <- function(seed = 123, n_events = 10, n_blocks = 2) {
  set.seed(seed)
  block_len <- ceiling(n_events / n_blocks)
  blocklens <- rep(block_len, n_blocks)
  total_scans <- sum(blocklens)
  TR <- 2
  sf <- sampling_frame(blocklens = blocklens, TR = TR)
  
  events <- data.frame(
    x = rnorm(n_events),
    y = rnorm(n_events),
    condition = factor(rep(letters[1:2], length.out=n_events)),
    modulator = seq(0, 1, length.out=n_events),
    # Generate realistic onsets within blocks
    onset = unlist(lapply(blocklens, function(bl) sort(sample(0:(bl*TR - TR), size=n_events/n_blocks, replace=FALSE)))),
    block = rep(1:n_blocks, each=n_events/n_blocks)
  )
  list(events=events, sf=sf)
}

# === Test Suite for the *new* event_model pipeline ===

test_that("event_model (formula) creates correct object structure and attributes", {
  test_data <- create_test_data()
  events <- test_data$events
  sf <- test_data$sf
  
  # Define formula with various terms
  form <- onset ~ hrf(condition)
  
  model <- event_model(
    formula_or_list = form,
    data = events,
    block = ~block, 
    sampling_frame = sf
  )
  
  # 1. Basic Structure Checks
  expect_s3_class(model, "event_model")
  expect_s3_class(model, "list")
  expect_named(model, c("terms", "design_matrix", "blockids", "sampling_frame", "contrasts", "model_spec"))
  expect_type(model$terms, "list")
  expect_s3_class(model$design_matrix, "tbl_df")
  expect_s3_class(model$sampling_frame, "sampling_frame")
  expect_true(is.numeric(model$blockids) || is.integer(model$blockids))
  expect_length(model$blockids, nrow(events)) # Check blockids length against original data
  
  # Check number of terms generated
  expect_equal(length(model$terms), 1)
  expect_s3_class(model$terms[[1]], "event_term") # Check class of a term
  
  # Check design matrix dimensions (rows should match total scans in sampling frame)
  expect_equal(nrow(model$design_matrix), sum(blocklens(sf)))
  
  # 2. Design Matrix Attribute Checks
  dm <- model$design_matrix
  term_spans <- attr(dm, "term_spans")
  col_indices <- attr(dm, "col_indices")
  
  expect_true(!is.null(term_spans))
  expect_true(!is.null(col_indices))
  
  expect_true(is.vector(term_spans), "term_spans should be a vector")
  expect_equal(length(term_spans), length(model$terms))
  if (length(model$terms) > 0) {
    expect_equal(term_spans, cumsum(sapply(model$terms, function(term) ncol(design_matrix(term)))))
  }
  expect_type(col_indices, "list")
  expect_equal(length(col_indices), length(model$terms))
  expect_equal(names(col_indices), names(model$terms))
  expect_type(col_indices[[1]], "integer") # Indices should be integers
  # Check total number of columns matches sum of indices lengths
  expect_equal(sum(sapply(col_indices, length)), ncol(dm))
  # Check indices are within bounds
  expect_true(all(unlist(col_indices) >= 1 & unlist(col_indices) <= ncol(dm)))
})

test_that("event_model (list) creates correct object structure and attributes", {
  test_data <- create_test_data()
  events <- test_data$events
  sf <- test_data$sf
  
  # Define list of hrfspec objects
  spec_list <- list(
    hrf(condition), 
    hrf(modulator),
    hrf(x, y),
    hrf(Poly(x, 2))
  )
  
  model <- event_model(
    formula_or_list = spec_list,
    data = events,
    block = events$block, # Use vector block specification
    sampling_frame = sf
  )
  
  # Repeat the same structure and attribute checks as the formula test
  # 1. Basic Structure Checks
  expect_s3_class(model, "event_model")
  expect_named(model, c("terms", "design_matrix", "blockids", "sampling_frame", "contrasts", "model_spec"))
  expect_type(model$terms, "list")
  expect_equal(length(model$terms), length(spec_list))
  expect_s3_class(model$design_matrix, "tbl_df")
  expect_equal(nrow(model$design_matrix), sum(blocklens(sf)))
  
  # 2. Design Matrix Attribute Checks
  dm <- model$design_matrix
  term_spans <- attr(dm, "term_spans")
  col_indices <- attr(dm, "col_indices")
  expect_true(!is.null(term_spans))
  expect_true(!is.null(col_indices))
  expect_true(inherits(term_spans, "matrix"))
  expect_equal(dim(term_spans), c(length(model$terms), 2))
  expect_type(col_indices, "list")
  expect_equal(length(col_indices), length(model$terms))
  expect_equal(names(col_indices), names(model$terms))
  expect_equal(sum(sapply(col_indices, length)), ncol(dm))
})

test_that("contrast_weights.event_model works with new attributes", {
  test_data <- create_test_data()
  events <- test_data$events
  sf <- test_data$sf
  
  # Define a contrast within hrfspec
  con1 <- pair_contrast(~ condition == "a", ~ condition == "b", name = "A_vs_B")
  
  # Model with one term containing a contrast
  model <- event_model(
    onset ~ hrf(condition, contrasts = list(con1)), 
    data = events, 
    block = ~block, 
    sampling_frame = sf
  )
  
  # Calculate contrast weights using the S3 method for event_model
  cw_list <- contrast_weights.event_model(model)
  
  # Checks
  expect_type(cw_list, "list")
  expect_equal(length(cw_list), 1) # Should find one contrast
  expect_named(cw_list, "condition.A_vs_B")
  
  cw <- cw_list[[1]]
  expect_s3_class(cw, "cell_contrast")
  #expect_named(cw, c("weights", "name", "term", "level1", "level2", "where", "offset_weights", "condnames"))
  
  # Check dimensions of offset_weights (should match full design matrix)
  dm <- design_matrix(model)
  expect_equal(nrow(cw$offset_weights), ncol(dm))
  expect_equal(ncol(cw$offset_weights), 1)
  expect_equal(rownames(cw$offset_weights), colnames(dm))
  
  # Check that weights are non-zero only in the columns for the relevant term
  term_indices <- attr(dm, "col_indices")[[names(model$terms)]] # Get indices for the 'condition' term
  expect_true(all(cw$offset_weights[-term_indices, ] == 0))
  expect_true(any(cw$offset_weights[term_indices, ] != 0))
  
  # Check the actual weight values (simple 1 vs -1 for pair_contrast)
  # The local weights should be [1, -1]
  expect_equal(as.vector(cw$offset_weights[term_indices, ]), c(1, -1))
})

# --- Test for B-Spline Basis --- 
test_that("event_model handles hrf_bspline basis correctly", {
  # Sampling frame with 2 blocks, 100 scans each
  sf_bspline <- sampling_frame(blocklens = c(100, 100), TR = 2)
  
  # Events data spanning both blocks
  n_events_bspline <- 20
  events_bspline <- data.frame(
    onset = unlist(lapply(c(100, 100), function(bl) sort(sample(0:(bl*2 - 2), size=n_events_bspline/2, replace=FALSE)))),
    condition = factor(rep(letters[3:4], length.out=n_events_bspline)), # Use c, d
    block = rep(1:2, each=n_events_bspline/2)
  )
  
  # Define formula with bspline basis
  form_bspline <- onset ~ hrf(condition, basis="bspline", nbasis=5)
  
  # Create the event model
  model_bspline <- event_model(
    formula_or_list = form_bspline,
    data = events_bspline,
    block = ~block, 
    sampling_frame = sf_bspline
  )
  
  # Basic structural checks
  expect_s3_class(model_bspline, "event_model")
  expect_length(model_bspline$terms, 1)
  term_tag <- names(model_bspline$terms)[[1]] # Get the assigned term tag
  expect_equal(term_tag, "condition") # Check default tag
  
  # Check HRF specification within the term
  hrfspec <- attr(model_bspline$terms[[1]], "hrfspec")
  expect_s3_class(hrfspec$hrf, "HRF")
  expect_equal(nbasis(hrfspec$hrf), 5, info = "Checking nbasis of the HRF object")
  expect_match(attr(hrfspec$hrf, "name"), "bspline", info = "Checking name of the HRF object")
  
  # Check design matrix dimensions
  dm_bspline <- design_matrix(model_bspline)
  expect_equal(nrow(dm_bspline), 200, info = "Checking total rows in design matrix")
  expect_equal(ncol(dm_bspline), 10, info = "Checking number of columns in design matrix")
  
  # Check attributes are present
  expect_true(!is.null(attr(dm_bspline, "term_spans")))
  expect_true(!is.null(attr(dm_bspline, "col_indices")))
  
  # Check term span corresponds to ncol
  term_spans <- attr(dm_bspline, "term_spans")
  expect_true(is.numeric(term_spans))
  expect_equal(length(term_spans), 1)
  expect_equal(as.vector(term_spans[1]), 10)
  
  # Check bspline basis column naming according to new scheme
  expected_base_conds <- c("condition.c", "condition.d")
  expected_names <- sort(c(
    paste0(term_tag, "_", expected_base_conds[1], "_b0", 1:5),
    paste0(term_tag, "_", expected_base_conds[2], "_b0", 1:5)
  ))
  expect_equal(sort(colnames(dm_bspline)), expected_names)
  
  # Test column_contrast for specific basis function pattern (should still work with new names)
  term_bspline <- model_bspline$terms[[1]]
  cc3 <- column_contrast(pattern_A = "_b03$", name = "Basis3")
  cw3 <- contrast_weights(cc3, term_bspline)
  all_rel <- conditions(term_bspline, drop.empty = FALSE, expand_basis = TRUE)
  expect_equal(rownames(cw3$weights), all_rel)
  mask <- grepl("_b03$", all_rel)
  expect_equal(sum(mask), length(unique(events_bspline$condition)), ignore_attr = TRUE)
  expect_equal(cw3$weights[mask, 1], rep(1 / sum(mask), sum(mask)), ignore_attr = TRUE)
  expect_equal(cw3$weights[!mask, 1], rep(0, length(all_rel) - sum(mask)), ignore_attr = TRUE)
  
  # Test pair_contrast broadcasting across bspline basis
  con1 <- pair_contrast(~ condition == "c", ~ condition == "d", name = "C_vs_D")
  model_contrast_bspline2 <- event_model(
    onset ~ hrf(condition, basis = "bspline", nbasis = 5, contrasts = list(con1)),
    data = events_bspline,
    block = ~block,
    sampling_frame = sf_bspline
  )
  cw_list2 <- contrast_weights.event_model(model_contrast_bspline2)
  expect_named(cw_list2, "condition.C_vs_D") # Name comes from contrast + term
  cw2 <- cw_list2[[1]]
  rown <- rownames(cw2$offset_weights)
  # Grep for the new naming patterns
  pos_idx <- grep(paste0("^",term_tag,"_condition\\.c_b"), rown)
  neg_idx <- grep(paste0("^",term_tag,"_condition\\.d_b"), rown)
  expect_true(length(pos_idx) == 5) # Should match 5 basis functions
  expect_true(length(neg_idx) == 5) # Should match 5 basis functions
  expect_true(all(cw2$offset_weights[pos_idx, 1] > 0))
  expect_true(all(cw2$offset_weights[neg_idx, 1] < 0))
})

# --- Tests for Term Naming and Clash Resolution ---
test_that("event_model handles term naming and clashes correctly", {
  test_data <- create_test_data()
  events <- test_data$events
  sf <- test_data$sf

  # Scenario 1: Simple clash, no explicit names
  # Default name for hrf(condition) is "condition"
  model1 <- event_model(
    onset ~ hrf(condition) + hrf(condition),
    data = events, block = ~block, sampling_frame = sf
  )
  # make_term_tag generates "condition", then "condition#1"
  expect_named(model1$terms, c("condition", "condition#1"))

  # Scenario 2: Clash with one explicit name identical to default
  # hrf(condition) -> default "condition"
  # hrf(condition, name="condition") -> explicit "condition"
  model2 <- event_model(
    onset ~ hrf(condition) + hrf(condition, name="condition"),
    data = events, block = ~block, sampling_frame = sf
  )
  # make_term_tag handles the clash: "condition", "condition#1"
  expect_named(model2$terms, c("condition", "condition#1"))

  # Scenario 3: No clash, one explicit name
  # hrf(condition, name="my_cond") -> explicit "my_cond"
  # hrf(modulator) -> default "modulator"
  model3 <- event_model(
    onset ~ hrf(condition, name="my_cond") + hrf(modulator),
    data = events, block = ~block, sampling_frame = sf
  )
  # No clash, names are kept as generated
  expect_named(model3$terms, c("my_cond", "modulator"))

  # Scenario 4: Clash between two explicit names
  # hrf(condition, name="term") -> explicit "term"
  # hrf(modulator, name="term") -> explicit "term"
  model4 <- event_model(
    onset ~ hrf(condition, name="term") + hrf(modulator, name="term"),
    data = events, block = ~block, sampling_frame = sf
  )
  # make_term_tag resolves the clash: "term", "term#1"
  expect_named(model4$terms, c("term", "term#1"))
  
  # Scenario 5: Multiple auto clashes mixed with unique names
  # hrf(condition) -> default "condition"
  # hrf(modulator) -> default "modulator"
  # hrf(condition) -> default "condition" (clash 1)
  # hrf(x, y) -> default "x_y"
  model5 <- event_model(
    onset ~ hrf(condition) + hrf(modulator) + hrf(condition) + hrf(x, y),
    data = events, block = ~block, sampling_frame = sf
  )
  # Expected sequence: "condition", "modulator", "condition#1", "x_y"
  expect_named(model5$terms, c("condition", "modulator", "condition#1", "x_y"))
  
  # Scenario 6: Using a list input with clashes
  # hrf(condition) -> default "condition"
  # hrf(modulator) -> default "modulator"
  # hrf(condition) -> default "condition" (clash 1)
  spec_list6 <- list(
    hrf(condition), 
    hrf(modulator),
    hrf(condition)
  )
  model6 <- event_model(spec_list6, data = events, block = ~block, sampling_frame = sf)
  # Expected sequence: "condition", "modulator", "condition#1"
  expect_named(model6$terms, c("condition", "modulator", "condition#1"))
  
  # Scenario 7: Clash where explicit name matches an auto-generated name 
  # hrf(condition) -> default "condition"
  # hrf(modulator, name="condition") -> explicit "condition" (clash 1)
  model7 <- event_model(
    onset ~ hrf(condition) + hrf(modulator, name="condition"),
    data = events, block = ~block, sampling_frame = sf
  )
  # Expected sequence: "condition", "condition#1"
  expect_named(model7$terms, c("condition", "condition#1"))
  
  # Scenario 8: Ensure subsetting doesn't affect default naming
  # hrf(condition, subset=cond_flag) -> default "condition"
  # hrf(condition, subset=!cond_flag) -> default "condition" (clash 1)
  events_subset <- events
  events_subset$cond_flag <- rep(c(TRUE, FALSE), length.out=nrow(events_subset))
  model8 <- event_model(
    onset ~ hrf(condition, subset=cond_flag) + hrf(condition, subset=!cond_flag),
    data = events_subset, block = ~block, sampling_frame = sf
  )
  # Expected sequence: "condition", "condition#1"
  expect_named(model8$terms, c("condition", "condition#1"))
  
  # Scenario 9: Explicit name that clashes with an index-disambiguated name
  # hrf(condition) -> default "condition"
  # hrf(condition) -> default "condition" -> clash 1 -> "condition#1"
  # hrf(modulator, name="condition") -> explicit "condition" -> clash 2 -> "condition#2"
  model9 <- event_model(
      onset ~ hrf(condition) + hrf(condition) + hrf(modulator, name="condition"),
      data = events, block = ~block, sampling_frame = sf
  )
  # Expected sequence: "condition", "condition#1", "condition#2" 
  expect_named(model9$terms, c("condition", "condition#1", "condition#2"))
  
  # Scenario 10: Name containing dot, sanitized
  # hrf(condition, name="term.one") -> explicit "term.one" -> sanitized "term_one"
  model10 <- event_model(
    onset ~ hrf(condition, name="term.one"),
    data = events, block = ~block, sampling_frame = sf
  )
  expect_named(model10$terms, c("term_one"))
  
  # Scenario 11: Clash after sanitization
  # hrf(condition, name="term.one") -> sanitized "term_one"
  # hrf(modulator, name="term_one") -> sanitized "term_one" -> clash -> "term_one#1"
  model11 <- event_model(
    onset ~ hrf(condition, name="term.one") + hrf(modulator, name="term_one"),
    data = events, block = ~block, sampling_frame = sf
  )
  expect_named(model11$terms, c("term_one", "term_one#1"))
})

# --- Golden Heading Snapshot Test ---
test_that("Golden heading test: diverse terms produce expected colnames", {
  td <- create_test_data(seed=555, n_events=10, n_blocks=1)
  events <- td$events
  sf     <- td$sf
  
  # Add more variables for diverse terms
  events$stim_type <- factor(rep(c("Face", "Scene"), length.out=10))
  events$group <- factor(rep(c("G1", "G2"), each=5))
  events$rt <- rnorm(10, mean=1.5, sd=0.2)
  
  # Create a model with various term types
  # Use explicit names to ensure stable term tags for snapshot
  model_golden <- event_model(
    onset ~ hrf(condition, name="Cond") + 
            hrf(condition, modulator, name="CondXMod") +
            hrf(stim_type, rt, basis="spmg3", name="StimRT_spmg3") + 
            hrf(Poly(x, 3), name="PolyX") +
            hrf(ScaleWithin(y, group), name="ScaleYbyG") +
            hrf(modulator, subset=condition=="a", name="Mod_CondA") + # Potential clash if auto-named
            hrf(modulator, subset=condition=="b", name="Mod_CondB"), 
    data = events,
    block = ~block,
    sampling_frame = sf
  )
  
  dm_golden <- design_matrix(model_golden)
  
  # Snapshot the column names
  expect_snapshot(colnames(dm_golden))
})

# --- Clash Test ---
test_that("Clash test: duplicate default term tags get unique suffixes", {
  td <- create_test_data(seed=1)
  events <- td$events
  sf <- td$sf
  
  # Create model where two terms would default to the same tag ("x")
  model_clash <- event_model(
    onset ~ hrf(x, subset = condition == "a") + 
            hrf(x, subset = condition == "b"), 
    data = events,
    block = ~block,
    sampling_frame = sf
  )
  
  dm_clash <- design_matrix(model_clash)
  cols <- colnames(dm_clash)
  
  # Check term tags assigned
  expect_named(model_clash$terms, c("x", "x#1"))
  
  # Check column name prefixes
  expect_true(all(startsWith(cols[1], "x_")))
  expect_true(all(startsWith(cols[2], "x.1_")))
  
  # Check specific column names (more precise)
  expect_equal(cols, c("x_x", "x.1_x"))
})

# --- Basis Suffix Test ---
test_that("Basis suffix test: _b## added correctly for multi-basis HRFs", {
  td <- create_test_data(seed=2)
  events <- td$events
  sf <- td$sf
  
  # HRF with 3 basis functions
  hrf_multi <- HRF_SPMG3
  expect_equal(nbasis(hrf_multi), 3)
  
  # HRF with 1 basis function
  hrf_single <- HRF_SPMG1
  expect_equal(nbasis(hrf_single), 1)
  
  # Model with multi-basis HRF
  model_multi <- event_model(
    onset ~ hrf(condition, modulator, basis=hrf_multi, name="Multi"), 
    data = events,
    block = ~block,
    sampling_frame = sf
  )
  dm_multi <- design_matrix(model_multi)
  cols_multi <- colnames(dm_multi)
  
  # Expected number of columns = nlevels(cond) * nbasis = 2 * 3 = 6
  expect_equal(ncol(dm_multi), 6)
  # All columns should end with _b01, _b02, or _b03
  expect_true(all(grepl("_b0[1-3]$", cols_multi)))
  # Check specific examples
  expect_true("Multi_condition.a_modulator_b01" %in% cols_multi)
  expect_true("Multi_condition.b_modulator_b03" %in% cols_multi)
  
  hrf_single <- HRF_SPMG1
  # Model with single-basis HRF
  model_single <- event_model(
    onset ~ hrf(condition, modulator, basis=hrf_single, name="Single"), 
    data = events,
    block = ~block,
    sampling_frame = sf
  )
  dm_single <- design_matrix(model_single)
  cols_single <- colnames(dm_single)
  
  # Expected number of columns = nlevels(cond) * nbasis = 2 * 1 = 2
  expect_equal(ncol(dm_single), 2)
  # No columns should end with _b## suffix
  expect_false(any(grepl("_b[0-9]+$", cols_single)))
  # Check specific examples
  expect_equal(sort(cols_single), 
               sort(c("Single_condition.a_modulator", "Single_condition.b_modulator")))
})

# --- Interaction Test ---
test_that("Interaction test: columns named correctly for factor*factor and factor*poly", {
  td <- create_test_data(seed=3)
  events <- td$events
  sf <- td$sf
  events$facA <- factor(rep(c("A1", "A2"), each=5))
  events$facB <- factor(rep(c("B1", "B2", "B1", "B2", "B1"), 2))
  events$contX <- rnorm(10)
  
  # Factor x Factor
  model_ff <- event_model(
    onset ~ hrf(facA, facB, name="FF"), 
    data = events,
    block = ~block,
    sampling_frame = sf
  )
  dm_ff <- design_matrix(model_ff)
  cols_ff <- colnames(dm_ff)
  # Expected: FF_facA.A1_facB.B1, FF_facA.A2_facB.B1, FF_facA.A1_facB.B2, FF_facA.A2_facB.B2
  expect_equal(ncol(dm_ff), 4)
  expect_true(all(startsWith(cols_ff, "FF_facA.")))
  expect_setequal(cols_ff, c("FF_facA.A1_facB.B1", "FF_facA.A2_facB.B1", 
                           "FF_facA.A1_facB.B2", "FF_facA.A2_facB.B2"))
                           
  # Factor x Poly
  model_fp <- event_model(
    onset ~ hrf(facA, Poly(contX, 2), name="FP"), 
    data = events,
    block = ~block,
    sampling_frame = sf
  )
  dm_fp <- design_matrix(model_fp)
  cols_fp <- colnames(dm_fp)
  # Expected: FP_facA.A1_01, FP_facA.A2_01, 
  #           FP_facA.A1_02, FP_facA.A2_02
  expect_equal(ncol(dm_fp), 4)                 
  expect_true(all(startsWith(cols_fp, "FP_facA.")))
  expect_setequal(cols_fp, c("FP_facA.A1_01", "FP_facA.A2_01",
                           "FP_facA.A1_02", "FP_facA.A2_02"))

  # Factor x Poly with multi-basis HRF
  hrf_multi <- HRF_SPMG3
  model_fp_basis <- event_model(
    onset ~ hrf(facA, Poly(contX, 2), basis=hrf_multi, name="FPB"), 
    data = events,
    block = ~block,
    sampling_frame = sf
  )
  dm_fpb <- design_matrix(model_fp_basis)
  cols_fpb <- colnames(dm_fpb)
  # Expected: 4 conditions * 3 basis = 12 columns
  expect_equal(ncol(dm_fpb), 12)
  expect_true(all(startsWith(cols_fpb, "FPB_facA.")))
  expect_true(all(grepl("_b0[1-3]$", cols_fpb))) # Check suffix
  expect_true("FPB_facA.A1_01_b01" %in% cols_fpb) # Corrected
  expect_true("FPB_facA.A2_02_b03" %in% cols_fpb) # Corrected
})

# --- Placeholder for future tests to be added ---

# (Original tests below are mostly for the deprecated create_event_model)
# It might be useful to adapt some scenarios (e.g., subsetting, basis functions) 
# to the new event_model interface later.

# test_that("create_event_model handles various variable specifications", { ... old code ... })
# test_that("create_event_model handles HRF specifications correctly", { ... old code ... })
# test_that("create_event_model handles subset specifications", { ... old code ... })
# test_that("create_event_model handles block-wise onsets correctly", { ... old code ... })
# test_that("event_model handles ~1 block formula correctly", { ... old code ... })

# Factorial design test: formula vs list interfaces
test_that("formula and list interfaces produce identical design matrices for 3x3 factorial design", {
  # Create events with two factors A (a,b,c) and B (x,y,z)
  n_events <- 9
  events <- data.frame(
    A = factor(rep(letters[1:3], each = 3)),
    B = factor(rep(letters[24:26], times = 3)),
    onset = seq_len(n_events),
    block = rep(1, n_events)
  )
  # Single block sampling frame
  sf <- sampling_frame(blocklens = 9, TR = 1)

  # Formula-based model
  fm <- event_model(
    onset ~ hrf(A) + hrf(B),
    data = events,
    block = ~block,
    sampling_frame = sf
  )
  
  # List-based model with same hrfspecs
  specs <- list(hrf(A), hrf(B))
  lm <- event_model(
    formula_or_list = specs,
    data = events,
    block = ~block,
    sampling_frame = sf
  )
  
  # Terms and design matrices should match
  expect_named(fm$terms, names(lm$terms))
  expect_equal(colnames(fm$design_matrix), colnames(lm$design_matrix))
  expect_equal(fm$design_matrix, lm$design_matrix, ignore_attr = TRUE)
})

# 1. Factor × Continuous Interaction with Custom Durations
test_that("event_model handles factor × continuous interaction with custom durations", {
  td <- create_test_data(seed=42, n_events=12, n_blocks=3)
  events <- td$events
  sf     <- td$sf

  # add a random durations vector
  events$durations <- runif(nrow(events), 0.1, 2)

  # Interaction term: condition × modulator, custom durations
  model_ic <- event_model(
    onset ~ hrf(condition, modulator),
    data = events,
    block = ~block,
    sampling_frame = sf,
    durations = events$durations
  )
  dm_ic <- design_matrix(model_ic)

  # Expect two columns: one per level of 'condition' × modulator
  expect_equal(ncol(dm_ic), length(levels(events$condition)))
  

  # Confirm the durations argument didn't break row counts
  expect_equal(nrow(dm_ic), sum(blocklens(sf)))
})

# 2. Fourier Basis on Continuous Modulator
test_that("event_model supports Fourier basis on continuous modulator", {
  td <- create_test_data(seed=7, n_events=8, n_blocks=2)
  events <- td$events; sf <- td$sf

  # Fourier basis of order 4
  model_fourier <- event_model(
    onset ~ hrf(modulator, basis = "fourier", nbasis = 4),
    data = events,
    block = ~block,
    sampling_frame = sf
  )
  dm_f <- design_matrix(model_fourier)
  term_tag <- names(model_fourier$terms)[[1]] # This is the name of the list element
  # The actual term_tag attribute on the event_term object is what matters for naming
  # but for a simple hrf(modulator), both should be "modulator".
  expect_equal(term_tag, "modulator")

  # Should have exactly 4 basis columns
  expect_equal(ncol(dm_f), 4)
  
  # Corrected expectation based on naming_refactoring.md:
  # term_tag = "modulator"
  # condition_tag for simple continuous variable "modulator" is "modulator"
  # HRF basis suffix = "_b##"
  # Final: modulator_modulator_b01, modulator_modulator_b02, ...
  expected_names <- paste0(term_tag, "_modulator", "_b", zeropad(1:4, 4))
  expect_setequal(colnames(dm_f), expected_names)
})

# 3. Mixed Bases via List Interface
test_that("event_model list interface supports mixed bases (Poly + BSpline + Std)", {
  td <- create_test_data(seed=101, n_events=15, n_blocks=3)
  events <- td$events; sf <- td$sf

  specs <- list(
    hrf(condition, name="COND"),
    hrf(modulator, basis = "bspline", nbasis = 4, name="MOD"),
    hrf(Poly(x, 2)), 
    hrf(Standardized(y)) 
  )
  model_mix <- event_model(
    formula_or_list = specs,
    data = events,
    block = ~block,
    sampling_frame = sf
  )
  dm_mix <- design_matrix(model_mix)
 
  # Check term tags based on new rules
  expected_term_tags <- c("COND", "MOD", "Poly_x", "Standardized_y")
  expect_named(model_mix$terms, expected_term_tags)
 
  # Check column names for each term
  actual_colnames <- colnames(dm_mix)

  # COND: COND_condition.a, COND_condition.b
  expect_true("COND_condition.a" %in% actual_colnames)
  expect_true("COND_condition.b" %in% actual_colnames)
  # MOD: MOD_modulator_b01 ... MOD_modulator_b04 (HRF bspline basis applied to modulator event)
  expect_true("MOD_modulator_b01" %in% actual_colnames)
  expect_true("MOD_modulator_b04" %in% actual_colnames)
  # Poly(x,2): Poly_x_01, Poly_x_02
  expect_true("Poly_x_01" %in% actual_colnames)
  expect_true("Poly_x_02" %in% actual_colnames)
  # Standardized(y): Standardized_y_y (Now returns argname 'y')
  expect_true("Standardized_y_y" %in% actual_colnames)
  
  # --- Check Total Columns --- (This calculation relies on the corrected columns/nbasis interaction)
  expected_cols_term1 <- length(levels(events$condition)) * 1 # nbasis=1 default for COND
  expected_cols_term2 <- 1 * 4 # modulator is 1 column (event), HRF nbasis=4 for MOD
  expected_cols_term3 <- 2 * 1 # Poly(x, 2) is 2 columns, nbasis=1 default
  expected_cols_term4 <- 1 * 1 # Standardized(y) is 1 column, nbasis=1 default
  expect_equal(ncol(dm_mix),
               expected_cols_term1 + expected_cols_term2 + expected_cols_term3 + expected_cols_term4)
})

# 4. Duration Recycling and Zero-Duration Events
test_that("event_model durations vector of length 1 is recycled", {
  td <- create_test_data(seed=99, n_events=6, n_blocks=2)
  events <- td$events; sf <- td$sf

  # Single scalar duration
  model_dur <- event_model(
    onset ~ hrf(condition),
    data = events,
    block = ~block,
    sampling_frame = sf,
    durations = 1.5
  )
  dm_dur <- design_matrix(model_dur)

  expect_equal(nrow(dm_dur), sum(blocklens(sf)))
  # We know duration doesn't affect the column count
  expect_equal(ncol(dm_dur), length(levels(events$condition)))
})

# 5. Amplitude Modulation: Factor × Identity Basis
test_that("event_model supports amplitude modulation via identity basis", {
  td <- create_test_data(seed=202, n_events=10, n_blocks=2)
  events <- td$events; sf <- td$sf

  # identity basis of modulator: treat modulator as its own basis
  # For hrf(Ident(modulator)) with no id, term_tag is NULL.
  # The term name in model_amp$terms might be auto-generated if make_term_tag returns NULL.
  # We care about the final column name and the term_tag attribute.
  model_amp <- event_model(
    onset ~ hrf(Ident(modulator)), # Wrap in Ident
    data = events,
    block = ~block,
    sampling_frame = sf
  )
  dm_amp <- design_matrix(model_amp)
  
  # Check term_tag attribute on the event_term object itself
  term_obj_name <- names(model_amp$terms)[[1]] 
  term_tag_attr <- attr(model_amp$terms[[term_obj_name]], "term_tag")
  expect_null(term_tag_attr) # term_tag attribute should be NULL for Ident() only with no id
  # Single continuous variable Identity(modulator) -> 1 column
  expect_equal(ncol(dm_amp), 1)
  # Check final name: condition_tag (modulator) directly
  expect_equal(colnames(dm_amp), "modulator") # Corrected
})

test_that("event_model correctly names columns for Ident() and combined basis functions", {
  td <- create_test_data(n_events = 10, n_blocks = 1) # Simpler data for these tests
  events <- td$events
  sf <- td$sf
  events$RT1 <- rnorm(10)
  events$RT2 <- rnorm(10)
  events$Age <- rnorm(10)

  # --- Ident() Naming Tests ---
  # 1. Simple Ident
  model_ident_simple <- event_model(onset ~ hrf(Ident(RT1, RT2)), data = events, block = ~block, sampling_frame = sf)
  cols_ident_simple <- colnames(design_matrix(model_ident_simple))
  expect_setequal(cols_ident_simple, c("RT1", "RT2"))

  # 2. Ident with HRF basis
  model_ident_hrf <- event_model(onset ~ hrf(Ident(RT1, RT2), basis="spmg2"), data = events, block = ~block, sampling_frame = sf)
  cols_ident_hrf <- colnames(design_matrix(model_ident_hrf))
  expect_setequal(cols_ident_hrf, c("RT1_b01", "RT1_b02", "RT2_b01", "RT2_b02"))

  # 3. Ident with id
  model_ident_id <- event_model(onset ~ hrf(Ident(RT1, RT2), id="myvars"), data = events, block = ~block, sampling_frame = sf)
  cols_ident_id <- colnames(design_matrix(model_ident_id))
  expect_setequal(cols_ident_id, c("myvars_RT1", "myvars_RT2"))

  # 4. Ident with id and HRF basis
  model_ident_id_hrf <- event_model(onset ~ hrf(Ident(RT1, RT2), id="myvars", basis="spmg2"), data = events, block = ~block, sampling_frame = sf)
  cols_ident_id_hrf <- colnames(design_matrix(model_ident_id_hrf))
  expect_setequal(cols_ident_id_hrf, c("myvars_RT1_b01", "myvars_RT1_b02", "myvars_RT2_b01", "myvars_RT2_b02"))

  # --- Ident() Clash Test ---
  # Expect warning because 'RT1' will be generated by both hrf() terms initially
  expect_warning(
    model_ident_clash <- event_model(onset ~ hrf(Ident(RT1, Age)) + hrf(Ident(RT1, RT2)), 
                                   data = events, block = ~block, sampling_frame = sf),
    regexp = "Duplicate column names detected and automatically resolved"
  )
  cols_ident_clash <- colnames(design_matrix(model_ident_clash))
  # Order might matter here if make.names is predictable, but setequal is safer for now.
  # We expect RT1, Age, RT1.1 (or similar), RT2
  expect_true("RT1" %in% cols_ident_clash)
  expect_true("Age" %in% cols_ident_clash)
  expect_true(any(grepl("^RT1\\.\\d+$", cols_ident_clash))) # Checks for RT1.1, RT1.2 etc.
  expect_true("RT2" %in% cols_ident_clash)
  expect_equal(length(cols_ident_clash), 4) # Ensure no extra columns
  
  # --- Combined Basis Naming Tests (Poly + HRF) ---
  # Test Poly() without explicit HRF basis (should use default single HRF basis, no _b## suffix)
  model_poly_plain <- event_model(onset ~ hrf(Poly(Age, 2)), 
                                  data = events, block = ~block, sampling_frame = sf)
  cols_poly_plain <- colnames(design_matrix(model_poly_plain))
  # TermTag from Poly(Age,2) is Poly_Age. ConditionTags from columns.Poly are 01, 02.
  # Final: Poly_Age_01, Poly_Age_02
  expect_setequal(cols_poly_plain, c("Poly_Age_01", "Poly_Age_02"))
  
  # Default name for Poly(Age,2) -> term_tag = "Poly_Age"
  model_poly_hrf <- event_model(onset ~ hrf(Poly(Age, 2), basis="spmg2"), 
                                data = events, block = ~block, sampling_frame = sf)
  cols_poly_hrf <- colnames(design_matrix(model_poly_hrf))
  # Expected: Poly_Age_01_b01, Poly_Age_01_b02, Poly_Age_02_b01, Poly_Age_02_b02
  expected_poly_hrf_cols <- c(
    "Poly_Age_01_b01", "Poly_Age_01_b02", 
    "Poly_Age_02_b01", "Poly_Age_02_b02"
  )
  expect_setequal(cols_poly_hrf, expected_poly_hrf_cols)
  
  # Poly + HRF with explicit ID
  model_poly_id_hrf <- event_model(onset ~ hrf(Poly(Age, 2), basis="spmg2", id="age_poly"), 
                                   data = events, block = ~block, sampling_frame = sf)
  cols_poly_id_hrf <- colnames(design_matrix(model_poly_id_hrf))
  # Expected: age_poly_01_b01, age_poly_01_b02, age_poly_02_b01, age_poly_02_b02
  expected_poly_id_hrf_cols <- c(
    "age_poly_01_b01", "age_poly_01_b02", 
    "age_poly_02_b01", "age_poly_02_b02"
  )
  expect_setequal(cols_poly_id_hrf, expected_poly_id_hrf_cols)

  # --- Combined Basis Naming Tests (BSpline + HRF) ---
  # Test BSpline() without explicit HRF basis
  model_bs_plain <- event_model(onset ~ hrf(BSpline(Age, 3)), 
                                data = events, block = ~block, sampling_frame = sf)
  cols_bs_plain <- colnames(design_matrix(model_bs_plain))
  # Expected: BSpline_Age_01, BSpline_Age_02, BSpline_Age_03
  expect_setequal(cols_bs_plain, c("BSpline_Age_01", "BSpline_Age_02", "BSpline_Age_03"))
  
  # Default name for BSpline(Age,3) -> term_tag = "BSpline_Age"
  model_bs_hrf <- event_model(onset ~ hrf(BSpline(Age, 3), basis="spmg2"), 
                              data = events, block = ~block, sampling_frame = sf)
  cols_bs_hrf <- colnames(design_matrix(model_bs_hrf))
  # Expected: BSpline_Age_01_b01 ... BSpline_Age_03_b02
  expected_bs_hrf_cols <- c(
    "BSpline_Age_01_b01", "BSpline_Age_01_b02", 
    "BSpline_Age_02_b01", "BSpline_Age_02_b02",
    "BSpline_Age_03_b01", "BSpline_Age_03_b02"
  )
  expect_setequal(cols_bs_hrf, expected_bs_hrf_cols)
  
  # BSpline + HRF with explicit ID
  model_bs_id_hrf <- event_model(onset ~ hrf(BSpline(Age, 3), basis="spmg2", id="age_bs"), 
                                 data = events, block = ~block, sampling_frame = sf)
  cols_bs_id_hrf <- colnames(design_matrix(model_bs_id_hrf))
  # Expected: age_bs_01_b01 ... age_bs_03_b02
  expected_bs_id_hrf_cols <- c(
    "age_bs_01_b01", "age_bs_01_b02", 
    "age_bs_02_b01", "age_bs_02_b02",
    "age_bs_03_b01", "age_bs_03_b02"
  )
  expect_setequal(cols_bs_id_hrf, expected_bs_id_hrf_cols)

})


# New tests for prefix, subset, and row count errors

test_that("prefix works with multi-variable term", {
  td <- create_test_data(seed = 111)
  events <- td$events
  sf <- td$sf

  model_pre <- event_model(
    onset ~ hrf(condition, modulator, prefix = "pre"),
    data = events,
    block = ~block,
    sampling_frame = sf
  )
  cols <- colnames(design_matrix(model_pre))
  expect_setequal(cols, c("pre_condition.a_modulator", "pre_condition.b_modulator"))
})

test_that("subset expression filters events", {
  td <- create_test_data(seed = 222)
  events <- td$events
  sf <- td$sf
  events$flag <- rep(c(TRUE, FALSE), length.out = nrow(events))

  m_sub <- event_model(onset ~ hrf(condition, subset = flag),
                       data = events, block = ~block, sampling_frame = sf)
  m_manual <- event_model(onset ~ hrf(condition),
                          data = subset(events, flag),
                          block = ~block, sampling_frame = sf)

  expect_equal(design_matrix(m_sub), design_matrix(m_manual), ignore_attr = TRUE)
})

test_that("error when onset length mismatched with data", {
  td <- create_test_data(seed = 333)
  events <- td$events
  sf <- td$sf
  bad_onsets <- events$onset[-nrow(events)]
  expect_error(
    event_model(bad_onsets ~ hrf(condition), data = events,
                block = ~block, sampling_frame = sf),
    "Length of extracted onset variable"
  )
})
</file>

<file path="tests/testthat/test_event_vector.R">
library(testthat)
#library(fmrireg)
library(tibble)

testthat::local_edition(3)

# Helper function to capture cli print output
# Note: Capturing exact cli output can be brittle. 
# Consider verify_output() or focusing on error/no-error for print tests.
capture_cli_print <- function(x) {
  # Force simpler cli output for capture by disabling dynamic features
  old_opts <- options(cli.dynamic = FALSE)
  on.exit(options(old_opts), add = TRUE) # Restore options on exit

  # Sink output to a temp file
  tmp <- tempfile()
  con <- file(tmp, open = "wt")
  sink(con, type = "output")
  sink(con, type = "message") # Capture messages too, just in case
  # on.exit ensures cleanup happens when function exits (normally or error)
  on.exit({
      sink(type = "output") # Close the sink directed to 'con'
      sink(type = "message")# Close the message sink directed to 'con'
      close(con)           # Close the file connection
      unlink(tmp)          # Delete the temp file
  }, add = TRUE)

  print(x) # Execute the print method, output goes to 'con'

  # The on.exit handler will close sinks and connection *after* this point
  # allowing us to read the file safely.
  out <- readLines(tmp)
  paste(out, collapse = "\n")
}

# Reference event creation using internal constructor for comparison
create_internal_event <- function(...) {
    fmrireg:::event(...)
}

# ==================================
# Tests for event_* wrappers
# ==================================

test_that("event_factor wrapper works and creates correct event object", {
  fac <- factor(c("A", "B", "A", "C", "B"))
  onsets <- c(0, 10, 20, 30, 40)
  ef <- event_factor(fac, "condition", onsets, rep(1, 5))
  
  expect_s3_class(ef, "event") # Check for unified class
  expect_s3_class(ef, "event_seq")
  expect_equal(ef$varname, "condition", ignore_attr = TRUE) 
  expect_equal(length(ef$onsets), 5)
  expect_false(is_continuous(ef)) # Use unified S3 method
  expect_true(is_categorical(ef)) # Use unified S3 method
  
  # Check internal structure
  expect_true(is.matrix(ef$value))
  expect_equal(ef$value[,1], as.integer(fac), ignore_attr = TRUE) # Should store integer codes
  expect_equal(levels(ef), c("A", "B", "C"), ignore_attr = TRUE) # Use S3 method, checks meta$levels
  expect_equal(ef$meta$levels, c("A", "B", "C"), ignore_attr = TRUE) # Check meta directly
  expect_null(ef$meta$basis)
})

test_that("event_variable wrapper works and creates correct event object", {
  vals <- rnorm(5)
  onsets <- seq(0, 40, length.out = 5)
  ev <- event_variable(vals, "continuous", onsets, rep(1, 5))
  
  expect_s3_class(ev, "event") # Check for unified class
  expect_equal(ev$varname, "continuous", ignore_attr = TRUE)
  expect_equal(length(ev$onsets), 5)
  expect_true(is_continuous(ev)) # Use unified S3 method
  expect_false(is_categorical(ev)) # Use unified S3 method
  
  # Check internal structure
  expect_true(is.matrix(ev$value))
  expect_equal(ev$value[,1], vals, ignore_attr = TRUE)
  expect_equal(levels(ev), "continuous", ignore_attr = TRUE) # Use S3 method, checks colnames
  expect_null(ev$meta)
})

test_that("event_matrix wrapper works and creates correct event object", {
  mat <- matrix(rnorm(15), ncol = 3)
  colnames(mat) <- c("V1", "V2", "V3")
  onsets <- seq(0, 40, length.out = 5)
  em <- event_matrix(mat, "matrix_var", onsets, rep(1, 5))
  
  expect_s3_class(em, "event") # Check for unified class
  expect_equal(em$varname, "matrix_var", ignore_attr = TRUE)
  expect_equal(length(em$onsets), 5)
  expect_true(is_continuous(em)) # Use unified S3 method
  
  # Check internal structure
  expect_true(is.matrix(em$value))
  expect_equal(dim(em$value), c(5, 3))
  expect_equal(em$value, mat, ignore_attr = TRUE)
  expect_equal(levels(em), c("V1", "V2", "V3"), ignore_attr = TRUE) # Use S3 method, checks colnames
  expect_equal(columns(em), c("V1", "V2", "V3"), ignore_attr = TRUE) # Alias
  expect_null(em$meta)
})

test_that("event_matrix sanitizes colnames when necessary", {
  mat <- matrix(rnorm(4), ncol = 2)
  colnames(mat) <- c("A B", "C-D")
  onsets <- c(1, 2)
  ev <- event_matrix(mat, "mat", onsets, rep(1, 2))
  expect_equal(levels(ev), .sanitizeName(c("A B", "C-D")), ignore_attr = TRUE)
})

# Add test for event_basis wrapper
test_that("event_basis wrapper works and creates correct event object", {
  skip_if_not_installed("splines")
  x_vals <- 1:5
  basis <- BSpline(x_vals, degree=3) 
  # Updated to match new naming scheme: just zero-padded indices
  expected_cols <- c("01", "02", "03") 
  # Expected varname uses the name stored in the basis object now
  expected_varname <- "bs_x_vals"
  
  onsets <- seq(0, 40, length.out = 5)
  # Call without explicit name to test default behaviour
  eb <- event_basis(basis, onsets = onsets, blockids = rep(1, 5))
  
  expect_s3_class(eb, "event") 
  # Check varname uses the restored name from the basis object
  expect_equal(eb$varname, expected_varname, ignore_attr = TRUE)
  expect_equal(length(eb$onsets), 5)
  expect_true(is_continuous(eb)) 
  
  # Check internal structure
  expect_true(is.matrix(eb$value))
  expect_equal(dim(eb$value), dim(basis$y))
  expect_equal(eb$value, basis$y, ignore_attr = TRUE)
  
  # Check columns() output matches the new naming scheme
  expect_equal(columns(eb), expected_cols, ignore_attr = TRUE) 
  expect_equal(levels(eb), expected_cols, ignore_attr = TRUE) 
  
  expect_s3_class(eb$meta$basis, "ParametricBasis")
  #expect_equal(eb$meta$basis, basis, ignore_attr = TRUE)
  expect_null(eb$meta$levels)
})

test_that("BSpline constructor respects degree argument", {
  skip_if_not_installed("splines")
  x <- seq(0, 1, length.out = 10)
  deg <- 4
  b <- BSpline(x, degree = deg)
  expect_equal(ncol(b$y), deg)
  expect_equal(nbasis(b), deg)
})

# ==================================
# Tests for event_term
# ==================================

test_that("event_term creation and processing works", {
  x1 <- factor(rep(letters[1:3], 2))
  x2 <- rnorm(6)
  onsets <- seq(0, 50, length.out = 6)
  blockids <- rep(1, 6)
  eterm <- event_term(list(Condition = x1, Modulator = x2), onsets, blockids)
  
  expect_s3_class(eterm, "event_term")
  expect_s3_class(eterm, "event_seq")
  expect_equal(length(eterm$events), 2)
  expect_s3_class(eterm$events$Condition, "event") 
  expect_s3_class(eterm$events$Modulator, "event")
  # $varname is no longer the term tag, it's based on original inputs
  # Check attributes for term_tag instead in later tests
  # expect_equal(eterm$varname, "Condition:Modulator", ignore_attr = TRUE)
  expect_false(is_continuous(eterm$events$Condition))
  expect_true(is_continuous(eterm$events$Modulator))
  
  # Check event_table construction (relies on elements())
  etab <- event_table(eterm)
  expect_s3_class(etab, "tbl_df")
  expect_equal(names(etab), c("Condition", "Modulator"), ignore_attr = TRUE)
  expect_equal(nrow(etab), 6)
  expect_true(is.factor(etab$Condition))
  # elements(..., what="labels") now returns sanitized varname for continuous
  expect_equal(etab$Modulator, rep("Modulator", 6), ignore_attr = TRUE) 
  expect_equal(levels(etab$Condition), c("a","b","c"), ignore_attr = TRUE)
  
  # Test subset functionality within event_term (passed down to event())
  subset_idx <- x2 > 0
  subset_term <- event_term(list(Condition = x1, Modulator = x2), onsets, blockids, 
                           subset = subset_idx)
  n_subset <- sum(subset_idx)
  expect_equal(length(subset_term$onsets), n_subset)
  expect_equal(length(subset_term$events$Condition$onsets), n_subset)
  expect_equal(length(subset_term$events$Modulator$onsets), n_subset)
  expect_equal(nrow(event_table(subset_term)), n_subset)
  expect_equal(subset_term$events$Modulator$value[,1], x2[subset_idx], ignore_attr = TRUE)
})

# ==================================
# Tests for .checkEVArgs & Validation (should still work)
# ==================================

test_that("event sequence validation in .checkEVArgs works", {
  # Test increasing blockids validation
  fac <- factor(c("A", "B", "A"))
  onsets <- c(0, 10, 20)
  expect_error(event_factor(fac, "condition", onsets, c(2, 1, 3)), 
               "blockids.*not non-decreasing")
  
  # Test onset ordering within blocks
  expect_error(event_factor(fac, "condition", c(10, 0, 20), c(1, 1, 2)), 
               regexp="Onsets not strictly increasing")
  
  # Test NA handling in onsets
  expect_error(event_factor(fac, "condition", c(0, NA, 20), c(1, 1, 2)), 
               regexp="NA in onsets")
               
  # Test length mismatches (now checked earlier or by recycle_or_error)
  expect_error(event_factor(fac, "condition", onsets = onsets[1:2], blockids = c(1,1,1)))
  expect_error(event_variable(1:3, "condition", onsets = onsets, blockids = c(1,1)))
  expect_error(event_factor(fac, "condition", onsets = onsets, durations = 1:2))
})


test_that("internal event() constructor handles subsetting", {
  vals <- 1:5
  onsets <- c(10, 20, 30, 40, 50)
  blockids <- c(1, 1, 2, 2, 2)
  durations <- c(1, 1, 1, 2, 2)
  subset_idx <- c(TRUE, FALSE, TRUE, FALSE, TRUE)
  
  ev_sub <- create_internal_event(vals, "sub_test", onsets, blockids, durations, subset = subset_idx)
  
  expect_equal(length(ev_sub$onsets), 3)
  expect_equal(ev_sub$onsets, onsets[subset_idx], ignore_attr = TRUE)
  expect_equal(ev_sub$blockids, blockids[subset_idx], ignore_attr = TRUE)
  expect_equal(ev_sub$durations, durations[subset_idx], ignore_attr = TRUE) # Duration recycled *before* subsetting
  expect_equal(nrow(ev_sub$value), 3)
  expect_equal(ev_sub$value[,1], vals[subset_idx], ignore_attr = TRUE)
})

test_that("internal event() handles duration recycling", {
    vals <- 1:4
    onsets <- c(1,2,3,4)
    blockids <- c(1,1,2,2)
    ev_d0 <- event(vals, "d0", onsets, blockids) # Default duration 0
    expect_equal(ev_d0$durations, rep(0, 4), ignore_attr = TRUE)
       
    ev_d1 <- event(vals, "d1", onsets, blockids, durations = 2)
    expect_equal(ev_d1$durations, rep(2, 4), ignore_attr = TRUE)
    
    ev_dvec <- event(vals, "dvec", onsets, blockids, durations = c(1,1,5,5))
    expect_equal(ev_dvec$durations, c(1,1,5,5), ignore_attr = TRUE)
    
    # Error for wrong length duration
    expect_error(event(vals, "derr", onsets, blockids, durations = 1:3))
})

# ==================================
# NEW Tests for S3 methods
# ==================================

# Setup common event objects for S3 tests
fac <- factor(rep(c("B", "A"), length.out=5))
onsets <- c(1, 2, 3, 4, 5)
blockids <- c(1, 1, 1, 1, 1)
event_fac <- event_factor(fac, "Condition", onsets, blockids)
event_num <- event_variable(1:5, "Modulator", onsets, blockids)
event_mat <- event_matrix(matrix(1:10, 5, 2, dimnames=list(NULL,c("M1","M2"))), "Matrix", onsets, blockids)

skip_if_not_installed("splines")
# Recreate basis object to ensure it has correct argname stored
basis_arg <- 1:5 
basis <- BSpline(basis_arg, degree=3)
event_bas <- event_basis(basis, onsets = onsets, blockids = blockids)

test_that("levels.event / columns.event work correctly", {
  # Factor levels are unchanged
  expect_equal(levels(event_fac), c("A", "B"), ignore_attr = TRUE)
  expect_equal(columns(event_fac), c("A", "B"), ignore_attr = TRUE)
  
  # Continuous variables now return sanitized name via continuous_token
  expect_equal(levels(event_num), "Modulator", ignore_attr = TRUE)
  expect_equal(columns(event_num), "Modulator", ignore_attr = TRUE)
  
  # Matrices return sanitized colnames
  expect_equal(levels(event_mat), c("M1", "M2"), ignore_attr = TRUE)
  expect_equal(columns(event_mat), c("M1", "M2"), ignore_attr = TRUE)
  
  # Basis objects return new naming scheme
  expected_bs_cols <- c("01", "02", "03") # Expect 0-padding
  expect_equal(levels(event_bas), expected_bs_cols, ignore_attr = TRUE)
  expect_equal(columns(event_bas), expected_bs_cols, ignore_attr = TRUE)
})

test_that("is_continuous.event / is_categorical.event work correctly", {
  expect_false(is_continuous(event_fac))
  expect_true(is_categorical(event_fac))
  
  expect_true(is_continuous(event_num))
  expect_false(is_categorical(event_num))
  
  expect_true(is_continuous(event_mat))
  expect_false(is_categorical(event_mat))
  
  expect_true(is_continuous(event_bas))
  expect_false(is_categorical(event_bas))
})

test_that("cells.event works correctly", {
  # Factor
  cells_fac <- cells(event_fac)
  expect_s3_class(cells_fac, "tbl_df")
  expect_equal(names(cells_fac), "Condition", ignore_attr = TRUE)
  expect_equal(nrow(cells_fac), 2) # Unique levels A, B
  expect_equal(cells_fac$Condition, as.factor(c("A", "B")), ignore_attr = TRUE)
  expect_equal(attr(cells_fac, "count"), c(A=2L, B=3L), ignore_attr = TRUE)
  
  # Numeric (continuous represented by varname)
  cells_num <- cells(event_num)
  expect_s3_class(cells_num, "tbl_df")
  expect_equal(names(cells_num), "Modulator", ignore_attr = TRUE)
  expect_equal(nrow(cells_num), 1) 
  expect_equal(cells_num$Modulator, "Modulator", ignore_attr = TRUE)
  expect_equal(attr(cells_num, "count"), 5L, ignore_attr = TRUE) # Number of events
  
  # Matrix (continuous represented by varname)
  cells_mat <- cells(event_mat)
  expect_s3_class(cells_mat, "tbl_df")
  expect_equal(names(cells_mat), "Matrix", ignore_attr = TRUE)
  expect_equal(nrow(cells_mat), 1) 
  expect_equal(cells_mat$Matrix, "Matrix", ignore_attr = TRUE)
  expect_equal(attr(cells_mat, "count"), 5L, ignore_attr = TRUE) # Number of events
  
  # Basis (continuous represented by varname)
  cells_bas <- cells(event_bas)
  expect_s3_class(cells_bas, "tbl_df")
  expect_equal(names(cells_bas), .sanitizeName(basis$name), ignore_attr = TRUE)
  expect_equal(nrow(cells_bas), 1)
  expect_equal(cells_bas[[1]], .sanitizeName(basis$name), ignore_attr = TRUE)
  expect_equal(attr(cells_bas, "count")[[1]], 5L, ignore_attr = TRUE) # Number of events
})

test_that("elements.event works correctly", {
  # Factor: what="values" (returns matrix with codes)
  els_fac_vT <- elements(event_fac, what = "values")
  expect_true(is.matrix(els_fac_vT))
  expect_equal(els_fac_vT, matrix(c(2L, 1L, 2L, 1L, 2L), ncol=1), ignore_attr = TRUE)
  
  # Factor: what="labels" (returns factor)
  els_fac_vF <- elements(event_fac, what = "labels")
  expect_true(is.factor(els_fac_vF))
  expect_equal(els_fac_vF, factor(c("B", "A", "B", "A", "B"), levels=c("A","B")), ignore_attr = TRUE)
  
  # Numeric: what="values" (returns matrix)
  els_num_vT <- elements(event_num, what = "values")
  expect_true(is.matrix(els_num_vT))
  expect_equal(els_num_vT, matrix(1:5, ncol=1), ignore_attr = TRUE)
  
  # Numeric: what="labels" (returns vector of varnames)
  els_num_vF <- elements(event_num, what = "labels")
  expect_true(is.character(els_num_vF))
  expect_equal(els_num_vF, rep("Modulator", 5), ignore_attr = TRUE)
  
  # Matrix: what="values" (returns matrix)
  els_mat_vT <- elements(event_mat, what = "values")
  expect_true(is.matrix(els_mat_vT))
  expect_equal(els_mat_vT, event_mat$value, ignore_attr = TRUE)
  
  # Matrix: what="labels" (returns matrix of colnames)
  els_mat_vF <- elements(event_mat, what = "labels")
  expect_true(is.matrix(els_mat_vF))
  expected_mat_vf <- matrix(rep(c("M1","M2"), each=5), ncol=2)
  colnames(expected_mat_vf) <- c("M1", "M2")
  expect_equal(els_mat_vF, expected_mat_vf, ignore_attr = TRUE)
  
  # Basis: what="values" (returns matrix)
  els_bas_vT <- elements(event_bas, what = "values")
  expect_true(is.matrix(els_bas_vT))
  expect_equal(els_bas_vT, event_bas$value, ignore_attr = TRUE)
  
  # Basis: what="labels" (returns matrix of level/colnames)
  els_bas_vF <- elements(event_bas, what = "labels")
  expect_true(is.matrix(els_bas_vF))
  expected_bas_vf <- matrix(rep(levels(basis), each=5), ncol=length(levels(basis)))
  colnames(expected_bas_vf) <- levels(basis)
  expect_equal(els_bas_vF, expected_bas_vf, ignore_attr = TRUE)
})

# ==================================
# NEW Tests for Downstream Compatibility
# ==================================

# Setup a common event term for compatibility tests
fac_comp <- factor(rep(c("A", "B"), each=3))
num_comp <- rep(c(10, 20, 30), 2)
onsets_comp <- c(10, 20, 30, 110, 120, 130)
blockids_comp <- c(1, 1, 1, 2, 2, 2)

term_comp <- event_term(list(Condition = fac_comp, Modulator = num_comp),
                        onsets = onsets_comp,
                        blockids = blockids_comp)

test_that("design_matrix.event_term output is consistent", {
  dm <- design_matrix(term_comp)
  
  # Check dimensions
  expect_equal(nrow(dm), 6)
  
  # Check column names using conditions() as the source of truth
  # conditions() itself will be updated in Phase 3, so this test might need 
  # further adjustment later. For now, assume conditions() output is the target.
  # *** NOTE: This test WILL FAIL until conditions() is updated ***
  expected_conditions <- conditions(term_comp, drop.empty = FALSE) 
  dm_dropped <- design_matrix(term_comp, drop.empty = TRUE)
  expected_conditions_dropped <- conditions(term_comp, drop.empty = TRUE)
  
  # Test 1: Column names match conditions output (this is the goal)
  # expect_identical(colnames(dm_dropped), expected_conditions_dropped)
  expect_true(TRUE) # Placeholder until conditions() is updated
  
  # Test 2: Verify the expected format based on NEW grammar rules 
  # (This anticipates Phase 3 changes for testing purposes)
  # Expected: Condition.A_Modulator, Condition.B_Modulator
  # expect_setequal(expected_conditions_dropped, 
  #                 c("Condition.A_Modulator", "Condition.B_Modulator"))
                  
  # Use snapshot testing for the *values* - should remain unchanged
  #expect_snapshot(as.data.frame(dm_dropped))
  
  # Test case with continuous only
  term_cont <- event_term(list(Modulator = num_comp), 
                          onsets = onsets_comp, blockids = blockids_comp)
  dm_cont <- design_matrix(term_cont)
  cond_cont <- conditions(term_cont) # This will change in Phase 3
  expect_equal(ncol(dm_cont), 1)
  # expect_identical(colnames(dm_cont), cond_cont) # Will fail until Phase 3
  # expect_equal(cond_cont, "Modulator") # Old output
  expect_equal(colnames(dm_cont), "Modulator") # Check raw name for now
  expect_equal(dm_cont[[1]], num_comp, ignore_attr = TRUE) # Check values using [[1]]
  #expect_snapshot(as.data.frame(dm_cont))
})

# ... (Fcontrasts test might need updates after conditions() changes)

# Test cells attribute count consistency
test_that("cells.event_term count attribute is correct", {
    term_fac_only <- event_term(list(Condition = fac_comp),
                              onsets = onsets_comp, blockids = blockids_comp)
    cells_fac <- cells(term_fac_only)
    # fac_comp has 3 'A' and 3 'B'
    expect_equal(attr(cells_fac, "count"), c(A=3L, B=3L), ignore_attr = TRUE)
    
    # Term with subsetting
    subset_idx <- c(TRUE, TRUE, FALSE, TRUE, FALSE, TRUE)
    term_sub <- event_term(list(Condition = fac_comp[subset_idx]),
                            onsets = onsets_comp[subset_idx], 
                            blockids = blockids_comp[subset_idx])
    cells_sub <- cells(term_sub)
    # Kept A, A, B, B -> 2 A, 2 B
    expect_equal(attr(cells_sub, "count"), c(A=2L, B=2L), ignore_attr = TRUE)
    
    # Term with continuous variable (count should be total events)
    term_cont <- event_term(list(Modulator = num_comp), 
                          onsets = onsets_comp, blockids = blockids_comp)
    cells_cont <- cells(term_cont)
    # Cell name for continuous should now be sanitized varname
    expect_equal(names(attr(cells_cont, "count")), "Modulator")
    expect_equal(attr(cells_cont, "count")[[1]], 6L, ignore_attr = TRUE)
})

test_that("Round-trip sanity check (wrappers -> event_term -> design_matrix)", {
  # Define inputs
  fac1 <- factor(rep(c("A", "B"), each=2))
  num1 <- c(10, 10, 20, 20)
  onsets <- c(1, 11, 21, 31)
  blockids <- c(1, 1, 1, 1)
  
  # Create event objects using wrappers
  # ev_fac <- event_factor(fac1, "Factor", onsets, blockids)
  # ev_num <- event_variable(num1, "Number", onsets, blockids)
  
  # Create event_term using the list of *values* (as typical usage)
  et <- event_term(list(Factor = fac1, Number = num1), 
                   onsets = onsets, blockids = blockids)
                   
  # Check levels and cells of the term
  # levels() no longer applies directly to event_term
  
  # cells() should ONLY reflect combinations of factor levels 
  cells_et <- cells(et)
  expect_s3_class(cells_et, "tbl_df")
  expect_equal(names(cells_et), "Factor") 
  expect_equal(nrow(cells_et), 2) 
  expect_equal(cells_et$Factor, factor(c("A","B"), levels=c("A","B")), ignore_attr = TRUE)
  expect_equal(attr(cells_et, "count"), c(A=2L, B=2L), ignore_attr = TRUE) 
  
  # Check design matrix (conditions should include continuous vars)
  # *** NOTE: This test WILL FAIL until conditions() is updated ***
  dm <- design_matrix(et)
  conds <- conditions(et)
  expect_equal(nrow(dm), 4)
  expect_equal(ncol(dm), 2) # Expect 2 columns for Factor.A_Number, Factor.B_Number (new format)
  
  # Check the exact conditions output format (anticipating Phase 3)
  # expect_identical(colnames(dm), conds)
  # expect_setequal(conds, c("Factor.A_Number", "Factor.B_Number"), ignore_attr = TRUE)
  expect_true(TRUE) # Placeholder until conditions() is updated

  
})

# ==================================
# NEW Tests for event() constructor
# ==================================

test_that("internal event() constructor handles types correctly", {
  # Factor input
  fac <- factor(c("B", "A", "B"))
  onsets <- c(1, 2, 3)
  blockids <- c(1, 1, 1)
  ev <- create_internal_event(fac, "Condition", onsets, blockids)
  
  expect_s3_class(ev, "event")
  expect_equal(ev$varname, "Condition", ignore_attr = TRUE)
  expect_equal(ev$onsets, onsets, ignore_attr = TRUE)
  expect_equal(ev$blockids, blockids, ignore_attr = TRUE)
  # levels/columns for simple factor event remain the same
  expect_equal(levels(ev), c("A", "B"), ignore_attr = TRUE)
  expect_equal(columns(ev), c("A", "B"), ignore_attr = TRUE)
})

# ==================================
# NEW Tests for conditions.event_term
# ==================================

# Setup common term for conditions tests
fac_A <- factor(rep(c("L1", "L2"), each = 3))
fac_B <- factor(rep(c("X", "Y", "Z"), 2))
num_P <- c(10, 11, 12, 20, 21, 22)
onsets_cond <- c(1, 5, 10, 101, 105, 110)
blockids_cond <- c(1, 1, 1, 2, 2, 2)

skip_if_not_installed("splines")
basis_P2 <- Poly(num_P, 2)

term_facA <- event_term(list(FacA = fac_A), onsets_cond, blockids_cond)
term_facAB <- event_term(list(FacA = fac_A, FacB = fac_B), onsets_cond, blockids_cond)
term_facA_P2 <- event_term(list(FacA = fac_A, Poly = basis_P2), onsets_cond, blockids_cond)
term_P2 <- event_term(list(Poly = basis_P2), onsets_cond, blockids_cond)
term_empty <- event_term(list(FacA = factor(character(0))), numeric(0), numeric(0))

# Attach dummy hrfspec for basis expansion tests
hrf_single <- HRF_GAUSSIAN # nbasis = 1
hrf_multi <- HRF_SPMG3
hrfspec_single <- list(hrf = hrf_single)
hrfspec_multi <- list(hrf = hrf_multi)

attr(term_facA, "hrfspec") <- hrfspec_multi
attr(term_facAB, "hrfspec") <- hrfspec_multi
attr(term_facA_P2, "hrfspec") <- hrfspec_multi
attr(term_P2, "hrfspec") <- hrfspec_multi
attr(term_empty, "hrfspec") <- hrfspec_multi

test_that("conditions.event_term - basic factor term", {
  conds <- conditions(term_facA)
  expect_equal(conds, c("FacA.L1", "FacA.L2"))
  
  # Check expand_basis=FALSE (default)
  conds_nobasis <- conditions(term_facA, expand_basis = FALSE)
  expect_equal(conds_nobasis, c("FacA.L1", "FacA.L2"))
  
  # Check expand_basis=TRUE
  conds_basis <- conditions(term_facA, expand_basis = TRUE)
  expected_basis <- c("FacA.L1_b01", "FacA.L2_b01", 
                      "FacA.L1_b02", "FacA.L2_b02", 
                      "FacA.L1_b03", "FacA.L2_b03")
  expect_equal(conds_basis, expected_basis)
})

test_that("conditions.event_term - factor interaction", {
  conds <- conditions(term_facAB)
  # Expect: L1_X, L2_X, L1_Y, L2_Y, L1_Z, L2_Z (order from expand.grid)
  expected <- c("FacA.L1_FacB.X", "FacA.L2_FacB.X", 
                "FacA.L1_FacB.Y", "FacA.L2_FacB.Y",
                "FacA.L1_FacB.Z", "FacA.L2_FacB.Z")
  expect_equal(conds, expected)
  
  # Expand basis
  conds_basis <- conditions(term_facAB, expand_basis = TRUE)
  expected_basis <- as.vector(outer(expected, c("_b01", "_b02", "_b03"), paste0))
  expect_equal(conds_basis, expected_basis)
})

test_that("conditions.event_term - factor x continuous interaction", {
  conds <- conditions(term_facA_P2)
  # Updated to match new naming scheme: simplified condition tags
  expected <- c("FacA.L1_01", "FacA.L2_01",
                "FacA.L1_02", "FacA.L2_02") 
  expect_equal(conds, expected)
  
  # Expand basis
  conds_basis <- conditions(term_facA_P2, expand_basis = TRUE)
  # Expect 0-padding for basis indices
  expected_basis <- as.vector(outer(expected, c("_b01", "_b02", "_b03"), paste0))
  expect_equal(conds_basis, expected_basis)
})

test_that("conditions.event_term - continuous only (shortcut and non-shortcut)", {
  # Test non-shortcut case (Poly(2) -> 2 columns)
  conds_P2 <- conditions(term_P2)
  expect_equal(conds_P2, c("01", "02")) # Updated to match new naming scheme
  
  # Expand basis
  conds_P2_basis <- conditions(term_P2, expand_basis = TRUE)
  # Expect 0-padding for basis indices
  expected_basis <- as.vector(outer(c("01", "02"), 
                                    c("_b01", "_b02", "_b03"), paste0))
  expect_equal(conds_P2_basis, expected_basis)
  
  # Test shortcut case (Scale -> 1 column)
  term_scale <- event_term(list(Scaled = Scale(num_P)), onsets_cond, blockids_cond)
  attr(term_scale, "hrfspec") <- hrfspec_multi # Add spec for expand_basis
  
  conds_scale <- conditions(term_scale)
  expect_equal(conds_scale, "num_P") # Updated to match new naming scheme (no z_ prefix)
  
  conds_scale_basis <- conditions(term_scale, expand_basis = TRUE)
  expect_equal(conds_scale_basis, c("num_P_b01", "num_P_b02", "num_P_b03"))
})

test_that("conditions.event_term - drop.empty works", {
  # Create term where one factor level has no events
  fac_sparse <- factor(c("L1", "L1", "L1"), levels = c("L1", "L2"))
  onsets_sparse <- c(1, 5, 10)
  blockids_sparse <- c(1, 1, 1)
  term_sparse <- event_term(list(FacSparse = fac_sparse), onsets_sparse, blockids_sparse)
  attr(term_sparse, "hrfspec") <- hrfspec_multi
  
  conds_all <- conditions(term_sparse, drop.empty = FALSE)
  expect_equal(conds_all, c("FacSparse.L1", "FacSparse.L2"))
  
  # drop.empty=TRUE should now have NO effect, returns same as drop.empty=FALSE
  conds_drop <- conditions(term_sparse, drop.empty = TRUE)
  expect_equal(conds_drop, c("FacSparse.L1", "FacSparse.L2")) 
  
  # Test with expansion
  conds_all_basis <- conditions(term_sparse, drop.empty = FALSE, expand_basis = TRUE)
  expect_equal(conds_all_basis, as.vector(outer(c("FacSparse.L1", "FacSparse.L2"), 
                                               c("_b01", "_b02", "_b03"), paste0)))
                                               
  # drop.empty=TRUE should also have NO effect here
  conds_drop_basis <- conditions(term_sparse, drop.empty = TRUE, expand_basis = TRUE)
  expect_equal(conds_drop_basis, as.vector(outer(c("FacSparse.L1", "FacSparse.L2"), 
                                                c("_b01", "_b02", "_b03"), paste0)))
})

test_that("design_matrix.event_term output matches new conditions format", {
  # This test depends on conditions.event_term being correct now
  dm_dropped <- design_matrix(term_comp, drop.empty = TRUE)
  expected_conditions_dropped <- conditions(term_comp, drop.empty = TRUE)
  
  # Test column names match conditions output
  expect_identical(colnames(dm_dropped), expected_conditions_dropped)
  
  # Check specific names generated by conditions()
  expect_setequal(expected_conditions_dropped, 
                  c("Condition.A_Modulator", "Condition.B_Modulator"))
                  
  # Snapshot values (should be unchanged)
  #expect_snapshot(as.data.frame(dm_dropped))
  
  # Test case with continuous only (Poly(2))
  term_P2_test <- event_term(list(Poly = basis_P2), onsets_cond, blockids_cond)
  dm_cont <- design_matrix(term_P2_test, drop.empty=TRUE)
  cond_cont <- conditions(term_P2_test, drop.empty=TRUE)
  expect_equal(ncol(dm_cont), 2)
  expect_identical(colnames(dm_cont), cond_cont) 
  expect_equal(cond_cont, c("01", "02")) # Updated to match new naming scheme
  #expect_snapshot(as.data.frame(dm_cont))
})

# ... (Fcontrasts test will likely need updates too) ...

test_that("Round-trip sanity check uses new conditions format", {
  # Define inputs
  fac1 <- factor(rep(c("A", "B"), each=2))
  num1 <- c(10, 10, 20, 20)
  onsets <- c(1, 11, 21, 31)
  blockids <- c(1, 1, 1, 1)
  
  # Create event_term 
  et <- event_term(list(Factor = fac1, Number = num1), 
                   onsets = onsets, blockids = blockids)
                   
  # Check design matrix and conditions
  dm <- design_matrix(et)
  conds <- conditions(et)
  expect_equal(nrow(dm), 4)
  expect_equal(ncol(dm), 2) 
  
  # Check conditions output format matches design matrix columns
  expect_identical(colnames(dm), conds)
  expect_setequal(conds, c("Factor.A_Number", "Factor.B_Number"))
})

test_that("conditions(expand_basis=TRUE) matches convolve output structure", {
  # Use term_facA_P2 (Factor x Poly) with hrf_multi (3 basis)
  term_test <- term_facA_P2 
  hrf_test <- hrf_multi
  sf_test <- sampling_frame(blocklens = rep(130,2), TR = 2) # Need a valid sampling frame
  
  # 1. Get conditions with expand_basis=TRUE
  conds_expanded <- conditions(term_test, expand_basis = TRUE, drop.empty=TRUE)
  
  # 2. Get convolved matrix column names
  attr(term_test, "term_tag") <- "TestTerm" 
  cmat <- convolve(term_test, hrf=hrf_test, sampling_frame=sf_test)
  cmat_cols <- colnames(cmat)
  
  # 3. Extract condition+basis part from full column names
  conds_from_convolve <- sub(paste0("^", attr(term_test, "term_tag"), "_"), "", cmat_cols)
  
 # 4. Compare
  expect_setequal(conds_expanded, conds_from_convolve)
})

test_that("conditions handles illegal characters in names/levels", {
  # Setup data with problematic names/levels
  illegal_fac <- factor(c("A/B", "C D"))
  illegal_var <- 1:2
  names(illegal_var) <- c("RT .ms") # Variable name with space and dot
  onsets_ill <- c(1, 10)
  blockids_ill <- c(1, 1)
  
  # Term 1: Illegal factor name and levels
  term1 <- event_term(list(`Fac/Name` = illegal_fac), onsets_ill, blockids_ill)
  attr(term1, "hrfspec") <- hrfspec_single # Assign dummy spec
  attr(term1, "term_tag") <- "IllegalFac"
  
  # Check conditions (should be sanitized)
  conds1 <- conditions(term1)
  expect_equal(conds1, c("Fac.Name.A.B", "Fac.Name.C.D")) # Sanitize uses make.names
  
  # Check convolved name (should use sanitized condition tag)
  cmat1 <- convolve(term1, hrf=hrf_single, sampling_frame=sampling_frame(blocklens=20, TR=2))
  expect_equal(colnames(cmat1), c("IllegalFac_Fac.Name.A.B", "IllegalFac_Fac.Name.C.D"))
  
 
})

# --- Round-Trip Test ---
test_that("Round-trip test: conditions(expand=T) matches stripped convolve colnames", {
  # Use term_facA_P2 (Factor x Poly) with hrf_multi (3 basis)
  term_test <- term_facA_P2 
  hrf_test <- hrf_multi
  sf_test <- sampling_frame(blocklens = rep(130, 2), TR = 2) 
  term_tag <- "RoundTrip"
  attr(term_test, "term_tag") <- term_tag 
  attr(term_test, "hrfspec") <- hrfspec_multi # Ensure hrfspec is attached
  
  # 1. Get convolved colnames
  cmat <- convolve(term_test, hrf=hrf_test, sampling_frame=sf_test)
  cmat_cols <- colnames(cmat)
  
  # 2. Get conditions(expand=T)
  conds_expanded <- conditions(term_test, expand_basis = TRUE, drop.empty=TRUE)
  
  # 3. Strip prefix from convolved names
  prefix_to_strip <- paste0("^", term_tag, "_")
  conds_from_convolve <- sub(prefix_to_strip, "", cmat_cols)
  
  # 4. Compare (use setequal for order robustness)
  expect_setequal(conds_expanded, conds_from_convolve)
  
  # Test with single basis HRF too
  term_test_single <- term_facA # Use simple factor term
  hrf_single_test <- hrf_single
  attr(term_test_single, "term_tag") <- "RoundTripSingle"
  attr(term_test_single, "hrfspec") <- hrfspec_single
  
  cmat_s <- convolve(term_test_single, hrf=hrf_single_test, sampling_frame=sf_test)
  cmat_cols_s <- colnames(cmat_s)
  conds_expanded_s <- conditions(term_test_single, expand_basis = TRUE, drop.empty=TRUE)
  prefix_to_strip_s <- paste0("^", attr(term_test_single, "term_tag"), "_")
  conds_from_convolve_s <- sub(prefix_to_strip_s, "", cmat_cols_s)
  
  expect_setequal(conds_expanded_s, conds_from_convolve_s)
  # For single basis, expand_basis=T should be same as expand_basis=F
  expect_equal(conds_expanded_s, conditions(term_test_single, expand_basis=FALSE, drop.empty=TRUE))
})
</file>

<file path="tests/testthat/test_fmriglm.R">
options(mc.cores=1)
facedes <- read.table(system.file("extdata", "face_design.txt", package = "fmrireg"), header=TRUE)
facedes$repnum <- factor(facedes$rep_num)

library(testthat)
library(foreach)
library(ggrepel)

gen_mask_file <- function(d, perc) {
  arr = array(0,d)
  vals <- ifelse(runif(prod(d)) > .5, 1, 0)
  vol <- NeuroVol(vals, NeuroSpace(d))
  fname <- paste0(tempfile(), ".nii")
  write_vol(vol, fname)
  fname
}

gen_fake_dataset <- function(d, nscans) {
  
  onames <- vector(length=nscans, mode="list")
  for (i in 1:nscans) {
    arr <- array(rnorm(prod(d)), d)
    bspace <- neuroim2::NeuroSpace(dim=d)
    vec <- neuroim2::NeuroVec(arr, bspace)
    fname <- paste0(tempfile(), ".nii")
    write_vec(vec, fname)
    onames[i] <- fname
  }
  onames
}


## test that latent and fmri_mem_dataset of same underlying latent dataset produce the same betas

test_that("can construct and run a simple fmri glm from in memory dataset", {
  
   scans <- lapply(1:length(unique(facedes$run)), function(i) {
     arr <- array(rnorm(10*10*10*244), c(10,10,10, 244))
     bspace <- neuroim2::NeuroSpace(dim=c(10,10,10,244))
     neuroim2::NeuroVec(arr, bspace)
   })
   
   mask <- neuroim2::LogicalNeuroVol(array(rnorm(10*10*10), c(10,10,10)) > 0, neuroim2::NeuroSpace(dim=c(10,10,10)))
   
   #scans <- list.files("test_data/images_study/epi/", "rscan0.*nii", full.names=TRUE)
   dset <- fmri_mem_dataset(scans=scans, 
                        mask=mask, 
                        TR=1.5, 
                        event_table=facedes)
   
   
   mod <- fmri_lm(onset ~ hrf(repnum), block = ~ run, dataset=dset, durations=0, strategy="chunkwise", nchunks=4)
   expect_true(!is.null(mod))
  
   # Fast path version
   mod_fast <- fmri_lm(onset ~ hrf(repnum), block = ~ run, dataset=dset, durations=0, strategy="chunkwise", nchunks=4, use_fast_path=TRUE)
   expect_true(!is.null(mod_fast))
   
   # Compare results
   expect_equal(coef(mod), coef(mod_fast), tolerance=1e-8)
   expect_equal(standard_error(mod), standard_error(mod_fast), tolerance=1e-8)
   expect_equal(stats(mod), stats(mod_fast), tolerance=1e-8)

})

test_that("can construct and run a simple fmri glm from in memory dataset and one contrast", {
  
  scans <- lapply(1:length(unique(facedes$run)), function(i) {
    arr <- array(rnorm(10*10*10*244), c(10,10,10, 244))
    bspace <- neuroim2::NeuroSpace(dim=c(10,10,10,244))
    neuroim2::NeuroVec(arr, bspace)
  })
  
  mask <- neuroim2::LogicalNeuroVol(array(rnorm(10*10*10), c(10,10,10)) > 0, neuroim2::NeuroSpace(dim=c(10,10,10)))
  
  #scans <- list.files("test_data/images_study/epi/", "rscan0.*nii", full.names=TRUE)
  dset <- fmri_mem_dataset(scans=scans, 
                           mask=mask, 
                           TR=1.5, 
                           event_table=facedes)
  
  con <<- contrast_set(pair_contrast( ~ repnum == 1, ~ repnum == 2, name="rep2_rep1"))
  
  mod1 <- fmri_lm(onset ~ hrf(repnum,  contrasts=con), block = ~ run, dataset=dset, durations=0, use_fast_path=TRUE)
  mod1a <- fmri_lm(onset ~ hrf(repnum,  contrasts=con), block = ~ run, dataset=dset, durations=0)
  mod2 <- fmri_lm(onset ~ hrf(repnum,  contrasts=con), block = ~ run, dataset=dset, durations=0, 
                  strategy="chunkwise", nchunks=10, verbose=FALSE)
  
  expect_true(!is.null(mod1))
  expect_true(!is.null(mod1a))
  expect_true(!is.null(mod2))
  
  expect_equal(ncol(stats(mod1, "contrasts")), 1)
  expect_equal(ncol(stats(mod1a, "contrasts")), 1)
  expect_equal(ncol(stats(mod2, "contrasts")), 1)
 
  # Fast path versions
  mod1_fast <- fmri_lm(onset ~ hrf(repnum,  contrasts=con), block = ~ run, dataset=dset, durations=0, use_fast_path=TRUE)
  mod2_fast <- fmri_lm(onset ~ hrf(repnum,  contrasts=con), block = ~ run, dataset=dset, durations=0, 
                       strategy="chunkwise", nchunks=10, verbose=FALSE, use_fast_path=TRUE)

  # Compare original runwise (mod1) vs fast runwise (mod1_fast)
  expect_equal(coef(mod1), coef(mod1_fast), tolerance=1e-8)
  expect_equal(standard_error(mod1), standard_error(mod1_fast), tolerance=1e-8)
  expect_equal(stats(mod1), stats(mod1_fast), tolerance=1e-8)
  expect_equal(coef(mod1, "contrasts"), coef(mod1_fast, "contrasts"), tolerance=1e-8)
  expect_equal(standard_error(mod1, "contrasts"), standard_error(mod1_fast, "contrasts"), tolerance=1e-8)
  expect_equal(stats(mod1, "contrasts"), stats(mod1_fast, "contrasts"), tolerance=1e-8)
  
  # Compare original chunkwise (mod2) vs fast chunkwise (mod2_fast)
  expect_equal(coef(mod2), coef(mod2_fast), tolerance=1e-8)
  expect_equal(standard_error(mod2), standard_error(mod2_fast), tolerance=1e-8)
  expect_equal(stats(mod2), stats(mod2_fast), tolerance=1e-8)
  expect_equal(coef(mod2, "contrasts"), coef(mod2_fast, "contrasts"), tolerance=1e-8)
  expect_equal(standard_error(mod2, "contrasts"), standard_error(mod2_fast, "contrasts"), tolerance=1e-8)
  expect_equal(stats(mod2, "contrasts"), stats(mod2_fast, "contrasts"), tolerance=1e-8)
 
})

test_that("can construct and run a simple fmri glm from a matrix_dataset with 1 column", {
  
  vals <- rep(rnorm(244),6)
  dset <- matrix_dataset(as.matrix(vals),TR=1.5, run_length=rep(244,6), event_table=facedes)
  
  c1 <- pair_contrast( ~ repnum == 1, ~ repnum == 2, name="rep2_rep1")
  c2 <- pair_contrast( ~ repnum == 3, ~ repnum == 4, name="rep3_rep4")
  con <<- contrast_set(c1,c2)
  
  mod1 <- fmri_lm(onset ~ hrf(repnum,  contrasts=con), block = ~ run, dataset=dset, durations=0)
  mod2 <- fmri_lm(onset ~ hrf(repnum,  contrasts=con), block = ~ run, dataset=dset, durations=0, 
                  strategy="chunkwise", nchunks=1)
  
  expect_true(!is.null(mod1))
  expect_equal(ncol(stats(mod1, "contrasts")), 2)
  expect_equal(ncol(stats(mod2, "contrasts")), 2)
  
  # Fast path versions
  mod1_fast <- fmri_lm(onset ~ hrf(repnum,  contrasts=con), block = ~ run, dataset=dset, durations=0, use_fast_path=TRUE)
  mod2_fast <- fmri_lm(onset ~ hrf(repnum,  contrasts=con), block = ~ run, dataset=dset, durations=0, 
                       strategy="chunkwise", nchunks=1, use_fast_path=TRUE)

  # Compare original runwise (mod1) vs fast runwise (mod1_fast)
  # Coefficients (betas) might differ slightly if only 1 voxel
  expect_equal(as.numeric(coef(mod1)), as.numeric(coef(mod1_fast)), tolerance=1e-8) 
  expect_equal(stats(mod1, "contrasts"), stats(mod1_fast, "contrasts"), tolerance=1e-8)
  expect_equal(standard_error(mod1, "contrasts"), standard_error(mod1_fast, "contrasts"), tolerance=1e-8)
  expect_equal(coef(mod1, "contrasts"), coef(mod1_fast, "contrasts"), tolerance=1e-8)

  # Compare original chunkwise (mod2) vs fast chunkwise (mod2_fast)
  expect_equal(as.numeric(coef(mod2)), as.numeric(coef(mod2_fast)), tolerance=1e-8)
  expect_equal(stats(mod2, "contrasts"), stats(mod2_fast, "contrasts"), tolerance=1e-8)
  expect_equal(standard_error(mod2, "contrasts"), standard_error(mod2_fast, "contrasts"), tolerance=1e-8)
  expect_equal(coef(mod2, "contrasts"), coef(mod2_fast, "contrasts"), tolerance=1e-8)
}) 

test_that("fmri glm for multivariate matrix and complex contrast ", {
  
  vals <- do.call(cbind, lapply(1:100, function(i) rnorm(244*6)))
  fd <- subset(facedes, null == 0 & rt < 2)
  fd$letter <- sample(factor(rep(letters[1:4], length.out=nrow(fd))))
  dset <- matrix_dataset(vals,TR=1.5, run_length=rep(244,6), event_table=fd)
  
  cset <<- contrast_set(pair_contrast( ~ letter %in% c("a", "b"), 
                       ~ letter %in% c("c", "d"),
                       name="abcd_efgh"),
                     pair_contrast( ~ letter %in% c("a", "c"), 
                       ~ letter %in% c("b", "d"),
                       name="ijkl_mnop"),
                     unit_contrast(~ letter, "letter"))
  
  #c3 <- unit_contrast(~ letter, "letter")

 
 # bmod <- baseline_model(basis="constant", degree=1, intercept="none", sframe=dset$sampling_frame)
  mod1 <- fmri_lm(onset ~ hrf(letter,  contrasts=cset), 
                  #baseline_model=bmod,
                  block = ~ run, dataset=dset, durations=0, nchunks=1,strategy="chunkwise")
  
  zz <- stats(mod1, "contrasts")
  expect_equal(ncol(zz),3)
  
  # Fast path version
  mod1_fast <- fmri_lm(onset ~ hrf(letter,  contrasts=cset), 
                       block = ~ run, dataset=dset, durations=0, nchunks=1, strategy="chunkwise", use_fast_path=TRUE)
  
  # Compare original chunkwise (mod1) vs fast chunkwise (mod1_fast)
  expect_equal(coef(mod1), coef(mod1_fast), tolerance=1e-8)
  expect_equal(stats(mod1, "contrasts"), stats(mod1_fast, "contrasts"), tolerance=1e-8)
  expect_equal(standard_error(mod1, "contrasts"), standard_error(mod1_fast, "contrasts"), tolerance=1e-8)
  expect_equal(coef(mod1, "contrasts"), coef(mod1_fast, "contrasts"), tolerance=1e-8)
  expect_true(!is.null(mod1))
  expect_true(!is.null(mod1_fast))
  
})

test_that("can construct and run a simple fmri glm from a matrix_dataset with 2 columns", {
  
  vals <- cbind(rep(rnorm(244),6), rep(rnorm(244),6))
  dset <- matrix_dataset(as.matrix(vals),TR=1.5, run_length=rep(244,6), event_table=facedes)
  
  c1 <- pair_contrast( ~ repnum == 1, ~ repnum == 2, name="rep2_rep1")
  c2 <- pair_contrast( ~ repnum == 2, ~ repnum == 3, name="rep3_rep2")
  con <<- contrast_set(c1,c2)
  
  mod1 <- fmri_lm(onset ~ hrf(repnum,  contrasts=con), block = ~ run, dataset=dset, durations=0)
  mod2 <- fmri_lm(onset ~ hrf(repnum,  contrasts=con), block = ~ run, dataset=dset, durations=0, 
                  strategy="chunkwise", nchunks=1)
  
  expect_true(!is.null(mod1))
  expect_true(!is.null(mod2))
  expect_equal(ncol(stats(mod1, "contrasts")), 2)
  expect_equal(ncol(stats(mod2, "contrasts")), 2)

  # Fast path versions
  mod1_fast <- fmri_lm(onset ~ hrf(repnum,  contrasts=con), block = ~ run, dataset=dset, durations=0, use_fast_path=TRUE)
  mod2_fast <- fmri_lm(onset ~ hrf(repnum,  contrasts=con), block = ~ run, dataset=dset, durations=0, 
                       strategy="chunkwise", nchunks=1, use_fast_path=TRUE)

  # Compare original runwise (mod1) vs fast runwise (mod1_fast)
  expect_equal(coef(mod1), coef(mod1_fast), tolerance=1e-8)
  expect_equal(stats(mod1, "contrasts"), stats(mod1_fast, "contrasts"), tolerance=1e-8)
  expect_equal(standard_error(mod1, "contrasts"), standard_error(mod1_fast, "contrasts"), tolerance=1e-8)
  expect_equal(coef(mod1, "contrasts"), coef(mod1_fast, "contrasts"), tolerance=1e-8)

  # Compare original chunkwise (mod2) vs fast chunkwise (mod2_fast)
  expect_equal(coef(mod2), coef(mod2_fast), tolerance=1e-8)
  expect_equal(stats(mod2, "contrasts"), stats(mod2_fast, "contrasts"), tolerance=1e-8)
  expect_equal(standard_error(mod2, "contrasts"), standard_error(mod2_fast, "contrasts"), tolerance=1e-8)
  expect_equal(coef(mod2, "contrasts"), coef(mod2_fast, "contrasts"), tolerance=1e-8)
  
})


test_that("can construct and run a simple fmri glm two terms and prefix args", {
  
  vals <- cbind(rep(rnorm(244),6), rep(rnorm(244),6))
  dset <- matrix_dataset(as.matrix(vals),TR=1.5, run_length=rep(244,6), event_table=facedes)
  
  
  mod1 <- fmri_lm(onset ~ hrf(repnum, subset=repnum %in% c(1,2), prefix="r12")+ 
                    hrf(repnum, subset=repnum %in% c(3,4), prefix="r34"),
                  block = ~ run, dataset=dset, durations=0)
 
  
  expect_true(!is.null(mod1))
  #expect_true(!is.null(mod2))
  expect_equal(ncol(stats(mod1)), 4)
  #expect_equal(ncol(mod2$result$contrasts$estimate()), 2)
  
  # Fast path version
  mod1_fast <- fmri_lm(onset ~ hrf(repnum, subset=repnum %in% c(1,2), prefix="r12")+ 
                         hrf(repnum, subset=repnum %in% c(3,4), prefix="r34"),
                       block = ~ run, dataset=dset, durations=0, use_fast_path=TRUE)
  
  expect_true(!is.null(mod1_fast))
  expect_equal(ncol(stats(mod1_fast)), 4)
  
  # Compare
  expect_equal(coef(mod1), coef(mod1_fast), tolerance=1e-8)
  expect_equal(stats(mod1), stats(mod1_fast), tolerance=1e-8)
  expect_equal(standard_error(mod1), standard_error(mod1_fast), tolerance=1e-8)
  
})


test_that("can run video fmri design with matrix_dataset", {
  des <- read.table(system.file("extdata", "video_design.txt", package = "fmrireg"), header=TRUE)
  events <- rep(320,7)
  sframe <- sampling_frame(rep(320, length(events)), TR=1.5)
  
  evmod <- event_model(Onset ~ hrf(Video, Condition, basis="spmg1"), 
                       block = ~ run, sampling_frame=sframe, data=des)
  bmod <- baseline_model(basis="bs", degree=4, sframe=sframe)
  fmod <- fmri_model(evmod, bmod)
  
  dset <- matrix_dataset(matrix(rnorm(320*7*100), 320*7, 100),TR=1.5, run_length=rep(320,7), event_table=des)

  #conset <- fmrireg::one_against_all_contrast(levels(des$Video), "Video")
  
  conset <<- do.call("contrast_set", lapply(levels(factor(des$Video)), function(v) {
    f1 <- as.formula(paste("~ Video == ", paste0('"', v, '"')))
    f2 <- as.formula(paste("~ Video != ", paste0('"', v, '"')))
    pair_contrast(f1, f2, name=paste0(v, "_vsall"))
  }))
  
  res1 <- fmrireg:::fmri_lm(Onset ~ hrf(Video, subset=Condition=="Encod", contrasts=conset) + 
                                   hrf(Video, subset=Condition=="Recall", prefix="rec"), block= ~ run, dataset=dset, 
                                  strategy="runwise")
  res2 <- fmrireg:::fmri_lm(Onset ~ hrf(Video, subset=Condition=="Encod", contrasts=conset) + 
                                    hrf(Video, subset=Condition=="Recall", prefix="rec"), block= ~ run, dataset=dset, 
                            strategy="chunkwise", nchunks=12)
  
  res3 <- fmrireg:::fmri_lm(Onset ~ hrf(Video, subset=Condition=="Encod", contrasts=conset) + 
                              hrf(Video, subset=Condition=="Recall", prefix="rec"), block= ~ run, dataset=dset, 
                            strategy="chunkwise", nchunks=1)
  
  expect_true(!is.null(coef(res1)))
  expect_true(!is.null(coef(res2)))
  expect_true(!is.null(coef(res3)))
  
  expect_true(!is.null(coef(res1, "contrasts")))
  expect_true(!is.null(coef(res2, "contrasts")))
  expect_true(!is.null(coef(res3, "contrasts")))
  

  # Fast path versions
  res1_fast <- fmrireg:::fmri_lm(Onset ~ hrf(Video, subset=Condition=="Encod", contrasts=conset) + 
                                   hrf(Video, subset=Condition=="Recall", prefix="rec"), block= ~ run, dataset=dset, 
                                  strategy="runwise", use_fast_path=TRUE)
  res2_fast <- fmrireg:::fmri_lm(Onset ~ hrf(Video, subset=Condition=="Encod", contrasts=conset) + 
                                    hrf(Video, subset=Condition=="Recall", prefix="rec"), block= ~ run, dataset=dset, 
                                  strategy="chunkwise", nchunks=12, use_fast_path=TRUE)
  res3_fast <- fmrireg:::fmri_lm(Onset ~ hrf(Video, subset=Condition=="Encod", contrasts=conset) + 
                              hrf(Video, subset=Condition=="Recall", prefix="rec"), block= ~ run, dataset=dset, 
                            strategy="chunkwise", nchunks=1, use_fast_path=TRUE)
  
  # Compare res1 vs res1_fast (runwise)
  expect_equal(coef(res1), coef(res1_fast), tolerance=1e-8)
  expect_equal(coef(res1, "contrasts"), coef(res1_fast, "contrasts"), tolerance=1e-8)
  expect_equal(stats(res1), stats(res1_fast), tolerance=1e-8)
  expect_equal(stats(res1, "contrasts"), stats(res1_fast, "contrasts"), tolerance=1e-8)
  expect_equal(standard_error(res1), standard_error(res1_fast), tolerance=1e-8)
  expect_equal(standard_error(res1, "contrasts"), standard_error(res1_fast, "contrasts"), tolerance=1e-8)
  
  # Compare res2 vs res2_fast (chunkwise, many chunks)
  expect_equal(coef(res2), coef(res2_fast), tolerance=1e-8)
  expect_equal(coef(res2, "contrasts"), coef(res2_fast, "contrasts"), tolerance=1e-8)
  expect_equal(stats(res2), stats(res2_fast), tolerance=1e-8)
  expect_equal(stats(res2, "contrasts"), stats(res2_fast, "contrasts"), tolerance=1e-8)
  expect_equal(standard_error(res2), standard_error(res2_fast), tolerance=1e-8)
  expect_equal(standard_error(res2, "contrasts"), standard_error(res2_fast, "contrasts"), tolerance=1e-8)

  # Compare res3 vs res3_fast (chunkwise, 1 chunk)
  expect_equal(coef(res3), coef(res3_fast), tolerance=1e-8)
  expect_equal(coef(res3, "contrasts"), coef(res3_fast, "contrasts"), tolerance=1e-8)
  expect_equal(stats(res3), stats(res3_fast), tolerance=1e-8)
  expect_equal(stats(res3, "contrasts"), stats(res3_fast, "contrasts"), tolerance=1e-8)
  expect_equal(standard_error(res3), standard_error(res3_fast), tolerance=1e-8)
  expect_equal(standard_error(res3, "contrasts"), standard_error(res3_fast, "contrasts"), tolerance=1e-8)

})

test_that("can run video fmri design with fmri_file_dataset", {
  library(neuroim2)
  des <- read.table(system.file("extdata", "video_design.txt", package = "fmrireg"), header=TRUE)
  events <- rep(320,7)
  sframe <- sampling_frame(rep(320, length(events)), TR=1.5)
  
  scans <- gen_fake_dataset(c(10,10,10,320), 7)
  maskfile <- gen_mask_file(c(10,10,10))
  
  dset <- fmri_dataset(scans, maskfile,TR=1.5, rep(320,7), base_path="/",mode="normal",  event_table=tibble::as_tibble(des))
  evmod <- event_model(Onset ~ hrf(Video, Condition, basis="spmg1"), 
                       block = ~ run, sampling_frame=sframe, data=des)
  bmod <- baseline_model(basis="bs", degree=4, sframe=sframe)
  fmod <- fmri_model(evmod, bmod)

  conset <<- NULL
  conset <<- do.call("contrast_set", lapply(levels(factor(des$Video)), function(v) {
    f1 <- as.formula(paste("~ Video == ", paste0('"', v, '"')))
    f2 <- as.formula(paste("~ Video != ", paste0('"', v, '"')))
    pair_contrast(f1, f2, name=paste0(v, "_vsall"))
  }))
  
 
  res2 <- fmrireg:::fmri_lm(Onset ~ hrf(Video, subset=Condition=="Encod", contrasts=conset) + 
                              hrf(Video, subset=Condition=="Recall", prefix="rec"), block= ~ run, 
                            dataset=dset, 
                            strategy="chunkwise", nchunks=22)
  
  res3 <- fmrireg:::fmri_lm(Onset ~ hrf(Video, subset=Condition=="Encod", contrasts=conset) + 
                              hrf(Video, subset=Condition=="Recall", prefix="rec"), block= ~ run, dataset=dset, 
                            strategy="chunkwise", nchunks=1)
  
  # Fast path versions
  res2_fast <- fmrireg:::fmri_lm(Onset ~ hrf(Video, subset=Condition=="Encod", contrasts=conset) + 
                              hrf(Video, subset=Condition=="Recall", prefix="rec"), block= ~ run, 
                            dataset=dset, 
                            strategy="chunkwise", nchunks=22, use_fast_path=TRUE)
  res3_fast <- fmrireg:::fmri_lm(Onset ~ hrf(Video, subset=Condition=="Encod", contrasts=conset) + 
                              hrf(Video, subset=Condition=="Recall", prefix="rec"), block= ~ run, dataset=dset, 
                            strategy="chunkwise", nchunks=1, use_fast_path=TRUE)
                            
  expect_true(!is.null(coef(res2)))
  expect_true(!is.null(coef(res3)))
  
  expect_true(!is.null(coef(res2_fast)))
  expect_true(!is.null(coef(res3_fast)))
  
  expect_true(!is.null(coef(res2, "contrasts")))
  expect_true(!is.null(coef(res3, "contrasts")))
  
  # Compare res2 vs res2_fast (chunkwise, many chunks)
  expect_equal(coef(res2), coef(res2_fast), tolerance=1e-8)
  expect_equal(coef(res2, "contrasts"), coef(res2_fast, "contrasts"), tolerance=1e-8)
  expect_equal(stats(res2), stats(res2_fast), tolerance=1e-8)
  expect_equal(stats(res2, "contrasts"), stats(res2_fast, "contrasts"), tolerance=1e-8)
  expect_equal(standard_error(res2), standard_error(res2_fast), tolerance=1e-8)
  expect_equal(standard_error(res2, "contrasts"), standard_error(res2_fast, "contrasts"), tolerance=1e-8)

  # Compare res3 vs res3_fast (chunkwise, 1 chunk)
  expect_equal(coef(res3), coef(res3_fast), tolerance=1e-8)
  expect_equal(coef(res3, "contrasts"), coef(res3_fast, "contrasts"), tolerance=1e-8)
  expect_equal(stats(res3), stats(res3_fast), tolerance=1e-8)
  expect_equal(stats(res3, "contrasts"), stats(res3_fast, "contrasts"), tolerance=1e-8)
  expect_equal(standard_error(res3), standard_error(res3_fast), tolerance=1e-8)
  expect_equal(standard_error(res3, "contrasts"), standard_error(res3_fast, "contrasts"), tolerance=1e-8)
  
  # Clean up temporary files
  unlink(scans)
  unlink(maskfile)
})

# test_that("can run video fmri design with latent_dataset", {
#   #library(multivarious)
#   des <- read.table(system.file("extdata", "video_design.txt", package = "fmrireg"), header=TRUE)
#   events <- rep(320,7)
#   sframe <- sampling_frame(rep(320, length(events)), TR=1.5)
#   
#   scans <- gen_fake_dataset(c(10,10,10,320), 7)
#   vecs <- lapply(scans, read_vec)
#   maskfile <- gen_mask_file(c(10,10,10))
#   mask <- read_vol(maskfile)
#   
#   mats <- lapply(vecs, function(v) series(v, mask!=0))
#   mat <- do.call(rbind, mats)
#   pres <- multivarious::pca(mat, ncomp=488, preproc=multivarious::pass())
#   lvec <- fmristore::LatentNeuroVec(pres$s, pres$v, add_dim(space(mask), nrow(mat)), 
#                                    mask=mask)
#   ldset <- latent_dataset(lvec, 1.5, run_length=rep(320,7), des)
#   
#   evmod <- event_model(Onset ~ hrf(Video, Condition, basis="spmg1"), 
#                        block = ~ run, sampling_frame=sframe, data=des)
#    
#   conset <<- NULL
#   conset <<- do.call("contrast_set", lapply(levels(factor(des$Video)), function(v) {
#     f1 <- as.formula(paste("~ Video == ", paste0('"', v, '"')))
#     f2 <- as.formula(paste("~ Video != ", paste0('"', v, '"')))
#     pair_contrast(f1, f2, name=paste0(v, "_vsall"))
#   }))
#   
#   conset2 <<- do.call("contrast_set", lapply(levels(factor(des$Video)), function(v) {
#     f1 <- as.formula(paste("~ rec_Video == ", paste0('"', v, '"')))
#     f2 <- as.formula(paste("~ rec_Video != ", paste0('"', v, '"')))
#     pair_contrast(f1, f2, name=paste0("rec_", v, "_vsall"))
#   }))
#   
#   
#   # Note: fmri_latent_lm does not currently have the fast path implementation
#   res2 <- fmrireg:::fmri_latent_lm(Onset ~ hrf(Video, subset=Condition=="Encod", contrasts=conset) + 
#                               hrf(Video, subset=Condition=="Recall", prefix="rec", contrasts=conset2), 
#                               block= ~ run, 
#                               autocor="none", dataset=ldset)
#   
#   se1 <- standard_error(res2, "contrasts", recon=TRUE)
#   con1 <- stats.fmri_latent_lm(res2, "contrasts", recon=TRUE)
#   
#   # Run standard fmri_lm for comparison (if needed, but latent path is different)
#   # dset <- fmri_dataset(scans, maskfile,TR=1.5, rep(320,7), base_path="/", event_table=des)
#   # res3 <- fmrireg:::fmri_lm(Onset ~ hrf(Video, subset=Condition=="Encod", contrasts=conset) + 
#   #                                    hrf(Video, subset=Condition=="Recall", prefix="rec"), block= ~ run, 
#   #                                  strategy="chunkwise", nchunks=1, dataset=dset)
#   # se2 <- standard_error(res3, "contrasts")
#   # con2 <- stats(res3, "contrasts")
#   
#   expect_true(!is.null(se1))
#   expect_true(!is.null(con1))
#   
#   # Clean up temporary files
#   unlink(scans)
#   unlink(maskfile)
# })
          

# test_that("a one-run, one-contrast linear model analysis", {
#   df1 <- subset(imagedes,run==1)
#   df1 <- subset(df1, !is.na(onsetTime))
#   
#   df1$sdur <- scale(df1$duration)[,1]
#   
#   dmat <- matrix(rnorm(400*100), 400, 100)
#   md <- matrix_dataset(dmat, TR=1.5, run_length=400, event_table=df1)
#   con <- contrast_set(contrast( ~ Thorns - Massage, name="Thorns_Massage"))
#   mod <- fmri_lm(onsetTime ~ hrf(imageName, subset = !is.na(onsetTime), contrasts=con), ~ run, dataset=md, durations=sdur)
#  
# })


# test_that("a two-run, one contrast linear model analysis", {
#   df1 <- subset(imagedes,run %in% c(1,2))
#   df1 <- subset(df1, !is.na(onsetTime))
#   
#   df1$sdur <- scale(df1$duration)[,1]
#   
#   dmat <- matrix(rnorm(800*100), 800, 100)
#   md <- matrix_dataset(dmat, TR=1.5, run_length=c(400,400), event_table=df1)
#   con <- contrast_set(contrast( ~ Thorns - Massage, name="Thorns_Massage"))
#   mod <- fmri_lm(onsetTime ~ hrf(imageName, contrasts=con), ~ run, dataset=md, durations=sdur)
#   
#   
# })

# test_that("can load and run a simple config file", {
#   config <- read_fmri_config("test_data/images_study/config.R")
#   dset <- fmri_dataset(config$scans, config$mask, config$TR, 
#                            config$run_length,
#                            config$event_table,
#                            config$aux_table, 
#                            base_path=config$base_path)
#   
#   frame <- sampling_frame(dset$run_length, config$TR)
#   mod <- fmri_model(config$event_model, config$baseline_model, config$design, dset$aux_table,
#                     basis=HRF_SPMG1, dset$runids, dset$run_length, config$TR, drop_empty=TRUE)
#                     
#   
#   mod <- fmri_glm(config$event_model, 
#                   dataset=dset, durations=0)
# })
</file>

<file path="tests/testthat/test_fmrimodel.R">
options(mc.cores=2)
facedes <- read.table(system.file("extdata", "face_design.txt", package = "fmrireg"), header=TRUE)


test_that("can construct and run an fmri_model", {

  facedes$repnum <- factor(facedes$rep_num)
  scans <- paste0("rscan0", 1:6, ".nii")
  dset <- fmri_dataset(scans=scans,
                       mask="mask.nii",
                       TR=1.5,
                       run_length=rep(436,6),
                       event_table=facedes)

 
  espec <- event_model(onset ~ hrf(repnum), data=facedes, block=~run, sampling_frame=dset$sampling_frame)
  bspec <- baseline_model(basis="bs", degree=5, sframe=dset$sampling_frame)
  fmod <- fmri_model(espec, bspec)
  expect_true(!is.null(fmod))
  expect_equal(length(terms(fmod)), 3)
  expect_equal(ncol(design_matrix(fmod)), length(conditions(fmod)))
  expect_equal(2, length(baseline_terms(fmod)))
  expect_null(contrast_weights(fmod)$repnum)
  #p<-print(fmod)
  expect_true(TRUE)
  
})



# test_that("a one-run, one-contrast linear model analysis", {
#   df1 <- subset(imagedes,run==1)
#   df1 <- subset(df1, !is.na(onsetTime))
#   
#   df1$sdur <- scale(df1$duration)[,1]
#   
#   dmat <- matrix(rnorm(400*100), 400, 100)
#   md <- matrix_dataset(dmat, TR=1.5, run_length=400, event_table=df1)
#   con <- contrast_set(contrast( ~ Thorns - Massage, name="Thorns_Massage"))
#   mod <- fmri_lm(onsetTime ~ hrf(imageName, subset = !is.na(onsetTime), contrasts=con), ~ run, dataset=md, durations=sdur)
#  
# })


# test_that("a two-run, one contrast linear model analysis", {
#   df1 <- subset(imagedes,run %in% c(1,2))
#   df1 <- subset(df1, !is.na(onsetTime))
#   
#   df1$sdur <- scale(df1$duration)[,1]
#   
#   dmat <- matrix(rnorm(800*100), 800, 100)
#   md <- matrix_dataset(dmat, TR=1.5, run_length=c(400,400), event_table=df1)
#   con <- contrast_set(contrast( ~ Thorns - Massage, name="Thorns_Massage"))
#   mod <- fmri_lm(onsetTime ~ hrf(imageName, contrasts=con), ~ run, dataset=md, durations=sdur)
#   
#   
# })

# test_that("can load and run a simple config file", {
#   config <- read_fmri_config("test_data/images_study/config.R")
#   dset <- fmri_dataset(config$scans, config$mask, config$TR, 
#                            config$run_length,
#                            config$event_table,
#                            config$aux_table, 
#                            base_path=config$base_path)
#   
#   frame <- sampling_frame(dset$run_length, config$TR)
#   mod <- fmri_model(config$event_model, config$baseline_model, config$design, dset$aux_table,
#                     basis=HRF_SPMG1, dset$runids, dset$run_length, config$TR, drop_empty=TRUE)
#                     
#   
#   mod <- fmri_glm(config$event_model, 
#                   dataset=dset, durations=0)
# })
</file>

<file path="tests/testthat/test_iterators.R">
options(mc.cores=2)

library(foreach)

gen_dataset <- function(nruns, ntp, nvox=1000) {
  mask <- neuroim2::LogicalNeuroVol(array(1, c(10,10,10)), space=neuroim2::NeuroSpace(c(10,10,10)))
  vec <- neuroim2::SparseNeuroVec(matrix(rnorm(ntp*nvox), ntp, nvox), space=neuroim2::NeuroSpace(c(10,10,10,ntp)), mask=mask)
  scans <- replicate(nruns, vec, simplify=FALSE)
  
  dset <- fmri_mem_dataset(scans, mask, TR=2)
}

test_that("runwise iterator maintains data integrity", {
  dset <- gen_dataset(3, 100, nvox=1000)
  rchunks <- data_chunks(dset, runwise=TRUE)
  
  # Test sequential access
  all_data <- list()
  foreach::foreach(chunk=rchunks) %do% {
    all_data[[length(all_data) + 1]] <- chunk$data
  }
  
  # Verify dimensions
  expect_equal(length(all_data), 3)
  expect_equal(nrow(all_data[[1]]), 100)
  expect_equal(ncol(all_data[[1]]), 1000)
  
  # Test parallel access with foreach
  res1 <- foreach::foreach(chunk = rchunks) %do% {
    colMeans(chunk$data)
  }
  
  # Test parallel access again to ensure iterator resets correctly
  res2 <- foreach::foreach(chunk = rchunks) %do% {
    colMeans(chunk$data)
  }
  
  # Results should be identical across iterations
  expect_equal(res1, res2)
})

test_that("arbitrary chunking works correctly", {
  dset <- gen_dataset(2, 100, nvox=1000)
  
  # Test different chunk sizes
  chunk_sizes <- c(2, 5, 10, 20)
  
  for (nchunks in chunk_sizes) {
    rchunks <- data_chunks(dset, nchunks=nchunks)
    
    # Collect all chunk data
    res <- foreach::foreach(chunk = rchunks) %do% {
      list(
        data_dim = dim(chunk$data),
        voxel_indices = range(chunk$voxel_ind),
        row_indices = range(chunk$row_ind),
        chunk_num = chunk$chunk_num
      )
    }
    
    # Verify chunk count
    expect_equal(length(res), nchunks)
    
    # Verify chunk numbers are sequential
    expect_equal(sapply(res, function(x) x$chunk_num), 1:nchunks)
    
    # Verify all voxels are covered
    all_voxels <- sort(unique(unlist(lapply(res, function(x) x$voxel_indices[1]:x$voxel_indices[2]))))
    expect_equal(all_voxels, 1:1000)
  }
})

test_that("iterator handles edge cases correctly", {
  # Test with single run
  dset_single <- gen_dataset(1, 100, nvox=1000)
  chunks_single <- data_chunks(dset_single, runwise=TRUE)
  res_single <- foreach::foreach(chunk = chunks_single) %do% dim(chunk$data)
  expect_equal(length(res_single), 1)
  
  # Test with single voxel
  #dset_small <- gen_dataset(2, 100, nvox=1)
  #chunks_small <- data_chunks(dset_small, nchunks=1)
  #res_small <- foreach::foreach(chunk = chunks_small) %do% dim(chunk$data)
  #expect_equal(res_small[[1]][2], 1)
  
  # Test with more chunks than voxels
  #dset_over <- gen_dataset(2, 100, nvox=5)
  #chunks_over <- data_chunks(dset_over, nchunks=10)
  #res_over <- foreach::foreach(chunk = chunks_over) %do% dim(chunk$data)
  #expect_equal(length(res_over), 5)  # Should limit to number of voxels
})

test_that("matrix_dataset chunking works correctly", {
  # Create a matrix dataset
  data_mat <- matrix(rnorm(1000 * 100), 100, 1000)
  sframe <- sampling_frame(c(50, 50), TR=2)
  mset <- matrix_dataset(data_mat, TR=2, run_length=c(50,50))
  
  # Test runwise chunking
  rchunks <- data_chunks.matrix_dataset(mset, runwise=TRUE)
  res_run <- foreach(chunk = rchunks) %do% {
    list(dim=dim(chunk$data), 
         row_indices=range(chunk$row_ind),
         chunk_num=chunk$chunk_num)
  }
  
  expect_equal(length(res_run), 2)  # Two runs
  expect_equal(res_run[[1]]$dim[1], 50)  # First run length
  expect_equal(res_run[[2]]$dim[1], 50)  # Second run length
  
  # Test arbitrary chunking
  chunks_arb <- data_chunks.matrix_dataset(mset, nchunks=4)
  res_arb <- foreach(chunk = chunks_arb) %do% {
    list(dim=dim(chunk$data),
         voxel_indices=range(chunk$voxel_ind),
         chunk_num=chunk$chunk_num)
  }
  
  expect_equal(length(res_arb), 4)
  # Verify voxel coverage
  all_voxels <- sort(unique(unlist(lapply(res_arb, function(x) x$voxel_indices[1]:x$voxel_indices[2]))))
  expect_equal(length(all_voxels), 1000)
})

test_that("parallel processing with foreach works correctly", {
  dset <- gen_dataset(4, 100, nvox=1000)
  
  # Test parallel processing with different chunk sizes
  chunk_sizes <- c(2, 4, 8)
  
  for (nchunks in chunk_sizes) {
    chunks <- data_chunks(dset, nchunks=nchunks)
    
    # Run parallel computation
    res_par <- foreach::foreach(chunk = chunks) %dopar% {
      colMeans(chunk$data)
    }
    
    chunks <- data_chunks(dset, nchunks=nchunks)
    # Run sequential computation
    res_seq <- foreach::foreach(chunk = chunks) %do% {
      colMeans(chunk$data)
    }
    
    # Results should be the same
    expect_equal(res_par, res_seq)
    expect_equal(length(res_par), nchunks)
  }
})

test_that("iterator reset functionality works", {
  dset <- gen_dataset(3, 100, nvox=1000)
  chunks <- data_chunks(dset, nchunks=5)
  
  # First iteration
  res1 <- foreach::foreach(chunk = chunks) %do% {
    sum(chunk$data)
  }
  
  chunks =  data_chunks(dset, nchunks=5)
  # Second iteration
  res2 <- foreach::foreach(chunk = chunks) %do% {
    sum(chunk$data)
  }
  
  # Results should be identical
  expect_equal(res1, res2)
  expect_equal(length(res1), 5)
  
  chunks =  data_chunks(dset, nchunks=5)
  
  # Test mixed foreach operators
  res3 <- foreach(chunk = chunks) %do% {
    sum(chunk$data)
  }
  
  chunks =  data_chunks(dset, nchunks=5)
  
  res4 <- foreach(chunk = chunks) %dopar% {
    sum(chunk$data)
  }
  
  expect_equal(res3, res4)
})

test_that("chunk indices are correct and complete", {
  dset <- gen_dataset(2, 100, nvox=1000)
  
  # Test runwise chunks
  rchunks <- data_chunks(dset, runwise=TRUE)
  run_indices <- list()
  
  foreach(chunk=rchunks) %do% {
    run_indices[[length(run_indices) + 1]] <- chunk$row_ind
  }
  
  # Verify run indices
  expect_equal(length(unlist(run_indices)), 200)  # Total timepoints
  expect_equal(range(unlist(run_indices)), c(1, 200))
  expect_equal(length(unique(unlist(run_indices))), 200)  # No duplicates
  
  # Test arbitrary chunks
  chunks <- data_chunks(dset, nchunks=3)
  voxel_indices <- list()
  
  foreach(chunk = chunks) %do% {
    voxel_indices[[length(voxel_indices) + 1]] <- chunk$voxel_ind
  }
  
  # Verify voxel indices
  all_voxels <- sort(unique(unlist(voxel_indices)))
  expect_equal(range(all_voxels), c(1, 1000))
  expect_equal(length(all_voxels), 1000)  # All voxels covered
})

test_that("can construct and iterate over a runwise iterator", {
  dset <- gen_dataset(5, 100, nvox=1000)
  rchunks <- data_chunks(dset, runwise=TRUE)
  res <- foreach (chunk = rchunks) %do% {
    list(ncol=ncol(chunk$data), nrow=nrow(chunk$data))
  }
  
  expect_equal(length(res), 5)
  expect_true(all(sapply(res, "[[", "ncol") == 1000))
  expect_true(all(sapply(res, "[[", "nrow") == 100))
})

test_that("can construct and iterate over a runwise-chunked iterator", {
  dset <- gen_dataset(5, 100, nvox=1000)
  rchunks <- data_chunks(dset, nchunks=5, runwise=TRUE)
  res <- foreach (chunk = rchunks) %do% {
    list(ncol=ncol(chunk$data), nrow=nrow(chunk$data))
  }
  
  expect_equal(length(res), 5)
  expect_true(all(sapply(res, "[[", "ncol") == 1000))
  expect_true(all(sapply(res, "[[", "nrow") == 100))
})
</file>

<file path="tests/testthat/test_parse_event_formula.R">
library(testthat)

# Ensure we use testthat edition 3
local_edition(3)

# Test that parse_event_formula returns hrfspec list intact

test_that("parse_event_formula returns hrfspec objects for multiple hrf calls", {
  events <- data.frame(
    onset = 1:4,
    condition = factor(c("a", "b", "a", "b")),
    modulator = rnorm(4)
  )

  form <- onset ~ hrf(condition) + hrf(modulator)

  parsed <- fmrireg:::parse_event_formula(form, events)

  expect_equal(nrow(parsed$spec_tbl), 2)
  expect_true(all(vapply(parsed$spec_tbl$spec, inherits, logical(1), "hrfspec")))
})
</file>

<file path="tests/testthat/test_parse_term.R">
library(fmrireg)

test_that("parse_term handles multiple variables and complex expressions", {
  vars <- list(quote(x), quote(log(y + 1)), quote(Poly(rt, 3)))
  res <- fmrireg:::parse_term(vars, "covariate")
  expect_equal(res$term, c("x", "log(y + 1)", "Poly(rt, 3)"))
  expect_equal(res$label, "covariate(x,log(y + 1),Poly(rt, 3))")
})
</file>

<file path="tests/testthat/test_regressor.R">
options(mc.cores=1)
library(testthat)
library(assertthat)

facedes <- read.table(system.file("extdata", "face_design.txt", package = "fmrireg"), header=TRUE)
lopdes <- read.table(system.file("extdata", "design_aug.txt", package = "fmrireg"), header=TRUE)


test_that("regressor generates correct outputs", {
  onsets <- seq(1,100, by=5)
  durations=1
  
  reg1 <- regressor(onsets, HRF_GAMMA)

  expect_equal(class(reg1)[1],"Reg")
  expect_equal(length(reg1$onsets), length(onsets))
  expect_equal(length(reg1$duration), length(onsets))
  expect_true(durations(reg1)[1] == 0)
  expect_true(amplitudes(reg1)[1] == 1)
})

test_that("generate an event model with one observation per level", {
  sframe <- sampling_frame(blocklens=rep(401,5), TR=1.5)
  lopdes$onset <- lopdes$WordPresentationOnset/1000
  lopdes$Target <- factor(lopdes$Target)
  ev <- event_model(onset ~ hrf(Target), data=lopdes, block= ~ Run, sampling_frame=sframe)
  expect_true(!is.null(ev))
})

test_that("can construct a convolved term from an hrfspec with one factor and one run", {
  N <- 100
  onsets <- seq(1,N,by=5)
  durations <- 0
  
  sframe <- sampling_frame(blocklens=100, TR=1)
  etab <- data.frame(onsets=onsets, fac=factor(c(1,1,2,2)), Run=rep(1,4))
  ev <- event_model(onsets ~ hrf(fac), data=etab, block= ~ Run, sampling_frame=sframe)

  expect_equal(ncol(design_matrix(ev)), length(levels(etab$fac)))
})

test_that("can construct a convolved term from an hrfspec with two factors and one run", {
  N <- 100
  onsets <- seq(1,N,by=5)
  durations <- 0
  
  sframe <- sampling_frame(blocklens=100, TR=1)
  etab <- data.frame(onsets=onsets, fac=factor(c(1,1,2,2)), fac2=factor(letters[1:2]), Run=1)
  espec <- event_model(onsets ~ hrf(fac) + hrf(fac2), block= ~ Run, data=etab, sampling_frame=sframe)
  expect_equal(dim(design_matrix(espec)), c(N,length(levels(interaction(etab$fac, etab$fac2)))))
})

test_that("can construct a convolved term from an hrfspec with one factor and two runs", {
  N <- 100
  onsets1 <- seq(1,N,by=5)
  onsets2 <- seq(1,N,by=5)
  onsets <- c(onsets1,onsets2)
  durations <- 0
  
  sframe <- sampling_frame(blocklens=c(100,100), TR=1)
  etab <- data.frame(onsets=onsets, fac=factor(c(1,1,2,2)), block=rep(1:2, c(length(onsets1), length(onsets2))))
  espec <- event_model(onsets ~ hrf(fac), data=etab, block = ~ block, sampling_frame=sframe)

  expect_equal(dim(design_matrix(espec)), c(N*2,length(levels(etab$fac))))
})


test_that("can construct a convolved trialwise term from an hrfspec with one factor and one run", {
  N <- 500
  onsets <- seq(1,N,by=5)
  durations <- 0
  
  sframe <- sampling_frame(blocklens=500, TR=1)
  
  etab <- data.frame(onsets=onsets, fac=factor(c(1,1,2,2)), block=1)
  espec <- event_model(onsets ~ trialwise(), data=etab, block=~block, sampling_frame=sframe)
 
  expect_equal(dim(design_matrix(espec)), c(N,length(onsets)))
})

test_that("can construct a convolved trialwise term with bspline basis from an hrfspec with one factor, one run", {
  N <- 500
  onsets <- seq(1,N,by=5)
  durations <- 0
  
  sframe <- sampling_frame(blocklens=500, TR=1)
  
  etab <- data.frame(onsets=onsets, fac=factor(c(1,1,2,2)), block=1)
  
  hrfb <- gen_hrf(hrf_bspline, N=5)
  espec <- event_model(onsets ~ trialwise(basis=hrfb), data=etab, block=~block, 
  sampling_frame=sframe)
  
  expect_equal(dim(design_matrix(espec)), c(N,length(onsets)*5))
})




test_that("can extract a design matrix from an fmri_model with two terms and one continuous variable", {
  N <- 100
  onsets <- seq(1,N,by=5)
  durations <- 0
  
  sframe <- sampling_frame(blocklens=100, TR=1)
  
  etab <- data.frame(onsets=onsets, fac=factor(c(1,1,2,2)), fac2=factor(letters[1:2]), z=rnorm(length(onsets)), run=1)
  
  espec <- event_model(onsets ~ hrf(fac,fac2) + hrf(z), data=etab, block = ~ run, sampling_frame=sframe)
  dmat <- design_matrix(espec)
  expect_equal(dim(dmat), c(N, 5))
})

test_that("can extract a design matrix from an fmri_model with one factor crossed with one continuous variable", {
  N <- 100
  onsets <- seq(1,N,by=10)
  sframe <- sampling_frame(blocklens=100, TR=1)
  
  etab <- data.frame(onsets=onsets, fac=factor(rep(c(1,2),5)), z=1:10, run=1)
  espec <- event_model(onsets ~ hrf(fac) + hrf(fac,z), etab, block=~run, sampling_frame=sframe)
  dmat <- design_matrix(espec)
  expect_equal(dim(dmat), c(N, length(levels(etab$fac)) * 2))
})

test_that("can extract a design matrix from an fmri_model with one factor and a 3rd degree bspline with 5 basis functions", {
  N <- 100
  onsets <- seq(1,N,by=10)
  durations <- 0
  sframe <- sampling_frame(blocklens=100, TR=1)

  etab <- data.frame(onsets=onsets, fac=factor(rep(c(1,2),5)), run=1)
  espec <- event_model(onsets ~ hrf(fac, basis="bs", nbasis=5), data=etab, block=~run, sampling_frame=sframe)
  dmat <- design_matrix(espec)
  expect_equal(dim(dmat), c(N, length(levels(etab$fac)) * 5))
})

test_that("can extract a design matrix from an fmri_model with one factor and SPMG3 basis", {
  N <- 100
  onsets <- seq(1,N,by=10)
  durations <- 0
  sframe <- sampling_frame(blocklens=100, TR=1)
  
  etab <- data.frame(onsets=onsets, fac=factor(rep(c(1,2),5)), run=1)
  espec <- event_model(onsets ~ hrf(fac, basis="spmg3"), data=etab, block=~run, sampling_frame=sframe)
  dmat <- design_matrix(espec)
  expect_equal(dim(dmat), c(N, length(levels(etab$fac)) * 3))
})


test_that("can extract a design matrix from an fmri_model with one trialwise factor and a 3rd degree bspline with 5 basis functions", {
  N <- 100
  onsets <- seq(1,N,by=10)
  durations <- 0
  
  etab <- data.frame(onsets=onsets, fac=factor(rep(c(1,2),5)), run=1)
  sframe <- sampling_frame(blocklens=100, TR=1)
  
  espec <- event_model(onsets ~ trialwise(basis="bspline"), 
                       data=etab, block=~run, sampling_frame = sframe)
  dmat <- design_matrix(espec)
  expect_equal(dim(dmat), c(N, 4 * length(onsets)))
})

test_that("event_model with duplicate terms at different lags", {
  N <- 100
  onsets <- seq(1,N,by=5)
  durations <- 0
  
  sframe <- sampling_frame(blocklens=100, TR=1)
  etab <- data.frame(onsets=onsets, fac=factor(c(1,1,2,2)), Run=rep(1,4))
  ev <- event_model(onsets ~ hrf(fac) + hrf(fac,lag=5, prefix="phase2") , data=etab, block= ~ Run, sampling_frame=sframe)
  expect_true(!is.null(ev))
  
})

test_that("can construct a model with a raw covariate term", {
  facedes$repnum <- factor(facedes$rep_num)
  sframe <- sampling_frame(blocklens=rep(436/2,max(facedes$run)), TR=2)
  cdat <- data.frame(x = rnorm(sum(sframe$blocklens)), y = rnorm(sum(sframe$blocklens)))
  
  espec <- event_model(onset ~ hrf(rt) + covariate(x, y, data=cdat) , data=facedes, block=~run, sampling_frame=sframe)
  dmat <- design_matrix(espec)

  expect_equal(dim(dmat), c(sum(sframe$blocklens), 3))
  expect_equal(dmat$x, cdat$x)
  expect_equal(dmat$y, cdat$y)
  
  bmod <- baseline_model(basis="constant", sframe=sframe)
  fmod <- fmri_model(espec,bmod)
  #alm <- afni_lm(fmod)
  expect_true(!is.null(fmod))
})

test_that("covariate captures subset expression", {
  df <- data.frame(x = 1:4, y = 5:8, flag = c(TRUE, FALSE, TRUE, FALSE))
  cspec <- covariate(x, y, data = df, subset = flag)
  expect_true(identical(cspec$subset, rlang::expr(flag)))
})

test_that("facedes model with rep_num", {
  facedes$repnum <- factor(facedes$rep_num)
  sframe <- sampling_frame(blocklens=rep(436/2,max(facedes$run)), TR=2)
  espec <- event_model(onset ~ hrf(repnum), data=facedes, block=~run, sampling_frame=sframe)
  dmat <- design_matrix(espec)
  expect_equal(dim(dmat), c(sum(sframe$blocklens), length(levels(facedes$repnum))))
})

test_that("facedes model with rep_num, subsetting rep_num == -1 ", {
  facedes$repnum <- factor(facedes$rep_num)
  sframe <- sampling_frame(blocklens=rep(436/2,max(facedes$run)), TR=2)
  
  espec <- event_model(onset ~ hrf(repnum, subset=repnum != "-1"), data=facedes, block=~run, sampling_frame=sframe)
  dmat <- design_matrix(espec)
  expect_equal(dim(dmat), c(sum(rep(436/2,max(facedes$run))), length(levels(facedes$repnum))-1))
})

test_that("facedes model with rep_num, and rep_num by rt ", {
  facedes$repnum <- factor(facedes$rep_num)
  sframe <- sampling_frame(blocklens=rep(436/2,max(facedes$run)), TR=2)
  
  espec <- event_model(onset ~ hrf(repnum, subset=repnum != "-1") + hrf(repnum,rt,subset=rep_num!= "-1"), 
                       data=facedes, block=~run,sampling_frame = sframe)
  
  dmat <- design_matrix(espec)
  expect_equal(dim(dmat), c(sum(rep(436/2,max(facedes$run))), (length(levels(facedes$repnum))-1)*2))
})

test_that("facedes model with RT and RT^2 as separate regressors ", {
  facedes$repnum <- factor(facedes$rep_num)
  sframe <- sampling_frame(blocklens=rep(436/2,max(facedes$run)), TR=2)
  
  facedes$rt_squared <- facedes$rt^2
  facedes$rt_cubed <- facedes$rt^3
  
  #conset <- contrast_set(contrast(~ rt - rt_sqared, "rt_diff"))
  espec <- event_model(onset ~ hrf(repnum) + hrf(Ident(rt, rt_squared)) + hrf(rt_cubed), 
                       data=facedes, block=~run,sampling_frame = sframe)
  
  dmat <- design_matrix(espec)
  expect_equal(dim(dmat), c(sum(rep(436/2,max(facedes$run))), (length(levels(facedes$repnum))-1)*2))
})




test_that("facedes model with polynomial parametric basis", {
  facedes$repnum <- factor(facedes$rep_num)
  sframe <- sampling_frame(blocklens=rep(436/2,max(facedes$run)), TR=2)
  
  espec <- event_model(onset ~  hrf(Poly(rt,3)), data=facedes, block=~run, sampling_frame=sframe)
  
  dmat <- design_matrix(espec)
  expect_equal(dim(dmat), c(sum(sframe$blocklens), 3))
})

test_that("facedes model with polynomial parametric basis and overriding onsets", {
  facedes$repnum <- factor(facedes$rep_num)
  facedes$onset2 <- facedes$onset+4
  sframe <- sampling_frame(blocklens=rep(436/2,max(facedes$run)), TR=2)
  
  espec <- event_model(onset ~  hrf(Poly(rt,2), onsets=onset2), 
                       data=facedes, block=~run, sampling_frame=sframe)
  
  dmat <- design_matrix(espec)
  expect_equal(dim(dmat), c(sum(sframe$blocklens), 2))
})

test_that("facedes model with bspline parametric basis", {
  facedes$repnum <- factor(facedes$rep_num)
  sframe <- sampling_frame(blocklens=rep(436/2,max(facedes$run)), TR=2)
  
  espec <- event_model(onset ~  hrf(BSpline(rt,3)), data=facedes, block=~run, sampling_frame=sframe)
  
  dmat <- design_matrix(espec)
  expect_equal(dim(dmat), c(sum(sframe$blocklens), 3))
})

# test_that("rcan create an identity regressor", {
#   onsets <- seq(0,9,by=1)
#   durations=1
#   
#   reg1 <- regressor(onsets, HRF_IDENT, duration=0, amplitude=1:10)
#   
#   expect_equal(class(reg1)[1],"regressor")
#   expect_equal(length(reg1$onsets), length(onsets))
#   expect_equal(length(reg1$duration), length(onsets))
#   expect_true(durations(reg1)[1] == 0)
#   expect_true(amplitudes(reg1)[1] == 1)
# })

# Test null_regressor
test_that("null_regressor creates a valid object", {
  nr <- null_regressor()
  expect_is(nr, "Reg")
})

# Test single_trial_regressor
test_that("single_trial_regressor creates a valid object", {
  str <- single_trial_regressor(onsets = 10)
  expect_is(str, "Reg")
})

# Test regressor
test_that("regressor creates a valid object", {
  reg <- regressor(onsets = c(10, 12, 14, 16, 18, 40))
  expect_is(reg, "Reg")

})

# Test evaluate.single_trial_regressor
test_that("evaluate.single_trial_regressor produces correct output", {
  str <- single_trial_regressor(onsets = 10)
  grid <- seq(0, 100, by = 2)
  eval_str <- evaluate(str, grid)
  expect_is(eval_str, "numeric")
})

# Test evaluate.null_regressor
test_that("evaluate.null_regressor produces correct output", {
  nr <- null_regressor()
  grid <- seq(0, 100, by = 2)
  eval_nr <- evaluate(nr, grid)
  expect_is(eval_nr, "matrix")
})






# cset = list(
#   repnum == 1 ~ repnum == 2 | fac == 1,
#   repnum == 3 ~ repnum == 2
# )
# 
# cset <- contrast_set (
#    c1=contrast(
#      repnum == 1,
#      repnum == 2
#    ),
#    c2=contrast(
#      repnum==1
#    ),
#    c3=poly_contrast(
#      repnum,
#      value_map=list("-1" =0)
#    )
#  )
</file>

<file path="tests/testthat/test_sampling_frame.R">
context("Sampling Frame")

test_that("sampling_frame constructor works correctly", {
  # Basic construction
  sframe <- sampling_frame(blocklens = c(100, 100), TR = 2)
  expect_s3_class(sframe, "sampling_frame")
  expect_equal(length(sframe$blocklens), 2)
  expect_equal(sframe$TR, c(2, 2))
  expect_equal(sframe$start_time, c(1, 1))
  
  # Test with different TRs per block
  sframe2 <- sampling_frame(blocklens = c(100, 200), TR = c(2, 1.5))
  expect_equal(sframe2$TR, c(2, 1.5))
  
  # Test input validation
  expect_error(sampling_frame(blocklens = c(-1, 100), TR = 2), 
              "Block lengths must be positive")
  expect_error(sampling_frame(blocklens = c(100, 100), TR = -1), 
              "TR .* must be positive")
  expect_error(sampling_frame(blocklens = c(100, 100), TR = 2, precision = 3),
              "Precision must be positive and less than")
})

test_that("samples.sampling_frame works correctly", {
  sframe <- sampling_frame(blocklens = c(100, 100), TR = 2)
  
  # Test relative timing
  rel_samples <- samples(sframe, global = FALSE)
  expect_equal(length(rel_samples), 200)
  expect_equal(rel_samples[1:5], c(1, 3, 5, 7, 9))
  
  # Test global timing
  glob_samples <- samples(sframe, global = TRUE)
  expect_equal(length(glob_samples), 200)
  expect_equal(glob_samples[101] - glob_samples[100], 2)  # Check TR spacing
  
  # Test block selection
  block1_samples <- samples(sframe, blockids = 1)
  expect_equal(length(block1_samples), 100)
  
  # Test memoization
  samples2 <- samples(sframe, global = FALSE)
  expect_identical(rel_samples, samples2)  # Should return cached result
})

test_that("global_onsets works correctly", {
  sframe <- sampling_frame(blocklens = c(100, 100), TR = 2)
  
  # Test basic functionality
  onsets <- c(10, 20)
  blockids <- c(1, 2)
  global_times <- global_onsets(sframe, onsets, blockids)
  expect_equal(length(global_times), 2)
  expect_equal(global_times[1], 10)  # First block onset unchanged
  expect_equal(global_times[2], 220)  # Second block onset = 200 (block1 duration) + 20
  
  # Test error conditions
  #expect_error(global_onsets(sframe, c(10), c(1, 2)), 
  #            "length.*onsets.*length.*blockids")
  #expect_error(global_onsets(sframe, c(10), c(3)), 
  #            "blockids.*1.*length")
})

test_that("print.sampling_frame works correctly", {
  sframe <- sampling_frame(blocklens = c(100, 100), TR = 2)
  expect_output(print(sframe), "Sampling Frame")
  expect_output(print(sframe), "Structure")
  expect_output(print(sframe), "Timing")
  expect_output(print(sframe), "Duration")
})

test_that("sampling_frame handles edge cases", {
  # Single block
  single_block <- sampling_frame(blocklens = 100, TR = 2)
  expect_equal(length(single_block$blocklens), 1)
  expect_equal(length(samples(single_block)), 100)
  
  # Very short block
  short_block <- sampling_frame(blocklens = c(1, 1), TR = 2)
  expect_equal(length(samples(short_block)), 2)
  
  # Different start times
  custom_starts <- sampling_frame(blocklens = c(100, 100), 
                                TR = 2, 
                                start_time = c(0, 5))
  expect_equal(custom_starts$start_time, c(0, 5))
  
  # High precision
  high_prec <- sampling_frame(blocklens = c(10, 10), 
                            TR = 2, 
                            precision = 0.01)
  expect_equal(high_prec$precision, 0.01)
})

test_that("sampling_frame maintains temporal consistency", {
  sframe <- sampling_frame(blocklens = c(100, 100, 100), TR = 2)
  glob_samples <- samples(sframe, global = TRUE)
  
  # Check uniform spacing within blocks
  for (block in 1:3) {
    block_idx <- which(sframe$blockids == block)
    diffs <- diff(glob_samples[block_idx])
    expect_true(all(abs(diffs - 2) < 1e-10))
  }
  
  # Check block transitions
  block_ends <- cumsum(sframe$blocklens)
  for (i in 1:(length(block_ends)-1)) {
    time_diff <- glob_samples[block_ends[i] + 1] - glob_samples[block_ends[i]]
    expect_equal(time_diff, 2)
  }
})
</file>

<file path="tests/testthat/test_standardized.R">
test_that("Standardized assigns column name", {
  x <- c(1, 2, 3)
  b <- Standardized(x)
  expect_equal(colnames(b$y), b$name)
  p <- predict(b, c(4, 5))
  expect_equal(colnames(p), b$name)
})

test_that("Standardized handles zero variance", {
  x <- rep(1, 5)
  b <- Standardized(x)
  expect_equal(b$sd, 1e-6)
  expect_equal(as.numeric(b$y[,1]), rep(0, 5))
})
</file>

<file path="tests/testthat/test_trialwise.R">
options(mc.cores=2)
library(purrr)

## generate an experimental design
gen_design <- function(nstim=50, isi_range=c(0,4), noise_sd=.8, rho=.12, TR=2, rnum=1) {
  isi <- runif(nstim, min=isi_range[1]+.1, max=isi_range[2]) 
  onsets <- cumsum(isi) + 1
  runlen <- ceiling(onsets[length(onsets)] + 16)
  nscans <- round(runlen/TR)
  
  fac <- factor(sample(rep(c("a", "b"), each=nstim/2)))
  
  design <- data.frame(
    isi=isi,
    trial=ordered(rep(1:nstim)),
    fac=fac,
    rnum=rnum,
    onsets=onsets
  )
}

## given a design matrix and number oscans, generate an event model
gen_event_model <- function(desmat, nscans, TR=2) {
  sframe <- sampling_frame(nscans, TR)
  desmat$constant <- factor(rep(1, nrow(desmat)))
  emod <- event_model(onsets ~ hrf(constant) + trialwise(), 
                      block= ~ rnum, 
                      sampling_frame=sframe,data=desmat)
  
}

## given an experimental design, generate a response
gen_simdata <- function(des, rho=.12, TR=2, noise_sd=.8, rnum=1) {
  runlen <- ceiling(des$onsets[nrow(des)] + 16)
  nscans <- round(runlen/TR)
  
  baseline <- rnorm(nscans, mean=0, sd=noise_sd)
  baseline <- c(baseline[1], map_dbl(2:length(baseline), function(i) {
    rho*baseline[i-1] + (1-rho)*baseline[i]
  }))
  
  amp_a <- rnorm(sum(des$fac == "a"), mean=5, sd=.5)
  y_a <- regressor(des$onsets[des$fac == "a"], amplitude=amp_a)
  amp_b <- rnorm(sum(des$fac == "b"), mean=3, sd=.5)
  y_b <- regressor(des$onsets[des$fac == "b"], amplitude=amp_b)
  
  y_a <- evaluate(y_a, seq(1,runlen, length.out=nscans))
  y_b <- evaluate(y_b, seq(1,runlen, length.out=nscans))
  y_signal <- y_a + y_b
  y <- y_signal + baseline
  data.frame(y_a=y_a,y_b=y_b,y_signal=y_signal,y=y, rnum=rnum)
  
}

## generate a full simulation data set for a single iteration
gen_sim_set <- function(nruns=3, isi_range=c(0,4), noise_sd=.8, TR=2) {
  
  des <- seq(1, nruns) %>% 
    map(~ gen_design(nstim=50, isi_range=isi_range, TR=TR, rnum=.)) 
  
  
  ydat <- des %>% 
    imap(~ gen_simdata(.x,TR=2, noise_sd=noise_sd, rnum=.y)) %>% 
    map_df(dplyr::bind_rows)
  
  desmat <- do.call(rbind, des)
  
  ev <- gen_event_model(desmat, nscans=table(ydat$rnum), TR=2)
  
  list(design=desmat, simdata=ydat, ev=ev)
}

test_that("can generate a trialwise regression model with a summed term term", {
  sim <- gen_sim_set(3, isi_range=c(0,4), noise_sd=.8)
  desmat <- design_matrix(sim$ev)
  expect_true(!is.null(desmat))
  
})
</file>

<file path="tests/testthat/test-naming-utils.R">
context("Naming Utilities")

source("helper-naming.R") # Load is_valid_heading

test_that("zeropad works correctly with min width 2", {
  expect_equal(zeropad(3, 9), "03")  # Now pads to 2 digits even for n_total < 10
  expect_equal(zeropad(9, 9), "09") 
  expect_equal(zeropad(3, 10), "03") # Remains 2 digits for n_total = 10
  expect_equal(zeropad(12, 99), "12")
  expect_equal(zeropad(12, 100), "012") # Becomes 3 digits when n_total >= 100
  expect_equal(zeropad(99, 100), "099")
  expect_equal(zeropad(1:3, 10), c("01", "02", "03")) # Check vector input
  expect_equal(zeropad(5, 0), "05") # handle n_total=0, pads to width 2
})

test_that("sanitize works correctly", {
  expect_equal(sanitize("a.b c"), "a.b.c")
  expect_equal(sanitize("a b.c", allow_dot = FALSE), "a_b_c")
  expect_equal(sanitize("1var"), "X1var")
  expect_equal(sanitize(c("a", "a")), c("a", "a")) # unique = FALSE
  expect_equal(sanitize("_start"), "X_start")
})

test_that("basis_suffix works correctly", {
  expect_equal(basis_suffix(1, 1), "")
  expect_equal(basis_suffix(1:3, 3), c("_b01", "_b02", "_b03")) # Now expects 2 digits
  expect_equal(basis_suffix(1:3, 15), c("_b01", "_b02", "_b03")) # Already 2 digits
  expect_equal(basis_suffix(1, 5), "_b01") # Now expects 2 digits
  expect_equal(basis_suffix(integer(0), 5), character(0)) # Empty input
})

test_that("make_unique_tags works correctly", {
  expect_equal(make_unique_tags(c("a", "b")), c("a", "b"))
  expect_equal(make_unique_tags(c("a", "a")), c("a", "a#1"))
  expect_equal(make_unique_tags(c("a", "a", "a#1")), c("a", "a#2", "a#1"))
})

# Basic test structure for other helpers - expand later

test_that("make_term_tag generates tags", {
  # Requires hrfspec structure - placeholder
  # spec1 <- list(id = "my_term", vars = list())
  # spec2 <- list(vars = list(quote(RT), quote(cond)))
  # expect_equal(make_term_tag(spec1), "my_term")
  # expect_equal(make_term_tag(spec2), "RT_cond")
  # expect_equal(make_term_tag(spec2, existing_tags = "RT_cond"), "RT_cond#1")
  # expect_equal(make_term_tag(list(vars=list(quote(X.y))), existing_tags="X_y"), "X_y#1")
  expect_true(TRUE) # Placeholder
})

test_that("level_token creates Var.Level format", {
  expect_equal(level_token("cond", "A"), "cond.A")
  expect_equal(level_token("cond name", "Level 1"), "cond.name.Level.1")
})

test_that("continuous_token sanitizes", {
  expect_equal(continuous_token("poly_RT_01"), "poly_RT_01")
  expect_equal(continuous_token("z_RT by cond"), "z_RT.by.cond")
})

test_that("make_cond_tag combines with underscore", {
  expect_equal(make_cond_tag(c("cond.A", "task.go")), "cond.A_task.go")
  expect_equal(make_cond_tag("cond.A"), "cond.A")
})

test_that("add_basis expands tags correctly", {
  expect_equal(add_basis("cond.A", 1), "cond.A")
  expect_equal(add_basis("cond.A", 3), c("cond.A_b1", "cond.A_b2", "cond.A_b3"))
  expect_equal(add_basis(c("t1", "t2"), 2), c("t1_b1", "t2_b1", "t1_b2", "t2_b2"))
})

test_that("make_column_names composes final names", {
  expect_equal(make_column_names("term1", "cond.A", 1), "term1_cond.A")
  expect_equal(make_column_names("term1", "cond.A", 3), c("term1_cond.A_b1", "term1_cond.A_b2", "term1_cond.A_b3"))
  expect_equal(make_column_names("term1", c("c1", "c2"), 2), c("term1_c1_b1", "term1_c2_b1", "term1_c1_b2", "term1_c2_b2"))
  expect_error(make_column_names("term__bad", "cond.A", 1)) # Double underscore guard
})

test_that("is_valid_heading works", {
    expect_true(is_valid_heading("term_cond.A"))
    expect_true(is_valid_heading("term_cond.A_b01"))
    expect_true(is_valid_heading("term#1_cond.A_b01"))
    expect_true(is_valid_heading(".internal"))
    expect_false(is_valid_heading("_term"))
    expect_true(is_valid_heading("term_"))
    expect_false(is_valid_heading("term name"))
    expect_true(is_valid_heading("term_cond.A_b##"))
})
</file>

<file path="tests/testthat.R">
library(testthat)
library(fmrireg)
Sys.setenv(R_TESTS="")
test_check("fmrireg")
</file>

<file path="README.rmd">
---
title: "fmrireg"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# In Development

 <!-- badges: start -->
  [![R-CMD-check](https://github.com/bbuchsbaum/fmrireg/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/bbuchsbaum/fmrireg/actions/workflows/R-CMD-check.yaml)
  <!-- badges: end -->

```{r, echo = FALSE}                                                                                                        
version <- as.vector(read.dcf('DESCRIPTION')[, 'Version'])                                                                 
version <- gsub('-', '.', version)                                                                                      
```        


The `fmrireg` package is currently in development. The goal of the project is to provide functions for carrying out regression anaysis with *f*MRI data. It's Not Ready for Primetime, but still have a look at vignettes:

## Vignettes

See examples of use of `fmrireg` in the [vignettes](https://bbuchsbaum.github.io/fmrireg/articles/index.html).
</file>

<file path="R/ar_utils.R">
# Autoregressive (AR) Utility Functions

#' Estimate AR(p) Coefficients via Yule-Walker
#'
#' Estimates autoregressive coefficients from a numeric residual time series
#' using the Yule-Walker equations.
#'
#' @param residuals_vec Numeric vector of residuals.
#' @param p_order Integer specifying the AR order `p`.
#' @return Numeric vector of length `p_order` containing the estimated AR coefficients.
#' @keywords internal
#' @noRd
.estimate_ar <- function(residuals_vec, p_order) {
  stopifnot(is.numeric(residuals_vec))
  stopifnot(length(p_order) == 1L, p_order >= 1L)

  res <- residuals_vec - mean(residuals_vec, na.rm = TRUE)
  acvf <- stats::acf(res, lag.max = p_order, plot = FALSE, type = "covariance")$acf
  # acvf[1] is lag 0, next p_order elements correspond to lags 1:p_order
  gamma <- as.numeric(acvf)
  R <- toeplitz(gamma[1:p_order])
  r <- gamma[2:(p_order + 1)]
  phi <- drop(solve(R, r))
  as.numeric(phi)
}
</file>

<file path="R/benchmark_datasets.R">
#' Load fMRI Benchmark Datasets
#'
#' This function provides easy access to the benchmark datasets included with the fmrireg package.
#' These datasets are designed for testing HRF fitting, beta estimation, and other fMRI analysis methods.
#'
#' @param dataset_name Character string specifying which dataset to load. Options include:
#'   \itemize{
#'     \item \code{"BM_Canonical_HighSNR"}: Canonical HRF with high SNR (3 conditions)
#'     \item \code{"BM_Canonical_LowSNR"}: Canonical HRF with low SNR (3 conditions)
#'     \item \code{"BM_HRF_Variability_AcrossVoxels"}: HRF varies across voxel groups (2 conditions)
#'     \item \code{"BM_Trial_Amplitude_Variability"}: Trial-to-trial amplitude variability (1 condition)
#'     \item \code{"BM_Complex_Realistic"}: Complex scenario with multiple factors (3 conditions)
#'     \item \code{"all"}: Returns all datasets as a list
#'     \item \code{"metadata"}: Returns metadata about the datasets
#'   }
#'
#' @return A list containing the specified benchmark dataset(s) with the following components:
#'   \itemize{
#'     \item \code{description}: Text description of the dataset
#'     \item \code{Y_noisy}: Matrix of noisy BOLD time series (time x voxels)
#'     \item \code{Y_clean}: Matrix of clean BOLD time series (when available)
#'     \item \code{X_list_true_hrf}: List of design matrices convolved with true HRF
#'     \item \code{true_hrf_parameters}: Information about the true HRF(s) used
#'     \item \code{event_onsets}: Vector of event onset times
#'     \item \code{condition_labels}: Vector of condition labels for each event
#'     \item \code{true_betas_condition}: Matrix of true condition-level beta values
#'     \item \code{true_amplitudes_trial}: Matrix of true trial-level amplitudes
#'     \item \code{TR}: Repetition time
#'     \item \code{total_time}: Total scan duration
#'     \item \code{noise_parameters}: Information about noise generation
#'     \item \code{simulation_seed}: Random seed used for generation
#'     \item \code{target_snr}: Target signal-to-noise ratio
#'   }
#'
#' @examples
#' # Load a specific dataset
#' high_snr_data <- load_benchmark_dataset("BM_Canonical_HighSNR")
#' 
#' # Get information about all available datasets
#' metadata <- load_benchmark_dataset("metadata")
#' 
#' # Load all datasets
#' all_data <- load_benchmark_dataset("all")
#' 
#' # Access the BOLD data
#' Y <- high_snr_data$Y_noisy
#' 
#' # Get event information
#' onsets <- high_snr_data$event_onsets
#' conditions <- high_snr_data$condition_labels
#'
#' @export
load_benchmark_dataset <- function(dataset_name = "BM_Canonical_HighSNR") {
  # Temporarily simplified
  all_processed_data <- .ensure_benchmark_data_loaded()
  if (dataset_name == "all" || dataset_name == "metadata" || !is.null(all_processed_data[[dataset_name]])) {
    return(list(message = "Dataset loading temporarily simplified"))
  } else {
    stop("Dataset not found (simplified check).")
  }
}

#' List Available Benchmark Datasets
#'
#' Returns a summary of all available benchmark datasets with their descriptions.
#'
#' @return A data.frame with dataset names and descriptions
#'
#' @examples
#' # See what benchmark datasets are available
#' list_benchmark_datasets()
#'
#' @export
list_benchmark_datasets <- function() {
  # Temporarily simplified
  return(data.frame(Dataset = "dummy", Description = "dummy"))
}

#' Get Benchmark Dataset Summary
#'
#' Provides a detailed summary of a specific benchmark dataset including
#' dimensions, experimental design, and ground truth information.
#'
#' @param dataset_name Character string specifying which dataset to summarize
#'
#' @return A list with summary information about the dataset
#'
#' @examples
#' # Get summary of a specific dataset
#' summary_info <- get_benchmark_summary("BM_Canonical_HighSNR")
#' print(summary_info)
#'
#' @export
get_benchmark_summary <- function(dataset_name) {
  # Temporarily simplified
  return(list(summary = "dummy"))
}

#' Create Design Matrix from Benchmark Dataset
#'
#' Helper function to create a design matrix from a benchmark dataset using
#' a specified HRF. This is useful for testing different HRF assumptions
#' against the ground truth.
#'
#' @param dataset_name Character string specifying which dataset to use
#' @param hrf HRF object to use for convolution (e.g., HRF_SPMG1)
#' @param include_intercept Logical, whether to include an intercept column
#'
#' @return A matrix with the design matrix (time x conditions)
#'
#' @examples
#' # Create design matrix using canonical HRF
#' X <- create_design_matrix_from_benchmark("BM_Canonical_HighSNR", HRF_SPMG1)
#' 
#' # Test with a different HRF
#' X_wrong <- create_design_matrix_from_benchmark("BM_Canonical_HighSNR", HRF_SPMG2)
#'
#' @export
create_design_matrix_from_benchmark <- function(dataset_name, hrf, include_intercept = TRUE) {
  # Temporarily simplified
  return(matrix(0,0,0))
}

#' Evaluate Method Performance on Benchmark Dataset
#'
#' Helper function to evaluate the performance of beta estimation methods
#' on benchmark datasets by comparing estimated betas to ground truth.
#'
#' @param dataset_name Character string specifying which dataset to use
#' @param estimated_betas Matrix of estimated beta values (conditions x voxels)
#' @param method_name Character string describing the method used
#'
#' @return A list with performance metrics
#'
#' @examples
#' \dontrun{
#' # Load dataset and create design matrix
#' dataset <- load_benchmark_dataset("BM_Canonical_HighSNR")
#' X <- create_design_matrix_from_benchmark("BM_Canonical_HighSNR", HRF_SPMG1)
#' 
#' # Fit simple linear model
#' betas <- solve(t(X) %*% X) %*% t(X) %*% dataset$Y_noisy
#' 
#' # Evaluate performance
#' performance <- evaluate_method_performance("BM_Canonical_HighSNR", 
#'                                           betas[-1, ], # Remove intercept
#'                                           "OLS")
#' }
#'
#' @export
evaluate_method_performance <- function(dataset_name, estimated_betas, method_name = "Unknown") {
  # Temporarily simplified
  return(list(performance = "dummy"))
}

# Helper function for null coalescing
`%||%` <- function(x, y) if (is.null(x)) y else x

# Environment to store the loaded and processed benchmark datasets
.benchmark_data_env <- new.env(parent = emptyenv())

# Helper function to reconstruct HRF objects
.reconstruct_hrf_object <- function(name) {
  # Temporarily simplified
  return(NULL)
}

# Recursive helper to process true_hrf_parameters
.process_hrf_params <- function(params_list) {
  # Temporarily simplified
  return(params_list)
}

.load_and_reconstruct_raw_dataset <- function(ds_raw) {
  # Temporarily simplified
  return(ds_raw)
}

.ensure_benchmark_data_loaded <- function() {
  # Temporarily simplified
  if (!exists("fmri_benchmark_datasets_processed", envir = .benchmark_data_env)) {
    .benchmark_data_env$fmri_benchmark_datasets_processed <- list() # Empty list
  }
  return(.benchmark_data_env$fmri_benchmark_datasets_processed)
}
</file>

<file path="R/data_fmri_benchmark_datasets.R">
#' Benchmark fMRI datasets
#'
#' A list of simulated datasets used for testing the package.
#'
#' @format A list with elements \code{BM_Canonical_HighSNR},
#'   \code{BM_Canonical_LowSNR},
#'   \code{BM_HRF_Variability_AcrossVoxels},
#'   \code{BM_Trial_Amplitude_Variability},
#'   \code{BM_Complex_Realistic}, and \code{metadata}.
#'   Each element contains simulated BOLD data and ground truth information.
#' @source Generated by \code{data-raw/generate_benchmark_datasets.R}
#' @docType data
#' @name fmri_benchmark_datasets
NULL
</file>

<file path="R/event_model.R">
#' @importFrom utils head
#' @importFrom plotly plot_ly layout animation_opts
#' @importFrom tidyr complete pivot_longer
#' @importFrom dplyr mutate
#' @importFrom rlang .data
NULL

## ============================================================================
## Section 1: Unified Event Model Constructor (NEW Pipeline)
## ============================================================================

#' Construct an fMRI Event Model
#' 
#' This is the main constructor for `event_model` objects. It unifies the previous
#' formula and list-based interfaces and uses a more efficient internal pipeline.
#'
#' @param formula_or_list Either a formula (e.g., `onset ~ hrf(cond) + hrf(mod)`) 
#'        or a list of pre-defined `hrfspec` objects.
#' @param data A `data.frame` containing event variables referenced in the formula 
#'        or needed by the `hrfspec` objects.
#' @param block A formula (e.g., `~ run`) or vector specifying the block/run for each event.
#' @param sampling_frame An object of class `sampling_frame` defining the scan timing (TR, block lengths).
#' @param durations Numeric vector or scalar specifying event durations (seconds). Default is 0.
#' @param drop_empty Logical indicating whether to drop empty events during term construction. Default is TRUE.
#' @param precision Numeric precision for HRF sampling/convolution. Default is 0.3.
#' @param parallel Logical indicating whether to use parallel processing for term convolution (requires `future.apply`). Default is FALSE.
#' @param progress Logical indicating whether to show a progress bar during term realisation. Default is FALSE.
#' @param ... Additional arguments (currently unused).
#' 
#' @details 
#' ### Column Naming
#' The columns in the resulting design matrix follow the naming convention: 
#' `term_tag` + `_` + `condition_tag` + `_b##` basis suffix
#' 
#' Where:
#' *   `term_tag`: The unique tag assigned to the `hrf()` term (see below).
#' *   `condition_tag`: Represents the specific factor level or continuous regressor within the term (e.g., `condition.A`, `poly_RT_01`, `condition.A_task.go`).
#' *   `_b##`: Optional suffix added for HRFs with multiple basis functions (e.g., `_b01`, `_b02`).
#' 
#' ### Term Naming and Clash Resolution
#' Each term in the model (typically defined by an `hrf()` call in a formula) gets a 
#' unique `term_tag`. This tag is used as the prefix for all columns generated by that term.
#' 
#' - **Default Naming:** If no explicit `id` (or `name`) is given in `hrf()`, the tag is derived  
#'   from the variable names (e.g., `hrf(condition)` -> `condition`, `hrf(RT, acc)` -> `RT_acc`).
#' - **Explicit Naming:** Use `id=` within `hrf()` for an explicit tag (e.g., `hrf(condition, id="CondMain")`).
#' - **Sanitization:** Dots (`.`) in tags are converted to underscores (`_`).   
#' - **Clash Resolution:** If multiple terms generate the same tag, `#` and a number are appended 
#'   to ensure uniqueness (e.g., `condition`, `condition#1`).
#' 
#' This consistent naming scheme replaces the previous `compact` and `qualified` styles.
#' 
#' @return An object of class `c("event_model", "list")` containing the terms, design matrix, 
#'         sampling frame, and other metadata.
#'         
#' @examples 
#' # Example using formula interface
#' des <- data.frame(onset = seq(0, 90, by=10),
#'                   run = rep(1:2, each=5),
#'                   cond = factor(rep(c("A","B"), 5)),
#'                   mod = rnorm(10))
#' sframe <- sampling_frame(blocklens=c(50, 60), TR=2)
#' 
#' ev_model_form <- event_model(onset ~ hrf(cond) + hrf(mod, basis="spmg3"), 
#'                             data = des, block = ~run, sampling_frame = sframe)
#' print(ev_model_form)
#' head(design_matrix(ev_model_form))
#' 
#' # Example using list interface (less common)
#' # spec1 <- hrf(cond)
#' # spec2 <- hrf(mod, basis="spmg3")
#' # ev_model_list <- event_model(list(spec1, spec2), data=des, block=des$run, sampling_frame=sframe)
#' # print(ev_model_list)                         
#'                              
#' @export
#' @include event_model_helpers.R
event_model <- function(formula_or_list, data, block, sampling_frame, 
                        durations = 0, drop_empty = TRUE, precision = 0.3, 
                        parallel = FALSE, progress = FALSE, ...) {
  
  # Stage 1: Parse inputs
  parsed <- parse_event_model(formula_or_list, data, block, durations)
  
  # Stage 2: Realise event terms
  terms <- realise_event_terms(parsed, sampling_frame, drop_empty, progress)
  
  # Stage 3: Build design matrix
  dm <- build_event_model_design_matrix(terms, sampling_frame, precision, parallel)
  
  # Assemble final event_model object
  ret <- list(
    terms          = terms,
    design_matrix  = dm,
    blockids       = parsed$blockids, # Store canonicalized blockids
    sampling_frame = sampling_frame,
    contrasts      = list(), # Contrasts are now primarily within terms via hrfspec
    model_spec     = list( # Store essential original inputs for reference?
        formula_or_list = formula_or_list, # Keep original spec
        data_names = names(data),
        block_arg = block,          # Keep original block arg
        durations_arg = durations,  # Keep original duration arg
        drop_empty = drop_empty,
        precision = precision
    )
  )
  class(ret) <- c("event_model", "list")
  ret
}

## ============================================================================
## Section 1.5: Deprecated Constructors (REMOVED)
## ============================================================================

# Deprecated event_model.formula removed.
# Deprecated event_model.list removed.
# Deprecated create_event_model removed.


#' @export
blocklens.event_model <- function(x, ...) {
  blocklens(x$sampling_frame)
}

#' @export
blockids.event_model <- function(x) {
  x$blockids
}

#' @export
#' @rdname design_matrix
design_matrix.event_model <- function(x, blockid = NULL, ...) {
  # New version simply returns the pre-computed matrix, subsetting if needed
  dm <- x$design_matrix
  if (is.null(blockid)) {
    dm
  } else {
    # The design matrix has one row per timepoint, not per event
    # We need to map blockid to timepoint indices using the sampling frame
    sampling_frame <- x$sampling_frame
    if (is.null(sampling_frame)) {
        warning("Sampling frame not stored in event_model; cannot subset design matrix by block.")
        return(dm)
    }
    
    # Get the block IDs for each timepoint from the sampling frame
    timepoint_blockids <- blockids(sampling_frame)
    if (is.null(timepoint_blockids)) {
        warning("Cannot determine timepoint block IDs from sampling frame.")
        return(dm)
    }
    
    # Find timepoints that belong to the requested blocks
    keep_rows <- timepoint_blockids %in% blockid
    if (!any(keep_rows)) {
        warning("Specified blockid(s) not found in the sampling frame.")
        # Return empty tibble with same colnames
        return(dm[0, , drop = FALSE]) 
    }
    dm[keep_rows, , drop = FALSE]
  }
}

#' @export
terms.event_model <- function(x, ...) {
  x$terms
}

#' @export
conditions.event_model <- function(x, drop.empty = TRUE, expand_basis = FALSE, ...) {
  unlist(lapply(terms(x), function(t) {
    conditions(t, drop.empty = drop.empty, expand_basis = expand_basis, ...)
  }), use.names = FALSE)
}

#' @export
#' @rdname contrast_weights
contrast_weights.convolved_term <- function(x, ...) {
  lapply(x$contrasts, function(cspec) {
    if (!is.null(cspec))
      contrast_weights(cspec, x)
  })
}

#' @export
#' @rdname Fcontrasts
Fcontrasts.convolved_term <- function(x, ...) {
  Fcontrasts(x$evterm)
}

#' @export
#' @rdname contrast_weights
contrast_weights.fmri_model <- function(x, ...) { 
  contrast_weights(x$event_model) 
}

#' @export
term_names.event_model <- function(x) {
  xt <- terms(x)
  unlist(lapply(xt, function(term) term$varname))
}

#' @export
#' @rdname contrast_weights
contrast_weights.event_model <- function(x, ...) {
  tnames <- term_names(x)
  tind <- attr(x$design_matrix, "col_indices") 
  ncond <- ncol(x$design_matrix)
  if (is.null(tind)) {
      stop("Cannot compute contrast weights: design matrix missing 'col_indices' attribute.")
  }
  
  ret <- lapply(seq_along(terms(x)), function(i) {
    # Get contrasts defined *within* the term (from hrfspec)
    term_contrasts <- attr(terms(x)[[i]], "hrfspec")$contrasts
    term_indices_vec <- tind[[ names(terms(x))[i] ]]
    
    if (!is.null(term_contrasts) && length(term_contrasts) > 0) {
      # Ensure term_contrasts list is treated as a contrast_set for dispatch
      cset <- term_contrasts
      if (!inherits(cset, "contrast_set")) class(cset) <- c("contrast_set", class(cset))
      cwlist_local <- contrast_weights(cset, terms(x)[[i]])
      
      # Map local weights to full design matrix
      ret_mapped <- lapply(cwlist_local, function(cw) {
          if(is.null(cw)) return(NULL) # Skip if contrast calculation failed
          
          # Check consistency
          if (nrow(cw$weights) != length(term_indices_vec)){
              warning(sprintf("Contrast '%s' for term '%s' has %d rows, but term has %d columns in design matrix. Skipping.", 
                             cw$name, names(terms(x))[i], nrow(cw$weights), length(term_indices_vec)), call.=FALSE)
              return(NULL)
          }
          
          out <- matrix(0, ncond, ncol(cw$weights))
          colnames(out) <- colnames(cw$weights) # Preserve contrast names if multiple columns
          rownames(out) <- colnames(x$design_matrix)
          out[term_indices_vec, ] <- cw$weights
          
          # Add attributes/update structure
          cw$offset_weights <- out
          cw$condnames <- colnames(x$design_matrix) # Update condnames to full set
          attr(cw, "term_indices") <- as.vector(term_indices_vec)
          cw
      })
      
      # Filter out NULLs from failed mappings
      ret_mapped <- ret_mapped[!sapply(ret_mapped, is.null)]
      
      # Set names based on original contrast list
      if (length(ret_mapped) > 0) {
         cnames <- sapply(ret_mapped, function(cw) cw$name)
         names(ret_mapped) <- cnames
      }
      ret_mapped
      
    } else { # No contrasts defined within this term
        NULL
    }
  })
  
  names(ret) <- tnames
  # Filter out terms that had no contrasts defined
  ret <- ret[!sapply(ret, is.null)]
  # Return the grouped structure instead of flattening
  # This preserves the term grouping that fmri_lm_fit expects
  return(ret)
}

#' @export
Fcontrasts.event_model <- function(x, ...) {
  tnames <- term_names(x)
  tind <- attr(x$design_matrix, "col_indices") 
  ncond <- ncol(x$design_matrix)
  if (is.null(tind)) {
      stop("Cannot compute Fcontrasts: design matrix missing 'col_indices' attribute.")
  }
  
  ret_list <- lapply(seq_along(terms(x)), function(i) {
    term_i <- terms(x)[[i]]
    term_indices_vec <- tind[[ names(terms(x))[i] ]]
    
    # Calculate Fcontrasts relative to the term itself
    fcon_local <- Fcontrasts(term_i)
    
    if (!is.null(fcon_local) && length(fcon_local) > 0) {
        ret_mapped <- lapply(names(fcon_local), function(con_name) {
            cw <- fcon_local[[con_name]]
            
            # Check consistency
            if (nrow(cw) != length(term_indices_vec)){
                warning(sprintf("F-contrast '%s' for term '%s' has %d rows, but term has %d columns in design matrix. Skipping.", 
                                con_name, names(terms(x))[i], nrow(cw), length(term_indices_vec)), call.=FALSE)
                return(NULL)
            }
            
            out <- matrix(0, ncond, ncol(cw))
            colnames(out) <- colnames(cw)
            rownames(out) <- colnames(x$design_matrix)
            out[term_indices_vec, ] <- cw
            
            # Add attributes/update structure if needed (Fcontrast might just be matrix)
            attr(out, "term_indices") <- as.vector(term_indices_vec)
            out
        })
      
        # Filter out NULLs from failed mappings
        ret_mapped <- ret_mapped[!sapply(ret_mapped, is.null)]
        
        # Set names based on original contrast names, prefixed with term name
        if (length(ret_mapped) > 0) {
            prefix <- tnames[i]
            # Check if sapply(fcon_local, non_null) is necessary or exists
            valid_local_cons <- !sapply(fcon_local, is.null) # Simple check for non-NULL
            names(ret_mapped) <- paste0(prefix, "#", names(fcon_local)[valid_local_cons]) 
        }
         ret_mapped
         
    } else { # No Fcontrasts for this term
        NULL
    }
    
  })

  # Drop NULL entries for terms without F-contrasts
  ret_list <- ret_list[!sapply(ret_list, is.null)]

  # Concatenate without modifying individual elements
  ret <- if (length(ret_list)) do.call(c, ret_list) else list()
  ret
}

#' Print an Event Model
#'
#' Provides a concise summary of an `event_model` object using `cli`.
#'
#' @param x An `event_model` object.
#' @param ... Additional arguments (unused).
#'
#' @importFrom cli cli_h1 cli_div cli_text cli_h2 cli_ul cli_li cli_end cli_verbatim cli_alert_info
#' @importFrom utils head
#' @export
#' @rdname print
print.event_model <- function(x, ...) {
  n_terms <- length(x$terms)
  term_names <- names(x$terms)
  n_events <- length(x$blockids)
  n_blocks <- length(unique(x$blockids))
  total_scans <- sum(blocklens(x$sampling_frame))
  dm <- design_matrix(x)
  dm_dims <- dim(dm)

  cli::cli_h1("fMRI Event Model")
  cli::cli_div(theme = list(
    span.info = list(color = "blue"),
    span.detail = list(color = "grey")
  ))

  cli::cli_text("{.info Number of Terms:} {n_terms}")
  cli::cli_text("{.info Number of Events:} {n_events}")
  cli::cli_text("{.info Number of Blocks:} {n_blocks}")
  cli::cli_text("{.info Total Scans:} {total_scans}")
  cli::cli_text("{.info Design Matrix Dimensions:} {dm_dims[1]} x {dm_dims[2]}")

  if (n_terms > 0) {
    cli::cli_h2("Terms")
    cli::cli_ul()
    for (i in seq_len(n_terms)) {
      tclass <- class(x$terms[[i]])[1]
      cli::cli_li("{.field {term_names[i]}} ({.cls {tclass}})")
    }
    cli::cli_end()
  }

  if (prod(dm_dims) > 0) {
    cli::cli_h2("Design Matrix Preview")
    dm_preview <- head(dm[, seq_len(min(4, dm_dims[2])), drop = FALSE], 3)
    dm_char <- apply(dm_preview, 2, function(col) sprintf("%7.3f", col))
    rownames(dm_char) <- paste("Scan", seq_len(nrow(dm_char)))
    preview_text <- capture.output(print(dm_char, quote = FALSE))
    cli::cli_verbatim(paste("  ", preview_text, collapse = "\n"))
    if (dm_dims[1] > nrow(dm_preview) || dm_dims[2] > ncol(dm_preview)) {
      cli::cli_text("  {.detail ...}")
    }
  } else {
    cli::cli_alert_info("Design matrix is empty.")
  }

  contrasts_info <- tryCatch(contrast_weights(x), error = function(e) NULL)
  if (!is.null(contrasts_info) && length(contrasts_info) > 0) {
    cli::cli_h2("Contrasts")
    cli::cli_ul()
    for (con in names(contrasts_info)) {
      cli::cli_li("{.field {con}}")
    }
    cli::cli_end()
  }

  cli::cli_end()
  invisible(x)
}
</file>

<file path="R/event-classes.R">
#' @include utils-internal.R
# Internal unified constructor for event sequences
# 
# Creates an 'event-sequence' object (many rows, one variable).
# This is the core internal function that standardizes various input types 
# into a common representation: a list with class c("event", "event_seq").
# It stores the event payload in `$value` (always a numeric matrix) and 
# additional metadata (like factor levels or basis objects) in `$meta`.
# Public-facing wrappers like `event_factor`, `event_variable` call this function.
#
# @param value Event values (factor, character, numeric vector, matrix, ParametricBasis).
# @param name Name of the event variable (will be sanitized).
# @param onsets Numeric vector of event onsets (seconds).
# @param blockids Numeric vector of block IDs (non-decreasing integers).
# @param durations Numeric vector of event durations (seconds), or a scalar.
# @param subset Optional logical vector indicating which events to keep. If
#   provided, the vector must be the same length as `onsets` and contain no `NA`
#   values.
# 
# @return An S3 object of class `event` and `event_seq`, containing:
#   \item{varname}{Sanitized variable name.} 
#   \item{onsets}{Numeric vector of onsets (subsetted).} 
#   \item{durations}{Numeric vector of durations (subsetted and recycled).}
#   \item{blockids}{Numeric vector of block IDs (subsetted).}
#   \item{value}{Numeric matrix storing the event payload. 
#                 For factors, this contains integer codes (1-based).
#                 For basis objects, this is the basis matrix (`basis$y`).
#                 For numeric vectors/matrices, it's the numeric data.} 
#   \item{continuous}{Logical flag. TRUE for numeric, matrix, basis; FALSE for factor/character.} 
#   \item{meta}{A list containing metadata, or NULL. 
#               For factors: `meta = list(levels = c("level1", "level2", ...))`. 
#               For basis objects: `meta = list(basis = <ParametricBasis object>)`.} 
# 
# @name event
# @keywords internal
# @noRd
event <- function(value, name, onsets, blockids, durations = 0, subset = NULL) {
  
  # --- Add NA check for input value --- 
  if (!inherits(value, "ParametricBasis") && anyNA(value)) { # Don't check inside basis objects
      warning(sprintf("NA values detected in input `value` for event variable '%s'. Coercion or filtering might occur.", name), call. = FALSE)
  }
  # -------------------------------------
  
  n_initial <- length(onsets)
  if (!is.null(subset)) {
      assertthat::assert_that(length(subset) == n_initial,
        msg = sprintf("subset length (%d) must match onsets length (%d)",
                      length(subset), n_initial))
      assertthat::assert_that(!anyNA(subset),
        msg = "subset cannot contain NA values")
  } else {
      subset <- rep(TRUE, n_initial)
  }
  
  # --------------------------------------------
  # 1. Validate / recycle / pre-process with the existing helper
  # TODO: Review/refactor/integrate .checkEVArgs itself later (Ticket EV-4)
  meta_checked <- .checkEVArgs(name, value, onsets, blockids, durations)
  
  # Overwrite with validated/processed objects from the helper
  name      <- meta_checked$varname # Use sanitized name
  value     <- meta_checked$value
  onsets    <- meta_checked$onsets
  blockids  <- meta_checked$blockids
  durations <- meta_checked$durations # Recycled by helper
  # --------------------------------------------
  
  # Apply subsetting safely AFTER validation and recycling
  keep_indices <- which(subset)
  onsets_sub    <- onsets[keep_indices]
  blockids_sub  <- blockids[keep_indices]
  durations_sub <- durations[keep_indices]
  n_final <- length(onsets_sub)
  
  # Determine continuous flag based on *original* input type
  # Basis, numeric, matrix are continuous; factor, character are not.
  is_continuous <- !(is.factor(value) || is.character(value))
  
  # Process value based on type, applying subsetting.
  # Use if/else if/else for conditional logic
  
  if (inherits(value, "ParametricBasis")) {
      basis_subset <- sub_basis(value, subset)
      switch_result <- list(value = basis_subset$y, meta = list(basis = basis_subset))
  } else if (is.factor(value) || is.character(value)) {
      # Store original levels - handle both factors and character vectors
      original_levels <- if (is.factor(value)) {
          levels(value)
      } else {
          # For character vectors, get unique values as levels
          unique(as.character(value))
      }
      # Create factor 'f' using subsetted values BUT preserving original levels
      f <- factor(as.character(value)[keep_indices], levels = original_levels)
      if (length(f) == 0) {
          val_payload <- matrix(numeric(0), nrow = 0, ncol = 1L)
      } else {
          val_payload <- matrix(as.integer(f), ncol = 1L)
      }
      # Store the ORIGINAL levels in meta$levels
      switch_result <- list(value = val_payload, meta = list(levels = original_levels))
  } else if (is.matrix(value)) {
      switch_result <- list(value = value[keep_indices, , drop = FALSE], meta = NULL)
  } else if (is.numeric(value) && (is.vector(value) || length(dim(value)) == 1)) {
      switch_result <- list(value = matrix(value[keep_indices], ncol = 1L), meta = NULL)
  } else {
      # Default case (should be caught by .checkEVArgs, but defensive)
      stop(paste("Unsupported `value` type:", class(value)[1], "for variable:", name))
  }
  
  # Assign results from the conditional logic
  val_mat   <- switch_result$value
  meta_list <- switch_result$meta

  # Ensure payload is a matrix
  if (!is.matrix(val_mat)) {
      stop("Internal error: Processed event value is not a matrix.") 
  }
  
  # Ensure colnames exist
  if (is.null(colnames(val_mat))) {
      if (ncol(val_mat) == 1 && !is.null(name)) {
          colnames(val_mat) <- name # Use varname for single column
      } else {
           # Use simple sequence for multi-column fallback
          colnames(val_mat) <- paste0("V", seq_len(ncol(val_mat)))
      } 
  }
  
  # Final length check (simplified as .checkEVArgs ensures alignment before subset)
  stopifnot(nrow(val_mat) == n_final)
  
  # Construct the final list structure
  structure(list(
      varname    = name, 
      onsets     = onsets_sub, 
      durations  = durations_sub, 
      blockids   = blockids_sub,
      value      = val_mat,        # Standardized matrix payload
      continuous = is_continuous,  # Robust flag based on input type
      meta       = meta_list       # List containing levels or basis object, or NULL
      ),
    class = c("event", "event_seq")
  )
} 


## ============================================================================
## Section: Public Event Constructor Wrappers
## ============================================================================

#' Create a categorical event sequence from a factor.
#' 
#' This is a user-facing wrapper around the internal `event()` constructor,
#' specifically for creating categorical event sequences from factors or characters.
#'
#' @param fac A factor or something coercible to a factor.
#' @param name Name of the event variable.
#' @param onsets Numeric vector of event onsets (seconds).
#' @param blockids Numeric vector of block IDs.
#' @param durations Numeric vector of event durations (seconds), or a scalar.
#' @param subset Optional logical vector indicating which events to keep. If
#'   provided, the vector must match `onsets` in length and contain no `NA`
#'   values.
#'
#' If `mat` has column names and more than one column, those names are
#' sanitized using `.sanitizeName()` before being stored. The sanitized
#' column names are returned by `levels()` for the resulting event object.
#'
#' @return An S3 object of class `event` and `event_seq`.
#'
#' @examples
#' efac <- event_factor(factor(c("a", "b", "c", "a", "b", "c")), "abc", 
#'         onsets = seq(1, 100, length.out = 6))
#' print(efac)
#' levels(efac)
#'
#' @seealso \code{\link{event_model}}, \code{\link{event_variable}}, \code{\link{event_matrix}}, \code{\link{event_basis}}
#' @export 
event_factor <- function(fac, name, onsets, blockids = 1, durations = 0, subset = NULL) {
  # Convert to factor early if needed, but event() handles characters too.
  if (!is.factor(fac) && !is.character(fac)) {
    warning("Input `fac` is not a factor or character, attempting to convert.")
    fac <- factor(as.character(fac))
  }
  
  # Call the unified internal constructor
  event(value = fac, 
        name = name, 
        onsets = onsets, 
        blockids = blockids, 
        durations = durations, 
        subset = subset)
}        

#' Create a continuous event sequence from a numeric vector.
#'
#' This is a user-facing wrapper around the internal `event()` constructor,
#' specifically for creating continuous event sequences from numeric vectors.
#' 
#' @param vec Numeric vector representing continuous event values.
#' @param name Name of the event variable.
#' @param onsets Numeric vector of event onsets (seconds).
#' @param blockids Numeric vector of block IDs.
#' @param durations Numeric vector of event durations (seconds), or a scalar.
#' @param subset Optional logical vector indicating which events to keep. If
#'   provided, the vector must match `onsets` in length and contain no `NA`
#'   values.
#'
#' @return An S3 object of class `event` and `event_seq`.
#'
#' @examples
#' evar <- event_variable(c(1, 2, 3, 4, 5, 6), "example_var", onsets = seq(1, 100, length.out = 6))
#' print(evar)
#' is_continuous(evar)
#'
#' @seealso \code{\link{event_factor}}
#' @export
event_variable <- function(vec, name, onsets, blockids = 1, durations = 0, subset = NULL) {
  if (!is.numeric(vec) || !(is.vector(vec) || length(dim(vec)) <= 1)) {
      stop("`vec` must be a numeric vector.")
  }
  if (is.factor(vec)) {
    stop("Cannot create an event_variable from a factor, use 'event_factor'.")
  }

  # Call the unified internal constructor
  event(value = vec, 
        name = name, 
        onsets = onsets, 
        blockids = blockids, 
        durations = durations, 
        subset = subset)
}       

#' Create a continuous event set from a matrix.
#'
#' This is a user-facing wrapper around the internal `event()` constructor,
#' specifically for creating continuous event sequences from numeric matrices.
#' 
#' @param mat A numeric matrix of continuous event values (one row per event).
#' @param name Name of the event variable.
#' @param onsets Numeric vector of event onsets (seconds).
#' @param blockids Numeric vector of block IDs.
#' @param durations Numeric vector of event durations (seconds), or a scalar.
#' @param subset Optional logical vector indicating which events to keep. If
#'   provided, the vector must match `onsets` in length and contain no `NA`
#'   values.
#'
#' If `mat` has column names and more than one column, those names are
#' sanitized using `.sanitizeName()` before being stored. The sanitized
#' column names are returned by `levels()` for the resulting event object.
#'
#' @return An S3 object of class `event` and `event_seq`.
#'
#' @examples
#' mat <- matrix(rnorm(20), 10, 2, dimnames=list(NULL, c("Val1", "Val2")))
#' onsets <- seq(1, 100, length.out = 10)
#' durations <- rep(1, 10)
#' blockids <- rep(1, 10)
#' eset <- event_matrix(mat, "eset", onsets, blockids, durations)
#' print(eset)
#' columns(eset) # Alias for levels
#'
#' @export
event_matrix <- function(mat, name, onsets, blockids = 1, durations = 0, subset = NULL) {
  if (!is.matrix(mat) || !is.numeric(mat)) {
      stop("`mat` must be a numeric matrix.")
  }
  assert_that(nrow(mat) == length(onsets),
              msg = sprintf("Length mismatch for '%s': nrow(mat)=%d, length(onsets)=%d",
                          name, nrow(mat), length(onsets)))
  # Sanitize column names when multiple columns are provided
  if (ncol(mat) > 1 && !is.null(colnames(mat))) {
      colnames(mat) <- .sanitizeName(colnames(mat))
  }
  
  # Call the unified internal constructor
  event(value = mat, 
        name = name, 
        onsets = onsets, 
        blockids = blockids, 
        durations = durations, 
        subset = subset)
}

#' Create an event set from a ParametricBasis object.
#'
#' This is a user-facing wrapper around the internal `event()` constructor,
#' specifically for creating event sequences modulated by a basis set.
#' 
#' @param basis A `ParametricBasis` object (e.g., from `BSpline`, `PolynomialBasis`).
#' @param name Optional name for the event variable. If NULL, uses `basis$name`.
#' @param onsets Numeric vector of event onsets (seconds).
#' @param blockids Numeric vector of block IDs.
#' @param durations Numeric vector of event durations (seconds), or a scalar.
#' @param subset Optional logical vector indicating which events to keep. If
#'   provided, the vector must match `onsets` in length and contain no `NA`
#'   values.
#'
#' @return An S3 object of class `event` and `event_seq`.
#'
#' @import assertthat
#' @examples
#' basis <- BSpline(1:21, 3)
#' onsets <- seq(0, 20, length.out = 21)
#' blockids <- rep(1, length(onsets))
#' ebasis <- event_basis(basis, onsets=onsets, blockids=blockids)
#' print(ebasis)
#' levels(ebasis)
#'
#' @export
event_basis <- function(basis, name = NULL, onsets, blockids = 1, durations = 0, subset = NULL) {
  assertthat::assert_that(inherits(basis, "ParametricBasis"))
  
  # Use basis$name if name is not provided
  if (is.null(name)) {
      name <- basis$name
      if (is.null(name)) { # Fallback if basis name is also NULL
          warning("No name provided and basis$name is NULL, using default name 'basis'")
          name <- "basis"
      }
  }
  
  # Call the unified internal constructor
  event(value = basis, 
        name = name, 
        onsets = onsets, 
        blockids = blockids, 
        durations = durations, 
        subset = subset)
} 

## ============================================================================
## Section: Unified S3 Methods for 'event' class
## ============================================================================

#' Get levels or column names of an event object
#' 
#' Retrieves the appropriate names associated with the event values.
#' - For factors (stored internally as integers), retrieves names from `$meta$levels`.
#' - For basis objects, retrieves names via `levels()` method of the stored basis object in `$meta$basis`.
#' - For matrices or numeric vectors, returns the column names of the internal `$value` matrix.
#'
#' @param x An object of class `event`.
#' @return A character vector of names.
#' @export
levels.event <- function(x) {
  if (!is.null(x$meta$basis)) {
    # Use levels method for the basis object itself
    levels(x$meta$basis) 
  } else if (!is.null(x$meta$levels)) {
    # Use stored levels for factors
    x$meta$levels
  } else {
    # Default to column names of the value matrix
    colnames(x$value)
  }
}

#' @describeIn levels.event Alias for levels.event
#' @export
columns.event <- levels.event

#' Check if an event object represents continuous values
#' 
#' Checks the `$continuous` flag set by the `event()` constructor.
#' 
#' @param x An object of class `event`.
#' @return Logical `TRUE` if continuous (numeric, matrix, basis), `FALSE` if categorical (factor).
#' @export
is_continuous.event <- function(x) {
  x$continuous
}

#' Check if an event object represents categorical values
#' 
#' Checks if an event is categorical (i.e., not continuous).
#' 
#' @param x An object of class `event`.
#' @return Logical `TRUE` if categorical (factor), `FALSE` if continuous.
#' @export
is_categorical.event <- function(x) {
  !is_continuous(x)
}

#' Retrieve cells for a single event sequence.
#'
#' For categorical events, returns observed factor levels and counts.
#' For continuous events, returns the variable name as a single cell with the total event count.
#'
#' @param x object of class `event`
#' @param drop.empty Logical; if TRUE (default), rows corresponding to levels with zero
#'        counts are dropped for categorical events.
#' @param ... Additional arguments (unused).
#' @return A one-column tibble (`.level` or `.name`) with a `count` attribute.
#' @importFrom tibble tibble
#' @export
#' @rdname cells
cells.event <- function(x, drop.empty = TRUE, ...) {
  var_name <- x$varname # Get the variable name
  
  if (is_categorical(x)) {
    lvl <- levels(x)
    if (length(lvl) == 0) { # Handle factor with no levels
        # Use dynamic name for the empty tibble column
        out <- tibble::tibble(!!var_name := factor(character(0)))
        attr(out, "count") <- integer(0)
        return(out)
    }
    counts <- tabulate(match(x$value[, 1L], seq_along(lvl)), nbins = length(lvl))
    names(counts) <- lvl
    
    if (drop.empty) {
        keep <- counts > 0
        lvl_out <- lvl[keep]
        counts_out <- counts[keep]
    } else {
        lvl_out <- lvl
        counts_out <- counts
    }
    # Use dynamic name var_name for the tibble column
    out <- tibble::tibble(!!var_name := factor(lvl_out, levels = lvl)) 
    attr(out, "count") <- counts_out
    
  } else {
    # Continuous -> single pseudo-cell representing the variable
    # Use dynamic name var_name for the tibble column
    out <- tibble::tibble(!!var_name := var_name)
    count_val <- length(x$onsets)
    attr(out, "count") <- count_val
    names(attr(out, "count")) <- var_name # Name the count
     # Handle drop.empty for zero-event continuous case
    if (drop.empty && count_val == 0) {
          out <- out[0, , drop=FALSE]
          attr(out, "count") <- integer(0)
          names(attr(out, "count")) <- character(0)
      }
  }
  out
}

#' Extract elements (values or labels) of an event object
#' 
#' Returns a list containing the event's data, either the actual numeric values 
#' or descriptive labels. Used internally by `event_term` and potentially for inspection.
#'
#' @param x An event object.
#' @param what Character, either "values" (default) to return the numeric data matrix 
#'        (from `$value`), or "labels" to return descriptive names/levels for each 
#'        event instance (e.g., factor levels as a factor vector, or column names/
#'        basis levels as a character vector or matrix).
#' @param transformed Logical; relevant only for basis events when `what="values"`. 
#'        If TRUE (default), return the transformed basis matrix (`$value`). 
#'        If FALSE, attempt to return the original pre-transformation values (not robustly supported).
#' @param ... Additional arguments (unused).
#' @return A named list containing one element (a matrix or vector). 
#'         If `what="values"`, an N x K numeric matrix.
#'         If `what="labels"`, an N-length factor/vector or N x K character matrix.
#'         The list element name is `x$varname`.
#' @export
elements.event <- function(x, what = c("values", "labels"), transformed = TRUE, ...) {
  
  what <- match.arg(what)
  var_name_sanitized <- .sanitizeName(x$varname)
  
  element_data <- NULL
  
  if (what == "values") {
      # --- Handle VALUES --- 
      
      # Check cache first
      cache_val_attr <- paste0("_elements_cache_", what) # Unique cache attribute name
      cached_data <- attr(x, cache_val_attr)
      if (!is.null(cached_data)) {
          # Return cached data wrapped in a named list
          return(stats::setNames(list(cached_data), var_name_sanitized))
      }
      
      # Handle basis 'transformed' case (although !transformed is tricky)
      if (!is.null(x$meta$basis) && !transformed) {
          warning("'transformed = FALSE' for basis elements is not reliably supported, returning the transformed basis matrix.")
          element_data <- x$value
      } else {
           element_data <- x$value # This is always an N x K matrix (or 0xK)
      }
      
      # Store in cache before returning
      attr(x, cache_val_attr) <- element_data
      
  } else {
      # --- Handle LABELS --- 
      # Return descriptive names/levels for EACH event instance
      n_events <- length(x$onsets)
      lvls <- levels.event(x) # Get the names/levels (length K)
      
      if (n_events == 0) {
          # Handle empty event sequence consistently
          if (!x$continuous && !is.null(x$meta$levels)) {
              element_data <- factor(character(0), levels = lvls)
          } else if (length(lvls) <= 1) { # Single name/level
              element_data <- character(0)
          } else { # Multi-column name/level
              element_data <- matrix(character(0), nrow=0, ncol=length(lvls), dimnames=list(NULL, lvls))
          }
      } else if (!x$continuous && !is.null(x$meta$levels)) {
          # Categorical: Reconstruct factor values as a factor vector (length = n_events)
          element_data <- factor(x$value[, 1L], levels = seq_along(lvls), labels = lvls)
      } else if (length(lvls) == 1) {
          # Single continuous variable or basis: repeat name n_events times (length = n_events)
          element_data <- rep(lvls, n_events)
      } else {
          # Multi-column continuous (matrix/basis): create matrix repeating colnames (N x K)
          element_data <- matrix(rep(lvls, each = n_events), 
                                 nrow = n_events, 
                                 ncol = length(lvls), 
                                 dimnames = list(NULL, lvls))
      } 
  }
  
  # Return the data directly, not wrapped in a list
  element_data
}

#' Print event objects
#'
#' Provides a concise summary of an event object using cli.
#'
#' @param x An event object.
#' @param ... Additional arguments (unused).
#' @import cli
#' @export
#' @rdname print
print.event <- function(x, ...) {
  nevents <- length(x$onsets)
  type <- if (is_continuous(x)) "Continuous" else "Categorical"
  
  cli::cli_h1("Event Sequence: {.field {x$varname}}")
  
  cli::cli_div(theme = list(span.info = list(color = "blue")))
  cli::cli_text("{.info • Type:} {type}")
  
  # Display Levels (categorical) or Columns (continuous)
  lvls <- levels(x) # Uses levels.event S3 method
  if (!is_continuous(x)) {
    cli::cli_text("{.info • Levels:} {paste(lvls, collapse = ', ')}")
  } else {
    cli::cli_text("{.info • Columns:} {paste(lvls, collapse = ', ')}")
  }
  
  cli::cli_text("{.info • Events:} {nevents}")
  
  if (nevents > 0) {
    cli::cli_h2("Timing")
    onset_range <- range(x$onsets, na.rm = TRUE)
    dur_range <- range(x$durations, na.rm = TRUE)
    onset_range_str <- sprintf("%.2f - %.2f sec", onset_range[1], onset_range[2])
    dur_range_str <- sprintf("%.2f - %.2f sec", dur_range[1], dur_range[2])
    cli::cli_text("{.info • Onset Range:} {onset_range_str}")
    cli::cli_text("{.info • Duration Range:} {dur_range_str}")
    
    cli::cli_h2("Blocks")
    blocks_table <- table(x$blockids)
    nblocks <- length(blocks_table)
    cli::cli_text("{.info • Number of Blocks:} {nblocks}")
    max_show_blocks <- 10
    blocks_display <- if(nblocks > max_show_blocks) {
                          paste(c(names(blocks_table)[1:max_show_blocks], "..."), collapse = ", ")
                      } else {
                          paste(names(blocks_table), collapse = ", ")
                      }
    cli::cli_text("{.info • Block IDs:} {blocks_display}")
  } else {
      cli::cli_alert_info("Event sequence is empty.")
  }
  
  # Display Value Range for continuous (non-basis) variables
  if (is_continuous(x) && is.null(x$meta$basis)) {
      cli::cli_h2("Values")
      value_range <- range(x$value, na.rm = TRUE)
      value_range_str <- sprintf("%.2f - %.2f", value_range[1], value_range[2])
       cli::cli_text("{.info • Value Range:} {value_range_str}")
  }
  
  cli::cli_end()
  
  invisible(x)
}

## ============================================================================
## Section: Get Formatted Labels for Single Event
## ============================================================================

#' Get Formatted Labels for a Single Event
#'
#' Returns a character vector of formatted labels for an event object,
#' using the `Variable[Level]` style for categorical events, 
#' `Variable[Index]` for multi-column continuous events, or just
#' `Variable` for single continuous events.
#' Useful for getting consistent labels for individual event components.
#' This is distinct from `levels()` which returns the raw level names or column names.
#' Relies on the internal `.level_vector` helper function.
#'
#' @param x An object of class `event`.
#' @param ... Additional arguments (unused).
#' @return A character vector of formatted labels, or `character(0)` if not applicable.
#' @export
#' @examples
#' fac <- factor(rep(c("A", "B"), 3))
#' onsets <- 1:6
#' ev_fac <- event_factor(fac, "Condition", onsets)
#' labels(ev_fac) # Should return c("Condition[A]", "Condition[B]")
#' 
#' vals <- 1:6
#' ev_num <- event_variable(vals, "Modulator", onsets)
#' labels(ev_num) # Should return "Modulator"
#' 
#' mat <- matrix(1:12, 6, 2)
#' colnames(mat) <- c("C1", "C2")
#' ev_mat <- event_matrix(mat, "MatrixVar", onsets)
#' labels(ev_mat) # Should return c("MatrixVar[1]", "MatrixVar[2]") 
#'
labels.event <- function(x, ...) {
  # Directly call the internal helper (now in utils-internal.R)
  # Assumes utils-internal.R functions are available in package namespace
  .level_vector(x)
}

## ============================================================================
## Section: End of File
</file>

<file path="R/fmri_latent_lm.R">
#' Fast fMRI Regression Model Estimation from a Latent Component Dataset
#'
#' This function estimates a regression model for fMRI data using a latent component dataset.
#' The dataset must be of type `latent_dataset`, which itself requires a `LatentNeuroVec` input.
#'
#' @param formula A formula specifying the regression model.
#' @param block A factor indicating the block structure of the data.
#' @param baseline_model An optional baseline model.
#' @param dataset A dataset of class 'latent_dataset'.
#' @param durations The duration of events in the dataset.
#' @param drop_empty Whether to drop empty events from the model. Default is TRUE.
#' @param robust Whether to use robust regression methods. Default is FALSE.
#' @param autocor The autocorrelation correction method to use on components.
#'   One of 'none', 'auto', 'ar1', 'ar2', or 'arma'. Default is 'none'.
#' @param bootstrap Whether to compute bootstrapped parameter estimates. Default is FALSE.
#' @param nboot The number of bootstrap iterations. Default is 1000.
#' @param ... Additional arguments.
#'
#' @return An object of class 'fmri_latent_lm' containing the regression model and dataset.
#'
#' @note This method is currently experimental.
#'
#' @export
#'
#' @examples
#' 
#'
#' # Estimate the fMRI regression model using the latent dataset
#' #result <- fmri_latent_lm(formula = formula, block = block, dataset = dset,
#' #                          durations = NULL, drop_empty = TRUE, robust = FALSE)
#'
#' # Print the result
#' #print(result)
fmri_latent_lm <- function(formula, block, baseline_model=NULL, dataset, 
                    durations, drop_empty=TRUE, robust=FALSE, 
                    autocor=c("none", "auto", "ar1", "ar2", "arma"), 
                    bootstrap=FALSE, nboot=1000,
                    ...) {
  
  autocor <- match.arg(autocor)
  assert_that(inherits(dataset, "latent_dataset"))
  
  model <- create_fmri_model(formula, block, baseline_model,dataset, drop_empty=drop_empty)
  ret <- fmri_lm_fit(model, dataset, strategy="chunkwise", robust=robust, 
                     nchunks=1, autocor=autocor, 
                     bootstrap=bootstrap, nboot=nboot)

  ret$dataset <- dataset
  class(ret) <- c("fmri_latent_lm", class(ret))
  ret
}


#' Internal function for performing chunkwise linear regression on latent datasets
#'
#' @keywords internal
#' @details This function is an internal helper function for fmri_latent_lm, which performs
#'          chunkwise linear regression on latent datasets. The function handles different
#'          autocorrelation options, as well as robust regression and bootstrapping.
#'
#' @param dset A latent dataset object.
#' @param model The fmri model object.
#' @param conlist A list of contrasts.
#' @param nchunks The number of chunks to use for the regression.
#' @param robust Logical, if TRUE, robust regression will be performed.
#' @param verbose Logical, if TRUE, additional output will be printed.
#' @param autocor A character string specifying the autocorrelation method to use.
#' @param bootstrap Logical, if TRUE, bootstrapping will be performed.
#' @param nboot The number of bootstrap iterations.
#' @param boot_rows Logical, if TRUE, bootstrap row-wise.
#' @return A list containing the results of the chunkwise linear regression.
#' @seealso fmri_latent_lm
#' @noRd
chunkwise_lm.latent_dataset <- function(dset, model, conlist, nchunks, robust=FALSE, verbose=FALSE, 
                                        autocor=c("auto", "ar1", "ar2", "arma", "none"), 
                                        bootstrap=FALSE, nboot=1000, boot_rows=FALSE) {
  autocor <- match.arg(autocor)
  form <- get_formula(model)
  tmats <- term_matrices(model)
  data_env <- list2env(tmats)
  data_env[[".y"]] <- rep(0, nrow(tmats[[1]]))
  modmat <- model.matrix(as.formula(form), data_env)
  
  basismat <- get_data(dset)

  #wmat <- if (autocor != "none") {
  #  message("whitening components")
  #  auto_whiten(basismat, modmat, autocor)
  #} else {
  #  basismat
  #}
  
  #data_env[[".y"]] <- as.matrix(wmat)
  data_env[[".y"]] <- as.matrix(basismat)
  
  event_indices=attr(tmats, "event_term_indices")
  baseline_indices=attr(tmats, "baseline_term_indices")
  
  if (bootstrap) {
    lmfun <- multiresponse_bootstrap_lm
    ret <- lmfun(form, data_env, conlist, attr(tmats,"varnames"), fcon=NULL, 
                 modmat=modmat, 
                 nboot=nboot, 
                 boot_rows=boot_rows,
                 event_indices=event_indices)
  } else if (autocor != "none") {
    
    ## need to split by run
    lmfun <- multiresponse_arma
   
    ret <- lmfun(form, data_env, conlist, attr(tmats,"varnames"), fcon=NULL, 
                 modmat=modmat, blockids=model$event_model$sampling_frame$blockids, autocor=autocor)
    unpack_chunkwise(ret, event_indices, baseline_indices) %>% purrr::list_modify(event_indices=event_indices,
                                                                                  baseline_indices=baseline_indices)
    
  } else {
    lmfun <- if (robust) multiresponse_rlm else multiresponse_lm
    ret <- lmfun(form, data_env, conlist, attr(tmats,"varnames"), fcon=NULL, 
                 modmat=modmat)
    
    rss <- colSums(as.matrix(ret$fit$residuals^2))
    rdf <- ret$fit$df.residual
    resvar <- rss/rdf
    sigma <- sqrt(resvar)
    
    unpack_chunkwise(list(ret), event_indices, baseline_indices) %>% purrr::list_modify(event_indices=event_indices,
                                                                                        baseline_indices=baseline_indices,
                                                                                        sigma=sigma,
                                                                                        residuals=resid(ret$fit),
                                                                                        df.residual=ret$fit$df.residual,
                                                                                        qr=qr.lm(ret$fit))
    
  }

}

  
#' @keywords internal
#' @noRd
tibble_to_neurovec <- function(dset, tab, mask) {
  sp <- neuroim2::space(get_mask(dset))
  neuroim2::SparseNeuroVec(as.matrix(tab), neuroim2::add_dim(sp, nrow(tab)), mask=mask)
}

#' @export
coef.fmri_latent_lm <- function(object, type=c("estimates", "contrasts"), recon=FALSE, comp=0, ...) {
  bvals <- coef.fmri_lm(object, type=type)
  if (recon) {
    lds <- object$dataset$lvec@loadings
    comp <- if (length(comp) == 1 && comp == 0) {
      seq(1, ncol(lds)) 
    } else {
      assertthat::assert_that(all(comp > 0) && all(comp <= ncol(lds)))
      comp
    }
    
    lds <- lds[,comp,drop=FALSE]
    
    out <- t(as.matrix(bvals)[comp,]) %*% t(lds)
    out <- as.matrix(t(out))
    tibble::as_tibble(out)
  } else {
    bvals
  }
}

#' Calculate the standard error for an fmri_latent_lm object
#'
#' @export
#' @param x An fmri_latent_lm object.
#' @param type A character string specifying whether to return the standard error for "estimates" or "contrasts".
#' @param recon Logical, if TRUE, the function calculates the standard error for reconstructed data.
#' @param ... Additional arguments (currently unused).
#' @return A tibble containing the standard error values.
#' @seealso fmri_latent_lm
#' @importFrom Matrix rowSums t
standard_error.fmri_latent_lm <- function(x, type=c("estimates", "contrasts"), recon=FALSE,...) {
  type <- match.arg(type)
 
  if (!recon) {
    standard_error.fmri_lm(x, type)
  } else {
    R <- x$result$residuals
    CR <- cov(R) * (nrow(R) - 1)/x$result$df.residual
    
    Qr <- x$result$qr
    cov.unscaled <- chol2inv(Qr$qr)
    lds <- x$dataset$lvec@loadings
  
    if (type == "estimates") {
      ret <- do.call(cbind, lapply(x$result$event_indices, function(i) {
        sqrt(rowSums((lds %*% (CR * cov.unscaled[i,i])) * lds))
      }))
      colnames(ret) <- conditions(x$model$event_model)
      tibble::as_tibble(ret, .name_repair="check_unique")
    } else {
      # Handle contrasts case
      contrasts_df <- x$result$contrasts %>% dplyr::filter(type == "contrast")
      
      if (nrow(contrasts_df) == 0) {
        return(tibble())  # Return empty tibble if no contrasts
      }
      
      ret <- do.call(cbind, lapply(seq_len(nrow(contrasts_df)), function(i) {
        cmat <- as.matrix(contrasts_df$conmat[[i]])  # Get contrast matrix directly from tibble
        cind <- contrasts_df$colind[[i]]  # Get column indices from tibble
        
        csc <- t(cmat) %*% cov.unscaled[cind, cind, drop=FALSE] %*% cmat
        sqrt(rowSums(as.matrix((lds %*% (CR * csc[1,1])) * lds)))
      }))
      
      colnames(ret) <- contrasts_df$name  # Use names from the contrasts tibble
      tibble::as_tibble(ret, .name_repair="check_unique")
    }
  }
}

#' @export
stats.fmri_latent_lm <- function(x,type = c("estimates", "contrasts"), recon = FALSE, ...) {
    if (!recon) {
      stats.fmri_lm(x,type)
    } else {
      if (type == "estimates") {
        bvals <- coef(x, type = "estimates", recon=TRUE)
        errs <- standard_error(x, type = "estimates", recon=TRUE)
        tibble::as_tibble(bvals/errs)
      } else {
        cvals <- coef(x, type="contrasts", recon=TRUE)
        errs <- standard_error(x, type = "contrasts", recon=TRUE)
        tibble::as_tibble(cvals/errs)
      }
    }
}
</file>

<file path="R/fmri_model.R">
###############################################################################
## fmrimodel.R
##
## This file creates the overall fMRI model by combining an event model 
## (describing experimental events) and a baseline model (modeling drift, 
## nuisance, and block effects).
##
## The file provides two main functions:
##   - create_fmri_model(): Creates an fMRI model from a formula, block formula,
##     (optionally) a baseline_model, and an fmri_dataset.
##   - fmri_model(): Combines an event_model and a baseline_model into an fmri_model.
##
## Additional functions build design matrices, compute contrasts, print, and plot
## the overall fMRI model.
###############################################################################

## ============================================================================
## Section 1: fMRI Model Construction Functions
## ============================================================================

#' Create an fMRI Model
#'
#' This function creates an fMRI model consisting of an event model and a baseline model.
#'
#' @param formula The model formula for experimental events.
#' @param block The model formula for block structure.
#' @param baseline_model (Optional) A \code{baseline_model} object. Default is \code{NULL}.
#' @param dataset An \code{fmri_dataset} object containing the time-series data.
#' @param drop_empty Logical. Whether to remove factor levels with zero size. Default is \code{TRUE}.
#' @param durations A vector of event durations. Default is \code{0}.
#' @return An \code{fmri_model} object.
#' @keywords internal
#' @noRd
#' @examples
#' \dontrun{
#' # Assuming you have an fmri_dataset object named ds and a formula for events:
#' fmri_mod <- create_fmri_model(formula = onset ~ hrf(x) + hrf(y),
#'                               block = ~ run,
#'                               dataset = ds,
#'                               drop_empty = TRUE,
#'                               durations = rep(0, nrow(ds$event_table)))
#' }
create_fmri_model <- function(formula, block, baseline_model = NULL, dataset, drop_empty = TRUE, durations = 0) {
  assert_that(is.formula(formula), msg = "'formula' must be a formula")
  assert_that(is.formula(block), msg = "'block' must be a formula")
  assert_that(inherits(dataset, "fmri_dataset"), msg = "'dataset' must be an 'fmri_dataset'")
  assert_that(is.numeric(durations), msg = "'durations' must be numeric")
  
  # Replicate durations if a single value is provided.
  if (length(durations) == 1) {
    durations <- rep(durations, nrow(dataset$event_table))
  }
  
  # Resolve conflict: use a temporary variable to hold the baseline model.
  if (is.null(baseline_model)) {
    base_model_obj <- baseline_model(
      basis = "bs",
      degree = max(ceiling(median(dataset$sampling_frame$blocklens) / 100), 3),
      sframe = dataset$sampling_frame
    )
  } else {
    assert_that(inherits(baseline_model, "baseline_model"),
                msg = "'baseline_model' must have class 'baseline_model'")
    base_model_obj <- baseline_model
  }
  
  ev_model <- event_model(
    x = formula,
    block = block,
    data = dataset$event_table,
    sampling_frame = dataset$sampling_frame,
    drop_empty = drop_empty,
    durations = durations
  )
  
  fmri_model(ev_model, base_model_obj)
}


#' Construct an fMRI Regression Model
#'
#' This function constructs an fMRI regression model consisting of an event model
#' and a baseline model. The resulting model can be used for the analysis of fMRI data.
#'
#' @param event_model An object of class "event_model" representing the event-related part of the fMRI regression model.
#' @param baseline_model An object of class "baseline_model" representing the baseline-related part of the fMRI regression model.
#' @return An object of class "fmri_model" containing the event and baseline models.
#' @export
#' @seealso event_model, baseline_model
fmri_model <- function(event_model, baseline_model) {
  assert_that(inherits(event_model, "event_model"))
  assert_that(inherits(baseline_model, "baseline_model"))
  
  fmodel <- list(event_model = event_model, baseline_model = baseline_model)
  class(fmodel) <- "fmri_model"
  fmodel
}


#' (Internal) Prediction Matrix
#'
#' This function is intended to compute a prediction matrix for the model.
#' (Currently a stub.)
#'
#' @param x An fmri_model object.
#' @return (Not implemented)
#' @keywords internal
#' @noRd
prediction_matrix <- function(x) {
  stop("not implemented")
}


## ============================================================================
## Section 2: Design Matrix and Environment for fMRI Models
## ============================================================================

#' @importFrom tibble as_tibble
#' @param blockid the block id to extract
#' @export
#' @rdname design_matrix
design_matrix.fmri_model <- function(x, blockid = NULL, ...) {
  suppressMessages(
    tibble::as_tibble(
      cbind(
        design_matrix(x$event_model, blockid),
        design_matrix(x$baseline_model, blockid)
      ),
      .name_repair = "check_unique"
    )
  )
}


#' @importFrom tibble as_tibble
#' @keywords internal
#' @noRd
design_env.fmri_model <- function(x, blockid = NULL) {
  stop("Not implemented")
}


## ============================================================================
## Section 3: Accessor Functions for fMRI Models
## ============================================================================

#' @export
terms.fmri_model <- function(x, ...) {
  c(terms(x$event_model), terms(x$baseline_model))
}

#' @export
#' @autoglobal
cells.fmri_model <- function(x, ...) {
  c1 <- cells(x$event_model) %>% dplyr::mutate(type = "event")
  c2 <- cells(x$baseline_model) %>% dplyr::mutate(type = "baseline")
  rbind(c1, c2) %>% dplyr::relocate(index, type)
}

#' @export
blocklens.fmri_model <- function(x, ...) {
  blocklens(x$event_model)
}

#' @export
event_terms.fmri_model <- function(x) {
  terms(x$event_model)
}

#' @export
baseline_terms.fmri_model <- function(x) {
  terms(x$baseline_model)
}

#' @export
contrast_weights.fmri_model <- function(x, ...) {
  contrast_weights.event_model(x$event_model, ...)
}

#' @export
conditions.fmri_model <- function(x, ...) {
  unlist(lapply(terms(x), function(t) conditions(t)), use.names = FALSE)
}

#' @export
conditions.baseline_model <- function(x, ...) {
  unlist(lapply(terms(x), function(t) conditions(t)), use.names = FALSE)
}


## ============================================================================
## Section 4: Plot and Print Methods for fMRI Models
## ============================================================================

#' @export
plot.fmri_model <- function(x, ...) {
  with_package("cowplot")
  p1 <- plot(x$event_model) + ggplot2::ggtitle("Event Model")
  p2 <- plot(x$baseline_model) + ggplot2::ggtitle("Baseline Model")
  cowplot::plot_grid(p1, p2, nrow = 2, align = "h")
}

#' @export
#' @rdname print
print.fmri_model <- function(x, ...) {
  # Header with fancy border
  cat("\n╔══════════════════════════════════════════╗")
  cat("\n║             fMRI Model                   ║")
  cat("\n╠══════════════════════════════════════════╣")
  
  # Event Model Section
  cat("\n║ Event Model                              ║")
  cat("\n╟──────────────────────────────────────────╢")
  cat("\n║ Formula:", crayon::cyan(Reduce(paste, deparse(x$event_model$model_spec$formula))))
  
  # Event Model Summary
  cat("\n║ Summary:")
  cat("\n║   • Terms:", crayon::yellow(length(terms(x$event_model))))
  cat("\n║   • Events:", crayon::yellow(nrow(x$event_model$model_spec$event_table)))
  cat("\n║   • Design Columns:", crayon::yellow(length(conditions(x$event_model))))
  cat("\n║   • Blocks:", crayon::yellow(length(unique(x$event_model$blockids))))
  
  # Baseline Model Section (if present)
  if (!is.null(x$baseline_model)) {
    cat("\n╟──────────────────────────────────────────╢")
    cat("\n║ Baseline Model                           ║")
    cat("\n║ Components:")
    
    # Drift term info
    if (!is.null(x$baseline_model$drift_term)) {
      drift_name <- x$baseline_model$drift_term$varname
      basis_type <- x$baseline_model$drift_spec$basis
      degree <- x$baseline_model$drift_spec$degree
      drift_cols <- ncol(design_matrix(x$baseline_model$drift_term))
      cat("\n║   • Drift:", crayon::magenta(drift_name))
      cat("\n║     - Type:", crayon::blue(basis_type))
      cat("\n║     - Degree:", crayon::blue(degree))
      cat("\n║     - Columns:", crayon::yellow(drift_cols))
    }
    
    # Block term info
    if (!is.null(x$baseline_model$block_term)) {
      const_cols <- ncol(design_matrix(x$baseline_model$block_term))
      cat("\n║   • Block Terms:", crayon::yellow(const_cols), "columns")
    }
    
    # Nuisance term info
    if (!is.null(x$baseline_model$nuisance_term)) {
      nuis_cols <- ncol(design_matrix(x$baseline_model$nuisance_term))
      cat("\n║   • Nuisance Terms:", crayon::yellow(nuis_cols), "columns")
    }
  }
  
  # Total Model Summary
  cat("\n╟──────────────────────────────────────────╢")
  cat("\n║ Total Model                              ║")
  total_cols <- ncol(design_matrix(x))
  cat("\n║   • Total Design Columns:", crayon::yellow(total_cols))
  
  # Footer
  cat("\n╚══════════════════════════════════════════╝\n")
}

#' correlation_map.fmri_model
#'
#' @description
#' Generates a correlation heatmap of the columns in an \code{fmri_model}'s combined
#' event+baseline design matrix.
#'
#' @param x An \code{fmri_model}.
#' @param method Correlation method (e.g., "pearson", "spearman").
#' @param half_matrix Logical; if TRUE, display only the lower triangle of the matrix.
#' @param absolute_limits Logical; if TRUE, set color scale limits from -1 to 1.
#' @param ... Additional arguments passed to internal plotting functions.
#' @export
correlation_map.fmri_model <- function(x,
                                       method          = c("pearson", "spearman"),
                                       half_matrix     = FALSE,
                                       absolute_limits = TRUE,
                                       ...) {
  DM <- as.matrix(design_matrix(x))
  .correlation_map_common(DM, method=method, half_matrix=half_matrix,
                          absolute_limits=absolute_limits, ...)
}


#' Heatmap visualization of the combined fmri_model design matrix
#'
#' @description
#' Produces a single heatmap of *all* columns in the design matrix from an
#' \code{fmri_model} object, which merges both the event_model and baseline_model
#' regressors. Rows are scans; columns are regressors.  
#' Optionally draws horizontal lines between blocks (runs), and rotates x‐axis
#' labels diagonally for readability.
#'
#' @param x An \code{fmri_model} object.
#' @param block_separators Logical; if \code{TRUE}, draw white horizontal lines between blocks.
#' @param rotate_x_text Logical; if \code{TRUE}, rotate x-axis labels by 45 degrees.
#' @param fill_midpoint Numeric or \code{NULL}; if not \code{NULL}, passed to
#'   \code{\link[ggplot2]{scale_fill_gradient2}} to center the color scale (e.g. \code{fill_midpoint=0}).
#' @param fill_limits Numeric vector of length 2 or \code{NULL}; passed to the fill scale
#'   \code{limits=} argument. This can clip or expand the color range.
#' @param ... Additional arguments passed to \code{\link[ggplot2]{geom_tile}}.
#'
#' @import ggplot2
#' @importFrom tibble as_tibble
#' @importFrom tidyr pivot_longer
#' @return A ggplot2 plot object.
#' @export
design_map.fmri_model <- function(x,
                                  block_separators = TRUE,
                                  rotate_x_text    = TRUE,
                                  fill_midpoint    = NULL,
                                  fill_limits      = NULL,
                                  ...) {
  # 1) Extract full design matrix (event + baseline)
  DM <- design_matrix(x)
  n_scans <- nrow(DM)
  
  # 2) Convert to a long data frame for ggplot
  df_long <- tibble::as_tibble(DM, .name_repair = "unique")
  df_long$scan_number <- seq_len(n_scans)
  df_long <- tidyr::pivot_longer(
    df_long,
    cols      = -scan_number,
    names_to  = "Regressor",
    values_to = "Value"
  )
  
  # 3) Construct the ggplot with tile geometry
  plt <- ggplot(df_long, aes(x = Regressor, y = scan_number, fill = Value)) +
    geom_tile(...)
  
  # 4) Reverse the y-axis so scan_number=1 is at the top
  plt <- plt + scale_y_reverse()
  
  # 5) Select a color scale
  #    - If fill_midpoint != NULL => scale_fill_gradient2 with that midpoint
  #    - Otherwise => a 3-color gradient
  if (is.null(fill_midpoint)) {
    plt <- plt + scale_fill_gradientn(
      colours = c("navy", "white", "firebrick"),
      limits  = fill_limits
    )
  } else {
    plt <- plt + scale_fill_gradient2(
      midpoint = fill_midpoint,
      low      = "navy",
      mid      = "white",
      high     = "firebrick",
      limits   = fill_limits
    )
  }
  
  # 6) Optionally draw block-separators if we have block information
  #    The fmri_model inherits block info from x$event_model (and baseline).
  #    We'll just rely on x$event_model$blockids for run boundaries
  if (!is.null(x$event_model$blockids) && block_separators) {
    block_ids  <- x$event_model$blockids
    run_info   <- rle(block_ids)
    row_breaks <- cumsum(run_info$lengths)
    num_cols   <- ncol(DM)
    
    # Draw white lines at each boundary
    for (rb in row_breaks[-length(row_breaks)]) {
      plt <- plt + 
        annotate("segment",
                 x    = 0.5, 
                 xend = num_cols + 0.5,
                 y    = rb + 0.5,
                 yend = rb + 0.5,
                 color = "white", size = 1)
    }
  }
  
  # 7) Apply some theming
  plt <- plt + 
    theme_minimal(base_size = 14) +
    labs(x = "Regressors", y = "Scan Number", fill = "Value") +
    theme(
      panel.grid  = element_blank(),
      axis.text.x = if (rotate_x_text) element_text(angle = 45, hjust = 1) else element_text()
    )
  
  plt
}
</file>

<file path="R/gen_contrast.R">
#' Fast factorial contrast generators
#'
#' Returns a matrix **N_cells × N_contrasts** – *each row is a design cell*,
#' columns are independent contrasts (difference‑coded for the factors you ask
#' for, grand‑mean for the rest).  Suitable for `tcrossprod(dm, C)` or
#' `lm.fit(design, y)` followed by `%*% coef` in the usual way.
#'
#' @param des      data.frame with one column per factor (must be `factor`)
#' @param factors  character vector: which factor(s) get **difference coding**.
#'                 • `generate_main_effect_contrast()` takes a **single**
#'                   factor name.<br>
#'                 • `generate_interaction_contrast()` takes ≥ 2 for an
#'                   interaction (or 1 to reproduce a main‑effect matrix).
#'
#' @return numeric matrix **nrow = ∏ levels(f) , ncol = ∏ (Lᵢ − 1)** for the
#'         chosen factors.
#'
#' @examples
#' des <- expand.grid(Time = factor(1:4),
#'                    Cond = factor(c("face","scene")))
#'
#' # Main effect of Time (4‑1 = 3 contrasts)
#' M <- generate_main_effect_contrast(des, "Time")
#'
#' # Full Time×Cond interaction ( (4‑1)*(2‑1) = 3 contrasts )
#' I <- generate_interaction_contrast(des, c("Time","Cond"))
#' dim(I)   # 8 rows (cells) × 3 columns (contrasts)
#' @export
generate_interaction_contrast <- function(des, factors) {

  stopifnot(all(factors %in% names(des)))
  fac_names <- names(des)

  build_block <- function(f, diff_needed) {
    L <- nlevels(f)
    if (diff_needed)             # (L x (L-1)) difference coding
      -t(diff(diag(L)))          # rows = levels, cols = contrasts
    else
      matrix(1, nrow = L, ncol = 1)
  }

  blocks   <- Map(build_block, des, fac_names %in% factors)
  C_matrix <- Reduce(kronecker, blocks)

  # Assert rows = design cells
  n_cells <- prod(vapply(des, nlevels, 1L))
  stopifnot(nrow(C_matrix) == n_cells)

  C_matrix
}

#' @param factor Single factor name for the main effect.
#' @rdname generate_interaction_contrast
#' @export
generate_main_effect_contrast <- function(des, factor) {
  if (length(factor) != 1L)
    stop("main‑effect contrast expects exactly one factor name")
  generate_interaction_contrast(des, factor)
}
</file>

<file path="R/globals.R">
# Generated by roxyglobals: do not edit by hand

utils::globalVariables(c(
  ".time", # <plot.baseline_model>
  ".block", # <plot.baseline_model>
  "xf", # <estimate_hrf>
  "index", # <cells.fmri_model>
  "type", # <cells.fmri_model>
  ".", # <reshape_coef>
  "row_id", # <reshape_coef>
  "name", # <meta_contrasts>
  NULL
))
</file>

<file path="R/penalty_matrix.R">
#' Penalty Matrix Methods for HRF Objects
#'
#' @description
#' This file contains S3 methods for generating penalty matrices for different
#' types of HRF basis functions. Penalty matrices encode shape priors that
#' improve regularized HRF estimation by discouraging implausible shapes.
#'
#' @name penalty_matrix_methods
NULL

# Helper functions for difference matrices ----

#' Create first-order difference matrix
#' @param d Dimension (number of basis functions)
#' @return First-order difference matrix
#' @keywords internal
#' @noRd
first_difference <- function(d) {
  if (d <= 1) {
    return(matrix(0, nrow = 0, ncol = d))
  }
  diff(diag(d), differences = 1)
}

#' Create second-order difference matrix  
#' @param d Dimension (number of basis functions)
#' @return Second-order difference matrix
#' @keywords internal
#' @noRd
second_difference <- function(d) {
  if (d <= 2) {
    return(matrix(0, nrow = 0, ncol = d))
  }
  diff(diag(d), differences = 2)
}

# Default method ----

#' Default penalty matrix method
#' 
#' @description
#' Returns an identity matrix (ridge penalty) when no specific penalty structure
#' is known for the HRF type. This method also handles name-based dispatch for
#' HRF objects since they all share the same class structure.
#' 
#' @param x An HRF object
#' @param ... Additional arguments passed to specific penalty methods
#' @return Identity matrix of dimension nbasis(x) × nbasis(x), or appropriate penalty matrix based on HRF name
#' @export
penalty_matrix.HRF <- function(x, ...) {
  # First try name-based dispatch
  hrf_name <- attr(x, "name")
  
  if (!is.null(hrf_name)) {
    # Normalize name for comparison
    name_lower <- tolower(hrf_name)
    
    if (name_lower == "fir") {
      return(penalty_matrix_fir(x, ...))
    } else if (name_lower %in% c("bspline", "bs")) {
      return(penalty_matrix_bspline(x, ...))
    } else if (grepl("spmg", name_lower)) {
      return(penalty_matrix_spmg(x, ...))
    } else if (name_lower %in% c("cosine", "fourier")) {
      return(penalty_matrix_fourier(x, ...))
    }
  }
  
  # Default: identity matrix (ridge penalty)
  d <- nbasis(x)
  diag(d)
}

# Specific penalty matrix implementations ----

#' FIR penalty matrix
#' @param hrf FIR HRF object
#' @param order Derivative order for roughness (1 or 2)
#' @param scale Logical; if TRUE, scales R so that diag(R) ≈ 1
#' @return Penalty matrix for FIR basis
#' @keywords internal
#' @noRd
penalty_matrix_fir <- function(hrf, order = 2, scale = TRUE) {
  d <- nbasis(hrf)
  
  if (d <= order) {
    # Not enough basis functions for the requested order
    return(diag(d))
  }
  
  D <- switch(as.character(order),
              "1" = first_difference(d),
              "2" = second_difference(d),
              stop("order must be 1 or 2"))
  
  R <- crossprod(D)  # D^T D
  
  if (scale && any(diag(R) > 0)) {
    R <- R / mean(diag(R)[diag(R) > 0])  # Scale so diagonal ≈ 1
  }
  
  R
}

#' B-spline penalty matrix
#' @param hrf B-spline HRF object
#' @param order Derivative order for roughness (1 or 2)
#' @param scale Logical; if TRUE, scales R so that diag(R) ≈ 1
#' @return Penalty matrix for B-spline basis
#' @keywords internal
#' @noRd
penalty_matrix_bspline <- function(hrf, order = 2, scale = TRUE) {
  # B-splines use the same difference-based penalty as FIR
  penalty_matrix_fir(hrf, order = order, scale = scale)
}

#' SPM canonical + derivatives penalty matrix
#' @param hrf SPM HRF object (canonical + derivatives)
#' @param shrink_deriv Shrinkage factor for derivative columns
#' @param shrink_disp Shrinkage factor for dispersion derivative (if present)
#' @param ... Additional arguments
#' @return Penalty matrix for SPM basis
#' @keywords internal
#' @noRd
penalty_matrix_spmg <- function(hrf, shrink_deriv = 4, shrink_disp = NULL, ...) {
  d <- nbasis(hrf)
  
  if (d == 1) {
    # Single canonical HRF - no penalty needed
    return(diag(1))
  } else if (d == 2) {
    # Canonical + temporal derivative
    return(diag(c(1, shrink_deriv)))
  } else if (d == 3) {
    # Canonical + temporal + dispersion derivatives
    if (is.null(shrink_disp)) {
      shrink_disp <- shrink_deriv
    }
    return(diag(c(1, shrink_deriv, shrink_disp)))
  } else {
    # Unexpected number of basis functions - fall back to identity
    return(diag(d))
  }
}

#' Fourier/Cosine penalty matrix
#' @param hrf Fourier/Cosine HRF object
#' @param order Derivative order for roughness (1 or 2)
#' @param scale Logical; if TRUE, scales R so that diag(R) ≈ 1
#' @return Penalty matrix for Fourier basis
#' @keywords internal
#' @noRd
penalty_matrix_fourier <- function(hrf, order = 2, scale = TRUE) {
  # Fourier bases use the same difference-based penalty as FIR
  # This penalizes high-frequency coefficients
  penalty_matrix_fir(hrf, order = order, scale = scale)
}

# Additional convenience functions ----

#' Create penalty matrix for any HRF-like object
#' 
#' @description
#' Convenience wrapper that can handle different types of HRF specifications
#' including hrfspec objects from model formulas.
#' 
#' @param x An HRF object, hrfspec, or other HRF-like object
#' @param ... Additional arguments passed to penalty_matrix methods
#' @return Appropriate penalty matrix
#' @export
penalty_matrix.hrfspec <- function(x, ...) {
  penalty_matrix(x$hrf, ...)
}
</file>

<file path="R/RcppExports.R">
# Generated by using Rcpp::compileAttributes() -> do not edit by hand
# Generator token: 10BE3573-1514-4C36-9D1C-5A225CD40393

instantaneous_correlation_rcpp <- function(x, y, eta = NA_real_, tau_half = NA_real_, offset = 0L, warmup = -1L, fill = "zero") {
    .Call('_fmrireg_instantaneous_correlation_rcpp', PACKAGE = 'fmrireg', x, y, eta, tau_half, offset, warmup, fill)
}

compute_residuals_cpp <- function(X_base_fixed, data_matrix, dmat_ran) {
    .Call('_fmrireg_compute_residuals_cpp', PACKAGE = 'fmrireg', X_base_fixed, data_matrix, dmat_ran)
}

lss_compute_cpp <- function(Q_dmat_ran, residual_data) {
    .Call('_fmrireg_lss_compute_cpp', PACKAGE = 'fmrireg', Q_dmat_ran, residual_data)
}

mixed_solve_internal <- function(y_in, Z_in = NULL, K_in = NULL, X_in = NULL, method = "REML", bounds = as.numeric( c(1e-9, 1e9)), SE = FALSE, return_Hinv = FALSE) {
    .Call('_fmrireg_mixed_solve_internal', PACKAGE = 'fmrireg', y_in, Z_in, K_in, X_in, method, bounds, SE, return_Hinv)
}

neural_input_rcpp <- function(x, from, to, resolution) {
    .Call('_fmrireg_neural_input_rcpp', PACKAGE = 'fmrireg', x, from, to, resolution)
}

evaluate_regressor_convolution <- function(grid, onsets, durations, amplitudes, hrf_values, hrf_span, start, end, precision) {
    .Call('_fmrireg_evaluate_regressor_convolution', PACKAGE = 'fmrireg', grid, onsets, durations, amplitudes, hrf_values, hrf_span, start, end, precision)
}

evaluate_regressor_fast <- function(grid, onsets, durations, amplitudes, hrfFine, dt, span) {
    .Call('_fmrireg_evaluate_regressor_fast', PACKAGE = 'fmrireg', grid, onsets, durations, amplitudes, hrfFine, dt, span)
}

evaluate_regressor_cpp <- function(grid, onsets, durations, amplitudes, hrf_matrix, hrf_span, precision, method = "fft") {
    .Call('_fmrireg_evaluate_regressor_cpp', PACKAGE = 'fmrireg', grid, onsets, durations, amplitudes, hrf_matrix, hrf_span, precision, method)
}

ar_whiten_inplace <- function(Y, X, phi_coeffs, exact_first_ar1 = FALSE) {
    .Call('_fmrireg_ar_whiten_inplace', PACKAGE = 'fmrireg', Y, X, phi_coeffs, exact_first_ar1)
}
</file>

<file path="R/reg-constructor.R">
#' @keywords internal
#' @noRd
#' @return An S3 object of class `Reg` (and `list`) with components:
#'   * `onsets`: Numeric vector of event onset times (seconds).
#'   * `hrf`: An object of class `HRF` used for convolution.
#'   * `duration`: Numeric vector of event durations (seconds).
#'   * `amplitude`: Numeric vector of event amplitudes/scaling factors.
#'   * `span`: Numeric scalar indicating the HRF span (seconds).
#'   * `summate`: Logical indicating if overlapping HRF responses should summate.
#' @importFrom assertthat assert_that
Reg <- function(onsets, hrf=HRF_SPMG1, duration=0, amplitude=1, span=40, summate=TRUE) {
  
  # Initial conversions
  onsets    <- as.numeric(onsets)
  duration  <- as.numeric(duration)
  amplitude <- as.numeric(amplitude)
  summate   <- isTRUE(summate)
  span_arg  <- as.numeric(span) # Store original arg

  # Handle NA onset case explicitly (represents intent for zero events)
  if (length(onsets) == 1 && is.na(onsets[1])) {
      onsets <- numeric(0)
  }
  n_onsets <- length(onsets)
  
  # Check for invalid onsets *before* recycling other args
  if (any(onsets < 0 | is.na(onsets))) {
      stop("`onsets` must be non-negative and non-NA.", call. = FALSE)
  }
  
  # Recycle/Validate inputs *before* filtering
  # Use recycle_or_error from utils-internal.R
  duration  <- recycle_or_error(duration, n_onsets, "duration")
  amplitude <- recycle_or_error(amplitude, n_onsets, "amplitude")
  
  # Check for invalid inputs early
  if (any(duration < 0, na.rm = TRUE)) stop("`duration` cannot be negative.")
  if (span_arg <= 0) stop("`span` must be positive.")
  
  # Filter events based on non-zero and non-NA amplitude (Ticket B-3)
  if (n_onsets > 0) { 
      keep_indices <- which(amplitude != 0 & !is.na(amplitude))
      # Store whether filtering occurred
      filtered_some <- length(keep_indices) < n_onsets
      # Store whether *all* were filtered
      filtered_all <- length(keep_indices) == 0
      
      if (filtered_some) {
          onsets    <- onsets[keep_indices]
          duration_filtered  <- duration[keep_indices]
          amplitude <- amplitude[keep_indices]
          n_onsets  <- length(onsets) # Update count after filtering
          duration <- recycle_or_error(duration_filtered, n_onsets, "duration")
      } 
  } else {
      filtered_all <- TRUE # If input was empty, effectively all are filtered
  }
  
  # Ensure HRF is a valid HRF object using make_hrf 
  # Explicitly namespace internal function call (Ticket G-3)
  hrf  <- make_hrf(hrf, lag = 0) 
  assert_that(inherits(hrf, "HRF"), msg = "Invalid 'hrf' provided or generated.")
  
  # Determine final span using %||% helper (ensure helper is available)
  final_span <- attr(hrf, "span") %||% span_arg
  # Optional: Adjust span based on max duration? (kept from old regressor, review)
  # if (n_onsets > 0 && any(duration > final_span / 2)) {
  #    final_span <- max(duration, na.rm=TRUE) * 2
  # }

  # Construct the final object
  out <- structure(list(
    onsets      = onsets,
    duration    = duration,
    amplitude   = amplitude,
    hrf         = hrf,
    span        = final_span,
    summate     = summate
  ), class = c("Reg", "list"))
  
  # Add attribute to signal if all events were filtered
  attr(out, "filtered_all") <- filtered_all 
  return(out)
}


#' Construct a Regressor Object
#' 
#' Creates an object representing event-related regressors for fMRI modeling.
#' This function defines event onsets and associates them with a hemodynamic 
#' response function (HRF) to generate predicted time courses.
#' 
#' @param onsets A numeric vector of event onset times in seconds.
#' @param hrf The hemodynamic response function (HRF) to convolve with the events.
#'   This can be a pre-defined `HRF` object (e.g., `HRF_SPMG1`), a custom `HRF` 
#'   object created with `as_hrf`, a function `f(t)`, or a character string 
#'   referring to a known HRF type (e.g., "spmg1", "gaussian"). Defaults to `HRF_SPMG1`.
#' @param duration A numeric scalar or vector specifying the duration of each event 
#'   in seconds. If scalar, it's applied to all events. Defaults to 0 (impulse events).
#' @param amplitude A numeric scalar or vector specifying the amplitude (scaling factor) 
#'   for each event. If scalar, it's applied to all events. Defaults to 1.
#' @param span The temporal window (in seconds) over which the HRF is defined 
#'   or evaluated. This influences the length of the convolution. If not provided, 
#'   it may be inferred from the `hrf` object or default to 40s. **Note:** Unlike some
#'   previous versions, the `span` is not automatically adjusted based on `duration`;
#'   ensure the provided or inferred `span` is sufficient for your longest event duration.
#' @param summate Logical; if `TRUE` (default), the HRF response amplitude scales 
#'   with the duration of sustained events (via internal convolution/summation). If `FALSE`, 
#'   the response reflects the peak HRF reached during the event duration.
#'   
#' @details 
#' This function serves as the main public interface for creating regressor objects. 
#' Internally, it utilizes the `Reg()` constructor which performs validation and 
#' efficient storage. The resulting object can be evaluated at specific time points 
#' using the `evaluate()` function.
#' 
#' Events with an amplitude of 0 or NA are automatically filtered out.
#' 
#' @return An S3 object of class `Reg` and `list` 
#'   containing processed event information and the HRF specification.
#' @importFrom assertthat assert_that
#' @export
regressor <- Reg # Assign Reg directly to regressor


#' Create an Empty Regressor Object
#' 
#' A convenience function to create a regressor object representing no events. 
#' Useful for placeholder or baseline scenarios.
#' 
#' @param hrf The HRF object to associate (defaults to `HRF_SPMG1`).
#' @param span The span to associate (defaults to 24).
#' @return A `Reg` object representing zero events.
#' @noRd
null_regressor <- function(hrf=HRF_SPMG1, span=24) {
  # Calls Reg directly, ensuring amplitude=0 triggers empty result
  Reg(onsets = numeric(0), hrf = hrf, span = span, amplitude = 0) 
}


#' Create a single trial regressor
#'
#' Creates a regressor object for modeling a single trial event in an fMRI experiment.
#' This is particularly useful for trial-wise analyses where each trial needs to be
#' modeled separately. The regressor represents the predicted BOLD response for a single
#' event using a specified hemodynamic response function (HRF).
#'
#' This is a convenience wrapper around `regressor` that ensures inputs have length 1.
#'
#' @param onsets the event onset in seconds, must be of length 1.
#' @param hrf a hemodynamic response function, e.g. \code{HRF_SPMG1}
#' @param duration duration of the event (default is 0), must be length 1.
#' @param amplitude scaling vector (default is 1), must be length 1.
#' @param span the temporal window of the impulse response function (default is 24).
#' @return A `Reg` object (inheriting from `regressor` and `list`).
#' @seealso \code{\link{regressor}}
#' @importFrom assertthat assert_that
#' @export
single_trial_regressor <- function(onsets, hrf=HRF_SPMG1, duration=0, amplitude=1, span=24) {
  # Basic validation specific to single trial before calling Reg
  stopifnot(length(onsets) == 1)
  stopifnot(length(duration) <= 1) # Allow scalar or length 1
  stopifnot(length(amplitude) <= 1) # Allow scalar or length 1
  
  # Call Reg constructor, which now sets correct classes
  Reg(onsets       = onsets,
      hrf          = hrf,
      duration     = duration,
      amplitude    = amplitude,
      span         = span, # Keep original default span 
      summate      = TRUE)
}
</file>

<file path="R/simulate.R">
#' Simulate fMRI Time Series
#'
#' This function simulates an fMRI time series for multiple experimental conditions with specified parameters.
#' It generates a realistic event-related design with randomized inter-stimulus intervals and condition orders.
#'
#' @param ncond The number of conditions to simulate.
#' @param hrf The hemodynamic response function to use (default is HRF_SPMG1).
#' @param nreps The number of repetitions per condition (default is 12).
#' @param amps A vector of amplitudes for each condition (default is a vector of 1s with length ncond).
#' @param ampsd The standard deviation of the amplitudes (default is 0).
#' @param isi A vector of length 2 specifying the range of inter-stimulus intervals to sample from (default is c(3, 6) seconds).
#' @param TR The repetition time of the fMRI acquisition (default is 1.5 seconds).
#'
#' @return A list with the following components:
#'   \itemize{
#'     \item onset: A vector of the onset times for each trial
#'     \item condition: A vector of condition labels for each trial
#'     \item mat: A matrix containing the simulated fMRI time series:
#'       \itemize{
#'         \item Column 1: Time points (in seconds)
#'         \item Columns 2:(ncond+1): Simulated BOLD responses for each condition
#'       }
#'   }
#' 
#' @importFrom assertthat assert_that
#' @examples
#' # Simulate 3 conditions with different amplitudes
#' sim <- simulate_bold_signal(ncond = 3, amps = c(1, 1.5, 2), TR = 2)
#' 
#' # Plot the simulated time series
#' matplot(sim$mat[,1], sim$mat[,-1], type = "l", 
#'         xlab = "Time (s)", ylab = "BOLD Response")
#' 
#' @export
simulate_bold_signal <- function(ncond, hrf=HRF_SPMG1, nreps=12, amps=rep(1,ncond), isi=c(3,6), ampsd=0, TR=1.5) {
  assert_that(length(amps) == ncond,
              msg = "Length of 'amps' must equal 'ncond'")
  # Note: If ampsd > 0, amplitude variability is sampled *once per condition*,
  # meaning all trials of a given condition share the same sampled amplitude.
  assert_that(length(isi) == 2 && isi[2] > isi[1], 
              msg = "ISI must be a vector of length 2 with isi[2] > isi[1]")
  assert_that(TR > 0, msg = "TR must be positive")
  
  # Use robust condition naming
  cond <- paste0("Cond", 1:ncond) 
  trials <- sample(rep(cond, nreps))
  isis <- runif(length(trials), min = isi[1], max = isi[2])
  onset <- cumsum(isis)
  
  span <- attr(hrf, "span") %||% 12
  time <- seq(0, max(onset) + span, by = TR)
  ymat <- do.call(cbind, lapply(1:length(cond), function(i) {
    idx <- which(trials == cond[i])
    reg <- regressor(onset[idx], hrf, amplitude=rnorm(1, mean=amps[i], sd=ampsd))
    evaluate(reg, time)
  }))
  
  list(onset=onset, condition=trials, mat=cbind(time, ymat))
}

#' Simulate fMRI Noise
#'
#' This function simulates realistic fMRI noise by combining:
#' \itemize{
#'   \item Temporal autocorrelation using an ARMA model
#'   \item Low-frequency drift
#'   \item Physiological noise (cardiac and respiratory)
#' }
#'
#' @param n The number of time points in the fMRI time series
#' @param TR The repetition time in seconds (default is 1.5)
#' @param ar A numeric vector containing autoregressive (AR) coefficients (default is c(0.3))
#' @param ma A numeric vector containing moving average (MA) coefficients (default is c(0.5))
#' @param sd The standard deviation of the white noise component (default is 1)
#' @param drift_freq Frequency of the low-frequency drift in Hz (default is 1/128)
#' @param drift_amplitude Amplitude of the low-frequency drift (default is 2)
#' @param physio Logical; whether to add simulated physiological noise (default is TRUE)
#' @param seed An optional seed for reproducibility (default is NULL)
#'
#' @return A numeric vector containing the simulated fMRI noise
#' 
#' @examples
#' # Simulate noise for a 5-minute scan with TR=2s
#' n_timepoints <- 150  # 5 minutes * 60 seconds / 2s TR
#' noise <- simulate_noise_vector(n_timepoints, TR = 2)
#' plot(noise, type = "l", xlab = "Time Point", ylab = "Signal")
#' 
#' @export
simulate_noise_vector <- function(n, TR = 1.5, ar = c(0.3), ma = c(0.5), sd = 1, 
                               drift_freq = 1/128, drift_amplitude = 2,
                               physio = TRUE, seed = NULL) {
  if (!is.null(seed)) {
    set.seed(seed)
  }
  
  # Generate ARMA noise
  noise <- arima.sim(n = n, model = list(ar = ar, ma = ma), sd = sd)
  
  # Add low-frequency drift
  time <- seq(0, (n-1)*TR, by = TR)
  drift <- drift_amplitude * sin(2 * pi * drift_freq * time)
  noise <- noise + drift
  
  # Add physiological noise if requested
  if (physio) {
    # Simulate cardiac (~1.2 Hz) and respiratory (~0.3 Hz) noise
    cardiac <- 0.5 * sin(2 * pi * 1.2 * time)
    respiratory <- 0.8 * sin(2 * pi * 0.3 * time)
    noise <- noise + cardiac + respiratory
  }
  
  return(noise)
}

#' Simulate Complete fMRI Dataset
#'
#' This function simulates a complete fMRI dataset by combining task-related signals
#' with realistic noise. It returns both the clean signals and the noisy data.
#'
#' @param ncond Number of conditions to simulate
#' @param nreps Number of repetitions per condition (default is 12)
#' @param TR Repetition time in seconds (default is 1.5)
#' @param snr Signal-to-noise ratio (default is 0.5)
#' @param hrf Hemodynamic response function to use (default is HRF_SPMG1)
#' @param seed Optional seed for reproducibility (default is NULL)
#'
#' @return A list containing:
#'   \itemize{
#'     \item clean: The simulated signals without noise (from simulate_bold_signal)
#'     \item noisy: The signals with added noise
#'     \item noise: The simulated noise component
#'     \item onsets: Trial onset times
#'     \item conditions: Condition labels for each trial
#'   }
#'
#' @examples
#' # Simulate a dataset with 3 conditions
#' data <- simulate_simple_dataset(ncond = 3, TR = 2, snr = 0.5)
#' 
#' # Plot clean and noisy data
#' par(mfrow = c(2,1))
#' matplot(data$clean$mat[,1], data$clean$mat[,-1], type = "l",
#'         main = "Clean Signal", xlab = "Time (s)", ylab = "BOLD")
#' matplot(data$noisy[,1], data$noisy[,-1], type = "l",
#'         main = "Noisy Signal", xlab = "Time (s)", ylab = "BOLD")
#'
#' @export
simulate_simple_dataset <- function(ncond, nreps = 12, TR = 1.5, snr = 0.5, 
                                 hrf = HRF_SPMG1, seed = NULL) {
  if (!is.null(seed)) {
    set.seed(seed)
  }
  
  # Generate clean signals
  clean <- simulate_bold_signal(ncond = ncond, nreps = nreps, TR = TR, hrf = hrf)
  
  # Calculate noise level based on SNR
  signal_sd <- sd(as.vector(clean$mat[,-1]))
  noise_sd <- signal_sd / snr
  
  # Generate noise for each condition
  n_timepoints <- nrow(clean$mat)
  noise_mat <- replicate(ncond, 
                        simulate_noise_vector(n = n_timepoints, TR = TR, 
                                         sd = noise_sd))
  
  # Combine signal and noise
  noisy_mat <- cbind(clean$mat[,1], clean$mat[,-1] + noise_mat)
  
  list(
    clean = clean,
    noisy = noisy_mat,
    noise = noise_mat,
    onsets = clean$onset,
    conditions = clean$condition
  )
}

#' Simulate fMRI Time Courses, Return Shared Onsets + Column-Specific Amplitudes/Durations
#'
#' Generates \eqn{n} time-series (columns) with a single set of onsets, but
#' *resampled* amplitudes/durations for each column if \code{amplitude_sd>0}
#' or \code{duration_sd>0}. Each column also gets independent noise. The result
#' is a list containing:
#' \itemize{
#'   \item \code{time_series}: a \code{matrix_dataset} with \eqn{T \times n}.
#'         The \code{event_table} uses the first column's amplitude/duration draws.
#'   \item \code{ampmat}: an \eqn{n\_events \times n} matrix of per-column amplitudes.
#'   \item \code{durmat}: an \eqn{n\_events \times n} matrix of per-column durations.
#'   \item \code{hrf_info}: info about the HRF.
#'   \item \code{noise_params}: info about noise generation (type + AR coefficients + SD).
#' }
#'
#' @details
#' - If \code{noise_type="ar1"} and you do not provide \code{noise_ar}, we
#'   default to \code{c(0.3)}.
#' - If \code{noise_type="ar2"} and you do not provide a 2-element \code{noise_ar},
#'   we default to \code{c(0.3, 0.2)}.
#' - Onsets are either provided or generated once for all columns.
#' - **Amplitudes/durations** are re-sampled \emph{inside the loop} so each
#'   column can differ randomly. The final arrays \code{ampmat} and \code{durmat}
#'   each have one column per time-series.
#' - The \code{matrix_dataset}'s \code{event_table} records the first column's
#'   amplitudes/durations. If you need each column's, see \code{ampmat} and
#'   \code{durmat}.
#'
#' @param n Number of time-series (columns).
#' @param total_time Numeric. Total scan length (seconds).
#' @param TR Numeric. Repetition time (seconds).
#' @param hrf Hemodynamic response function, e.g. \code{HRF_SPMG1}.
#' @param n_events Number of events (ignored if \code{onsets} is provided).
#' @param onsets Optional numeric vector of event onsets. If \code{NULL}, will be generated.
#' @param isi_dist One of \code{"even"}, \code{"uniform"}, or \code{"exponential"}.
#'   Default is \code{"even"} so events are evenly spaced from 0..total_time.
#' @param isi_min,isi_max For \code{isi_dist="uniform"}.
#' @param isi_rate For \code{isi_dist="exponential"}.
#' @param durations Numeric, scalar or length-\code{n_events}. If \code{duration_sd>0},
#'   random sampling is done per column.
#' @param duration_sd Numeric. If >0, random variation in durations.
#' @param duration_dist \code{"lognormal"} or \code{"gamma"} (strictly positive).
#' @param amplitudes Numeric, scalar or length-\code{n_events}. If \code{amplitude_sd>0},
#'   random sampling is done per column.
#' @param amplitude_sd Numeric. If >0, random variation in amplitudes.
#' @param amplitude_dist \code{"lognormal"}, \code{"gamma"}, or \code{"gaussian"} (can be negative).
#' @param single_trial If TRUE, each event is a separate single-trial regressor that gets summed.
#' @param noise_type \code{"none"}, \code{"white"}, \code{"ar1"}, or \code{"ar2"}.
#' @param noise_ar Numeric vector for AR(1) or AR(2). If missing or insufficient,
#'   defaults are used (0.3 for AR(1); c(0.3,0.2) for AR(2)).
#' @param noise_sd Std dev of the noise.
#' @param random_seed Optional integer for reproducibility.
#' @param verbose If TRUE, prints messages.
#'
#' @return A list containing:
#' \describe{
#'   \item{\code{time_series}}{A \code{matrix_dataset} with \eqn{T \times n} data
#'         and \code{event_table} for the *first* column's random draws.}
#'   \item{\code{ampmat}}{An \eqn{n\_events \times n} numeric matrix of amplitudes.}
#'   \item{\code{durmat}}{An \eqn{n\_events \times n} numeric matrix of durations.}
#'   \item{\code{hrf_info}}{A list with HRF metadata.}
#'   \item{\code{noise_params}}{A list describing noise generation.}
#' }
#'
#' @importFrom stats rnorm rexp runif rgamma rlnorm arima.sim
#' @export

# Internal helper for value resampling
#' @param base Base values to resample from
#' @param sd Standard deviation for resampling
#' @param dist Distribution to use for resampling
#' @param allow_negative Whether to allow negative values
#' @keywords internal
.resample_param <- function(base, sd, dist = c("lognormal", "gamma", "gaussian"),
                            allow_negative = FALSE) {
  dist <- match.arg(dist)
  out  <- base
  if (sd > 0) {
    out <- vapply(seq_along(base), function(i) {
      mu <- base[i]
      if (!allow_negative && mu <= 0 && dist != "gaussian") {
        stop("base values must be >0 for lognormal or gamma sampling")
      }
      switch(dist,
             lognormal = rlnorm(1, meanlog = log(mu), sdlog = sd),
             gamma = {
               shape_par <- (mu^2) / (sd^2)
               rate_par  <- mu / (sd^2)
               rgamma(1, shape = shape_par, rate = rate_par)
             },
             gaussian = rnorm(1, mean = mu, sd = sd))
    }, numeric(1))
  }
  out
}

simulate_fmri_matrix <- function(
    n                 = 1,
    total_time        = 240,
    TR                = 2,
    hrf               = HRF_SPMG1,
    
    n_events          = 10,
    onsets            = NULL,
    isi_dist          = c("even", "uniform", "exponential"),
    isi_min           = 2,
    isi_max           = 6,
    isi_rate          = 0.25,
    
    durations         = 0,
    duration_sd       = 0,
    duration_dist     = c("lognormal", "gamma"),
    
    amplitudes        = 1,
    amplitude_sd      = 0,
    amplitude_dist    = c("lognormal", "gamma", "gaussian"),
    
    single_trial      = FALSE,
    noise_type        = c("none", "white", "ar1", "ar2"),
    noise_ar          = NULL,
    noise_sd          = 1.0,
    
    random_seed       = NULL,
    verbose           = FALSE,
    buffer            = 16
) {
  # ---------------------------
  # 0) Setup
  # ---------------------------
  if (!is.null(random_seed)) {
    set.seed(random_seed)
  }
  
  isi_dist        <- match.arg(isi_dist)
  noise_type      <- match.arg(noise_type)
  duration_dist   <- match.arg(duration_dist)
  amplitude_dist  <- match.arg(amplitude_dist)
  
  # Handle default AR params if user omitted or gave insufficient length
  if (noise_type == "ar1") {
    if (is.null(noise_ar) || length(noise_ar) < 1) {
      noise_ar <- 0.3
      if (verbose) message("Defaulting to noise_ar = 0.3 for AR(1).")
    }
  } else if (noise_type == "ar2") {
    if (is.null(noise_ar) || length(noise_ar) < 2) {
      noise_ar <- c(0.3, 0.2)
      if (verbose) message("Defaulting to noise_ar = c(0.3, 0.2) for AR(2).")
    }
  }
  
  # Original time grid without buffer (for event generation)
  effective_time <- total_time - buffer
  
  # Sample event onsets - ensure they only occur in the effective time, not the buffer
  if (isi_dist == "uniform") {
    isi_samples <- runif(n_events, min = isi_min, max = isi_max)
  } else if (isi_dist == "exponential") {
    isi_samples <- isi_min + rexp(n_events, rate = isi_rate)
  } else if (isi_dist == "even") {
    isi_samples <- rep(effective_time / n_events, n_events)
  }
  
  # Generate onsets cumulative ISIs, but ensure they fall within effective_time
  onsets <- cumsum(isi_samples)
  if (max(onsets) > effective_time) {
    # Keep only events that fit within effective time
    keepers <- which(onsets <= effective_time)
    onsets <- onsets[keepers]
    n_events <- length(onsets)
    message(sprintf("Reduced to %d events to fit within effective time", n_events))
  }
  
  # Final time grid with buffer
  n_time_points <- ceiling(total_time / TR)
  time_grid <- seq(0, by = TR, length.out = n_time_points)
  
  # ---------------------------
  # 1) Helper fns to sample durations/amplitudes for 1 column
  # ---------------------------
  do_sample_durations <- function() {
    if (length(durations) == 1L) {
      base_durs <- rep(durations, n_events)
    } else {
      if (length(durations) != n_events) {
        stop("durations must be length=1 or match n_events.")
      }
      base_durs <- durations
    }
    .resample_param(base_durs, duration_sd, duration_dist)
  }

  do_sample_amplitudes <- function() {
    if (length(amplitudes) == 1L) {
      base_amps <- rep(amplitudes, n_events)
    } else {
      if (length(amplitudes) != n_events) {
        stop("amplitudes must be length=1 or match n_events.")
      }
      base_amps <- amplitudes
    }
    .resample_param(base_amps, amplitude_sd, amplitude_dist,
                    allow_negative = (amplitude_dist == "gaussian"))
  }

  gen_noise <- function() {
    switch(noise_type,
           none  = rep(0, n_time_points),
           white = rnorm(n_time_points, 0, noise_sd),
           ar1   = arima.sim(model = list(ar = noise_ar),
                             n = n_time_points, sd = noise_sd),
           ar2   = arima.sim(model = list(ar = noise_ar),
                             n = n_time_points, sd = noise_sd))
  }
  
  # ---------------------------
  # 2) Build data matrix, col by col
  #    plus store amplitude/duration in big matrices
  # ---------------------------
  signal_list <- vector("list", n)
  ampmat <- matrix(NA, nrow=n_events, ncol=n)  # amplitude
  durmat <- matrix(NA, nrow=n_events, ncol=n)  # durations
  
  for (ii in seq_len(n)) {
    # sample for column ii
    this_dur <- do_sample_durations()
    this_amp <- do_sample_amplitudes()
    
    durmat[, ii] <- this_dur
    ampmat[, ii] <- this_amp
    
    # Build the BOLD signal using the full time grid (including buffer)
    if (!single_trial) {
      reg <- regressor(
        onsets    = onsets,
        hrf       = hrf,
        duration  = this_dur,
        amplitude = this_amp
      )
      bold_signal <- evaluate(reg, grid=time_grid)
    } else {
      bold_signal <- numeric(n_time_points)
      for (j in seq_along(onsets)) {
        sreg <- single_trial_regressor(
          onsets    = onsets[j],
          hrf       = hrf,
          duration  = this_dur[j],
          amplitude = this_amp[j]
        )
        bold_signal <- bold_signal + evaluate(sreg, time_grid)
      }
    }
    
    # Add noise to the entire signal including buffer
    eps <- gen_noise()
    noisy_tc <- bold_signal + eps
    signal_list[[ii]] <- noisy_tc
  }
  
  sim_matrix <- do.call(cbind, signal_list)
  
  # ---------------------------
  # 3) matrix_dataset
  #    event_table = first column's durations/amplitudes
  # ---------------------------
  event_tab <- data.frame(
    run       = 1,
    onset     = onsets,
    duration  = durmat[,1],
    amplitude = ampmat[,1]
  )
  
  ds <- matrix_dataset(
    datamat     = sim_matrix,
    TR          = TR,
    run_length  = n_time_points,
    event_table = event_tab
  )
  
  # ---------------------------
  # 4) Return
  # ---------------------------
  out <- list(
    time_series  = ds,         # matrix_dataset T x n
    ampmat       = ampmat,     # n_events x n
    durmat       = durmat,     # n_events x n
    hrf_info     = list(
      hrf_class = class(hrf),
      hrf_name  = attr(hrf, "name"),
      nbasis    = nbasis(hrf),
      span      = attr(hrf, "span")
    ),
    noise_params = list(
      noise_type = noise_type,
      noise_ar   = noise_ar,
      noise_sd   = noise_sd
    )
  )
  
  return(out)
}
</file>

<file path="R/zzz.R">
.onLoad <- function(libname, pkgname) {
  env_threads <- Sys.getenv("FMRIREG_NUM_THREADS", unset = NA)
  opt_threads <- getOption("fmrireg.num_threads", default = NA)
  val <- NA
  if (!is.na(opt_threads)) {
    val <- opt_threads
  } else if (!is.na(env_threads) && nzchar(env_threads)) {
    val <- as.numeric(env_threads)
  }
  if (!is.na(val) && val > 0) {
    try({
      RcppParallel::setThreadOptions(numThreads = as.integer(val))
    }, silent = TRUE)
  }
}
</file>

<file path="tests/testthat/test_ar_args.R">
context("AR argument passing")

options(mc.cores=1)

library(testthat)

# simple synthetic dataset
etab <- data.frame(onset=c(1,10), repnum=factor(c("A","B")), run=c(1,1))
Y <- matrix(rnorm(20*5), 20, 5)
dset <- matrix_dataset(Y, TR=1, run_length=20, event_table=etab)

test_that("fmri_lm accepts AR arguments", {
  expect_error(
    fmri_lm(onset ~ hrf(repnum), block = ~ run, dataset = dset,
            cor_struct = "ar1", cor_iter = 2, cor_global = FALSE,
            ar1_exact_first = TRUE),
    NA
  )

  expect_error(
    fmri_lm(onset ~ hrf(repnum), block = ~ run, dataset = dset,
            strategy = "chunkwise", nchunks = 2,
            cor_struct = "ar1", cor_iter = 1, cor_global = TRUE,
            ar1_exact_first = FALSE),
    NA
  )
})

test_that("ar_p validation works", {
  expect_error(
    fmri_lm(onset ~ hrf(repnum), block = ~ run, dataset = dset,
            cor_struct = "arp"),
    "ar_p"
  )

  expect_error(
    fmri_lm(onset ~ hrf(repnum), block = ~ run, dataset = dset,
            cor_struct = "arp", ar_p = 2),
    NA
  )
})
</file>

<file path="tests/testthat/test_ar_integration.R">
context("AR modeling integration")

simulate_ar_dataset <- function(ar_coeff = numeric(), n_runs = 2, n_time = 30, n_vox = 4) {
  dat_list <- vector("list", n_runs)
  for (r in seq_len(n_runs)) {
    run_mat <- replicate(n_vox, {
      if (length(ar_coeff) == 0) {
        rnorm(n_time)
      } else {
        as.numeric(arima.sim(model = list(ar = ar_coeff), n = n_time))
      }
    })
    dat_list[[r]] <- run_mat
  }
  datamat <- do.call(rbind, dat_list)
  event_tab <- expand.grid(run = seq_len(n_runs), onset = c(5, 15))
  event_tab$cond <- factor("A")
  matrix_dataset(datamat, TR = 1, run_length = rep(n_time, n_runs), event_table = event_tab)
}


# Test that AR1 with no correlation matches IID

test_that("iid and ar1 give similar results on white noise", {
  set.seed(1)
  dset <- simulate_ar_dataset(n_runs = 2, ar_coeff = numeric())
  mod_iid <- fmri_lm(onset ~ hrf(cond), block = ~ run, dataset = dset,
                     use_fast_path = TRUE, cor_struct = "iid")
  mod_ar1 <- fmri_lm(onset ~ hrf(cond), block = ~ run, dataset = dset,
                     use_fast_path = TRUE, cor_struct = "ar1")
  expect_equal(coef(mod_iid), coef(mod_ar1), tolerance = 1e-6)

  model <- create_fmri_model(onset ~ hrf(cond), block = ~ run, dataset = dset, durations = 0)
  X <- design_matrix(model)
  proj <- .fast_preproject(X)
  Y <- get_data_matrix(dset)
  ols <- .fast_lm_matrix(X, Y, proj, return_fitted = TRUE)
  resid_ols <- Y - ols$fitted
  phi_hat <- .estimate_ar(rowMeans(resid_ols), 1)
  expect_equal(as.numeric(phi_hat), 0, tolerance = 0.1)
})

# Test AR1 recovery and SE comparison

test_that("ar1 recovers phi and adjusts standard errors", {
  set.seed(2)
  phi <- 0.4
  dset <- simulate_ar_dataset(ar_coeff = phi, n_runs = 2)

  model <- create_fmri_model(onset ~ hrf(cond), block = ~ run, dataset = dset, durations = 0)
  X <- design_matrix(model)
  proj <- .fast_preproject(X)
  Y <- get_data_matrix(dset)
  ols <- .fast_lm_matrix(X, Y, proj, return_fitted = TRUE)
  resid_ols <- Y - ols$fitted
  phi_hat <- .estimate_ar(rowMeans(resid_ols), 1)
  expect_equal(as.numeric(phi_hat), phi, tolerance = 0.1)

  mod_iid <- fmri_lm(onset ~ hrf(cond), block = ~ run, dataset = dset,
                     use_fast_path = TRUE, cor_struct = "iid")
  mod_ar1 <- fmri_lm(onset ~ hrf(cond), block = ~ run, dataset = dset,
                     use_fast_path = TRUE, cor_struct = "ar1")
  se_iid <- unlist(standard_error(mod_iid))
  se_ar1 <- unlist(standard_error(mod_ar1))
  expect_gt(se_ar1[1], se_iid[1])
})

# Test AR2 recovery

test_that("ar2 recovers coefficients", {
  set.seed(3)
  phi <- c(0.5, -0.25)
  dset <- simulate_ar_dataset(ar_coeff = phi, n_runs = 2)

  model <- create_fmri_model(onset ~ hrf(cond), block = ~ run, dataset = dset, durations = 0)
  X <- design_matrix(model)
  proj <- .fast_preproject(X)
  Y <- get_data_matrix(dset)
  ols <- .fast_lm_matrix(X, Y, proj, return_fitted = TRUE)
  resid_ols <- Y - ols$fitted
  phi_hat <- .estimate_ar(rowMeans(resid_ols), 2)
  expect_equal(as.numeric(phi_hat), phi, tolerance = 0.1)
})

# Test global vs runwise

test_that("cor_global gives similar results", {
  set.seed(4)
  phi <- 0.4
  dset <- simulate_ar_dataset(ar_coeff = phi, n_runs = 2)
  mod_run <- fmri_lm(onset ~ hrf(cond), block = ~ run, dataset = dset,
                     use_fast_path = TRUE, cor_struct = "ar1", cor_global = FALSE)
  mod_global <- fmri_lm(onset ~ hrf(cond), block = ~ run, dataset = dset,
                        use_fast_path = TRUE, cor_struct = "ar1", cor_global = TRUE)
  expect_equal(coef(mod_run), coef(mod_global), tolerance = 1e-6)
})

# Test ar1_exact_first option

test_that("ar1_exact_first runs", {
  set.seed(5)
  phi <- 0.4
  dset <- simulate_ar_dataset(ar_coeff = phi, n_runs = 1)
  expect_error(
    fmri_lm(onset ~ hrf(cond), block = ~ run, dataset = dset,
            use_fast_path = TRUE, cor_struct = "ar1", ar1_exact_first = TRUE),
    NA
  )
})

# Test multiple iterations

test_that("cor_iter > 1 runs", {
  set.seed(6)
  phi <- 0.4
  dset <- simulate_ar_dataset(ar_coeff = phi, n_runs = 1)
  expect_error(
    fmri_lm(onset ~ hrf(cond), block = ~ run, dataset = dset,
            use_fast_path = TRUE, cor_struct = "ar1", cor_iter = 2),
    NA
  )
})
</file>

<file path="tests/testthat/test_ar_whiten.R">
context("C++ AR whitening")

whiten_R <- function(M, phi, exact_first_ar1 = FALSE) {
  p <- length(phi)
  nT <- nrow(M)
  nC <- ncol(M)
  res <- M
  for (c in seq_len(nC)) {
    prev <- rep(0, p)
    for (t in seq_len(nT)) {
      orig <- M[t, c]
      val <- orig - sum(phi * prev)
      if (t == 1 && exact_first_ar1 && p == 1) {
        val <- val * sqrt(1 - phi^2)
      }
      if (p > 0) {
        if (p > 1) prev[p:2] <- prev[(p-1):1]
        prev[1] <- orig
      }
      res[t, c] <- val
    }
  }
  res
}

test_that("ar_whiten_inplace AR1", {
  Y <- matrix(1:4, ncol = 1)
  X <- matrix(4:1, ncol = 1)
  phi <- 0.5
  Yref <- whiten_R(Y, phi)
  Xref <- whiten_R(X, phi)
  ar_whiten_inplace(Y, X, phi)
  expect_equal(Y, Yref)
  expect_equal(X, Xref)
})

test_that("ar_whiten_inplace AR2", {
  Y <- matrix(1:6, ncol = 1)
  X <- matrix(6:1, ncol = 1)
  phi <- c(0.6, -0.3)
  Yref <- whiten_R(Y, phi)
  Xref <- whiten_R(X, phi)
  ar_whiten_inplace(Y, X, phi)
  expect_equal(Y, Yref)
  expect_equal(X, Xref)
})

test_that("ar_whiten_inplace exact first AR1", {
  Y <- matrix(rnorm(5), ncol = 1)
  X <- matrix(rnorm(5), ncol = 1)
  phi <- 0.4
  Yref <- whiten_R(Y, phi, TRUE)
  Xref <- whiten_R(X, phi, TRUE)
  ar_whiten_inplace(Y, X, phi, TRUE)
  expect_equal(Y, Yref)
  expect_equal(X, Xref)
})
</file>

<file path="tests/testthat/test_benchmark_datasets.R">
test_that("benchmark dataset loading works", {
  skip_if_not_installed("fmrireg")
  
  # Test that we can list datasets
  datasets_info <- list_benchmark_datasets()
  expect_true(is.data.frame(datasets_info))
  expect_true(nrow(datasets_info) >= 5)
  expect_true(all(c("Dataset", "Description") %in% colnames(datasets_info)))
  
  # Test loading a specific dataset
  data <- load_benchmark_dataset("BM_Canonical_HighSNR")
  expect_true(is.list(data))
  expect_true("Y_noisy" %in% names(data))
  expect_true("event_onsets" %in% names(data))
  expect_true("condition_labels" %in% names(data))
  expect_true("true_betas_condition" %in% names(data))
  
  # Check dimensions are reasonable
  expect_true(is.matrix(data$Y_noisy))
  expect_true(ncol(data$Y_noisy) == 100)  # 100 voxels
  expect_true(nrow(data$Y_noisy) > 100)   # Should have many time points
  
  # Test metadata loading
  metadata <- load_benchmark_dataset("metadata")
  expect_true(is.list(metadata))
  expect_true("creation_date" %in% names(metadata))
  expect_true("description" %in% names(metadata))
})

test_that("benchmark dataset summary works", {
  skip_if_not_installed("fmrireg")
  
  summary_info <- get_benchmark_summary("BM_Canonical_HighSNR")
  expect_true(is.list(summary_info))
  expect_true("dimensions" %in% names(summary_info))
  expect_true("experimental_design" %in% names(summary_info))
  expect_true("hrf_information" %in% names(summary_info))
  
  # Check dimensions
  dims <- summary_info$dimensions
  expect_equal(dims$n_voxels, 100)
  expect_equal(dims$n_conditions, 3)
  expect_true(dims$n_events > 0)
})

test_that("design matrix creation works", {
  skip_if_not_installed("fmrireg")
  
  # Test design matrix creation
  X <- create_design_matrix_from_benchmark("BM_Canonical_HighSNR", HRF_SPMG1)
  expect_true(is.matrix(X))
  expect_true(ncol(X) == 4)  # 3 conditions + intercept
  expect_true(nrow(X) > 100)  # Should have many time points
  expect_true("Intercept" %in% colnames(X))
  
  # Test without intercept
  X_no_int <- create_design_matrix_from_benchmark("BM_Canonical_HighSNR", HRF_SPMG1, 
                                                  include_intercept = FALSE)
  expect_true(ncol(X_no_int) == 3)  # 3 conditions only
  expect_false("Intercept" %in% colnames(X_no_int))
})

test_that("performance evaluation works", {
  skip_if_not_installed("fmrireg")
  
  # Load dataset and create simple test
  data <- load_benchmark_dataset("BM_Canonical_HighSNR")
  true_betas <- data$true_betas_condition
  
  # Create some fake estimated betas with more realistic variation
  # Add noise to true betas AND add some spatial variation to avoid zero variance
  set.seed(123)
  estimated_betas <- true_betas + matrix(rnorm(prod(dim(true_betas)), 0, 0.1), 
                                        nrow = nrow(true_betas))
  
  # Add some spatial variation to make correlations meaningful
  for (i in 1:nrow(estimated_betas)) {
    spatial_trend <- seq(-0.1, 0.1, length.out = ncol(estimated_betas))
    estimated_betas[i, ] <- estimated_betas[i, ] + spatial_trend
  }
  
  # Evaluate performance
  performance <- evaluate_method_performance("BM_Canonical_HighSNR", 
                                            estimated_betas, 
                                            "Test_Method")
  
  expect_true(is.list(performance))
  expect_true("overall_metrics" %in% names(performance))
  expect_true("condition_metrics" %in% names(performance))
  expect_true("voxel_metrics" %in% names(performance))
  
  # Check that correlation is reasonable (should be positive but not perfect due to added noise)
  expect_true(performance$overall_metrics$correlation > 0.5)
  expect_true(performance$overall_metrics$correlation < 1.0)
  expect_true(performance$overall_metrics$mse > 0)
})

test_that("all benchmark datasets can be loaded", {
  skip_if_not_installed("fmrireg")
  
  # Get list of all datasets
  datasets_info <- list_benchmark_datasets()
  dataset_names <- datasets_info$Dataset
  
  # Try to load each dataset
  for (dataset_name in dataset_names) {
    data <- load_benchmark_dataset(dataset_name)
    expect_true(is.list(data))
    expect_true("Y_noisy" %in% names(data))
    expect_true("event_onsets" %in% names(data))
    expect_true("condition_labels" %in% names(data))
    
    # Check that dimensions are consistent with simulation
    # The simulation uses ceiling(total_time / TR) for the number of timepoints
    expected_timepoints <- ceiling(data$total_time / data$TR)
    expect_equal(nrow(data$Y_noisy), expected_timepoints)
    expect_equal(length(data$event_onsets), length(data$condition_labels))
  }
})

test_that("error handling works correctly", {
  skip_if_not_installed("fmrireg")
  
  # Test invalid dataset name
  expect_error(load_benchmark_dataset("NonExistent_Dataset"))
  expect_error(get_benchmark_summary("NonExistent_Dataset"))
  
  # Test performance evaluation with wrong dimensions
  data <- load_benchmark_dataset("BM_Canonical_HighSNR")
  wrong_betas <- matrix(1, nrow = 2, ncol = 50)  # Wrong dimensions
  expect_error(evaluate_method_performance("BM_Canonical_HighSNR", wrong_betas, "Test"))
})
</file>

<file path="tests/testthat/test_betas.R">
Sys.unsetenv("R_TESTS")
options(mc.cores=1)

facedes <- read.table(system.file("extdata", "face_design.txt", package = "fmrireg"), header=TRUE)
facedes$repnum <- factor(facedes$rep_num)
library(dplyr)


gen_dset <- function(D=5, des=facedes) {
  D <- 5
  scans <- lapply(1:length(unique(des$run)), function(i) {
    arr <- array(rnorm(D*D*D*300), c(D,D,D, 300))
    bspace <- neuroim2::NeuroSpace(dim=c(D,D,D,300))
    neuroim2::NeuroVec(arr, bspace)
  })
  
  mask <- neuroim2::LogicalNeuroVol(array(rnorm(D*D*D), c(D,D,D)) > 0, neuroim2::NeuroSpace(dim=c(D,D,D)))
  
  
  #scans <- list.files("test_data/images_study/epi/", "rscan0.*nii", full.names=TRUE)
  fmri_mem_dataset(scans=scans, 
                   mask=mask, 
                   TR=1.5, 
                   event_table=des)
  
  
}


test_that("can run a beta estimation", {
  
  facedes$frun <- factor(facedes$run)
  facedes$constant <- factor(rep(1, nrow(facedes)))
  

  facedes <- facedes %>% dplyr::filter(run==1)
  
  dset <- gen_dset(5, facedes)
  
  basis <- gen_hrf(HRF_SPMG3)
  
  ret1 <- estimate_betas(dset, fixed = onset ~ hrf(constant), ran = onset ~ trialwise(), block = ~ run, 
                       method="pls", ncomp=1)
  ret2 <- estimate_betas(dset, fixed = onset ~ hrf(constant), ran = onset ~ trialwise(), block = ~ run, 
                         method="pls", ncomp=3)
  ret3 <- estimate_betas(dset, fixed = onset ~ hrf(constant), ran = onset ~ trialwise(), block = ~ run, 
                        method="mixed")
  
  ret4 <- estimate_betas(dset, ran = onset ~ trialwise(), block = ~ run, 
                         method="ols")
  ret5 <- estimate_betas(dset, ran = onset ~ trialwise(), block = ~ run, 
                         method="lss")
  ret6 <- estimate_betas(dset, ran = onset ~ trialwise(), block = ~ run, 
                         method="lss_cpp")
  


 
  expect_true(!is.null(ret1))
  expect_true(!is.null(ret2))
  expect_true(!is.null(ret3))
  expect_true(!is.null(ret4))
  expect_true(!is.null(ret5))
  expect_true(!is.null(ret6))
  #expect_true(!is.null(ret7))
  #expect_true(!is.null(ret9))
  
})

# test_that("can accurate estimate an hrf shape with appropriate methods", {
#   amps <- 1
#   hrf <- gen_hrf(hrf_half_cosine,h1=2, h2=7, h4=11 )
#   ret <- sim_ts(ncond=1, hrf,nreps=20, amps=amps,isi=c(8,16))
#   
#   etab <- data.frame(onset=ret$onset, fac=rep("a", length(ret$onset)), run=factor(rep(1, length(ret$onset))))
#   matrix_dataset(as.matrix(ret$mat[,2]), TR=1.5, run_length=143, event_table=etab)
#   
# })

test_that("can run a beta estimation with different durations", {

  facedes$frun <- factor(facedes$run)
  facedes$constant <- factor(rep(1, nrow(facedes)))

  facedes <- facedes %>% dplyr::filter(run==1)
  dset <- gen_dset(5, facedes)

  hf <- gen_hrf(hrf_spmg1, width=2, lag=5)
  ret1 <- estimate_betas(dset, fixed = onset ~ hrf(constant, durations=1), ran = onset ~ trialwise(),
                         block = ~ run,
                         method="pls", ncomp=1)

  ret2 <- estimate_betas(dset, fixed = onset ~ hrf(constant, basis=hf), ran = onset ~ trialwise(basis=hf),
                         block = ~ run,
                         method="pls", ncomp=1)


  expect_true(!is.null(ret1))
  expect_true(!is.null(ret2))
  expect_lt(cor(as.vector(ret1$betas_ran[,]), as.vector(ret2$betas_ran[,])), 0.8)

})


test_that("can run a beta estimation with multiple basis functions", {

  facedes$frun <- factor(facedes$run)
  facedes$constant <- factor(rep(1, nrow(facedes)))

  dset <- gen_dset(5, facedes)

  #hrfbasis = NULL
  hrfbasis <- do.call(gen_hrf_set, lapply(0:12, function(i) {
    gen_hrf(hrf_gaussian, lag=i,width=.01)
  }))


  # est <- estimate_betas(dset, fixed = onset ~ hrf(constant, basis=hrfbasis, durations=0),
  #                                 ran = onset ~ trialwise(basis=hrfbasis, durations=0), block = ~ run,
  #                                 method="pls",ncomp=3)
  
  est <- estimate_betas(dset, fixed = onset ~ hrf(constant, durations=0),
                                   ran = onset ~ trialwise(), block = ~ run,
                                   method="pls",ncomp=3)


  expect_true(!is.null(est))

})

test_that("can run a beta estimation with custom basis", {

  facedes$frun <- factor(facedes$run)
  facedes$constant <- factor(rep(1, nrow(facedes)))
  dset <- gen_dset(5, facedes)

  b1 <<- gen_hrf(hrf_spmg1, lag=1, width=3, normalize=TRUE)


  # est <- estimate_betas(dset, fixed = onset ~ hrf(constant),
  #                       ran = onset ~ trialwise(basis=b1, durations=0), block = ~ run,
  #                       method="pls_global",ncomp=30)
  
  est <- estimate_betas(dset, fixed = onset ~ hrf(constant,durations=0),
                                   ran = onset ~ trialwise(), block = ~ run,
                                   method="pls",ncomp=3)

  expect_true(!is.null(est))


})

test_that("can run a beta estimation with fixed duration", {
  
  facedes$frun <- factor(facedes$run)
  facedes$constant <- factor(rep(1, nrow(facedes)))
  
  dset <- gen_dset(5,facedes)
  #scans <- list.files("test_data/images_study/epi/", "rscan0.*nii", full.names=TRUE)
  
  dset <- fmri_mem_dataset(scans=dset$scans, 
                           mask=dset$mask, 
                           TR=1.5, 
                           event_table=facedes)
  
  b1 <- gen_hrf(hrf_spmg1, lag=1, width=3, normalize=TRUE)
  
  
  est <- estimate_betas(dset, fixed = onset ~ hrf(constant),
                        ran = onset ~ trialwise(), block = ~ run, 
                        method="pls_global",ncomp=20)
  
  expect_true(!is.null(est))
  
  
})
</file>

<file path="tests/testthat/test_convenience_functions.R">
library(testthat)
library(fmrireg)

# Helper function to create test data
create_test_data <- function(seed = 123) {
  set.seed(seed)
  Y <- matrix(rnorm(1000), 100, 10)  # 100 timepoints, 10 voxels
  
  event_data <- data.frame(
    onset = c(10, 30, 50, 70),
    condition = factor(c('A', 'B', 'A', 'B')),
    run = rep(1, 4)
  )
  
  dset <- matrix_dataset(Y, TR = 2, run_length = 100, event_table = event_data)
  
  sframe <- sampling_frame(blocklens = 100, TR = 2)
  model_obj <- event_model(onset ~ hrf(condition), 
                          data = event_data, 
                          block = ~ run, 
                          sampling_frame = sframe)
  
  list(dataset = dset, model = model_obj, event_data = event_data)
}

# Tests for glm_ols ----

test_that("glm_ols works with basic inputs", {
  test_data <- create_test_data()
  
  result <- glm_ols(test_data$dataset, test_data$model, HRF_SPMG1)
  
  expect_s3_class(result, "fmri_betas")
  expect_true(!is.null(result$betas_ran))
  expect_true(!is.null(result$design_ran))
  
  # Should have 2 conditions (A, B) x 10 voxels
  expect_equal(dim(result$betas_ran), c(2, 10))
  expect_equal(dim(result$design_ran), c(100, 2))
})

test_that("glm_ols works with different HRF bases", {
  test_data <- create_test_data()
  
  # Test with SPMG1 (canonical)
  result_spmg1 <- glm_ols(test_data$dataset, test_data$model, HRF_SPMG1)
  expect_equal(dim(result_spmg1$betas_ran), c(2, 10))
  
  # Test with SPMG2 (canonical + temporal derivative)
  result_spmg2 <- glm_ols(test_data$dataset, test_data$model, HRF_SPMG2)
  expect_equal(dim(result_spmg2$betas_ran), c(4, 10))  # 2 conditions x 2 basis functions
  
  # Test with SPMG3 (canonical + both derivatives)
  result_spmg3 <- glm_ols(test_data$dataset, test_data$model, HRF_SPMG3)
  expect_equal(dim(result_spmg3$betas_ran), c(6, 10))  # 2 conditions x 3 basis functions
})

test_that("glm_ols validates inputs correctly", {
  test_data <- create_test_data()
  
  # Test with invalid dataset
  expect_error(glm_ols("not_a_dataset", test_data$model, HRF_SPMG1),
               "dataset must be a matrix_dataset object")
  
  # Test with invalid model
  expect_error(glm_ols(test_data$dataset, "not_a_model", HRF_SPMG1),
               "model_obj must be an event_model object")
})

test_that("glm_ols matches traditional estimate_betas approach", {
  test_data <- create_test_data()
  
  # Convenience function approach
  result_convenience <- glm_ols(test_data$dataset, test_data$model, HRF_SPMG1)
  
  # Traditional approach
  result_traditional <- estimate_betas(test_data$dataset, 
                                     fixed = NULL,
                                     ran = onset ~ hrf(condition, basis = HRF_SPMG1), 
                                     block = ~ run,
                                     method = "ols")
  
  # Results should be identical
  expect_equal(result_convenience$betas_ran, result_traditional$betas_ran, tolerance = 1e-10)
  expect_equal(dim(result_convenience$design_ran), dim(result_traditional$design_ran))
})

# Tests for glm_lss ----

test_that("glm_lss works with basic inputs", {
  test_data <- create_test_data()
  
  result <- glm_lss(test_data$dataset, test_data$model, HRF_SPMG1)
  
  expect_s3_class(result, "fmri_betas")
  expect_true(!is.null(result$betas_ran))
  expect_true(!is.null(result$design_ran))
  
  # Should have 2 trials (single trial estimation) x 10 voxels
  # Note: LSS estimates separate betas for each trial
  expect_equal(dim(result$betas_ran), c(2, 10))
  expect_equal(dim(result$design_ran), c(100, 2))
})

test_that("glm_lss works with different HRF bases", {
  test_data <- create_test_data()
  
  # Test with SPMG1 (canonical)
  result_spmg1 <- glm_lss(test_data$dataset, test_data$model, HRF_SPMG1)
  expect_equal(dim(result_spmg1$betas_ran), c(2, 10))
  
  # Test with SPMG2 (canonical + temporal derivative)
  result_spmg2 <- glm_lss(test_data$dataset, test_data$model, HRF_SPMG2)
  expect_equal(dim(result_spmg2$betas_ran), c(4, 10))  # 2 conditions x 2 basis functions
})

test_that("glm_lss validates inputs correctly", {
  test_data <- create_test_data()
  
  # Test with invalid dataset
  expect_error(glm_lss("not_a_dataset", test_data$model, HRF_SPMG1),
               "dataset must be a matrix_dataset object")
  
  # Test with invalid model
  expect_error(glm_lss(test_data$dataset, "not_a_model", HRF_SPMG1),
               "model_obj must be an event_model object")
})

test_that("glm_lss works with both C++ and R implementations", {
  test_data <- create_test_data()
  
  # Test with C++ implementation
  result_cpp <- glm_lss(test_data$dataset, test_data$model, HRF_SPMG1, use_cpp = TRUE)
  expect_s3_class(result_cpp, "fmri_betas")
  
  # Test with R implementation
  result_r <- glm_lss(test_data$dataset, test_data$model, HRF_SPMG1, use_cpp = FALSE)
  expect_s3_class(result_r, "fmri_betas")
  
  # Both should have same dimensions
  expect_equal(dim(result_cpp$betas_ran), dim(result_r$betas_ran))
})

test_that("glm_lss matches traditional estimate_betas LSS approach", {
  test_data <- create_test_data()
  
  # Convenience function approach
  result_convenience <- glm_lss(test_data$dataset, test_data$model, HRF_SPMG1)
  
  # Traditional approach
  result_traditional <- estimate_betas(test_data$dataset, 
                                     fixed = NULL,
                                     ran = onset ~ hrf(condition, basis = HRF_SPMG1), 
                                     block = ~ run,
                                     method = "lss")
  
  # Results should be identical
  expect_equal(result_convenience$betas_ran, result_traditional$betas_ran, tolerance = 1e-10)
  expect_equal(dim(result_convenience$design_ran), dim(result_traditional$design_ran))
})

# Comparison tests ----

test_that("glm_ols and glm_lss produce different results as expected", {
  test_data <- create_test_data()
  
  result_ols <- glm_ols(test_data$dataset, test_data$model, HRF_SPMG1)
  result_lss <- glm_lss(test_data$dataset, test_data$model, HRF_SPMG1)
  
  # Both should have same dimensions for this simple case
  expect_equal(dim(result_ols$betas_ran), dim(result_lss$betas_ran))
  
  # But the actual beta values should be different (OLS averages, LSS doesn't)
  expect_false(identical(result_ols$betas_ran, result_lss$betas_ran))
})

test_that("convenience functions work with baseline models", {
  test_data <- create_test_data()
  
  # Create a baseline model
  sframe <- sampling_frame(blocklens = 100, TR = 2)
  basemod <- baseline_model("constant", sframe = sframe)
  
  # Test both functions with baseline model
  result_ols <- glm_ols(test_data$dataset, test_data$model, HRF_SPMG1, basemod = basemod)
  result_lss <- glm_lss(test_data$dataset, test_data$model, HRF_SPMG1, basemod = basemod)
  
  expect_s3_class(result_ols, "fmri_betas")
  expect_s3_class(result_lss, "fmri_betas")
  expect_true(!is.null(result_ols$design_base))
  expect_true(!is.null(result_lss$design_base))
})

test_that("convenience functions work with different block specifications", {
  test_data <- create_test_data()
  
  # Test with different block specification
  result_ols <- glm_ols(test_data$dataset, test_data$model, HRF_SPMG1, block = ~ run)
  result_lss <- glm_lss(test_data$dataset, test_data$model, HRF_SPMG1, block = ~ run)
  
  expect_s3_class(result_ols, "fmri_betas")
  expect_s3_class(result_lss, "fmri_betas")
})
</file>

<file path="tests/testthat/test_estimate_ar.R">
context("AR coefficient estimation")

options(mc.cores=1)

library(testthat)

# .estimate_ar should recover AR coefficients from simulated data

test_that(".estimate_ar recovers AR(1) coefficient", {
  set.seed(123)
  phi <- 0.6
  x <- as.numeric(arima.sim(model = list(ar = phi), n = 500))
  est <- .estimate_ar(x, 1)
  expect_equal(as.numeric(est), phi, tolerance = 0.05)
})

test_that(".estimate_ar recovers AR(2) coefficients", {
  set.seed(123)
  phi <- c(0.5, -0.25)
  x <- as.numeric(arima.sim(model = list(ar = phi), n = 1000))
  est <- .estimate_ar(x, 2)
  expect_equal(as.numeric(est), phi, tolerance = 0.05)
})
</file>

<file path="tests/testthat/test_hrf.R">
library(testthat)

test_that("HRF_GAMMA has correct structure and properties", {
  # Test basic structure
  expect_true(inherits(HRF_GAMMA, "HRF"))
  expect_equal(attr(HRF_GAMMA, "name"), "gamma")
  expect_equal(attr(HRF_GAMMA, "param_names"), c("shape", "rate"))
  
  # Test function evaluation
  t <- seq(0, 20, by=0.5)
  result <- HRF_GAMMA(t)
  expect_true(is.numeric(result))
  expect_equal(length(result), length(t))
  expect_true(all(result >= 0))  # Gamma HRF should be non-negative
})

test_that("HRF_SPMG1 has correct structure and properties", {
  # Test basic structure
  expect_true(inherits(HRF_SPMG1, "HRF"))
  expect_equal(attr(HRF_SPMG1, "name"), "SPMG1")
  expect_equal(attr(HRF_SPMG1, "param_names"), c("A1", "A2"))
  
  # Test function evaluation
  t <- seq(0, 30, by=0.5)
  result <- HRF_SPMG1(t)
  expect_true(is.numeric(result))
  expect_equal(length(result), length(t))
  expect_equal(result[t < 0], rep(0, sum(t < 0)))  # Should be 0 for negative time
  
  # Test peak timing (should peak around 5-6 seconds)
  peak_time <- t[which.max(result)]
  expect_true(peak_time >= 4 && peak_time <= 7)
})

test_that("HRF_SPMG2 has correct structure and properties", {
  # Test basic structure
  expect_true(inherits(HRF_SPMG2, "HRF"))
  expect_equal(attr(HRF_SPMG2, "name"), "SPMG2")
  expect_equal(nbasis(HRF_SPMG2), 2)  # Should have 2 basis functions
  
  # Test function evaluation
  t <- seq(0, 30, by=0.5)
  result <- HRF_SPMG2(t)
  expect_true(is.matrix(result))
  expect_equal(nrow(result), length(t))
  expect_equal(ncol(result), 2)  # Should return 2 columns for canonical and temporal derivative
})

test_that("HRF_GAUSSIAN has correct structure and properties", {
  # Test basic structure
  expect_true(inherits(HRF_GAUSSIAN, "HRF"))
  expect_equal(attr(HRF_GAUSSIAN, "name"), "gaussian")
  expect_equal(attr(HRF_GAUSSIAN, "param_names"), c("mean", "sd"))
  
  # Test function evaluation
  t <- seq(0, 20, by=0.5)
  result <- HRF_GAUSSIAN(t)
  expect_true(is.numeric(result))
  expect_equal(length(result), length(t))
  expect_true(all(result >= 0))  # Gaussian HRF should be non-negative
})

test_that("HRF_BSPLINE has correct structure and properties", {
  # Test basic structure
  expect_true(inherits(HRF_BSPLINE, "HRF"))
  expect_equal(attr(HRF_BSPLINE, "name"), "bspline")
  expect_equal(nbasis(HRF_BSPLINE), 5)  # Default number of basis functions
  
  # Test function evaluation
  t <- seq(0, 20, by=0.5)
  result <- HRF_BSPLINE(t)
  expect_true(is.matrix(result))
  expect_equal(nrow(result), length(t))
  expect_equal(ncol(result), 5)  # Should return 5 columns for basis functions
})

test_that("evaluate.HRF handles different duration scenarios", {
  t <- seq(0, 20, by=0.2)
  
  # Test zero duration
  result1 <- evaluate(HRF_SPMG1, t, duration=0)
  expect_true(is.numeric(result1))
  expect_equal(length(result1), length(t))
})

test_that("gen_hrf handles lag and width correctly", {
  # Test lag
  hrf_lag <- gen_hrf(HRF_SPMG1, lag = 2)
  t <- seq(0, 20, by = 0.5)
  result_lag <- hrf_lag(t)
  result_no_lag <- HRF_SPMG1(t)
  
  # Peak should be shifted by lag
  peak_lag <- t[which.max(result_lag)]
  peak_no_lag <- t[which.max(result_no_lag)]
  expect_equal(peak_lag - peak_no_lag, 2)
  
  # Test width (block duration)
  hrf_block <- gen_hrf(HRF_SPMG1, width = 3)
  result_block <- hrf_block(t)
  
  # Block HRF should have wider response
  width_block <- sum(result_block > 0)
  width_no_block <- sum(result_no_lag > 0)
  expect_true(width_block > width_no_block)
  
  # Test combined lag and width
  hrf_both <- gen_hrf(HRF_SPMG1, lag = 2, width = 3)
  result_both <- hrf_both(t)
  peak_both <- t[which.max(result_both)]
  expect_true(peak_both > peak_no_lag)
})

test_that("gen_hrf_set combines HRFs correctly", {
  # Create basis set
  hrf1 <- gen_hrf(HRF_SPMG1, lag = 0)
  hrf2 <- gen_hrf(HRF_SPMG1, lag = 2)
  hrf3 <- gen_hrf(HRF_SPMG1, lag = 4)
  hrf_set <- gen_hrf_set(hrf1, hrf2, hrf3, name = "test_set")
  
  # Test structure
  expect_true(inherits(hrf_set, "HRF"))
  expect_equal(nbasis(hrf_set), 3)
  expect_equal(attr(hrf_set, "name"), "test_set")
  
  # Test evaluation
  t <- seq(0, 20, by = 0.5)
  result <- hrf_set(t)
  expect_true(is.matrix(result))
  expect_equal(dim(result), c(length(t), 3))
  
  # Test peaks are correctly shifted
  peaks <- apply(result, 2, function(x) t[which.max(x)])
  expect_equal(diff(peaks), c(2, 2))
})

test_that("evaluate.HRF handles different durations and summation correctly", {
  t <- seq(0, 20, by = 0.2)
  
  # Test non-zero duration
  result_dur <- evaluate(HRF_SPMG1, t, duration = 2)
  result_no_dur <- evaluate(HRF_SPMG1, t, duration = 0)
  
  # Response should be larger with duration
  expect_true(max(result_dur) > max(result_no_dur))
  
  # Test summation
  result_sum <- evaluate(HRF_SPMG1, t, duration = 2, summate = TRUE)
  result_no_sum <- evaluate(HRF_SPMG1, t, duration = 2, summate = FALSE)
  expect_false(identical(result_sum, result_no_sum))
  
  # Test precision effects
  result_fine <- evaluate(HRF_SPMG1, t, duration = 2, precision = 0.1)
  result_coarse <- evaluate(HRF_SPMG1, t, duration = 2, precision = 0.5)
  expect_false(identical(result_fine, result_coarse))
})

test_that("gen_empirical_hrf creates valid HRF", {
  # Create simple empirical HRF
  t <- seq(0, 20, by = 0.5)
  y <- dnorm(t, mean = 6, sd = 2)
  hrf <- gen_empirical_hrf(t, y, name = "test_empirical")
  
  # Test structure
  expect_true(inherits(hrf, "HRF"))
  expect_equal(attr(hrf, "name"), "test_empirical")
  expect_equal(nbasis(hrf), 1)
  
  # Test interpolation
  new_t <- seq(0, 20, by = 0.3)
  result <- hrf(new_t)
  expect_equal(length(result), length(new_t))
  expect_true(all(result >= 0))
  
  # Test extrapolation
  extended_t <- c(-2, t, 22)
  result_ext <- hrf(extended_t)
  expect_equal(result_ext[1], 0)  # Left extrapolation
  expect_equal(result_ext[length(result_ext)], 0)  # Right extrapolation
})

test_that("HRF objects maintain correct attributes", {
  # Test basic HRF attributes
  t <- seq(0, 20, by = 0.5)
  
  hrfs <- list(
    HRF_SPMG1 = HRF_SPMG1,
    HRF_SPMG2 = HRF_SPMG2,
    HRF_GAMMA = HRF_GAMMA,
    HRF_GAUSSIAN = HRF_GAUSSIAN
  )
  
  for (name in names(hrfs)) {
    hrf <- hrfs[[name]]
    expect_true(inherits(hrf, "HRF"))
    expect_true(is.function(hrf))
    expect_true(!is.null(attr(hrf, "span")))
    expect_true(!is.null(attr(hrf, "nbasis")))
    expect_true(!is.null(attr(hrf, "name")))
    
    # Test evaluation produces correct dimensions
    result <- hrf(t)
    if (attr(hrf, "nbasis") == 1) {
      expect_true(is.numeric(result))
      expect_equal(length(result), length(t))
    } else {
      expect_true(is.matrix(result))
      expect_equal(nrow(result), length(t))
      expect_equal(ncol(result), attr(hrf, "nbasis"))
    }
  }
})

test_that("as_hrf creates valid HRF objects", {
  # Simple function
  my_func <- function(t) { t^2 }
  
  # Create HRF using as_hrf
  hrf_obj <- as_hrf(my_func, name = "test_sq", nbasis = 1L, span = 10, 
                      params = list(power = 2))
  
  # Check class
  expect_true(inherits(hrf_obj, "HRF"))
  expect_true(inherits(hrf_obj, "function"))
  
  # Check attributes
  expect_equal(attr(hrf_obj, "name"), "test_sq")
  expect_equal(attr(hrf_obj, "nbasis"), 1L)
  expect_equal(attr(hrf_obj, "span"), 10)
  expect_equal(attr(hrf_obj, "param_names"), "power")
  expect_equal(attr(hrf_obj, "params"), list(power = 2))
  
  # Check function evaluation
  expect_equal(hrf_obj(5), 25)
  
  # Check defaults
  hrf_obj_default <- as_hrf(my_func)
  expect_equal(attr(hrf_obj_default, "name"), "my_func")
  expect_equal(attr(hrf_obj_default, "nbasis"), 1L)
  expect_equal(attr(hrf_obj_default, "span"), 24)
  expect_null(attr(hrf_obj_default, "param_names"))
  expect_equal(attr(hrf_obj_default, "params"), list())
  
  # Check multi-basis
  my_multi_func <- function(t) { cbind(t, t^2) }
  hrf_multi <- as_hrf(my_multi_func, nbasis = 2L)
  expect_equal(attr(hrf_multi, "nbasis"), 2L)
  expect_equal(as.matrix(hrf_multi(3)), as.matrix(cbind(3, 9)), check.attributes = FALSE)
})

test_that("bind_basis combines HRF objects correctly", {
  # Create individual HRF objects
  f1 <- function(t) { t }
  f2 <- function(t) { t^2 }
  f3 <- function(t) { rep(1, length(t)) }
  
  hrf1 <- as_hrf(f1, name="linear", span=10)
  hrf2 <- as_hrf(f2, name="quadratic", span=12)
  hrf3 <- as_hrf(f3, name="constant", span=8)
  
  # Combine them
  combined_hrf <- bind_basis(hrf1, hrf2, hrf3)
  
  # Check class
  expect_true(inherits(combined_hrf, "HRF"))
  expect_true(inherits(combined_hrf, "function"))
  
  # Check attributes
  expect_equal(attr(combined_hrf, "name"), "linear + quadratic + constant")
  expect_equal(attr(combined_hrf, "nbasis"), 3L) # 1 + 1 + 1
  expect_equal(attr(combined_hrf, "span"), 12) # max(10, 12, 8)
  
  # Check function evaluation
  t_vals <- c(0, 1, 2, 5)
  expected_output <- cbind(f1(t_vals), f2(t_vals), f3(t_vals))
  colnames(expected_output) <- NULL # Match the expected output of bind_basis function
  
  # Use check.attributes = FALSE for robustness against potential slight differences
  expect_equal(combined_hrf(t_vals), expected_output, check.attributes = FALSE)
  
  # Test with a multi-basis input
  f_multi <- function(t) cbind(sin(t), cos(t))
  hrf_multi <- as_hrf(f_multi, name="trig", nbasis=2L, span=15)
  
  combined_hrf2 <- bind_basis(hrf1, hrf_multi)
  expect_equal(attr(combined_hrf2, "nbasis"), 3L) # 1 + 2
  expect_equal(attr(combined_hrf2, "span"), 15) # max(10, 15)
  expect_equal(attr(combined_hrf2, "name"), "linear + trig")
  
  expected_output2 <- cbind(f1(t_vals), f_multi(t_vals))
  colnames(expected_output2) <- NULL
  expect_equal(combined_hrf2(t_vals), expected_output2, check.attributes = FALSE)
  
  # Test binding just one element
  combined_single <- bind_basis(hrf1)
  expect_equal(attr(combined_single, "name"), "linear")
  expect_equal(attr(combined_single, "nbasis"), 1L)
  expect_equal(attr(combined_single, "span"), 10)
  expect_equal(combined_single(t_vals), f1(t_vals))
})

test_that("lag_hrf correctly lags an HRF object", {
  # Use HRF_SPMG1 as the base HRF
  base_hrf <- HRF_SPMG1
  t <- seq(0, 30, by = 0.5)
  lag_amount <- 5
  
  # Create lagged HRF
  lagged_hrf <- lag_hrf(base_hrf, lag_amount)
  
  # Test basic structure
  expect_true(inherits(lagged_hrf, "HRF"))
  expect_true(inherits(lagged_hrf, "function"))
  expect_equal(nbasis(lagged_hrf), nbasis(base_hrf))
  expect_equal(attr(lagged_hrf, "span"), attr(base_hrf, "span") + lag_amount)
  expect_true(grepl(paste0("_lag\\(", lag_amount, "\\)"), attr(lagged_hrf, "name")))
  expect_equal(attr(lagged_hrf, "params")$.lag, lag_amount)

  # Test function evaluation: lagged_hrf(t) should equal base_hrf(t - lag)
  result_lagged <- lagged_hrf(t)
  result_manual_lag <- base_hrf(t - lag_amount)
  expect_equal(result_lagged, result_manual_lag)
  
  # Test peak timing (should be shifted by lag_amount)
  peak_lagged <- t[which.max(result_lagged)]
  peak_base <- t[which.max(base_hrf(t))]
  # Allow for slight tolerance due to discrete time steps
  expect_true(abs((peak_lagged - peak_base) - lag_amount) < 1) 
  
  # Test with zero lag
  lagged_zero <- lag_hrf(base_hrf, 0)
  expect_equal(lagged_zero(t), base_hrf(t))
  expect_equal(attr(lagged_zero, "span"), attr(base_hrf, "span"))
  
  # Test with a multi-basis HRF (HRF_SPMG2)
  base_hrf_multi <- HRF_SPMG2
  lagged_hrf_multi <- lag_hrf(base_hrf_multi, lag_amount)
  expect_equal(nbasis(lagged_hrf_multi), nbasis(base_hrf_multi))
  expect_equal(lagged_hrf_multi(t), base_hrf_multi(t - lag_amount))
  expect_equal(attr(lagged_hrf_multi, "span"), attr(base_hrf_multi, "span") + lag_amount)
})

test_that("block_hrf correctly blocks an HRF object", {
  base_hrf <- HRF_SPMG1
  t <- seq(0, 30, by = 0.2)
  width <- 5
  precision <- 0.2

  blocked_hrf_sum <- block_hrf(base_hrf, width = width, precision = precision, summate = TRUE, normalize = FALSE)
  blocked_hrf_max <- block_hrf(base_hrf, width = width, precision = precision, summate = FALSE, normalize = FALSE)
  blocked_hrf_norm <- block_hrf(base_hrf, width = width, precision = precision, summate = TRUE, normalize = TRUE)

  # Test basic structure
  expect_true(inherits(blocked_hrf_sum, "HRF"))
  expect_equal(nbasis(blocked_hrf_sum), nbasis(base_hrf))
  expect_equal(attr(blocked_hrf_sum, "span"), attr(base_hrf, "span") + width)
  expect_true(grepl(paste0("_block\\(w=", width, "\\)"), attr(blocked_hrf_sum, "name")))
  expect_equal(attr(blocked_hrf_sum, "params")$.width, width)
  expect_equal(attr(blocked_hrf_sum, "params")$.summate, TRUE)
  expect_equal(attr(blocked_hrf_max, "params")$.summate, FALSE)
  expect_equal(attr(blocked_hrf_norm, "params")$.normalize, TRUE)

  # Test function evaluation - Compare with evaluate.HRF which uses similar logic
  eval_res_sum <- evaluate(base_hrf, t, duration = width, precision = precision, summate = TRUE, normalize = FALSE)
  eval_res_max <- evaluate(base_hrf, t, duration = width, precision = precision, summate = FALSE, normalize = FALSE)
  eval_res_norm <- evaluate(base_hrf, t, duration = width, precision = precision, summate = TRUE, normalize = TRUE)

  expect_equal(blocked_hrf_sum(t), eval_res_sum)
  # Max logic might differ slightly depending on implementation details, check if shape is reasonable
  # expect_equal(blocked_hrf_max(t), eval_res_max)
  expect_false(identical(blocked_hrf_sum(t), blocked_hrf_max(t)))
  expect_equal(blocked_hrf_norm(t), eval_res_norm)
  expect_equal(max(abs(blocked_hrf_norm(t))), 1) # Check normalization worked

  # Test width_block > width_no_block (as in gen_hrf test)
  result_block <- blocked_hrf_sum(t)
  result_no_block <- base_hrf(t)
  
  # Compare Area Under Curve (AUC) approximation as a measure of width/magnitude
  auc_block <- sum(abs(result_block)) * (t[2]-t[1]) # Multiply by time step for approx integral
  auc_no_block <- sum(abs(result_no_block)) * (t[2]-t[1])
  
  expect_true(auc_block > auc_no_block)

  # Test half_life
  blocked_hl <- block_hrf(base_hrf, width = width, precision = precision, half_life = 2)
  expect_false(identical(blocked_hl(t), blocked_hrf_sum(t)))
  expect_true(max(abs(blocked_hl(t))) < max(abs(blocked_hrf_sum(t)))) # Expect decay to reduce peak

  # Test negligible width
  blocked_negligible <- block_hrf(base_hrf, width = 0.01, precision = 0.1)
  expect_equal(blocked_negligible(t), base_hrf(t))
})

test_that("normalise_hrf correctly normalises an HRF object", {
  # Create an unnormalised HRF (Gaussian scaled by 5)
  unnorm_func <- function(t) 5 * dnorm(t, 6, 2)
  unnorm_hrf <- as_hrf(unnorm_func, name="unnorm_gauss")
  t <- seq(0, 20, by=0.1)
  
  # Normalise it
  norm_hrf <- normalise_hrf(unnorm_hrf)

  # Test basic structure
  expect_true(inherits(norm_hrf, "HRF"))
  expect_equal(nbasis(norm_hrf), 1)
  expect_equal(attr(norm_hrf, "span"), attr(unnorm_hrf, "span"))
  expect_true(grepl("_norm", attr(norm_hrf, "name")))
  expect_equal(attr(norm_hrf, "params")$.normalised, TRUE)
  
  # Test peak value
  result_norm <- norm_hrf(t)
  expect_equal(max(abs(result_norm)), 1)
  
  # Test relationship to original
  result_unnorm <- unnorm_hrf(t)
  peak_unnorm <- max(abs(result_unnorm))
  expect_equal(result_norm, result_unnorm / peak_unnorm)
  
  # Test with an already normalised HRF (should remain normalised)
  norm_spmg1 <- normalise_hrf(HRF_SPMG1)
  expect_equal(max(abs(norm_spmg1(t))), 1, tolerance = 1e-7)
  
  # Test with multi-basis HRF (HRF_SPMG2)
  unnorm_spmg2_func <- function(t) cbind(5 * HRF_SPMG2(t)[,1], 10 * HRF_SPMG2(t)[,2])
  unnorm_spmg2 <- as_hrf(unnorm_spmg2_func, name="unnorm_spmg2", nbasis=2L)
  norm_spmg2 <- normalise_hrf(unnorm_spmg2)
  
  expect_equal(nbasis(norm_spmg2), 2)
  result_norm_spmg2 <- norm_spmg2(t)
  expect_equal(max(abs(result_norm_spmg2[,1])), 1)
  expect_equal(max(abs(result_norm_spmg2[,2])), 1)
})

test_that("gen_hrf correctly sets nbasis for function inputs", {
  # Single basis functions
  hrf_g <- gen_hrf(hrf_gaussian)
  expect_equal(nbasis(hrf_g), 1)
  
  hrf_s1 <- gen_hrf(hrf_spmg1)
  expect_equal(nbasis(hrf_s1), 1)
  
  # Single basis HRF object
  hrf_s1_obj <- gen_hrf(HRF_SPMG1)
  expect_equal(nbasis(hrf_s1_obj), 1)

  # Multi-basis HRF objects
  hrf_s2_obj <- gen_hrf(HRF_SPMG2)
  expect_equal(nbasis(hrf_s2_obj), 2)
  
  hrf_s3_obj <- gen_hrf(HRF_SPMG3)
  expect_equal(nbasis(hrf_s3_obj), 3)

  # Function with parameters determining nbasis
  hrf_bs5 <- gen_hrf(hrf_bspline, N = 5)
  expect_equal(nbasis(hrf_bs5), 5)
  
  hrf_bs4 <- gen_hrf(hrf_bspline, N = 4)
  expect_equal(nbasis(hrf_bs4), 4)
  
  # Tent function (bspline with degree 1)
  hrf_tent7 <- gen_hrf(hrf_bspline, N = 7, degree = 1)
  expect_equal(nbasis(hrf_tent7), 7)
})
</file>

<file path="tests/testthat/test_ls_svd_benchmark.R">
context("ls_svd engine with benchmark dataset")

library(fmrireg)

# This test loads the BM_Canonical_HighSNR benchmark dataset and
# runs the LS+SVD+1ALS engine via fmrireg_cfals. Only a subset of voxels
# are used to keep the test lightweight.

test_that("ls_svd_1als_engine works on benchmark data", {
  skip_if_not_installed("fmrireg")

  bm <- load_benchmark_dataset("BM_Canonical_HighSNR")
  dset <- bm$core_data

  # Use only the first 5 voxels for speed
  Y <- dset$datamat[, 1:5]

  evtab <- dset$event_table
  evtab$block <- 1
  emod <- event_model(onset ~ hrf(condition), data = evtab,
                      block = ~ block, sampling_frame = dset$sampling_frame)

  fit <- fmrireg_cfals(Y, emod, HRF_SPMG1,
                       method = "ls_svd_1als",
                       lambda_init = 0.1,
                       lambda_b = 0.1,
                       lambda_h = 0.1)

  expect_equal(nrow(fit$h_coeffs), nbasis(HRF_SPMG1))
  expect_equal(ncol(fit$h_coeffs), ncol(Y))
  expect_equal(dim(fit$beta_amps), c(length(unique(evtab$condition)), ncol(Y)))
  expect_true(all(is.finite(fit$h_coeffs)))
})
</file>

<file path="tests/testthat/test_penalty_matrix.R">
library(testthat)
library(fmrireg)

# Test helper functions ----

test_that("first_difference creates correct difference matrix", {
  # Test with d = 1 (edge case)
  D1 <- fmrireg:::first_difference(1)
  expect_equal(nrow(D1), 0)
  expect_equal(ncol(D1), 1)
  
  # Test with d = 2
  D2 <- fmrireg:::first_difference(2)
  expected2 <- matrix(c(-1, 1), nrow = 1)
  expect_equal(D2, expected2)
  
  # Test with d = 3
  D3 <- fmrireg:::first_difference(3)
  expected3 <- matrix(c(-1, 1, 0, 0, -1, 1), nrow = 2, byrow = TRUE)
  expect_equal(D3, expected3)
  
  # Test with d = 4
  D4 <- fmrireg:::first_difference(4)
  expected4 <- matrix(c(-1, 1, 0, 0, 0, -1, 1, 0, 0, 0, -1, 1), nrow = 3, byrow = TRUE)
  expect_equal(D4, expected4)
})

test_that("second_difference creates correct difference matrix", {
  # Test with d = 1 (edge case)
  D1 <- fmrireg:::second_difference(1)
  expect_equal(nrow(D1), 0)
  expect_equal(ncol(D1), 1)
  
  # Test with d = 2 (edge case)
  D2 <- fmrireg:::second_difference(2)
  expect_equal(nrow(D2), 0)
  expect_equal(ncol(D2), 2)
  
  # Test with d = 3
  D3 <- fmrireg:::second_difference(3)
  expected3 <- matrix(c(1, -2, 1), nrow = 1)
  expect_equal(D3, expected3)
  
  # Test with d = 4
  D4 <- fmrireg:::second_difference(4)
  expected4 <- matrix(c(1, -2, 1, 0, 0, 1, -2, 1), nrow = 2, byrow = TRUE)
  expect_equal(D4, expected4)
  
  # Test with d = 5
  D5 <- fmrireg:::second_difference(5)
  expected5 <- matrix(c(1, -2, 1, 0, 0, 0, 1, -2, 1, 0, 0, 0, 1, -2, 1), nrow = 3, byrow = TRUE)
  expect_equal(D5, expected5)
})

# Test penalty matrix for different HRF types ----

test_that("penalty_matrix works for HRF_SPMG1 (canonical)", {
  R <- penalty_matrix(HRF_SPMG1)
  
  # Should be 1x1 identity matrix
  expect_equal(dim(R), c(1, 1))
  expect_equal(R[1,1], 1)
  expect_true(isSymmetric(R))
})

test_that("penalty_matrix works for HRF_SPMG2 (canonical + temporal derivative)", {
  R <- penalty_matrix(HRF_SPMG2)
  
  # Should be 2x2 diagonal matrix with differential shrinkage
  expect_equal(dim(R), c(2, 2))
  expect_true(isSymmetric(R))
  expect_true(all(diag(R) > 0))
  expect_equal(R[1,1], 1)  # Canonical not penalized
  expect_true(R[2,2] > R[1,1])  # Derivative penalized more
  expect_equal(R[1,2], 0)  # Off-diagonal should be zero
  expect_equal(R[2,1], 0)
})

test_that("penalty_matrix works for HRF_SPMG3 (canonical + both derivatives)", {
  R <- penalty_matrix(HRF_SPMG3)
  
  # Should be 3x3 diagonal matrix
  expect_equal(dim(R), c(3, 3))
  expect_true(isSymmetric(R))
  expect_true(all(diag(R) > 0))
  expect_equal(R[1,1], 1)  # Canonical not penalized
  expect_true(R[2,2] > R[1,1])  # Temporal derivative penalized
  expect_true(R[3,3] > R[1,1])  # Dispersion derivative penalized
  
  # Off-diagonals should be zero
  expect_equal(R[1,2], 0)
  expect_equal(R[1,3], 0)
  expect_equal(R[2,3], 0)
})

test_that("penalty_matrix works for HRF_FIR", {
  R <- penalty_matrix(HRF_FIR)
  
  # Should be symmetric and positive semi-definite
  expect_true(isSymmetric(R))
  expect_equal(dim(R), c(nbasis(HRF_FIR), nbasis(HRF_FIR)))
  
  # Check that it's a valid penalty matrix (positive semi-definite)
  eigenvals <- eigen(R, only.values = TRUE)$values
  expect_true(all(eigenvals >= -1e-10))  # Allow for numerical precision
  
  # Should have banded structure (non-zero near diagonal)
  # For second-order differences, should be pentadiagonal
  expect_true(all(R[abs(row(R) - col(R)) > 2] == 0))
})

test_that("penalty_matrix works for HRF_BSPLINE", {
  R <- penalty_matrix(HRF_BSPLINE)
  
  # Should be symmetric and positive semi-definite
  expect_true(isSymmetric(R))
  expect_equal(dim(R), c(nbasis(HRF_BSPLINE), nbasis(HRF_BSPLINE)))
  
  # Check that it's a valid penalty matrix
  eigenvals <- eigen(R, only.values = TRUE)$values
  expect_true(all(eigenvals >= -1e-10))
  
  # Should have banded structure like FIR
  expect_true(all(R[abs(row(R) - col(R)) > 2] == 0))
})

# Test penalty matrix parameters ----

test_that("penalty_matrix respects order parameter for FIR", {
  # Test first-order differences
  R1 <- penalty_matrix(HRF_FIR, order = 1)
  expect_true(isSymmetric(R1))
  
  # Test second-order differences  
  R2 <- penalty_matrix(HRF_FIR, order = 2)
  expect_true(isSymmetric(R2))
  
  # They should be different
  expect_false(identical(R1, R2))
  
  # First-order should have tridiagonal structure
  expect_true(all(R1[abs(row(R1) - col(R1)) > 1] == 0))
  
  # Second-order should have pentadiagonal structure
  expect_true(all(R2[abs(row(R2) - col(R2)) > 2] == 0))
})

test_that("penalty_matrix respects scale parameter", {
  # Test with scaling
  R_scaled <- penalty_matrix(HRF_FIR, scale = TRUE)
  
  # Test without scaling
  R_unscaled <- penalty_matrix(HRF_FIR, scale = FALSE)
  
  # They should be different
  expect_false(identical(R_scaled, R_unscaled))
  
  # Scaled version should have diagonal elements closer to 1
  if (any(diag(R_scaled) > 0)) {
    expect_true(abs(mean(diag(R_scaled)[diag(R_scaled) > 0]) - 1) < 0.1)
  }
})

test_that("penalty_matrix respects shrink_deriv parameter for SPMG", {
  # Test with default shrinkage
  R_default <- penalty_matrix(HRF_SPMG2)
  
  # Test with custom shrinkage
  R_custom <- penalty_matrix(HRF_SPMG2, shrink_deriv = 10)
  
  # They should be different
  expect_false(identical(R_default, R_custom))
  
  # Custom should have larger penalty on derivative
  expect_true(R_custom[2,2] > R_default[2,2])
  expect_equal(R_custom[1,1], R_default[1,1])  # Canonical unchanged
})

test_that("penalty_matrix respects shrink_disp parameter for SPMG3", {
  # Test with default (shrink_disp = shrink_deriv)
  R_default <- penalty_matrix(HRF_SPMG3, shrink_deriv = 4)
  
  # Test with custom dispersion shrinkage
  R_custom <- penalty_matrix(HRF_SPMG3, shrink_deriv = 4, shrink_disp = 8)
  
  # They should be different
  expect_false(identical(R_default, R_custom))
  
  # Custom should have different penalty on dispersion derivative
  expect_true(R_custom[3,3] != R_default[3,3])
  expect_equal(R_custom[1,1], R_default[1,1])  # Canonical unchanged
  expect_equal(R_custom[2,2], R_default[2,2])  # Temporal derivative unchanged
})

# Test edge cases ----

test_that("penalty_matrix handles small basis sets gracefully", {
  # Save original nbasis function
  original_nbasis <- getFromNamespace("nbasis.HRF", "fmrireg")
  
  # Test with 1 basis function
  mock_hrf_1 <- HRF_SPMG1
  attr(mock_hrf_1, "name") <- "fir"
  
  # Mock nbasis to return 1
  mock_nbasis_1 <- function(x, ...) 1L
  assignInNamespace("nbasis.HRF", mock_nbasis_1, "fmrireg")
  
  R <- penalty_matrix(mock_hrf_1)
  expect_equal(dim(R), c(1, 1))
  expect_equal(R[1,1], 1)
  
  # Test with 2 basis functions for second-order differences
  mock_hrf_2 <- HRF_SPMG1
  attr(mock_hrf_2, "name") <- "fir"
  
  # Mock nbasis to return 2
  mock_nbasis_2 <- function(x, ...) 2L
  assignInNamespace("nbasis.HRF", mock_nbasis_2, "fmrireg")
  
  # Should fall back to identity for second-order with only 2 basis functions
  R <- penalty_matrix(mock_hrf_2, order = 2)
  expect_equal(R, diag(2))
  
  # Restore original function
  assignInNamespace("nbasis.HRF", original_nbasis, "fmrireg")
})

test_that("penalty_matrix handles unknown HRF types", {
  # Create a mock HRF with unknown name
  mock_hrf <- HRF_SPMG1
  attr(mock_hrf, "name") <- "unknown_type"
  
  R <- penalty_matrix(mock_hrf)
  
  # Should fall back to identity matrix
  expect_equal(R, diag(nbasis(mock_hrf)))
})

test_that("penalty_matrix handles HRF without name attribute", {
  # Create a mock HRF without name
  mock_hrf <- HRF_SPMG1
  attr(mock_hrf, "name") <- NULL
  
  R <- penalty_matrix(mock_hrf)
  
  # Should fall back to identity matrix
  expect_equal(R, diag(nbasis(mock_hrf)))
})

test_that("penalty_matrix validates order parameter", {
  # Test that invalid order values throw errors
  expect_error(penalty_matrix(HRF_FIR, order = 3))
  expect_error(penalty_matrix(HRF_FIR, order = 0))
  expect_error(penalty_matrix(HRF_FIR, order = -1))
  
  # Test that valid orders work
  expect_no_error(penalty_matrix(HRF_FIR, order = 1))
  expect_no_error(penalty_matrix(HRF_FIR, order = 2))
})

# Test mathematical properties ----

test_that("penalty matrices are positive semi-definite", {
  hrfs <- list(
    HRF_SPMG1, HRF_SPMG2, HRF_SPMG3,
    HRF_FIR, HRF_BSPLINE
  )
  
  for (hrf in hrfs) {
    R <- penalty_matrix(hrf)
    eigenvals <- eigen(R, only.values = TRUE)$values
    expect_true(all(eigenvals >= -1e-10), 
                info = paste("HRF:", attr(hrf, "name")))
  }
})

test_that("penalty matrices are symmetric", {
  hrfs <- list(
    HRF_SPMG1, HRF_SPMG2, HRF_SPMG3,
    HRF_FIR, HRF_BSPLINE
  )
  
  for (hrf in hrfs) {
    R <- penalty_matrix(hrf)
    expect_true(isSymmetric(R), 
                info = paste("HRF:", attr(hrf, "name")))
  }
})

test_that("penalty matrices have correct dimensions", {
  hrfs <- list(
    HRF_SPMG1, HRF_SPMG2, HRF_SPMG3,
    HRF_FIR, HRF_BSPLINE
  )
  
  for (hrf in hrfs) {
    R <- penalty_matrix(hrf)
    d <- nbasis(hrf)
    expect_equal(dim(R), c(d, d), 
                info = paste("HRF:", attr(hrf, "name")))
  }
})

# Test integration with other functions ----

test_that("penalty_matrix works with hrfspec objects", {
  # Test that the method exists in the methods list
  methods_list <- methods("penalty_matrix")
  expect_true("penalty_matrix.hrfspec" %in% methods_list)
})

# Test specific penalty structures ----

test_that("FIR penalty matrix has expected structure", {
  # Create a simple FIR-like HRF for testing
  mock_fir <- HRF_FIR
  
  R <- penalty_matrix(mock_fir, order = 2, scale = FALSE)
  d <- nbasis(mock_fir)
  
  # Should be banded with specific pattern
  # Main diagonal should be positive
  expect_true(all(diag(R) > 0))
  
  # Should have the characteristic pattern of D^T D where D is second difference
  # For second differences: main diagonal has 1, 5, 6, 6, ..., 6, 5, 1
  # Off-diagonals have specific patterns
  if (d >= 3) {
    # Check that it has the right sparsity pattern
    expect_true(all(R[abs(row(R) - col(R)) > 2] == 0))
  }
})

test_that("SPMG penalty matrices have diagonal structure", {
  # Test SPMG2
  R2 <- penalty_matrix(HRF_SPMG2, shrink_deriv = 4)
  expect_true(all(R2[row(R2) != col(R2)] == 0))  # Off-diagonal zeros
  expect_equal(R2[1,1], 1)
  expect_equal(R2[2,2], 4)
  
  # Test SPMG3 - verify it works with custom parameters
  R3 <- penalty_matrix(HRF_SPMG3, shrink_deriv = 4, shrink_disp = 6)
  expect_equal(dim(R3), c(3, 3))  # Should be 3x3
  expect_true(all(R3[row(R3) != col(R3)] == 0))  # Off-diagonal zeros
  expect_equal(R3[1,1], 1)
  expect_equal(R3[2,2], 4)
  expect_equal(R3[3,3], 6)
  
  # Test SPMG3 with default parameters (shrink_disp = shrink_deriv)
  R3_default <- penalty_matrix(HRF_SPMG3, shrink_deriv = 4)
  expect_equal(dim(R3_default), c(3, 3))
  expect_equal(R3_default[1,1], 1)
  expect_equal(R3_default[2,2], 4)
  expect_equal(R3_default[3,3], 4)  # Should equal shrink_deriv when shrink_disp is NULL
})

# Test name-based dispatch ----

test_that("name-based dispatch works correctly", {
  # Test different name variations
  test_names <- list(
    c("fir", "FIR"),
    c("bspline", "BSPLINE", "bs", "BS"),
    c("spmg1", "SPMG1", "spmg2", "SPMG2"),
    c("fourier", "FOURIER", "cosine", "COSINE")
  )
  
  for (names_group in test_names) {
    # Create mock HRFs with different name cases
    for (name in names_group) {
      mock_hrf <- HRF_SPMG1
      attr(mock_hrf, "name") <- name
      
      # Should not error
      R <- penalty_matrix(mock_hrf)
      expect_true(is.matrix(R))
      expect_true(isSymmetric(R))
    }
  }
})
</file>

<file path="tests/testthat/test_thread_option.R">
context("Thread configuration")

test_that(".onLoad sets thread count from option", {
  testthat::local_edition(3)
  skip_if_not_installed("RcppParallel")
  old_threads <- RcppParallel::defaultNumThreads()
  old_opt <- getOption("fmrireg.num_threads")
  on.exit({
    options(fmrireg.num_threads = old_opt)
    RcppParallel::setThreadOptions(numThreads = old_threads)
  })

  options(fmrireg.num_threads = 2)
  fmrireg::.onLoad(NULL, NULL)
  expect_equal(RcppParallel::defaultNumThreads(), 2)
})

 test_that(".onLoad sets thread count from env var", {
   skip_if_not_installed("RcppParallel")
   old_threads <- RcppParallel::defaultNumThreads()
   old_env <- Sys.getenv("FMRIREG_NUM_THREADS", unset = NA)
   on.exit({
     if (is.na(old_env)) Sys.unsetenv("FMRIREG_NUM_THREADS") else Sys.setenv(FMRIREG_NUM_THREADS = old_env)
     RcppParallel::setThreadOptions(numThreads = old_threads)
   })

   Sys.setenv(FMRIREG_NUM_THREADS = 3)
   options(fmrireg.num_threads = NULL)
   fmrireg::.onLoad(NULL, NULL)
   expect_equal(RcppParallel::defaultNumThreads(), 3)
 })
</file>

<file path="tests/testthat/test-regressor.R">
# Test suite for Regressor functionality

library(testthat)
library(fmrireg)
library(ggplot2)

# Helper to get default HRF span safely
get_default_hrf_span <- function(hrf = HRF_SPMG1) {
  attr(hrf, "span") %||% 24 # Use 24 as a fallback
}

# === Test Core Reg Constructor (Tickets A-1, B-1, B-2, B-3) ===

test_that("Reg constructor creates object with correct class and structure", {
  ons <- c(10, 20, 30)
  reg <- fmrireg:::Reg(onsets = ons)
  expect_s3_class(reg, "Reg")
  expect_s3_class(reg, "list")
  expect_named(reg, c("onsets", "duration", "amplitude", "hrf", "span", "summate"))
  expect_equal(reg$onsets, ons)
  expect_true(inherits(reg$hrf, "HRF"))
  expect_equal(reg$duration, rep(0, 3))
  expect_equal(reg$amplitude, rep(1, 3))
  expect_true(is.numeric(reg$span))
  expect_true(is.logical(reg$summate))
})

test_that("Reg constructor recycles scalar duration and amplitude", {
  ons <- c(10, 20, 30)
  reg <- fmrireg:::Reg(onsets = ons, duration = 2, amplitude = 5)
  expect_equal(reg$duration, rep(2, 3))
  expect_equal(reg$amplitude, rep(5, 3))
})

test_that("Reg constructor handles vector duration and amplitude", {
  ons <- c(10, 20, 30)
  dur <- c(1, 2, 3)
  amp <- c(4, 5, 6)
  reg <- fmrireg:::Reg(onsets = ons, duration = dur, amplitude = amp)
  expect_equal(reg$duration, dur)
  expect_equal(reg$amplitude, amp)
})

test_that("Reg constructor errors on mismatched vector lengths", {
  ons <- c(10, 20, 30)
  # Use regexp to match the error structure flexibly
  expect_error(fmrireg:::Reg(onsets = ons, duration = c(1, 2)), 
               regexp = "`duration` must be length 1 or 3 \\(got 2\\)")
  expect_error(fmrireg:::Reg(onsets = ons, amplitude = c(1, 2)), 
               regexp = "`amplitude` must be length 1 or 3 \\(got 2\\)")
})

test_that("Reg constructor filters zero and NA amplitudes (B-3)", {
  ons <- c(10, 20, 30, 40, 50)
  amp <- c(1, 0, 2, NA, 3)
  dur <- c(1, 2, 3, 4, 5) # Provide vector to check filtering alignment
  
  reg <- fmrireg:::Reg(onsets = ons, amplitude = amp, duration = dur)
  
  expect_equal(reg$onsets, c(10, 30, 50))
  expect_equal(reg$amplitude, c(1, 2, 3))
  expect_equal(reg$duration, c(1, 3, 5))
})

test_that("Reg constructor handles all-zero/NA amplitudes", {
  ons <- c(10, 20, 30)
  amp <- c(0, NA, 0)
  reg <- regressor(onsets = ons, amplitude = amp)

  expect_equal(length(reg$onsets), 0)
  expect_equal(length(reg$duration), 0)
  expect_equal(length(reg$amplitude), 0)
})

test_that("Reg constructor handles empty onsets", {
  reg <- fmrireg:::Reg(numeric(0))
  
  expect_true(inherits(reg, "Reg"))
  expect_equal(length(reg$onsets), 0)
  expect_equal(length(reg$duration), 0) 
  expect_equal(length(reg$amplitude), 0)
})

test_that("Reg constructor handles NA onset (for null_regressor case)", {
   # Should not warn for the explicit NA case, should produce empty fields
   expect_warning(reg <- fmrireg:::Reg(onsets = NA, amplitude=0), regexp = NA) 
   expect_equal(length(reg$onsets), 0)
   expect_equal(length(reg$duration), 0)
   expect_equal(length(reg$amplitude), 0)
})

# === Test shift.Reg (Ticket B-4) ===

test_that("shift.Reg shifts onsets correctly", {
  ons <- c(10, 20, 30)
  reg_orig <- fmrireg:::Reg(onsets = ons)
  
  reg_plus5 <- shift(reg_orig, 5)
  expect_s3_class(reg_plus5, "Reg")
  expect_equal(reg_plus5$onsets, c(15, 25, 35))
  expect_equal(reg_plus5$hrf, reg_orig$hrf) # Other fields remain the same
  
  reg_minus3 <- shift(reg_orig, -3)
  expect_s3_class(reg_minus3, "Reg")
  expect_equal(reg_minus3$onsets, c(7, 17, 27))
  
  reg_zero <- shift(reg_orig, 0)
  expect_equal(reg_zero$onsets, reg_orig$onsets)
})

test_that("shift.Reg preserves original class structure", {
  ons <- c(10, 20, 30)
  # Create using the public wrapper to get 'regressor' class
  reg_orig_pub <- regressor(onsets = ons)
  expect_true(inherits(reg_orig_pub, "Reg"))
  
  reg_shifted <- shift(reg_orig_pub, 5)
  expect_true(inherits(reg_shifted, "Reg"))
  expect_equal(class(reg_shifted), class(reg_orig_pub))
})

test_that("shift.Reg handles empty regressors", {
  reg_empty1 <- fmrireg:::Reg(numeric(0))
  reg_empty2 <- fmrireg:::Reg(c(10, 20), amplitude = 0)
  
  expect_warning(shift(reg_empty1, 5), regexp = NA) # No warning expected
  expect_equal(length(shift(reg_empty1, 5)$onsets), 0)
  
  expect_warning(shift(reg_empty2, 5), regexp = NA)
  expect_equal(length(shift(reg_empty2, 5)$onsets), 0)
})

# === Test Legacy Wrappers (Ticket A-2') ===

test_that("regressor() facade works", {
  ons <- c(10, 20, 30)
  reg_pub <- regressor(onsets = ons, amplitude = 2)
  expect_true(inherits(reg_pub, "Reg"))
  expect_equal(reg_pub$amplitude, c(2, 2, 2)) # Check args passed through
})


# === Test evaluate.Reg (Tickets C-1, C-4) ===

# More evaluate tests needed, especially parity tests (F-3)

test_that("evaluate.Reg basic loop execution", {
    ons <- c(10, 30, 50)
    reg <- regressor(ons, HRF_SPMG1)
    grid <- seq(0, 70, by=2)
    
    # Currently only testing loop method works without error
    expect_no_error(val_loop <- evaluate(reg, grid, method="loop"))
    expect_true(is.numeric(val_loop))
    expect_equal(length(val_loop), length(grid))
    
    # Test multi-basis HRF
    reg_multi <- regressor(ons, HRF_SPMG3)
    expect_no_error(val_multi_loop <- evaluate(reg_multi, grid, method="loop"))
    expect_true(is.matrix(val_multi_loop))
    expect_equal(nrow(val_multi_loop), length(grid))
    expect_equal(ncol(val_multi_loop), 3)
})

test_that("evaluate.Reg handles empty regressor", {
    reg_empty <- fmrireg:::Reg(numeric(0))
    grid <- seq(0, 50, by=1)
    res <- evaluate(reg_empty, grid)
    expect_true(is.matrix(res))
    expect_equal(dim(res), c(length(grid), 1)) # Should default to nbasis=1
    expect_true(all(res == 0))
    
    # Empty with multi-basis hrf
    reg_empty_multi <- fmrireg:::Reg(numeric(0), hrf=HRF_SPMG3)
    res_multi <- evaluate(reg_empty_multi, grid)
    expect_true(is.matrix(res_multi))
    expect_equal(dim(res_multi), c(length(grid), 3))
    expect_true(all(res_multi == 0))
})

# === Test Evaluation Parity (Ticket F-3) ===

test_that("evaluate.Reg methods (loop, fft, conv) give consistent results", {
  ons <- c(10, 30, 50)
  grid <- seq(0, 70, by=2)
  
  # Scenario 1: Simple SPMG1
  reg_spmg1 <- regressor(ons, HRF_SPMG1)
  
  val_loop <- evaluate(reg_spmg1, grid, method = "loop")
  val_fft  <- evaluate(reg_spmg1, grid, method = "fft")
  val_conv <- evaluate(reg_spmg1, grid, method = "conv")
  
  expect_equal(val_fft, val_loop, tolerance = .1, info = "SPMG1: FFT vs Loop")
  expect_equal(val_conv, val_loop, tolerance = .1, info = "SPMG1: Conv vs Loop")

  # Scenario 2: Multi-basis SPMG3
  reg_spmg3 <- regressor(ons, HRF_SPMG3)
  
  val_multi_loop <- evaluate(reg_spmg3, grid, method = "loop")
  val_multi_fft  <- evaluate(reg_spmg3, grid, method = "fft")
  val_multi_conv <- evaluate(reg_spmg3, grid, method = "conv")
  
  expect_equal(val_multi_fft, val_multi_loop, tolerance = .1, info = "SPMG3: FFT vs Loop")
  expect_equal(val_multi_conv, val_multi_loop, tolerance = .1, info = "SPMG3: Conv vs Loop")

  # Scenario 3: With duration 
  reg_dur <- regressor(ons, HRF_SPMG1, duration = 5)
  
  val_dur_loop <- evaluate(reg_dur, grid, method = "loop")
  val_dur_fft  <- evaluate(reg_dur, grid, method = "fft")
  val_dur_conv <- evaluate(reg_dur, grid, method = "conv")
  
  # Tolerance might need adjustment depending on precision differences
  expect_equal(val_dur_fft, val_dur_loop, tolerance = .1, info = "Duration: FFT vs Loop")
  expect_equal(val_dur_conv, val_dur_loop, tolerance = .1, info = "Duration: Conv vs Loop")
  
  # Scenario 4: With amplitude modulation
  reg_amp <- regressor(ons, HRF_SPMG1, amplitude = c(1, -0.5, 2))
  
  val_amp_loop <- evaluate(reg_amp, grid, method = "loop")
  val_amp_fft  <- evaluate(reg_amp, grid, method = "fft")
  val_amp_conv <- evaluate(reg_amp, grid, method = "conv")
  
  expect_equal(val_amp_fft, val_amp_loop, tolerance = .1, info = "Amplitude: FFT vs Loop")
  expect_equal(val_amp_conv, val_amp_loop, tolerance = .1, info = "Amplitude: Conv vs Loop")
  
  # Note: More scenarios (Rconv, edge cases, sparse) still needed for full F-3 completion
})

# === Test Plotting & Printing (Tickets E-1, E-2) ===

test_that("print.Reg runs without error", {
  reg <- regressor(c(10, 20))
  expect_no_error(print(reg))
  
  reg_empty <- fmrireg:::Reg(numeric(0))
  expect_no_error(print(reg_empty))
})

test_that("autoplot.Reg runs without error", {
  skip_if_not_installed("ggplot2")
  reg <- regressor(c(10, 20))
  expect_s3_class(autoplot(reg), "ggplot")
  
  reg_multi <- regressor(c(10, 20), hrf=HRF_SPMG3)
  expect_s3_class(autoplot(reg_multi), "ggplot")
  
  reg_empty <- fmrireg:::Reg(numeric(0))
  expect_s3_class(autoplot(reg_empty), "ggplot")
})

test_that("generate an event model with one observation per level", {
  sframe <- sampling_frame(blocklens=rep(401,5), TR=1.5)
  lopdes$onset <- lopdes$WordPresentationOnset/1000
  lopdes$Target <- factor(lopdes$Target)
  # Suppress warnings specifically for this call, as empty cells might trigger them
  expect_warning(ev <- event_model(onset ~ hrf(Target), data=lopdes, block= ~ Run, sampling_frame=sframe),
                 regexp = NA) # Expect warnings, but don't fail test if they occur
  expect_true(!is.null(ev))
})

test_that("evaluate.Reg errors when FFT size would be huge", {
  reg <- regressor(onsets = 0, hrf = HRF_SPMG1)
  grid <- seq(0, 1, by = 1)
  expect_error(
    evaluate(reg, grid, precision = 1e-6, method = "fft"),
    regexp = "FFT size"
  )
})
</file>

<file path="R/autoplot-methods.R">
#' Autoplot method for Reg objects
#' 
#' Creates a ggplot visualization of an fMRI regressor object.
#' 
#' @param object A `Reg` object (or one inheriting from it, like `regressor`).
#' @param grid Optional numeric vector specifying time points (seconds) for evaluation. 
#'   If NULL, a default grid is generated based on the object's onsets and span.
#' @param precision Numeric precision for HRF evaluation if `grid` needs generation or 
#'   if internal evaluation requires it (passed to `evaluate`).
#' @param method Evaluation method passed to `evaluate`.
#' @param ... Additional arguments (currently unused).
#' 
#' @return A ggplot object.
#' 
#' @importFrom ggplot2 ggplot aes geom_line facet_wrap labs theme_minimal autoplot
#' @importFrom tidyr pivot_longer
#' @importFrom dplyr mutate across where
#' @export
#' @method autoplot Reg
#' @rdname autoplot
autoplot.Reg <- function(object, grid = NULL, precision = 0.1, method = "conv", ...) {
  
  # Determine evaluation grid if not provided
  if (is.null(grid)) {
    if (length(onsets(object)) > 0) {
        min_onset <- min(onsets(object), na.rm = TRUE)
        max_onset <- max(onsets(object), na.rm = TRUE)
        # Extend grid by HRF span, ensure start isn't negative if possible
        grid_start <- max(0, min_onset - 5) 
        grid_end <- max_onset + attr(object$hrf, "span") + 5
        # Use a reasonable step based on span or default to precision
        grid_step <- min(precision, attr(object$hrf, "span") / 100, 0.5) 
        grid <- seq(grid_start, grid_end, by = grid_step)
    } else {
        # Default grid if no onsets (e.g., null regressor)
        grid <- seq(0, (attr(object$hrf, "span") %||% 24), by = precision)
    }
  }
  
  # Evaluate the regressor
  eval_data <- evaluate(object, grid, precision = precision, method = method)
  nb <- nbasis(object)
  
  # Prepare data frame for plotting
  if (nb == 1) {
    plot_df <- data.frame(Time = grid, Response = as.vector(eval_data))
    p <- ggplot(plot_df, aes(x = .data$Time, y = .data$Response)) +
         geom_line() +
         labs(title = paste("Regressor:", attr(object$hrf, "name") %||% "Custom"), 
              x = "Time (seconds)", y = "Amplitude")
  } else {
    colnames(eval_data) <- paste0("Basis_", 1:nb)
    plot_df <- as.data.frame(eval_data)
    plot_df$Time <- grid
    
    plot_df_long <- plot_df |>
      tidyr::pivot_longer(cols = starts_with("Basis_"), 
                          names_to = "Basis", 
                          values_to = "Response")
                          
    p <- ggplot(plot_df_long, aes(x = .data$Time, y = .data$Response)) +
         geom_line() +
         facet_wrap(~ .data$Basis) +
         labs(title = paste("Regressor:", attr(object$hrf, "name") %||% "Custom", "(Multi-basis)"),
              x = "Time (seconds)", y = "Amplitude")
  }
  
  p + theme_minimal()
} 




#' Internal helper to build a correlation heatmap from a numeric matrix
#'
#' @param DM A numeric matrix of regressors (columns).
#' @param method Correlation method, passed to `stats::cor()` (e.g. "pearson" or "spearman").
#' @param half_matrix Logical; if TRUE, show only the lower-triangle (including diagonal).
#' @param absolute_limits Logical; if TRUE, force the fill color scale to -1..+1.
#' @param ... Additional arguments passed to `geom_tile()`.
#'
#' @return A ggplot2 object.
#' @keywords internal
#' @noRd
.correlation_map_common <- function(DM,
                                    method         = c("pearson", "spearman"),
                                    half_matrix    = FALSE,
                                    absolute_limits = TRUE,
                                    ...) {
  method <- match.arg(method)
  stopifnot(is.matrix(DM), ncol(DM) >= 2)  # must have at least 2 columns to correlate
  
  # 1) Compute correlation matrix
  cormat <- stats::cor(DM, use = "pairwise.complete.obs", method = method)
  
  # 2) Optionally mask to show only the lower triangle.
  #    (Below we keep the diagonal, so i >= j.)
  if (half_matrix) {
    cormat[upper.tri(cormat)] <- NA  # set upper triangle to NA
  }
  
  # 3) Convert to a long data frame:
  #    row var becomes `Var1`, column var -> `Var2`, correlation -> `value`
  #    We remove any rows with NA if half_matrix=TRUE
  df_long <- as.data.frame(as.table(cormat), stringsAsFactors = FALSE)
  names(df_long) <- c("Var1", "Var2", "Correlation")
  if (half_matrix) {
    df_long <- df_long[!is.na(df_long$Correlation), ]
  }
  
  # Ensure factor ordering matches the original column order
  varnames <- colnames(DM)
  df_long$Var1 <- factor(df_long$Var1, levels = varnames)
  df_long$Var2 <- factor(df_long$Var2, levels = varnames)
  
  # 4) Base ggplot
  plt <- ggplot2::ggplot(df_long, 
                         ggplot2::aes(x = Var2, y = Var1, fill = Correlation)) +
    ggplot2::geom_tile(...)
  
  # Flip the y-axis so the first row is at the top (like many correlation-lower-triangle plots)
  plt <- plt + ggplot2::scale_y_discrete(limits = rev(levels(df_long$Var1)))
  
  # 5) Decide color-scale limits
  fillmin <- if (absolute_limits) -1 else min(df_long$Correlation, na.rm=TRUE)
  fillmax <- if (absolute_limits)  1 else max(df_long$Correlation, na.rm=TRUE)
  
  plt <- plt + 
    ggplot2::scale_fill_gradient2(
      limits   = c(fillmin, fillmax),
      midpoint = 0,
      low  = "blue",
      mid  = "white",
      high = "red"
    )
  
  # 6) Theming
  plt <- plt + 
    ggplot2::theme_minimal(base_size = 14) +
    ggplot2::theme(
      axis.title  = ggplot2::element_blank(),
      axis.ticks  = ggplot2::element_blank(),
      panel.grid  = ggplot2::element_blank(),
      axis.text.x = ggplot2::element_text(angle = 45, hjust = 1)
    )
  
  plt
}
</file>

<file path="R/bootstrap.R">
#' Multiresponse bootstrap linear model
#'
#' @description
#' Performs block bootstrap resampling for multiresponse linear models, particularly
#' useful for fMRI time series data where temporal dependencies exist. The function
#' implements a block bootstrap approach to maintain the temporal correlation structure
#' within the data.
#'
#' @details
#' The function performs the following steps:
#' 1. Fits the original linear model
#' 2. Implements block bootstrap resampling of residuals
#' 3. Reconstructs response variables using fitted values and resampled residuals
#' 4. Computes contrasts for each bootstrap sample
#'
#' The block bootstrap approach helps preserve temporal dependencies in the data by
#' resampling blocks of consecutive observations rather than individual observations.
#'
#' @param form Formula for the linear model. Required if modmat is NULL.
#' @param data_env Environment containing the data for the linear model.
#' @param conlist List of contrasts to be computed for each bootstrap sample.
#' @param vnames Vector of variable names.
#' @param fcon Contrasts for fixed effects.
#' @param modmat Optional pre-computed model matrix. If provided, form is ignored.
#' @param block_size Size of the blocks for the bootstrap (default: 30).
#'        Should be large enough to capture temporal dependencies but small enough
#'        to allow sufficient randomization.
#' @param boot_rows Logical flag indicating whether to bootstrap rows (default: FALSE).
#' @param nboot Number of bootstrap iterations (default: 100).
#' @param event_indices Indices of events for computing beta covariances.
#'
#' @return A list containing:
#' \itemize{
#'   \item original: The fitted original model with contrasts
#'   \item con_cov: Covariance matrices for contrasts (if contrasts provided)
#'   \item beta_cov: Covariance matrices for beta estimates
#'   \item nboot: Number of bootstrap iterations performed
#'   \item bootstrap: Logical indicating this is a bootstrap result
#' }
#'
#' @examples
#' \donttest{
#' # Simple example with synthetic data
#' X <- model.matrix(~ x1 + x2, data = data.frame(x1 = rnorm(100), x2 = rnorm(100)))
#' y <- matrix(rnorm(100 * 3), 100, 3)  # 3 response variables
#' result <- multiresponse_bootstrap_lm(modmat = X, data_env = list(.y = y),
#'                                     nboot = 100, block_size = 20)
#' }
#' @keywords internal
#' @importFrom foreach foreach %dopar%
multiresponse_bootstrap_lm <- function(form, data_env, 
                                     conlist, 
                                     vnames, 
                                     fcon, modmat=NULL, 
                                     block_size=30,
                                     boot_rows=FALSE,
                                     nboot=100,
                                     event_indices) {
  
  # Input validation
  if (is.null(modmat) && missing(form)) {
    stop("Either 'form' or 'modmat' must be provided")
  }
  
  if (!is.numeric(block_size) || block_size < 1) {
    stop("block_size must be a positive integer")
  }
  
  if (!is.numeric(nboot) || nboot < 1) {
    stop("nboot must be a positive integer")
  }
  
  if (!is.null(modmat)) {
    if (!inherits(modmat, "matrix")) {
      stop("modmat must be a matrix")
    }
    if (is.null(data_env$.y)) {
      stop("data_env$.y must contain response variables when using modmat")
    }
    if (nrow(modmat) != nrow(data_env$.y)) {
      stop("Number of rows in modmat must match number of rows in response variables")
    }
  }
  
  # Fit original model
  lm.orig <- if (is.null(modmat)) {
    lm(as.formula(form), data=data_env)
  } else {
    lm.fit(modmat, data_env$.y)
  }
  
  # Prepare for bootstrap
  yhat <- fitted(lm.orig)
  rows <- 1:nrow(yhat)
  nblocks <- as.integer(length(rows)/block_size)
  
  # Create blocks for resampling
  blocks <- split(rows, rep(1:nblocks, each=length(rows)/nblocks, length.out=length(rows)))
  maxind <- max(blocks[[length(blocks)]])
  if (maxind < nrow(yhat)) {
    last_block <- (maxind+1):nrow(yhat)
    blocks <- c(blocks, list(last_block))
  }
  
  # Perform bootstrap
  boot_res <- foreach(1:nboot) %dopar% {
    sam_blocks <- sample(1:length(blocks), replace=TRUE)
    samples <- unlist(blocks[sam_blocks])
    
    # Adjust sample size if necessary
    if (length(samples) > nrow(yhat)) {
      samples <- samples[1:nrow(yhat)]
    } else if (length(samples) < nrow(yhat)) {
      delta <- nrow(yhat) - length(samples) 
      samples <- c(samples, sample(rows, delta, replace=TRUE))
    }
    
    # Generate bootstrap sample
    rstar <- lm.orig$residuals[samples,]
    ynew <- yhat + rstar
    
    # Fit bootstrap model and compute contrasts
    lm.boot <- lm.fit(modmat, ynew)
    fit_lm_contrasts(lm.boot, conlist, fcon, vnames, se=FALSE) 
  }
  
  # Compute covariance matrices
  con_cov <- if (length(conlist) > 0) {
    lapply(names(boot_res[[1]]$conres), function(bname) {
      bm <- do.call(rbind, lapply(boot_res, function(br) {
        br$conres[[bname]]$estimate
      }))
      cov(bm)
    })
  }
  
  beta_cov <- lapply(event_indices, function(i) {
    bm <- do.call(rbind, lapply(boot_res, function(br) {
      br$bstats$estimate
    }))
    cov(bm)
  })
  
  # Return results
  orig <- fit_lm_contrasts(lm.orig, conlist, fcon, vnames) %>%
    purrr::list_modify(
      con_cov = con_cov,
      beta_cov = beta_cov,
      nboot = nboot,
      bootstrap = TRUE
    )

  orig
}
</file>

<file path="R/covariate.R">
#' @keywords internal
#' @noRd
parse_term <- function(vars, ttype) {
  nvars <- length(vars) # number of variables

  term <- vapply(vars, function(v) {
    parsed <- deparse(v, backtick = TRUE)
    attr(terms(reformulate(parsed)), "term.labels")
  }, character(1))

  label <- sprintf("%s(%s)", ttype, paste(term, collapse = ","))

  list(term = term, label = label)
}

#' Construct a Covariate Term
#'
#' @description
#' Creates a covariate term that is added directly to the fMRI model without being convolved 
#' with a hemodynamic response function (HRF). This is useful for including nuisance variables, 
#' continuous covariates, or any other regressors that should not undergo HRF convolution.
#'
#' @details
#' In fMRI analysis, some predictors should not be convolved with the HRF because they 
#' represent:
#' * Continuous physiological measurements (e.g., heart rate, respiration)
#' * Motion parameters from head movement correction
#' * Scanner drift or other technical artifacts
#' * Behavioral measures that directly correlate with BOLD signal
#' * Global signal or other nuisance variables
#'
#' The covariate term can be combined with standard HRF-convolved event terms in the 
#' same model. For example:
#' ```r
#' model <- event_model(signal ~ hrf(stimulus) + covariate(motion_x, motion_y), 
#'                     data = data)
#' ```
#'
#' @param ... A variable argument set of covariate names.
#' @param data A data.frame containing the variables.
#' @param id An optional identifier for the covariate term.
#' @param prefix An optional prefix to add to the covariate names.
#' @param subset Optional expression used to subset the covariate data.
#'
#' @return A list containing information about the covariate term with class 
#' 'covariatespec' that can be used within an event_model.
#'
#' @examples
#' # Add motion parameters as covariates
#' motion_data <- data.frame(
#'   x = rnorm(100),  # x translation
#'   y = rnorm(100)   # y translation
#' )
#' cv <- covariate(x, y, data = motion_data, prefix = "motion")
#'
#' # Combine with event model
#' sframe <- sampling_frame(blocklens = c(100), TR = 2)
#' event_data <- data.frame(
#'   stimulus = factor(rep(c("A", "B"), 50)),
#'   onset = seq(0, 198, by = 4)
#' )
#' 
#' # Full model with both HRF-convolved events and non-convolved covariates
#' model <- event_model(
#'   signal ~ hrf(stimulus) + covariate(x, y),
#'   data = event_data,
#'   sampling_frame = sframe
#' )
#' 
#' @seealso 
#' * [event_model()] for creating complete fMRI models
#' * [hrf()] for creating HRF-convolved event terms
#'
#' @export
covariate <- function(..., data, id=NULL, prefix=NULL, subset=NULL) {
  vars <- as.list(substitute(list(...)))[-1] 
  parsed <- parse_term(vars, "covariate")
  term <- parsed$term
  label <- parsed$label
  
  varnames <- if (!is.null(prefix)) {
    paste0(prefix, "_", term)
  } else {
    term
  }
  
  termname <- paste0(varnames, collapse="::")
  
  if (is.null(id)) {
    id <- termname
  }  

  ret <- list(
    data=data,
    name=termname, ## covariate(x,y), where termname = "x::y"
    id=id, ## covariate(x), id by default is "x::y"
    varnames=varnames, ## list of all variables (e.g. list(x,y))
    vars=term, ## list of unparsed vars
    label=label, ## "covariate(x)" the full expression
    subset=rlang::enexpr(subset))
  
  class(ret) <- c("covariatespec", "hrfspec", "list")
  ret
}

#' @keywords internal
#' @noRd
covariate_term <- function(varname, mat) {
  stopifnot(is.matrix(mat))
  ret <- list(varname=varname, design_matrix=suppressMessages(tibble::as_tibble(mat)))
  class(ret) <- c("covariate_term", "matrix_term", "fmri_term", "list")
  ret
}

#' @export
construct.covariatespec <- function(x, model_spec, sampling_frame=NULL, ...) {
  mat <- do.call(cbind, lapply(x$vars, function(v) {
    expr <- rlang::parse_expr(v)
    rlang::eval_tidy(expr, data = x$data)
  }))
  
  colnames(mat) <- x$varnames

  cterm <- covariate_term(x$name, mat)

  sframe <- if (is.null(sampling_frame)) {
    model_spec$sampling_frame
  } else {
    sampling_frame
  }

  ## Validate that the covariate matrix matches the sampling frame length
  expected_rows <- sum(sframe$blocklens)
  if (nrow(mat) != expected_rows) {
    stop(sprintf(
      "Covariate term '%s' has %d rows but sampling_frame expects %d",
      x$name, nrow(mat), expected_rows
    ), call. = FALSE)
  }

  ret <- list(
    varname=x$name,
    spec=x,
    evterm=cterm,
    design_matrix=cterm$design_matrix,
    sampling_frame=sframe,
    id=if(!is.null(x$id)) x$id else x$varname
  )
  
  class(ret) <- c("covariate_convolved_term", "convolved_term", "fmri_term", "list") 
  ret
}

#' @export
event_table.covariate_convolved_term <- function(x) {
  cnames <- colnames(x$design_matrix)
  ret <- do.call(cbind, lapply(cnames, function(tname) {
    rep(.sanitizeName(tname), nrow(x$design_matrix))
  }))
  
  colnames(ret) <- cnames
  suppressMessages(tibble::as_tibble(ret,.name_repair="check_unique"))
  
}

#' @rdname nbasis
#' @export
nbasis.covariate_convolved_term <- function(x,...) {
  ncol(x$design_matrix)
}
</file>

<file path="R/event_model_helpers.R">
# Internal Helper Functions for Event Model Construction

#' @importFrom tibble tibble
#' @importFrom rlang is_formula f_rhs f_lhs f_env eval_tidy syms sym is_list is_call call_name call_args %||% empty_env %||% is_expression as_label expr quo_get_expr env_bury
#' @import assertthat
#' @importFrom purrr map map_dfr
#' @importFrom cli cli_progress_bar cli_progress_update cli_progress_done
#' @importFrom stats setNames approxfun quantile dnorm dgamma poly model.matrix terms reformulate
#' @importFrom utils head combn modifyList

# Helper to recursively find and evaluate hrf/trialwise calls in formula RHS
#' @keywords internal
#' @noRd
find_and_eval_hrf_calls <- function(expr, data, f_env) {
  
  if (rlang::is_call(expr)) {
    fun_name <- rlang::call_name(expr)
    
    # Base case: Found a target function call
    if (fun_name %in% c("hrf", "trialwise", "afni_hrf", "afni_trialwise", "covariate")) {
      # Evaluate the call in the formula env, using data as a mask
      eval_env <- rlang::env_bury(f_env %||% rlang::empty_env(), !!!data)
      evaluated_spec <- try(rlang::eval_tidy(expr, env = eval_env), silent = TRUE)
      
      if (inherits(evaluated_spec, "try-error")) {
          stop(sprintf("Failed to evaluate term '%s': %s", 
                       rlang::as_label(expr), attr(evaluated_spec, "condition")$message), call. = FALSE)
      }
      if (!inherits(evaluated_spec, "hrfspec")) {
          stop(sprintf("Term '%s' did not evaluate to an 'hrfspec' object (result class: %s)",
                       rlang::as_label(expr), class(evaluated_spec)[1]), call. = FALSE)
      }
      return(list(evaluated_spec))
    }
    
    # Recursive case: Traverse arguments of other calls (like + or *)
    # Collect results from each argument and concatenate while preserving
    # list structure (so each hrfspec remains intact)
    results_list <- lapply(rlang::call_args(expr), find_and_eval_hrf_calls, data, f_env)
    results <- do.call(c, results_list)
    return(results)
    
  } else {
    # Ignore symbols, constants, other non-calls that aren't target functions
    return(list())
  }
}


#' Parse fmri model formula (Internal Helper for EM-2)
#'
#' Takes a model formula (e.g., `onset ~ hrf(cond) + hrf(mod, basis="spmg3")`)
#' and extracts the onset variable, evaluates the `hrf()` calls on the RHS
#' to create `hrfspec` objects, and returns these components along with the
#' formula's environment.
#'
#' @param formula The model formula.
#' @param data The data frame providing context for evaluation.
#' @return A list containing: 
#'  `spec_tbl` (tibble with term_id, spec), 
#'  `onsets` (numeric vector), 
#'  `formula_env` (the formula environment).
#' @keywords internal
#' @noRd
parse_event_formula <- function(formula, data) {
  stopifnot(rlang::is_formula(formula))
  formula_env <- rlang::f_env(formula)
  
  # --- Extract and Evaluate LHS (Onsets) --- 
  lhs_expr <- rlang::f_lhs(formula)
  if (is.null(lhs_expr)) stop("Model formula must have a left-hand side (LHS) specifying the onset variable.", call.=FALSE)
  
  # Evaluate LHS in the data environment (masked)
  onsets <- try(rlang::eval_tidy(lhs_expr, data = data, env = formula_env %||% rlang::empty_env()), silent = TRUE)
  if (inherits(onsets, "try-error")) {
       stop(sprintf("Failed to evaluate onset variable '%s' from formula LHS: %s", 
                    rlang::as_label(lhs_expr), attr(onsets, "condition")$message), call. = FALSE)
  }
  if (!is.numeric(onsets)) {
       stop(sprintf("Onset variable '%s' extracted from formula LHS is not numeric (class: %s).", 
                    rlang::as_label(lhs_expr), class(onsets)[1]), call. = FALSE)
  }
  
  # --- Parse and Evaluate RHS (hrfspec terms) --- 
  rhs_expr <- rlang::f_rhs(formula)
  
  # Recursively find and evaluate hrfspec calls
  hrfspec_list <- find_and_eval_hrf_calls(rhs_expr, data, formula_env)
  
  if (length(hrfspec_list) == 0) {
      stop("No valid hrf(...) or similar terms found on the right-hand side of the formula.", call.=FALSE)
  }
  
  # Create the spec table
  spec_tbl <- tibble::tibble(
    term_id = seq_along(hrfspec_list),
    spec = hrfspec_list
  )
  
  # Return components
  list(
    spec_tbl = spec_tbl,
    onsets = onsets,
    formula_env = formula_env
  )
}

#' Construct an event_term object from an hrfspec (Internal Helper for EM-4)
#'
#' Takes a single hrf specification and the parsed model spec containing shared
#' timing info and evaluation context. Evaluates the variables/expressions 
#' in the hrfspec and calls the public `event_term` constructor.
#'
#' @param hrfspec An `hrfspec` object.
#' @param model_spec The list returned by `parse_event_model`.
#' @return An `event_term` object with the `hrfspec` attached as an attribute.
#' @keywords internal
#' @noRd
construct_event_term <- function(hrfspec, model_spec) {
  stopifnot(inherits(hrfspec, "hrfspec"))
  stopifnot(is.list(model_spec))
  
  vars_quos <- hrfspec$vars # List of quosures
  data_env <- model_spec$data
  f_env <- model_spec$formula_env %||% rlang::empty_env()
  
  # Create safe evaluation environment with onsets available for trialwise()
  eval_env <- rlang::env_bury(f_env, !!!data_env, onsets = model_spec$onsets)
  
  evaluated_vars <- list()
  var_names <- character(length(vars_quos))
  
  for (i in seq_along(vars_quos)) {
    quo <- vars_quos[[i]]
    expr <- rlang::quo_get_expr(quo)
    var_label <- rlang::as_label(expr)
    
    val <- try(rlang::eval_tidy(quo, data = data_env, env = eval_env), silent = TRUE)
    
    # Special handling for trialwise expressions - use eval() instead of eval_tidy()
    # This is needed because eval_tidy() doesn't properly handle the onsets variable
    # in the evaluation environment for expressions like .trial_factor(length(onsets))
    if (!inherits(val, 'try-error') && grepl("trial_factor", var_label)) {
      val <- try(eval(rlang::quo_get_expr(quo), envir = eval_env), silent = TRUE)
    }
    
    if (inherits(val, 'try-error')) {
        stop(sprintf("Failed to evaluate variable/expression '%s' for term '%s': %s", 
                     var_label, hrfspec$name %||% "UnnamedTerm", 
                     attr(val, "condition")$message), call. = FALSE)
    }
    
    # Store the evaluated value directly
    evaluated_vars[[i]] <- val
    
    # Determine the name to use for this variable within the event_term list
    # Use the basis object name if available, otherwise the label
    var_names[i] <- if (inherits(val, 'ParametricBasis') && !is.null(val$name)) {
      # Use the pre-defined name from the basis object (e.g., "z_RT", "poly_RT", "RT1_RT2")
      # This name might not be globally unique yet, but identifies the component
      val$name 
    } else {
      # Use the sanitized label for simple variables or basis without names
      make.names(var_label) 
    }
  }
  
  # Ensure unique names *within this specific term's evaluated variable list*
  # These names are internal to the event_term object and NOT the final design matrix colnames.
  names(evaluated_vars) <- make.unique(var_names)
  
  # Evaluate subset expression if present
  subset_result <- NULL
  if (!is.null(hrfspec$subset)) {
    subset_result <- try(rlang::eval_tidy(hrfspec$subset, data = data_env, env = eval_env), silent = TRUE)
    if (inherits(subset_result, 'try-error')) {
      stop(sprintf("Failed to evaluate subset expression for term '%s': %s", 
                   hrfspec$name %||% "UnnamedTerm", 
                   attr(subset_result, "condition")$message), call. = FALSE)
    }
    if (!is.logical(subset_result)) {
      stop(sprintf("Subset expression for term '%s' must evaluate to a logical vector, got: %s", 
                   hrfspec$name %||% "UnnamedTerm", class(subset_result)[1]), call. = FALSE)
    }
  }
  
  # Call the public event_term constructor
  et <- event_term(evlist = evaluated_vars, 
                   onsets = model_spec$onsets, 
                   blockids = model_spec$blockids, 
                   durations = model_spec$durations,
                   subset = subset_result)
                   
  attr(et, "hrfspec") <- hrfspec
  
  # TODO (EM-19): Add check here
  
  et
}

#' Build event model design matrix (Stage 3 of Pipeline)
#'
#' Takes the list of realised event terms, convolves each one, 
#' cbinds the results, and attaches term span/index attributes.
#'
#' @param terms A named list of `event_term` objects.
#' @param sampling_frame The fmri sampling_frame object.
#' @param precision Numeric precision for convolution.
#' @param parallel Logical indicating whether to use parallel processing (requires `future.apply`).
#' @return A tibble representing the full event model design matrix, with 
#'         `term_spans` and `col_indices` attributes.
#' @keywords internal
#' @noRd
build_event_model_design_matrix <- function(terms, sampling_frame, precision, parallel = FALSE) {

  if (length(terms) == 0) {
    warning("No terms provided to build design matrix.", call. = FALSE)
    return(tibble::tibble(.rows = sum(sampling_frame$blocklens)))
  }

  # Convolution function for a single term
  convolve_one_term <- function(term) {
      # Check if this is a covariate term (already "convolved" - no HRF needed)
      if (inherits(term, "covariate_convolved_term")) {
          # Covariate terms don't need convolution, just return their design matrix
          dm <- as.matrix(term$design_matrix)
          # Ensure proper column names
          if (is.null(colnames(dm))) {
              colnames(dm) <- paste0("cov_", seq_len(ncol(dm)))
          }
          return(dm)
      }
      
      # Check if this is already a convolved term (AFNI only now)
      if (inherits(term, "afni_hrf_convolved_term") || inherits(term, "afni_trialwise_convolved_term")) {
          # AFNI terms are already "convolved" and should return NULL
          # since they are meant to be handled by AFNI's 3dDeconvolve, not R's convolution
          warning("AFNI terms are not fully supported in the current event_model pipeline. ", 
                  "They are intended for use with AFNI's 3dDeconvolve.", call. = FALSE)
          # Return NULL to indicate this term should not contribute columns to the design matrix
          return(NULL)
      }
      
      # For regular event_term objects, check for hrfspec and convolve
      hrfspec <- attr(term, "hrfspec")
      if (is.null(hrfspec) || is.null(hrfspec$hrf)) {
          stop(sprintf("Cannot convolve term '%s': missing attached hrfspec or HRF object within spec.", 
                       attr(term, "term_tag") %||% term$varname %||% "Unnamed"), call. = FALSE)
      }
      
      # Regular convolution for event_term objects
      convolve.event_term(term, hrf = hrfspec$hrf, sampling_frame = sampling_frame, 
                          precision = precision, drop.empty = TRUE)
  }

  # Apply convolution (potentially in parallel)
  term_matrices <- if (parallel) {
      warning("Parallel processing not fully implemented yet, using sequential lapply.", call. = FALSE)
      lapply(terms, convolve_one_term)
  } else {
      lapply(terms, convolve_one_term)
  }

  # Filter out NULL matrices (from AFNI terms that don't contribute to design matrix)
  non_null_indices <- which(!sapply(term_matrices, is.null))
  term_matrices_filtered <- term_matrices[non_null_indices]
  terms_filtered <- terms[non_null_indices]
  
  # Handle case where all terms are NULL (all AFNI terms)
  if (length(term_matrices_filtered) == 0) {
    warning("All terms are AFNI terms that don't contribute to the design matrix. Returning empty design matrix.", call. = FALSE)
    empty_dm <- tibble::tibble(.rows = sum(sampling_frame$blocklens))
    attr(empty_dm, "term_spans") <- integer(0)
    attr(empty_dm, "col_indices") <- list()
    attr(empty_dm, "colnames_final") <- TRUE
    return(empty_dm)
  }

  # Calculate col_indices based on term_ncols before combining matrices
  term_ncols <- vapply(term_matrices_filtered, ncol, integer(1))
  term_spans <- cumsum(term_ncols)
  col_indices <- vector("list", length(terms))
  start_idx <- 1
  for (i in seq_along(terms)) {
      if (i %in% non_null_indices) {
        # Find position in filtered list
        filtered_pos <- which(non_null_indices == i)
        end_idx <- if (filtered_pos == 1) term_ncols[1] else term_spans[filtered_pos]
        col_indices[[i]] <- seq.int(start_idx, end_idx)
        start_idx <- end_idx + 1
      } else {
        # AFNI term - no columns
        col_indices[[i]] <- integer(0)
      }
  }
  names(col_indices) <- names(terms) # Names are now the term_tags

  # --- Combine convolved term matrices --- 
  # Store original names before potential modification by cbind/tibble
  original_colnames_list <- lapply(term_matrices_filtered, colnames)
  # Perform cbind
  dm_mat <- do.call(cbind, term_matrices_filtered)
  
  # Assign combined list of original names initially proposed by convolve.event_term
  current_colnames <- unlist(original_colnames_list)
  
  # Ensure global uniqueness using make.names before tibble conversion
  # This respects the naming_refactoring.md guarantee for unique final names.
  unique_colnames <- make.names(current_colnames, unique = TRUE)
  
  # Warn if names were actually changed by make.names (indicates initial clash)
  if (!identical(current_colnames, unique_colnames)) {
      changed_indices <- which(current_colnames != unique_colnames)
      
      # Filter out changes that are just empty strings being converted to valid names
      # These are not real duplicates, just invalid names being fixed
      real_duplicate_indices <- changed_indices[current_colnames[changed_indices] != ""]
      
      # Only warn if there are actual meaningful duplicates (not just empty string fixes)
      if (length(real_duplicate_indices) > 0) {
          # Provide a more informative warning about which names were auto-suffixed
          warning_message <- paste0(
              "Duplicate column names detected and automatically resolved by appending suffixes (e.g., '.1', '.2'). ",
              "This typically occurs when multiple terms generate identical column name proposals (e.g., from multiple hrf(Ident(X,Y)) calls where 'X' is repeated, or if term_tags clash in unforeseen ways).",
              " Review model specification if this is unexpected. Changed names include:\n",
              paste0("  Original: '", current_colnames[real_duplicate_indices], "' -> Became: '", unique_colnames[real_duplicate_indices], "'", collapse = "\n")
          )
          warning(warning_message, call. = FALSE)
      }
  }
  colnames(dm_mat) <- unique_colnames
  
  # Convert to tibble - .name_repair = "minimal" is now safe as names are unique and valid R names.
  dm <- tibble::as_tibble(dm_mat, .name_repair = "minimal") 

  # Check column count consistency
  if (ncol(dm) != term_spans[length(term_spans)]) {
      warning("Column mismatch after combining term matrices. Check names/cbind.", call. = FALSE)
  }
  
  # --- Attach Attributes --- 
  # Attach term_spans: vector for formula interface, matrix for list interface
  interface_type <- attr(terms, "interface") %||% "formula"
  if (interface_type == "list") {
    starts <- c(1, head(term_spans, -1) + 1)
    spans_mat <- cbind(starts, term_spans)
    attr(dm, "term_spans") <- spans_mat
  } else {
    attr(dm, "term_spans") <- term_spans
  }
  attr(dm, "col_indices") <- col_indices
  # Add flag indicating names are final according to new grammar
  attr(dm, "colnames_final") <- TRUE
  
  dm
}


#' Realise event terms from parsed specification (Stage 2 of Pipeline)
#'
#' Takes the parsed model specification and iterates through each term spec,
#' calling `construct_event_term` to create the actual `event_term` objects.
#' Handles optional progress display.
#'
#' @param parsed_spec Output list from `parse_event_model`.
#' @param sampling_frame The fmri sampling_frame object.
#' @param drop_empty Logical indicating whether to drop empty events (passed to term construction).
#' @param progress Logical indicating whether to show a progress bar.
#' @return A named list of `event_term` objects.
#' @keywords internal
#' @noRd
realise_event_terms <- function(parsed_spec, sampling_frame, drop_empty = TRUE, progress = FALSE) {

  n_terms <- nrow(parsed_spec$spec_tbl)
  term_specs <- parsed_spec$spec_tbl$spec

  if (progress) {
    pb <- cli::cli_progress_bar("Realising event terms", total = n_terms, clear = FALSE)
    on.exit(cli::cli_progress_done(id = pb), add = TRUE)
  }

  # Create a complete model_spec that includes sampling_frame for construct methods
  model_spec <- parsed_spec
  model_spec$sampling_frame <- sampling_frame

  term_list <- vector("list", n_terms)
  term_tags <- character(n_terms)
  term_uids <- character(n_terms)

  for (i in 1:n_terms) {
    spec <- term_specs[[i]]

    # 1. Generate UID (t01, t02, ...)
    term_uid <- sprintf("t%02d", i)
    spec$uid <- term_uid # Store on spec
    term_uids[i] <- term_uid # Collect UIDs

    # 2. Generate Term Tag using helper
    # Pass *previously generated* tags for uniqueness check (use actual tags collected so far)
    # Note: existing_tags should contain the actual tags, not placeholders like NA
    term_tag_value <- make_term_tag(spec, existing_tags = stats::na.omit(term_tags[seq_len(i - 1)]))
    # ^^^ Get the value (could be NULL or a character tag)

    spec$term_tag <- term_tag_value # Store actual value (NULL or tag) on spec

    # Store a placeholder (NA) in the character vector if tag is NULL,
    # otherwise store the actual tag.
    term_tags[i] <- if (is.null(term_tag_value)) NA_character_ else term_tag_value
    
    # 3. Construct the event_term object
    # Use the generic construct method which will dispatch to the appropriate method
    # (construct.afni_hrfspec, construct.hrfspec, etc.) based on the spec type
    # Pass the complete model_spec that includes sampling_frame
    term_list[[i]] <- construct(spec, model_spec)

    # 4. Store UID and *actual* Term Tag (NULL or character) attribute on the event_term object itself
    if (!is.null(term_list[[i]])) {
        attr(term_list[[i]], "uid") <- term_uid
        attr(term_list[[i]], "term_tag") <- term_tag_value # Assign NULL or tag here
    } else {
        # This might happen if construct_event_term fails or returns NULL
        warning(paste("Term", i, "construction resulted in NULL. Cannot set attributes."))
    }

    # Update progress
    if (progress) {
      cli::cli_progress_update(id = pb)
    }
  }

  # --- Post-processing --- 

  # Assign names to the list, handling NAs from NULL term tags.
  final_list_names <- term_tags
  na_indices <- which(is.na(final_list_names))
  if (length(na_indices) > 0) {
      # Generate default names for NA elements, e.g., based on index or variable names
      for(idx in na_indices) {
         # Try to get a fallback name from the term object's varname attribute if available
         term_obj <- term_list[[idx]]
         fallback_name <- if (!is.null(term_obj) && !is.null(term_obj$varname)) {
                              term_obj$varname # Use varname (e.g., "Ident.RT1..RT2.") as list name
                          } else {
                              paste0("term_", idx) # Generic fallback
                          } 
         final_list_names[idx] <- fallback_name
      }
      message(sprintf("Generated default list names for %d terms with NULL term_tags (likely Ident).", length(na_indices)))
  }
  
  # Ensure final list names are unique
  names(term_list) <- make.unique(final_list_names) 
  
  # Tag input interface type for later builder
  attr(term_list, "interface") <- parsed_spec$interface

  term_list
}

#' Parse event model inputs (Stage 1 of Pipeline)
#'
#' Internal helper to normalize formula/list inputs, validate/extract shared
#' onset, block, duration info, and create a standardized spec table.
#'
#' @param formula_or_list Formula or list of hrfspec objects.
#' @param data The data frame containing event variables.
#' @param block Formula or vector specifying blocks/runs.
#' @param durations Numeric vector or scalar for event durations.
#' @return A list containing: spec_tbl, onsets, durations, blockids, data, formula_env.
#' @keywords internal
#' @noRd
parse_event_model <- function(formula_or_list, data, block, durations = 0) {
  
  stopifnot(inherits(data, "data.frame"))
  
  spec_tbl <- NULL
  onsets <- NULL
  formula_env <- NULL
  
  if (rlang::is_formula(formula_or_list)) {
    parsed_form <- parse_event_formula(formula_or_list, data)
    spec_tbl <- parsed_form$spec_tbl
    onsets <- parsed_form$onsets
    formula_env <- parsed_form$formula_env
    stopifnot(is.numeric(onsets))
    if(length(onsets) != nrow(data)) {
         stop(sprintf("Length of extracted onset variable (%d) != nrow(data) (%d)",
                      length(onsets), nrow(data)), call.=FALSE)
    }
    
  } else if (is.list(formula_or_list)) {
    stopifnot(all(vapply(formula_or_list, inherits, TRUE, "hrfspec")), 
              length(formula_or_list) > 0)
              
    spec_tbl <- tibble::tibble(
        term_id = seq_along(formula_or_list),
        spec = formula_or_list
    )
    
    if (!"onset" %in% names(data)) {
        stop("When providing a list of hrfspecs, `data` must contain an 'onset' column. If named differently, please use the formula interface.", call.=FALSE)
    }
    onsets <- data$onset
    stopifnot(is.numeric(onsets))
    if(length(onsets) != nrow(data)) {
         stop(sprintf("Length of 'onset' column (%d) != nrow(data) (%d)",
                      length(onsets), nrow(data)), call.=FALSE)
    }
    formula_env <- rlang::empty_env() 
    
  } else {
    stop("`formula_or_list` must be a formula or a list of hrfspec objects.", call.=FALSE)
  }
  
  stopifnot(all(!is.na(onsets)))

  blockids_raw <- NULL
  if (rlang::is_formula(block)) {
    block_rhs <- rlang::f_rhs(block)
    if (identical(block_rhs, 1L) || identical(block_rhs, 1)) {
      blockids_raw <- rep(1, nrow(data))
    } else {
      blockids_raw <- rlang::eval_tidy(block_rhs, data)
    }
  } else {
    blockids_raw <- block
  }
  
  if (is.factor(blockids_raw)) {
    blockids_raw <- as.integer(as.character(blockids_raw))
  }
  
  stopifnot(length(blockids_raw) == length(onsets),
            all(!is.na(blockids_raw))) 
            
  # Use stopifnot for non-decreasing check for better trace
  if (is.unsorted(blockids_raw, strictly = FALSE)) {
       stop("'blockids' must be non-decreasing.", call. = FALSE)
  }
  
  # Canonicalize blockids
  blockids <- as.integer(match(blockids_raw, unique(blockids_raw)))
  
  if (is.null(durations)) durations <- 0 
  durations_proc <- recycle_or_error(durations, length(onsets), "durations")
  stopifnot(all(!is.na(durations_proc)))

  list(
    spec_tbl    = spec_tbl,
    onsets      = onsets,
    durations   = durations_proc,
    blockids    = blockids, # Use canonicalized IDs
    data        = data, 
    formula_env = formula_env,
    interface   = if (rlang::is_formula(formula_or_list)) "formula" else "list"
  )
}
</file>

<file path="R/fmri_dataset.R">
`%dopar%` <- foreach::`%dopar%`
`%do%` <- foreach::`%do%`

#' @keywords internal
#' @noRd
default_config <- function() {
  env <- new.env()
  env$cmd_flags <- ""
  env$jobs <- 1
  env
  
}


#' read a basic fMRI configuration file
#' 
#' @param file_name name of configuration file
#' @param base_path the file path to be prepended to relative file names
#' @importFrom assertthat assert_that
#' @importFrom tibble as_tibble
#' @export
#' @return a \code{fmri_config} instance
read_fmri_config <- function(file_name, base_path=NULL) {
  #print(file_name)
  env <- default_config()
  
  source(file_name, env)
  
  env$base_path <- if (is.null(env$base_path) && is.null(base_path)) {
   "."
  } else if (!is.null(base_path) && is.null(env$base_path)) {
    base_path
  } 
  
  if (is.null(env$output_dir)) {
    env$output_dir = "stat_out"
  }
  

  assert_that(!is.null(env$scans))
  assert_that(!is.null(env$TR))
  assert_that(!is.null(env$mask))
  assert_that(!is.null(env$run_length))
  assert_that(!is.null(env$event_model))
  assert_that(!is.null(env$event_table))
  assert_that(!is.null(env$block_column))
  assert_that(!is.null(env$baseline_model))
  
  if (!is.null(env$censor_file)) {
    env$censor_file = NULL
  }
  
  if (!is.null(env$contrasts)) {
    env$contrasts = NULL
  }
  
  if (!is.null(env$nuisance)) {
    env$nuisance = NULL
  }
  
  dname <- file.path(env$base_path, env$event_table)
  
  assert_that(file.exists(dname))
  env$design <- suppressMessages(tibble::as_tibble(read.table(dname, header=TRUE),.name_repair="check_unique"))

  out <- as.list(env)
  class(out) <- c("fmri_config", "list")
  out
}

#' Create a Matrix Dataset Object
#'
#' This function creates a matrix dataset object, which is a list containing information about the data matrix, TR, number of runs, event table, sampling frame, and mask.
#'
#' @param datamat A matrix where each column is a voxel time-series.
#' @param TR Repetition time (TR) of the fMRI acquisition.
#' @param run_length A numeric vector specifying the length of each run in the dataset.
#' @param event_table An optional data frame containing event information. Default is an empty data frame.
#'
#' @return A matrix dataset object of class c("matrix_dataset", "fmri_dataset", "list").
#' @export
#'
#' @examples
#' # A matrix with 100 rows and 100 columns (voxels)
#' X <- matrix(rnorm(100*100), 100, 100)
#' dset <- matrix_dataset(X, TR=2, run_length=100)
matrix_dataset <- function(datamat, TR, run_length, event_table=data.frame()) {
  if (is.vector(datamat)) {
    datamat <- as.matrix(datamat)
  }
  assert_that(sum(run_length) == nrow(datamat))
  
  frame <- sampling_frame(run_length, TR)
  
  ret <- list(
    datamat=datamat,
    TR=TR,
    nruns=length(run_length),
    event_table=event_table,
    sampling_frame=frame,
    mask=rep(1,ncol(datamat))
  )
  
  class(ret) <- c("matrix_dataset", "fmri_dataset", "list")
  ret
  
}

#' Create an fMRI Memory Dataset Object
#'
#' This function creates an fMRI memory dataset object, which is a list containing information about the scans, mask, TR, number of runs, event table, base path, sampling frame, and censor.
#'
#' @param scans A list of objects of class \code{\linkS4class{NeuroVec}}.
#' @param mask A binary mask of class \code{\linkS4class{NeuroVol}} indicating the set of voxels to include in analyses.
#' @param TR Repetition time (TR) of the fMRI acquisition.
#' @param run_length A numeric vector specifying the length of each run in the dataset. Default is the length of the scans.
#' @param event_table An optional data frame containing event information. Default is an empty data frame.
#' @param base_path An optional base path for the dataset. Default is "." (current directory).
#' @param censor An optional numeric vector specifying which time points to censor. Default is NULL.
#'
#' @return An fMRI memory dataset object of class c("fmri_mem_dataset", "volumetric_dataset", "fmri_dataset", "list").
#' @export
#'
#' @examples
#' # Create a NeuroVec object
#' d <- c(10, 10, 10, 10)
#' nvec <- neuroim2::NeuroVec(array(rnorm(prod(d)), d), space=neuroim2::NeuroSpace(d))
#'
#' # Create a NeuroVol mask
#' mask <- neuroim2::NeuroVol(array(rnorm(10*10*10), d[1:3]), space=neuroim2::NeuroSpace(d[1:3]))
#' mask[mask < .5] <- 0
#'
#' # Create an fmri_mem_dataset
#' dset <- fmri_mem_dataset(list(nvec), mask, TR=2)
fmri_mem_dataset <- function(scans, mask, TR, 
                             run_length=sapply(scans, function(x) dim(x)[4]),
                             event_table=data.frame(), 
                             base_path=".",
                             censor=NULL) {
  
  
  
  assert_that(all(map_lgl(scans, function(x) inherits(x, "NeuroVec"))))
  assert_that(inherits(mask, "NeuroVol"))
  assert_that(all(dim(mask) == dim(scans[[1]][1:3])))
  
  ntotscans <- sum(sapply(scans, function(x) dim(x)[4]))
  #run_length <- map_dbl(scans, ~ dim(.)[4])
  assert_that(sum(run_length) == ntotscans)
  
  if (is.null(censor)) {
    censor <- rep(0, sum(run_length))
  }

  frame <- sampling_frame(run_length, TR)
  
  ret <- list(
    scans=scans,
    mask=mask,
    nruns=length(run_length),
    event_table=event_table,
    base_path=base_path,
    sampling_frame=frame,
    censor=censor
  )
  
  class(ret) <- c("fmri_mem_dataset", "volumetric_dataset", "fmri_dataset", "list")
  ret
}

#' Create a Latent Dataset Object
#'
#' This function creates a latent dataset object, which encapsulates a dimension-reduced
#' subspace of "latent variables". The dataset is a list containing information about the latent
#' neuroimaging vector, TR, number of runs, event table, base path, sampling frame, and censor.
#'
#' @param lvec An instance of class \code{LatentNeuroVec}. (Typically, a \code{LatentNeuroVec} is
#'   created using the \code{fmristore} package.)
#' @param TR Repetition time (TR) of the fMRI acquisition.
#' @param run_length A numeric vector specifying the length of each run in the dataset.
#' @param event_table An optional data frame containing event information. Default is an empty data frame.
#'
#' @return A latent dataset object of class \code{c("latent_dataset", "matrix_dataset", "fmri_dataset", "list")}.
#'
#' @export
#'
#' @examples
#' \dontrun{
#' # Create a matrix with 100 rows and 1000 columns (voxels)
#' X <- matrix(rnorm(100 * 1000), 100, 1000)
#' pres <- prcomp(X)
#' basis <- pres$x[, 1:25]
#' loadings <- pres$rotation[, 1:25]
#' offset <- colMeans(X)
#'
#' # Create a LatentNeuroVec object (requires the fmristore package)
#' lvec <- fmristore::LatentNeuroVec(basis, loadings,
#'             neuroim2::NeuroSpace(c(10, 10, 10, 100)),
#'             mask = rep(TRUE, 1000), offset = offset)
#'
#' # Create a latent_dataset
#' dset <- latent_dataset(lvec, TR = 2, run_length = 100)
#' }
latent_dataset <- function(lvec, TR, run_length, event_table = data.frame()) {
  # Lazy check: make sure fmristore is installed (fmristore is not a hard dependency)
  if (!requireNamespace("fmristore", quietly = TRUE)) {
    stop("The 'fmristore' package is required to create a latent_dataset. Please install fmristore.",
         call. = FALSE)
  }
  
  # Ensure the total run length matches the number of time points in lvec
  assertthat::assert_that(
    sum(run_length) == dim(lvec)[4],
    msg = "Sum of run lengths must equal the 4th dimension of lvec"
  )
  
  frame <- sampling_frame(run_length, TR)
  
  ret <- list(
    lvec = lvec,
    datamat = lvec@basis,
    TR = TR,
    nruns = length(run_length),
    event_table = event_table,
    sampling_frame = frame,
    mask = rep(1, ncol(lvec@basis))
  )
  
  class(ret) <- c("latent_dataset", "matrix_dataset", "fmri_dataset", "list")
  ret
}
#' Create an fMRI Dataset Object from a Set of Scans
#'
#' This function creates an fMRI dataset object from a set of scans, design information, and other data. The dataset is a list containing information about the scans, mask, TR, number of runs, event table, base path, sampling frame, censor, mode, and preload.
#'
#' @param scans A vector of one or more file names of the images comprising the dataset.
#' @param mask Name of the binary mask file indicating the voxels to include in the analysis.
#' @param TR The repetition time in seconds of the scan-to-scan interval.
#' @param run_length A vector of one or more integers indicating the number of scans in each run.
#' @param event_table A data.frame containing the event onsets and experimental variables. Default is an empty data.frame.
#' @param base_path The file path to be prepended to relative file names. Default is "." (current directory).
#' @param censor A binary vector indicating which scans to remove. Default is NULL.
#' @param preload Read image scans eagerly rather than on first access. Default is FALSE.
#' @param mode The type of storage mode ('normal', 'bigvec', 'mmap', filebacked'). Default is 'normal'.
#'
#' @return An fMRI dataset object of class c("fmri_file_dataset", "volumetric_dataset", "fmri_dataset", "list").
#' @export
#'
#' @examples
#' # Create an fMRI dataset with 3 scans and a mask
#' dset <- fmri_dataset(c("scan1.nii", "scan2.nii", "scan3.nii"), 
#'   mask="mask.nii", TR=2, run_length=rep(300, 3), 
#'   event_table=data.frame(onsets=c(3, 20, 99, 3, 20, 99, 3, 20, 99), 
#'   run=c(1, 1, 1, 2, 2, 2, 3, 3, 3))
#' )
#'
#' # Create an fMRI dataset with 1 scan and a mask
#' dset <- fmri_dataset("scan1.nii", mask="mask.nii", TR=2, 
#'   run_length=300, 
#'   event_table=data.frame(onsets=c(3, 20, 99), run=rep(1, 3))
#' ) 
fmri_dataset <- function(scans, mask, TR, 
                         run_length, 
                         event_table=data.frame(), 
                         base_path=".",
                         censor=NULL,
                         preload=FALSE,
                         mode=c("normal", "bigvec", "mmap", "filebacked")) {
  
  assert_that(is.character(mask), msg="'mask' should be the file name of the binary mask file")
  mode <- match.arg(mode)
  
  #if (length(run_length) == 1) {
  #  run_length <- rep(run_length, length(scans))
  #}
  
  ## run_length should equal total length of images in scans -- but we can 't confirm that here.
  
  if (is.null(censor)) {
    censor <- rep(0, sum(run_length))
  }
  
  frame <- sampling_frame(run_length, TR)
  
  #assert_that(length(run_length) == length(scans))
  
  maskfile <- paste0(base_path, "/", mask)
  scans=paste0(base_path, "/", scans)

  maskvol <- if (preload) {
    assert_that(file.exists(maskfile))
    message(paste("preloading masks", maskfile))
    neuroim2::read_vol(maskfile)
  }
  
  vec <- if (preload) {
    message(paste("preloading scans", paste(scans, collapse = " ")))
    neuroim2::read_vec(scans, mode=mode,mask=maskvol)
  }
  
  
  ret <- list(
    scans=scans,
    vec=vec,
    mask_file=maskfile,
    mask=maskvol,
    nruns=length(run_length),
    event_table=suppressMessages(tibble::as_tibble(event_table,.name_repair="check_unique")),
    base_path=base_path,
    sampling_frame=frame,
    censor=censor,
    mode=mode,
    preload=preload
  )
  
  class(ret) <- c("fmri_file_dataset", "volumetric_dataset", "fmri_dataset", "list")
  ret
}



#' @export
#' @importFrom neuroim2 NeuroVecSeq 
get_data.latent_dataset <- function(x, ...) {
  x$lvec@basis
}

#' @export
#' @importFrom neuroim2 NeuroVecSeq 
get_data.fmri_mem_dataset <- function(x, ...) {
  if (length(x$scans) > 1) {
    do.call(neuroim2::NeuroVecSeq, x$scans)
  } else {
    x$scans[[1]]
  }
}

#' @export
#' @importFrom neuroim2 NeuroVecSeq 
get_data.matrix_dataset <- function(x, ...) {
  x$datamat
}

#' @export
#' @importFrom neuroim2 NeuroVecSeq FileBackedNeuroVec
get_data.fmri_file_dataset <- function(x, ...) {
  if (is.null(x$vec)) {
    get_data_from_file(x,...)
  } else {
    x$vec
  }
}

#' @export
get_data_matrix.matrix_dataset <- function(x, ...) {
  x$datamat
}


#' @export
get_data_matrix.fmri_mem_dataset <- function(x, ...) {
  bvec <- get_data(x)
  mask <- get_mask(x)
  series(bvec, which(mask != 0))
}


#' @export
get_data_matrix.fmri_file_dataset <- function(x, ...) {
  bvec <- get_data(x)
  mask <- get_mask(x)
  series(bvec, which(mask != 0))
}



#' @import memoise
#' @keywords internal
#' @noRd
get_data_from_file <- memoise::memoise(function(x, ...) {
  m <- get_mask(x)
  neuroim2::read_vec(x$scans, mask=m, mode=x$mode, ...)
})



#' @export
get_mask.fmri_file_dataset <- function(x, ...) {
  if (is.null(x$mask)) {
    neuroim2::read_vol(x$mask_file)
  } else {
    x$mask
  }
}


#' @export
get_mask.fmri_mem_dataset <- function(x, ...) {
  x$mask
}

#' @export
get_mask.matrix_dataset <- function(x, ...) {
  x$mask
}

#' @export
get_mask.latent_dataset <- function(x, ...) {
  x$lvec@mask
}


#' @keywords internal
#' @noRd
data_chunk <- function(mat, voxel_ind, row_ind, chunk_num) {
  ret <- list(
       data=mat,
       voxel_ind=voxel_ind,
       row_ind=row_ind,
       chunk_num=chunk_num)
  
  class(ret) <- c("data_chunk", "list")
  ret
}

#' @keywords internal
#' @noRd
chunk_iter <- function(x, nchunks, get_chunk) {
  chunk_num <- 1
  
  nextEl <- function() {
    if (chunk_num > nchunks) {
      stop("StopIteration")
    } else {
      ret <- get_chunk(chunk_num)
      chunk_num <<- chunk_num + 1
      ret
    }
  }
  
  iter <- list(nchunks=nchunks, nextElem=nextEl)
  class(iter) <- c("chunkiter", "abstractiter", "iter")
  iter
}

#' @export
blocklens.matrix_dataset <- function(x, ...) {
  x$run_length
}



#' Create Data Chunks for fmri_mem_dataset Objects
#'
#' This function creates data chunks for fmri_mem_dataset objects. It allows for the retrieval of run-wise or sequence-wise data chunks, as well as arbitrary chunks.
#'
#' @param x An object of class 'fmri_mem_dataset'.
#' @param nchunks The number of data chunks to create. Default is 1.
#' @param runwise If TRUE, the data chunks are created run-wise. Default is FALSE.
#' @param ... Additional arguments.
#'
#' @return A list of data chunks, with each chunk containing the data, voxel indices, row indices, and chunk number.
#' @importFrom neuroim2 series
#' @autoglobal
#' @export
#'
#' @examples
#' # Create an fmri_mem_dataset
#' # ... (see example for fmri_mem_dataset)
#'
#' # Create an iterator with 5 chunks
#' iter <- data_chunks(dset, nchunks=5)
#' `%do%` <- foreach::`%do%`
#' y <- foreach::foreach(chunk = iter) %do% { colMeans(chunk$data) }
#' length(y) == 5
#'
#' # Create an iterator with 100 chunks
#' iter <- data_chunks(dset, nchunks=100)
#' y <- foreach::foreach(chunk = iter) %do% { colMeans(chunk$data) }
#' length(y) == 100
#'
#' # Create a "runwise" iterator
#' iter <- data_chunks(dset, runwise=TRUE)
#' y <- foreach::foreach(chunk = iter) %do% { colMeans(chunk$data) }
#' length(y) == 2
data_chunks.fmri_mem_dataset <- function(x, nchunks=1,runwise=FALSE,...) {
  mask <- get_mask(x)
  #print("data chunks")
  #print(nchunks)
  get_run_chunk <- function(chunk_num) {
    bvec <- x$scans[[chunk_num]]
    voxel_ind <- which(mask>0)
    #print(voxel_ind)
    row_ind <- which(x$sampling_frame$blockids == chunk_num)
    ret <- data_chunk(neuroim2::series(bvec,voxel_ind), 
                      voxel_ind=voxel_ind, 
                      row_ind=row_ind, 
                      chunk_num=chunk_num)
  }
  
  get_seq_chunk <- function(chunk_num) {
    bvecs <- x$scans
    voxel_ind <- maskSeq[[chunk_num]]
    #print(voxel_ind)

    m <- do.call(rbind, lapply(bvecs, function(bv) neuroim2::series(bv, voxel_ind)))
    ret <- data_chunk(do.call(rbind, lapply(bvecs, function(bv) neuroim2::series(bv, voxel_ind))), 
                      voxel_ind=voxel_ind, 
                      row_ind=1:nrow(m),
                      chunk_num=chunk_num)
    
  }
  
  maskSeq <- NULL
  if (runwise) {
    chunk_iter(x, length(x$scans), get_run_chunk)
  } else if (nchunks == 1) {
    maskSeq <- one_chunk()
    chunk_iter(x, 1, get_seq_chunk)
  #} #else if (nchunks == dim(mask)[3]) {
    #maskSeq <<- slicewise_chunks(x)
    #chunk_iter(x, length(maskSeq), get_seq_chunk)
  } else {
    maskSeq <- arbitrary_chunks(x, nchunks)
    chunk_iter(x, length(maskSeq), get_seq_chunk)
  }
  
}


#' Create Data Chunks for fmri_file_dataset Objects
#'
#' This function creates data chunks for fmri_file_dataset objects. It allows for the retrieval of run-wise or sequence-wise data chunks, as well as arbitrary chunks.
#'
#' @param x An object of class 'fmri_file_dataset'.
#' @param nchunks The number of data chunks to create. Default is 1.
#' @param runwise If TRUE, the data chunks are created run-wise. Default is FALSE.
#' @param ... Additional arguments.
#'
#' @return A list of data chunks, with each chunk containing the data, voxel indices, row indices, and chunk number.
#' @noRd
data_chunks.fmri_file_dataset <- function(x, nchunks=1, runwise=FALSE, ...) {
  mask <- get_mask(x)
  maskSeq <- NULL
  
  # Define chunk getter functions first
  get_run_chunk <- function(chunk_num) {
    bvec <- neuroim2::read_vec(file.path(x$scans[chunk_num]), mask=mask)
    ret <- data_chunk(bvec@data, voxel_ind=which(x$mask>0), 
                     row_ind=which(x$sampling_frame$blockids == chunk_num), 
                     chunk_num=chunk_num)
  }
  
  get_seq_chunk <- function(chunk_num) {
    v <- get_data(x)
    vind <- maskSeq[[chunk_num]]
    m <- series(v, vind)
    ret <- data_chunk(m, voxel_ind=vind, 
                     row_ind=1:nrow(x$event_table), 
                     chunk_num=chunk_num)
  }

 
  # Then create iterator based on strategy
  if (runwise) {
    chunk_iter(x, length(x$scans), get_run_chunk)
  } else if (nchunks == 1) {
    maskSeq <- one_chunk(x)
    chunk_iter(x, 1, get_seq_chunk)
  } else {
    maskSeq <- arbitrary_chunks(x, nchunks)
    chunk_iter(x, length(maskSeq), get_seq_chunk)
  }
}


#' Create Data Chunks for matrix_dataset Objects
#'
#' This function creates data chunks for matrix_dataset objects. It allows for the retrieval 
#' of run-wise or sequence-wise data chunks, as well as arbitrary chunks.
#'
#' @param x An object of class 'matrix_dataset'
#' @param nchunks The number of chunks to split the data into. Default is 1.
#' @param runwise If TRUE, creates run-wise chunks instead of arbitrary chunks
#' @param ... Additional arguments passed to methods
#' @return A list of data chunks, each containing data, indices and chunk number
#' @export
data_chunks.matrix_dataset <- function(x, nchunks=1, runwise=FALSE,...) {
  get_run_chunk <- function(chunk_num) {
    ind <- which(blockids(x$sampling_frame) == chunk_num)
    mat <- x$datamat[ind,,drop=FALSE]
    #browser()
    data_chunk(mat, voxel_ind=1:ncol(mat), row_ind=ind, chunk_num=chunk_num)
  }
  
  get_one_chunk <- function(chunk_num) {
    data_chunk(x$datamat, voxel_ind=1:ncol(x$datamat), row_ind=1:nrow(x$datamat), chunk_num=chunk_num)
  }
  
  
  if (runwise) {
    chunk_iter(x, length(x$sampling_frame$blocklens), get_run_chunk)
  } else if (nchunks==1) {
    chunk_iter(x, 1, get_one_chunk)
  } else {
    sidx <- split(1:ncol(x$datamat), sort(rep(1:nchunks, length.out=ncol(x$datamat))))
    get_chunk <- function(chunk_num) {
      data_chunk(x$datamat[,sidx[[chunk_num]], drop=FALSE], 
                 voxel_ind=sidx[[chunk_num]], 
                 row_ind=1:nrow(x$datamat), 
                 chunk_num=chunk_num)
    }
    chunk_iter(x, nchunks, get_chunk)
  }
  
}

#' @keywords internal
#' @noRd
exec_strategy <- function(strategy=c("voxelwise", "runwise", "chunkwise"), nchunks=NULL) {
  strategy <- match.arg(strategy)
  
  function(dset) {
    if (strategy == "runwise") {
      data_chunks(dset, runwise=TRUE)
    } else if (strategy == "voxelwise") {
      m <- get_mask(dset)
      data_chunks(dset, nchunks = sum(m), runwise=FALSE)
    } else if (strategy == "chunkwise") {
      m <- get_mask(dset)
      ##message("nchunks is", nchunks)
      assert_that(!is.null(nchunks) && is.numeric(nchunks))
      if (nchunks > sum(m)) {
        warning("requested number of chunks is greater than number of voxels in mask")
        nchunks <- sum(m)
      }
      data_chunks(dset, nchunks = nchunks, runwise=FALSE)
    }
  }
  
}


#' @keywords internal
#' @noRd
#' @importFrom deflist deflist
arbitrary_chunks <- function(x, nchunks) {
  #print("arbitrary chunks")
  #browser()
  mask <- get_mask(x)
  #print(mask)
  indices <- as.integer(which(mask != 0))
  chsize <- round(length(indices)/nchunks)
  #print(indices)
  
  assert_that(chsize > 0)
  chunkids <- sort(rep(1:nchunks, each=chsize, length.out=length(indices)))
  #print(chunkids)
  
  mfun <- function(i) indices[chunkids==i]
  #print(mfun)
  
  ret <- deflist::deflist(mfun, len=nchunks)
  #print(ret[[1]])
  return(ret)
  
}

#' @keywords internal
#' @noRd
slicewise_chunks <- function(x) {
  mask <- x$mask
  template <- neuroim2::NeuroVol(array(0, dim(mask)), neuroim2::space(mask))
  nchunks <- dim(mask)[3]
  
  maskSeq <- lapply(1:nchunks, function(i) {
    m <- template
    m[,,i] <- 1
    m
  })
  
  maskSeq
  
}

#' @keywords internal
#' @noRd
one_chunk <- function(x) {
  mask <- get_mask(x)
  voxel_ind <- which(mask > 0)
  list(voxel_ind)
}

#' @export
#' @rdname print
print.fmri_dataset <- function(x, ...) {
  # Header
  cat("\n═══ fMRI Dataset ═══\n")
  
  # Basic dimensions
  cat("\n📊 Dimensions:\n")
  cat("  • Timepoints:", sum(x$sampling_frame$run_length), "\n")
  cat("  • Runs:", x$nruns, "\n")
  
  # Mask info
  mask <- get_mask(x)
  cat("  • Voxels in mask:", sum(mask > 0), "\n")
  cat("  • Mask dimensions:", paste(dim(mask), collapse=" × "), "\n")
  
  # Sampling frame info
  cat("\n⏱️  Temporal Structure:\n")
  cat("  • TR:", x$sampling_frame$TR, "seconds\n")
  cat("  • Run lengths:", paste(x$sampling_frame$run_length, collapse=", "), "\n")
  
  # Event table summary
  cat("\n📋 Event Table:\n")
  if (nrow(x$event_table) > 0) {
    cat("  • Rows:", nrow(x$event_table), "\n")
    cat("  • Variables:", paste(names(x$event_table), collapse=", "), "\n")
    
    # Show first few events if they exist
    if (nrow(x$event_table) > 0) {
      cat("  • First few events:\n")
      print(head(x$event_table, 3))
    }
  } else {
    cat("  • Empty event table\n")
  }
  
  cat("\n")
}

#' @export
#' @rdname print
print.latent_dataset <- function(x, ...) {
  # Header
  cat("\n═══ Latent Dataset ═══\n")
  
  # Basic dimensions
  cat("\n📊 Dimensions:\n")
  cat("  • Timepoints:", nrow(x$datamat), "\n")
  cat("  • Latent components:", ncol(x$datamat), "\n")
  cat("  • Runs:", x$nruns, "\n")
  
  # Original space info if available
  if (!is.null(x$original_space)) {
    cat("  • Original space:", paste(x$original_space, collapse=" × "), "\n")
  }
  
  # Sampling frame info
  cat("\n⏱️  Temporal Structure:\n")
  cat("  • TR:", x$sampling_frame$TR, "seconds\n")
  cat("  • Run lengths:", paste(x$sampling_frame$run_length, collapse=", "), "\n")
  
  # Event table summary
  cat("\n📋 Event Table:\n")
  if (nrow(x$event_table) > 0) {
    cat("  • Rows:", nrow(x$event_table), "\n")
    cat("  • Variables:", paste(names(x$event_table), collapse=", "), "\n")
    
    # Show first few events if they exist
    if (nrow(x$event_table) > 0) {
      cat("  • First few events:\n")
      print(head(x$event_table, 3))
    }
  } else {
    cat("  • Empty event table\n")
  }
  
  # Data summary
  cat("\n📈 Latent Data Summary:\n")
  data_summary <- summary(as.vector(x$datamat[1:min(1000, length(x$datamat))]))[c(1,3,4,6)]
  cat("  • Values (sample):", paste(names(data_summary), data_summary, sep=":", collapse=", "), "\n")
  
  cat("\n")
}

#' Pretty Print a Chunk Iterator
#'
#' This function prints a summary of a chunk iterator using colored output.
#'
#' @param x A chunkiter object.
#' @param ... Additional arguments (ignored).
#' @export
#' @rdname print
print.chunkiter <- function(x, ...) {
  if (!requireNamespace("crayon", quietly = TRUE)) {
    stop("Please install the crayon package to use this function.")
  }
  cat(crayon::blue("Chunk Iterator:\n"))
  cat(crayon::magenta("  Total number of chunks: "), x$nchunks, "\n")
  invisible(x)
}

#' Convert an fMRI Dataset to a Matrix Dataset
#'
#' This function converts various types of fMRI datasets to a matrix_dataset object.
#' 
#' @param x An object of class 'fmri_dataset'
#' @param ... Additional arguments passed to methods
#' @return A matrix_dataset object
#' @export
as.matrix_dataset <- function(x, ...) {
  UseMethod("as.matrix_dataset")
}

#' @export
as.matrix_dataset.matrix_dataset <- function(x, ...) {
  x  # Already a matrix_dataset
}

#' @export
as.matrix_dataset.fmri_mem_dataset <- function(x, ...) {
  # Get the data matrix
  bvec <- get_data(x)
  mask <- get_mask(x)
  datamat <- series(bvec, which(mask != 0))
  
  # Create matrix_dataset
  matrix_dataset(
    datamat = datamat,
    TR = x$sampling_frame$TR,
    run_length = x$sampling_frame$run_length,
    event_table = x$event_table
  )
}

#' @export
as.matrix_dataset.fmri_file_dataset <- function(x, ...) {
  # Get the data matrix
  vec <- get_data(x)
  mask <- get_mask(x)
  datamat <- series(vec, which(mask != 0))
  
  # Create matrix_dataset
  matrix_dataset(
    datamat = datamat,
    TR = x$sampling_frame$TR,
    run_length = x$sampling_frame$run_length,
    event_table = x$event_table
  )
}


#' Pretty Print a Data Chunk Object
#'
#' This function prints a summary of a data chunk using crayon for colored output.
#'
#' @param x A data_chunk object.
#' @param ... Additional arguments (ignored).
#' @export
#' @rdname print
print.data_chunk <- function(x, ...) {
  if (!requireNamespace("crayon", quietly = TRUE)) {
    stop("Please install the crayon package to use this function.")
  }
  cat(crayon::blue("Data Chunk Object\n"))
  cat(crayon::magenta("  Chunk number: "), x$chunk_num, "\n")
  cat(crayon::magenta("  Number of voxels: "), length(x$voxel_ind), "\n")
  cat(crayon::magenta("  Number of rows: "), length(x$row_ind), "\n")
  if (!is.null(dim(x$data))) {
    cat(crayon::magenta("  Data dimensions: "), paste(dim(x$data), collapse = " x "), "\n")
  } else {
    cat(crayon::magenta("  Data: "), paste(head(x$data, 10), collapse = ", "), "\n")
  }
  invisible(x)
}
</file>

<file path="R/fmrirlm.R">
#' Fit a Robust Linear Model for fMRI Data Analysis
#'
#' This function fits a robust linear regression model for fMRI data analysis using the specified model formula,
#' block structure, and dataset. The model can be fit using either a runwise or chunkwise data splitting strategy.
#'
#' @inheritParams fmri_lm
#' @param nchunks Number of data chunks when strategy is "chunkwise". Default is 10.
#' @return A fitted robust linear regression model for fMRI data analysis.
#' @export
#' @examples
#' etab <- data.frame(onset=c(1,30,15,25), fac=factor(c("A", "B", "A", "B")), run=c(1,1,2,2))
#' etab2 <- data.frame(onset=c(1,30,65,75), fac=factor(c("A", "B", "A", "B")), run=c(1,1,1,1))
#' mat <- matrix(rnorm(100*100), 100,100)
#' dset <- matrix_dataset(mat, TR=1, run_length=c(50,50),event_table=etab)
#' dset2 <- matrix_dataset(mat, TR=1, run_length=c(100),event_table=etab2)
#' lm.1 <- fmri_rlm(onset ~ hrf(fac), block= ~ run, dataset=dset)
#' lm.2 <- fmri_rlm(onset ~ hrf(fac), block= ~ run, dataset=dset2)
fmri_rlm <- function(formula, block, baseline_model = NULL, dataset,
                     durations = 0, drop_empty = TRUE,
                     strategy = c("runwise", "chunkwise"),
                     nchunks = 10,
                     cor_struct = c("iid", "ar1", "ar2", "arp"), cor_iter = 1L,
                     cor_global = FALSE, ar_p = NULL, ar1_exact_first = FALSE,
                     ...) {

  res <- fmri_lm(formula, block, baseline_model = baseline_model, dataset = dataset,
                 durations = durations, drop_empty = drop_empty,
                 strategy = strategy, nchunks = nchunks,
                 cor_struct = cor_struct, cor_iter = cor_iter,
                 cor_global = cor_global, ar_p = ar_p,
                 ar1_exact_first = ar1_exact_first,
                 robust = TRUE, ...)
  class(res) <- c("fmri_rlm", class(res))
  res
}

#' Perform Chunkwise Robust Linear Modeling on fMRI Dataset
#'
#' @inheritParams chunkwise_lm.fmri_dataset
#' @keywords internal
chunkwise_rlm <- function(dset, model, contrast_objects, nchunks,
                          verbose = FALSE, use_fast_path = FALSE,
                          progress = FALSE,
                          cor_struct = c("iid", "ar1", "ar2", "arp"), cor_iter = 1L,
                          cor_global = FALSE, ar_p = NULL, ar1_exact_first = FALSE) {
  chunkwise_lm.fmri_dataset(dset, model, contrast_objects, nchunks,
                            robust = TRUE, verbose = verbose,
                            use_fast_path = use_fast_path, progress = progress,
                            cor_struct = cor_struct, cor_iter = cor_iter,
                            cor_global = cor_global, ar_p = ar_p,
                            ar1_exact_first = ar1_exact_first)
}

#' Perform Runwise Robust Linear Modeling on fMRI Dataset
#'
#' @inheritParams runwise_lm
#' @keywords internal
runwise_rlm <- function(dset, model, contrast_objects,
                       verbose = FALSE, use_fast_path = FALSE,
                       progress = FALSE,
                       cor_struct = c("iid", "ar1", "ar2", "arp"), cor_iter = 1L,
                       cor_global = FALSE, ar_p = NULL, ar1_exact_first = FALSE) {
  runwise_lm(dset, model, contrast_objects, robust = TRUE,
             verbose = verbose, use_fast_path = use_fast_path,
             progress = progress,
             cor_struct = cor_struct, cor_iter = cor_iter,
             cor_global = cor_global, ar_p = ar_p,
             ar1_exact_first = ar1_exact_first)
}

#' Fit a multiresponse robust linear model
#'
#' This function fits a robust linear model to multiple responses in an fMRI dataset.
#' Unlike the standard multiresponse_lm, this processes one response at a time due
#' to limitations of robust regression implementations.
#'
#' @param form The formula used to define the linear model.
#' @param data_env The environment containing the data to be used in the linear model.
#' @param conlist The list of contrasts used in the analysis.
#' @param vnames The names of the variables used in the linear model.
#' @param fcon The F-contrasts used in the analysis.
#' @param modmat The model matrix (default is NULL, which will calculate the model matrix using the formula).
#' @return A list containing the results from the multiresponse robust linear model analysis.
#' @keywords internal
#' @noRd
multiresponse_rlm <- function(form, data_env, conlist, vnames, fcon, modmat = NULL) {
  with_package("robustbase")
  Y <- data_env$.y
  ctrl <- robustbase::lmrob.control(k.max=500, maxit.scale=500)
  
  # Process each response variable separately
  results <- lapply(1:ncol(Y), function(i) {
    data_env$.y <- Y[,i]
    
    # Fit robust model
    fit <- if (is.null(modmat)) {
      robustbase::lmrob(as.formula(form), data = data_env, control = ctrl)
    } else {
      robustbase::lmrob(modmat, Y[,i], control = ctrl)
    }
    
    # Get contrasts and stats
    fit_lm_contrasts(fit, conlist, fcon, vnames)
  })
  
  # Combine results
  bstats <- lapply(results, function(x) x$bstats) %>% dplyr::bind_rows()
  contrasts <- lapply(results, function(x) x$contrasts) %>% dplyr::bind_rows()
  
  list(
    contrasts = contrasts,
    bstats = bstats
  )
}

#' Print method for fmri_rlm objects
#' 
#' @param x An fmri_rlm object
#' @param ... Additional arguments passed to print.fmri_lm
#' @export
#' @rdname print
print.fmri_rlm <- function(x, ...) {
  cat("\n═══ Robust fMRI Linear Model ═══\n")
  NextMethod()
}
</file>

<file path="R/hrf-afni.R">
#' @importFrom assertthat assert_that
#' @importFrom rlang enexpr
NULL

#' AFNI HRF Constructor Function
#'
#' @description
#' The `AFNI_HRF` function creates an object representing an AFNI-specific hemodynamic response function (HRF). It is a class constructor for AFNI HRFs.
#'
#' @param name A string specifying the name of the AFNI HRF.
#' @param nbasis An integer representing the number of basis functions for the AFNI HRF.
#' @param params A list containing the parameter values for the AFNI HRF.
#' @param span A numeric value representing the span in seconds of the HRF. Default is 24.
#'
#' @return An AFNI_HRF object with the specified properties.
#'
#' @seealso HRF
#'
#' @export
#' @rdname AFNI_HRF-class
AFNI_HRF <- function(name, nbasis, params, span = 24) {
  structure(name,
            nbasis = as.integer(nbasis),
            params = params,
            span = span,
            class = c("AFNI_HRF", "HRF"))
  
}


#' @export
as.character.AFNI_HRF <- function(x,...) {
  paste(x, "\\(", paste(attr(x, "params"), collapse=","), "\\)", sep="")
}

#' construct an native AFNI hrf specification for '3dDeconvolve' with the 'stim_times' argument.
#' 
#' @inheritParams hrf
#' @param start the start of the window for sin/poly/csplin models
#' @param stop the stop time for sin/poly/csplin models
#' @export
#' @return an \code{afni_hrfspec} instance
afni_hrf <- function(..., basis=c("spmg1", "block", "dmblock",
                                  "tent",   "csplin", "poly",  "sin",
                                  "gam", "spmg2", "spmg3", "wav"),
                                  onsets=NULL, durations=NULL, prefix=NULL, subset=NULL,
                                  nbasis=1, contrasts=NULL, id=NULL,
                                  lag=0, precision = 0.3, summate = TRUE,
                                  start=NULL, stop=NULL) {
  
  ## TODO cryptic error message when argument is mispelled and is then added to ...
  basis <- tolower(basis)
  if (basis == "sin") basis <- "sine"
  if (basis == "gam") basis <- "gamma"
  basis <- match.arg(basis)
  
  vars <- as.list(base::substitute(list(...)))[-1]
  # Convert raw expressions to quosures for compatibility with construct_event_term
  vars_quos <- lapply(vars, function(expr) rlang::new_quosure(expr, env = rlang::caller_env()))
  # Requires parse_term (assuming it exists elsewhere now or is removed)
  # parsed <- parse_term(vars, "afni_hrf") 
  # term <- parsed$term
  # label <- parsed$label
  # --- Need to replace parse_term dependency --- 
  # Simplified naming based on input expressions/symbols for now
  var_labels <- sapply(vars, rlang::as_label)
  varnames <- sapply(vars, function(v) {
       if (rlang::is_symbol(v)) as.character(v) else make.names(rlang::as_label(v))
  })
  term <- vars_quos # Store quosures instead of raw expressions
  label <- paste0("afni_hrf(", paste0(var_labels, collapse=","), ")")
  # --- End replacement --- 
  
  hrf <- if (!is.null(durations)) {
    assert_that(length(durations) == 1, msg="afni_hrf does not currently accept variable durations")
    get_AFNI_HRF(basis, nbasis=nbasis, duration=durations[1], b=start, c=stop)
  } else {
    get_AFNI_HRF(basis, nbasis=nbasis, b=start, c=stop)
  }
  
  
  # varnames <- if (!is.null(prefix)) {
  #   paste0(prefix, "_", term)
  # } else {
  #   term
  # } 
  # Use the new varnames logic
  if (!is.null(prefix)) {
      varnames <- paste0(prefix, "_", varnames)
  }
  
  termname <- paste0(varnames, collapse="::")
  
  if (is.null(id)) {
    id <- termname
  }  
  
  cset <- if (inherits(contrasts, "contrast_spec")) {
    contrast_set(con1=contrasts)
  } else if (inherits(contrasts, "contrast_set")) {
    contrasts
  } else { NULL } # Default to NULL if not correct type
  
  ret <- list(
    name=termname,
    id=id,
    varnames=varnames,
    vars=term, # Store original expressions/symbols
    label=label,
    hrf=hrf,
    onsets=onsets,
    durations=durations,
    prefix=prefix,
    subset=rlang::enexpr(subset), # Capture subset expression
    lag=lag,
    precision = precision,
    summate = summate,
    contrasts=cset)
  
  class(ret) <- c("afni_hrfspec", "hrfspec", "list")
  ret
  
}

#' construct a native AFNI hrf specification for '3dDeconvolve' and individually modulated events using the 'stim_times_IM' argument.
#' 
#' 
#' @param label name of regressor
#' @param start start of hrf (for multiple basis hrfs)
#' @param stop end of hrf (for multiple basis hrfs)
#' 
#' @inheritParams hrf
#' @examples 
#' 
#' 
#' tw <- afni_trialwise("trialwise", basis="gamma", onsets=seq(1,100,by=5))
#' 
#' @export
#' @return an \code{afni_trialwise_hrfspec} instance
afni_trialwise <- function(label, basis=c("spmg1", "block", "dmblock", "gamma", "wav"),
                     onsets=NULL, durations=0, subset=NULL,
                      id=NULL, start=0, stop=22,
                      precision = 0.3, summate = TRUE) {
  
  ## TODO cryptic error message when argument is mispelled and is then added to ...
  basis <- match.arg(basis)
  basis <- tolower(basis)
  if (basis == "gam") basis <- "gamma"
  
  hrf <- if (!is.null(durations)) {
    assert_that(length(durations) == 1, msg="afni_trialwise does not currently accept variable durations")
    get_AFNI_HRF(basis, nbasis=1, duration=durations[1], b=start, c=stop)
  } else {
    get_AFNI_HRF(basis, nbasis=1, b=start, c=stop)
  }
  
  
  if (is.null(id)) {
    id <- label
  }  
  
  ret <- list(
    name=label,
    varname=label,
    id=id,
    hrf=hrf,
    onsets=onsets,
    durations=durations,
    subset=rlang::enexpr(subset),
    precision = precision,
    summate = summate)
  
  class(ret) <- c("afni_trialwise_hrfspec", "hrfspec", "list")
  ret
  
}

#' @export
construct.afni_hrfspec <- function(x, model_spec, ...) {
  
  # Assuming construct_event_term is defined in event_model_helpers.R
  # Note: construct_event_term might need adaptation if afni_hrfspec structure differs slightly
  et <- construct_event_term(x, model_spec)
  
  ## do not convolve an afni term
  ##cterm <- convolve(et, x$hrf, model_spec$sampling_frame, summate=x$summate)
  
  ret <- list(
    varname=et$varname,
    evterm=et,
    sampling_frame=model_spec$sampling_frame,
    hrfspec=x,
    precision = x$precision,
    summate = x$summate,
    lag = x$lag,
    contrasts=x$contrasts,
    id=if(!is.null(x$id)) x$id else et$varname
  )
  
  class(ret) <- c("afni_hrf_convolved_term", "convolved_term", "fmri_term", "list") 
  ret
}


#' @export
construct.afni_trialwise_hrfspec <- function(x, model_spec, ...) {
  
  ## compied almost verbatim from construct.hrfspec
  onsets <- if (!is.null(x$onsets)) x$onsets else model_spec$onsets
  durations <- if (!is.null(x$durations)) x$durations else model_spec$durations
  
  trial_index <- factor(seq(1, length(onsets)))
  
  # Use the passed hrfspec varname (label)
  varlist <- list(trial_index)
  names(varlist) <- x$varname
  
  # Evaluate subset using model_spec$data and formula_env
  subs <- if (!is.null(x$subset) && !rlang::is_null(x$subset)) {
            eval_env <- rlang::env_bury(model_spec$formula_env %||% rlang::empty_env(), !!!model_spec$data)
            tryCatch(rlang::eval_tidy(x$subset, env = eval_env), 
                     error = function(e) stop(sprintf("Failed to evaluate subset expression for afni_trialwise term '%s': %s", x$name, e$message)))
          } else {
            rep(TRUE, length(onsets))
          }
  
  et <- event_term(varlist, onsets, model_spec$blockids, durations, subs)
  #cterm <- convolve(et, x$hrf, model_spec$sampling_frame)
  
  ret <- list(
    varname=et$varname,
    evterm=et,
    sampling_frame=model_spec$sampling_frame,
    hrfspec=x,
    precision = x$precision,
    summate = x$summate,
    id=x$id
  )
  
  class(ret) <- c("afni_trialwise_convolved_term", "convolved_term", "fmri_term", "list") 
  ret
}


#' @keywords internal
#' @noRd
AFNI_SPMG1 <- function(d=1) AFNI_HRF(name="SPMG1", nbasis=as.integer(1), params=list(d=d)) 

#' @keywords internal
#' @noRd
AFNI_SPMG2 <- function(d=1) AFNI_HRF(name="SPMG2", nbasis=as.integer(2), params=list(d=d))

#' @keywords internal
#' @noRd
AFNI_SPMG3 <- function(d=1) AFNI_HRF(name="SPMG3", nbasis=as.integer(3), params=list(d=d))

#' @keywords internal
#' @noRd
AFNI_BLOCK <- function(d=1,p=1) AFNI_HRF(name="BLOCK", nbasis=as.integer(1), params=list(d=d,p=p))

#' @keywords internal
#' @noRd
AFNI_dmBLOCK <- function(d=1,p=1) AFNI_HRF(name="dmBLOCK", nbasis=as.integer(1), params=list(d=d,p=p))

#' @keywords internal
#' @noRd
AFNI_TENT <- function(b=0,c=18, n=10) AFNI_HRF(name="TENT", nbasis=as.integer(n), params=list(b=b,c=c,n=n))

#' @keywords internal
#' @noRd
AFNI_CSPLIN <- function(b=0,c=18, n=6) AFNI_HRF(name="CSPLIN", nbasis=as.integer(n), params=list(b=b,c=c,n=n))

#' @keywords internal
#' @noRd
AFNI_POLY <- function(b=0,c=18, n=10) AFNI_HRF(name="POLY", nbasis=as.integer(n), params=list(b=b,c=c,n=n))

#' @keywords internal
#' @noRd
AFNI_SIN <- function(b=0,c=18, n=10) AFNI_HRF(name="SIN", nbasis=as.integer(n), params=list(b=b,c=c,n=n))

#' @keywords internal
#' @noRd
AFNI_GAM <- function(p=8.6,q=.547) AFNI_HRF(name="GAM", nbasis=as.integer(1), params=list(p=p,q=q))

#' @keywords internal
#' @noRd
AFNI_WAV <- function(d=1) AFNI_HRF(name="WAV", nbasis=as.integer(1), params=list(d=1))


#' @keywords internal
#' @noRd
get_AFNI_HRF <- function(name, nbasis=1, duration=1, b=0, c=18) {
  name <- tolower(name)
  if (name == "sin") name <- "sine"
  if (name == "gam") name <- "gamma"
  hrf <- switch(name,
                gamma=AFNI_GAM(),
                spmg1=AFNI_SPMG1(d=duration),
                spmg2=AFNI_SPMG2(d=duration),
                spmg3=AFNI_SPMG3(d=duration),
                csplin=AFNI_CSPLIN(b=b,c=c, n=nbasis),
                poly=AFNI_POLY(b=b,c=c, n=nbasis),
                sine=AFNI_SIN(b=b,c=c,n=nbasis),
                wav=AFNI_WAV(),
                block=AFNI_BLOCK(d=duration),
                dmblock=AFNI_dmBLOCK(),
                # Add tent as an alias or explicit entry
                tent=AFNI_TENT(b=b, c=c, n=nbasis))
  
  if (is.null(hrf)) {
    stop("could not find afni hrf named: ", name)
  }
  
  hrf
  
}
</file>

<file path="R/hrf-formula.R">
#' @importFrom rlang enquos enexpr syms is_formula is_quosure is_call as_label %||% quo_get_expr is_symbol
#' @importFrom assertthat assert_that
#' @importFrom stats setNames


#' @keywords internal
#' @noRd
make_hrf <- function(basis, lag, nbasis=1) {
  if (!is.numeric(lag) || length(lag) > 1) {
    stop("hrf: 'lag' must be a numeric scalar")
  }
  
  if (is.character(basis)) {
    # Resolve character name to a base HRF object or function using getHRF
    # Note: getHRF itself might need simplification later (Ticket 12)
    # but currently it calls gen_hrf internally for most types.
    base_hrf_obj <- getHRF(basis, nbasis=nbasis, lag=0)
    # Apply lag using gen_hrf
    final_hrf <- gen_hrf(base_hrf_obj, lag = lag)

  } else if (inherits(basis, "HRF")) {
    # If it's already an HRF object, apply lag using gen_hrf
    final_hrf <- gen_hrf(basis, lag = lag)
    
  } else if (is.function(basis)) {
    # If it's a raw function, gen_hrf will handle conversion via as_hrf and apply lag
    final_hrf <- gen_hrf(basis, lag = lag)

  } else {
    stop("invalid basis function: must be 1) character string indicating hrf type, e.g. 'gamma' 2) a function or 3) an object of class 'HRF': ", basis)
  }
  
  return(final_hrf)
}

#### TODO character variables need an "as.factor"

#' hemodynamic regressor specification function for model formulas.
#' 
#' This function is to be used in formulas for fitting functions, e.g. onsets ~ hrf(fac1,fac2) ...
#' It captures the variables/expressions provided and packages them with HRF/contrast 
#' information into an `hrfspec` object, which is then processed by `event_model`.
#' 
#' @param ... One or more variable names (bare or character) or expressions involving variables 
#'            present in the `data` argument of `event_model`.
#' @param basis the impulse response function or the name of a pre-supplied function, 
#'        one of: "gamma", "spmg1", "spmg2", "spmg3", "bspline", "gaussian", "tent", "bs". 
#'        Can also be an `HRF` object.
#' @param onsets optional onsets override. If missing, onsets will be taken from the LHS of the main model formula.
#' @param durations optional durations override. If missing, durations argument from `event_model` is used.
#' @param prefix a character string that is prepended to the variable names and used to identify the term. 
#'               Can be used to disambiguate two \code{hrf} terms with the same variable(s) but different onsets or basis functions.
#' @param subset an expression indicating the subset of 'onsets' to keep.
#' @param precision sampling precision in seconds.
#' @param nbasis number of basis functions -- only used for hemodynamic response functions (e.g. bspline) that take a variable number of bases.
#' @param contrasts one or more \code{contrast_spec} objects created with the \code{contrast}, `pair_contrast` etc. functions. 
#'                  Must be NULL, a single contrast spec, or a *named* list of contrast specs.
#' @param id a unique \code{character} identifier used to refer to term, otherwise will be determined from variable names.
#' @param name Optional human-readable name for the term.
#' @param lag a temporal offset in seconds which is added to onset before convolution
#' @param summate whether impulse amplitudes sum up when duration is greater than 0.
#' @examples 
#' 
#' ## 'hrf' is typically used in the context of \code{formula}s passed to `event_model`.
#' 
#' # Simple model with one factor
#' form1 <- onsets ~ hrf(condition, basis="spmg1")
#' 
#' # Model with factor and continuous modulator, using default SPMG1 for both terms
#' form2 <- onsets ~ hrf(condition) + hrf(RT)
#' 
#' # Model with interaction term and SPMG3 basis
#' form3 <- onsets ~ hrf(condition, RT, basis="spmg3")
#' 
#' # Model with an expression and contrasts
#' library(rlang)
#' con1 <- pair_contrast(~ condition == "A", ~ condition == "B", name="AvB")
#' form4 <- onsets ~ hrf(condition, Poly(RT, 2), contrasts=con1)
#' 
#' @export
#' @importFrom rlang enquos enexpr syms is_formula is_quosure is_call as_label %||%
#' @return an \code{hrfspec} instance
hrf <- function(..., basis="spmg1", onsets=NULL, durations=NULL, prefix=NULL, subset=NULL, precision=.3, 
                nbasis=1, contrasts=NULL, id=NULL, name=NULL, lag=0, summate=TRUE) {
  
  vars <- rlang::enquos(...) # Capture variables/expressions as quosures
  
  # --- Handle special named arguments within ... ---
  var_names <- names(vars)
  # Remove any quosures whose name matches hrf formals (these are control args, not vars)
  hrf_formals <- names(formals(hrf))
  var_indices <- ! (var_names %in% hrf_formals)
  vars <- vars[var_indices]
  
  if (length(vars) == 0) {
      stop("`hrf` must have at least one variable or expression specified in `...`")
  }
  
  # --- Determine Term ID/Name (Prioritize id, then name, then auto) --- 
  final_id <- id # Prioritize explicit id
  if (is.null(final_id) && !is.null(name)) { # Use name if id is missing
      final_id <- name
  }
  # final_id remains NULL if neither id nor name provided, hrfspec will generate default
  
  # --- Check contrasts argument --- 
  if (!is.null(contrasts)) {
    if (!is.list(contrasts)) {
        if (inherits(contrasts, "contrast_spec")) {
            contrast_list <- list(contrasts)
            cname <- contrasts$name %||% "contrast1"
            names(contrast_list) <- cname
            contrasts <- contrast_list
        } else {
             stop("`contrasts=` argument must be a single contrast_spec object or a list of them.\n",
                  "  Detected type: ", class(contrasts)[1], "\n",
                  "  Hint: Use functions like contrast(), pair_contrast(), contrast_set() to define contrasts.", 
                  call. = FALSE)
        }
    } else {
        is_spec <- vapply(contrasts, inherits, logical(1), "contrast_spec")
        if (!all(is_spec)) {
             stop("If `contrasts=` is a list, all elements must be contrast_spec objects.\n",
                  "  Hint: Use functions like contrast(), pair_contrast(), contrast_set() to define contrasts.", 
                  call. = FALSE)
        }
        if (is.null(names(contrasts)) || any(names(contrasts) == "")) {
            cnames <- sapply(contrasts, function(cs) cs$name %||% paste0("contrast", which(sapply(contrasts, identical, cs))))
             if (any(duplicated(cnames))) {
                stop("If `contrasts=` is a list, it must be a *named* list (or auto-naming must yield unique names).", call. = FALSE)
            }
            names(contrasts) <- cnames
        }
    }
  }
  # -----------------------------
  
  basis_obj <- make_hrf(basis, lag, nbasis=nbasis)
  
  # Call the internal constructor, passing quosures directly
  ret <- hrfspec(
    vars = vars, # Pass list of quosures captured by enquos
    basis = basis_obj,         
    onsets = onsets,       
    durations = durations, 
    prefix = prefix,       
    subset = rlang::enexpr(subset), # Capture subset expr unevaluated
    precision = precision,
    contrasts = contrasts, ## Pass validated list of contrast specs
    summate = summate,
    id = final_id # Pass the determined ID 
    )

  ret
}


#' Internal constructor for hrfspec objects
#' 
#' Creates the hrfspec list structure. Called by `hrf()`.
#' Generates termname and label from the input variables/expressions.
#'
#' @param vars List of quosures representing variables/expressions.
#' @param label Optional label for the term (if NULL, generated automatically).
#' @param basis An `HRF` object.
#' @param ... Other arguments passed from `hrf()` (onsets, durations, prefix, subset, etc.)
#' @return An `hrfspec` instance (list with class `hrfspec`).
#' @importFrom rlang as_label is_symbol is_call quo_get_expr
#' @noRd
#' @keywords internal
hrfspec <- function(vars, label=NULL, basis=HRF_SPMG1, ...) {

  assert_that(inherits(basis, "HRF"))
  
  # Generate varnames and termname from quosures
  var_labels <- sapply(vars, rlang::as_label)
  # Simple heuristic for names: use symbol directly, otherwise make.names on label
  varnames <- sapply(vars, function(q) {
       expr <- rlang::quo_get_expr(q)
       if (rlang::is_symbol(expr)) as.character(expr) else make.names(rlang::as_label(expr))
  })
  
  termname <- paste0(varnames, collapse=":")
  
  # Generate label if not provided
  if (is.null(label)) {
      label <- paste0("hrf(", paste0(var_labels, collapse=","), ")")
  }
  
  # Capture other arguments passed via ... from hrf()
  other_args <- list(...)
  
  ret <- list(
    name = termname, 
    label = label,
    id = other_args$id,
    vars = vars,
    varnames = varnames, 
    hrf = basis,
    onsets = other_args$onsets,
    durations = other_args$durations,
    prefix = other_args$prefix,
    subset = other_args$subset, # Should be an expression
    precision = other_args$precision %||% 0.3,
    contrasts = other_args$contrasts, # Already validated list or NULL
    summate = other_args$summate %||% TRUE
    # data_env is NOT stored here, added later during evaluation
  )
  
  # If user supplied an explicit id (or via name= alias), use it as the primary term name
  if (!is.null(other_args$id)) {
      ret$name <- other_args$id
  }
  
  class(ret) <- c("hrfspec", "list")
  ret
}



#' @export
nbasis.hrfspec <- function(x, ...) {
  nbasis(x$hrf)
}

#' @export
construct.hrfspec <- function(x, model_spec, ...) {
  ons <- if (!is.null(x$onsets)) x$onsets else model_spec$onsets
  et <- construct_event_term(x, model_spec)
  
  # Set the term_tag attribute on the event_term before returning
  # This ensures that when convolution happens later, the correct column names are generated
  term_tag <- x$id %||% x$name
  attr(et, "term_tag") <- term_tag
  
  # DON'T convolve here - let build_event_model_design_matrix handle convolution
  # Just return the event_term with hrfspec attached
  # The hrfspec is already attached in construct_event_term
  
  # Handle add_sum flag if present in the hrfspec (set by trialwise)
  # Store this as an attribute for later processing during convolution
  if (isTRUE(x$add_sum)) {
    attr(et, "add_sum") <- TRUE
    attr(et, "add_sum_label") <- x$id %||% x$name
  }

  # Return the event_term directly, not a convolved_term
  et
}

#' evaluate.hrfspec
#'
#' This function evaluates a hemodynamic response function (HRF) specified by an hrfspec object for a given set of time points (grid) and other parameters.
#' It is a wrapper function that calls the evaluate.HRF function with the HRF function contained in the hrfspec object.
#'
#' @param x The hrfspec object containing the HRF function.
#' @param grid A vector of time points.
#' @param amplitude The scaling value for the event (default: 1).
#' @param duration The duration of the event (default: 0).
#' @param precision The temporal resolution used for computing summed responses when duration > 0 (default: 0.1).
#' @param ... Additional arguments to be passed to the evaluate.HRF function.
#' @return A vector of HRF values at the specified time points.
#' @noRd
evaluate.hrfspec <- function(x, grid, amplitude=1, duration=0, precision=.1, ...) {
  evaluate(x$hrf, grid,amplitude, duration, precision)
}

#' trialwise
#'
#' Generate one regressor per trial (plus an optional grand-mean column)
#' by delegating everything to `hrf()`.
#'
#' Use it **only on the RHS** of an event-model formula:
#'
#'     onset ~ trialwise(basis = "spmg1", add_sum = TRUE)
#'
#' @param basis,lag,nbasis Passed straight to `hrf()`.
#' @param add_sum If TRUE, append a column that is the average of all
#'                trialwise columns (useful as a conventional main effect).
#' @param label Term label / prefix for the generated columns.
#' @export
trialwise <- function(basis   = "spmg1",
                      lag     = 0,
                      nbasis  = 1,
                      add_sum = FALSE,
                      label   = "trial") {

  # Create an expression that will evaluate .trial_factor(length(onsets)) 
  # when the onsets variable is available at evaluation time
  trial_expr <- rlang::expr(.trial_factor(length(onsets)))

  term <- hrf(!!trial_expr,  # Use !! to inject the expression
              basis = basis,
              lag   = lag,
              nbasis = nbasis,
              id     = label) # Use id argument for naming

  term$add_sum <- isTRUE(add_sum) # flag for construct() to act upon
  term
}

#' Internal helper for generating trial factors
#'
#' @param n Length of the factor to generate.
#' @keywords internal
.trial_factor <- function(n) {
  pad <- nchar(as.character(n))
  factor(sprintf(paste0("%0", pad, "d"), seq_len(n)))
}
</file>

<file path="R/hrf-functions.R">
#' @importFrom splines bs
#' @importFrom stats dgamma dnorm quantile
NULL

#' HRF (hemodynamic response function) as a linear function of time
#'
#' The `hrf_time` function computes the value of an HRF, which is a simple linear function of time `t`, when `t` is greater than 0 and less than `maxt`.
#'
#' @param t A numeric value representing time in seconds.
#' @param maxt A numeric value representing the maximum time point in the domain. Default value is 22.
#' @return A numeric value representing the value of the HRF at the given time `t`.
#' @family hrf_functions
#' @export
#' @examples
#' # Compute the HRF value for t = 5 seconds with the default maximum time
#' hrf_val <- hrf_time(5)
#'
#' # Compute the HRF value for t = 5 seconds with a custom maximum time of 30 seconds
#' hrf_val_custom_maxt <- hrf_time(5, maxt = 30)
hrf_time <- function(t, maxt=22) {
  ifelse(t > 0 & t < maxt, t, 0)
}

# hrf_ident
# 
# @param t time in seconds
# @export
hrf_ident <- function(t) {
  ifelse( t == 0, 1, 0)
}

#' B-spline HRF (hemodynamic response function)
#'
#' The `hrf_bspline` function computes the B-spline representation of an HRF (hemodynamic response function) at given time points `t`.
#'
#' @param t A vector of time points.
#' @param span A numeric value representing the temporal window over which the basis set spans. Default value is 20.
#' @param N An integer representing the number of basis functions. Default value is 5.
#' @param degree An integer representing the degree of the spline. Default value is 3.
#' @return A matrix representing the B-spline basis for the HRF at the given time points `t`.
#' @family hrf_functions
#' @examples
#' # Compute the B-spline HRF representation for time points from 0 to 20 with 0.5 increments
#' hrfb <- hrf_bspline(seq(0, 20, by = .5), N = 4, degree = 2)
#' @export
#' @importFrom splines bs
#' @param ... Additional arguments passed to `splines::bs`.
hrf_bspline <- function(t, span=24, N=5, degree=3, ...) {
	
	ord <- 1 + degree
	# Check if requested N is sufficient for the degree
	if (N < ord) {
	    warning(paste0("Requested N=", N, " basis functions is less than degree+1=", ord, ". ",
	                   "Using minimum required of ", ord, " basis functions."))
	    # We don't change N here, let splines::bs handle the df inconsistency if needed,
	    # but the warning informs the user.
	}
	
	nIknots <- N - ord + 1
	if (nIknots < 0) {
		nIknots <- 0
		#warning("'df' was too small; have used  ", ord - (1 - intercept))
	}
	
	knots <- if (nIknots > 0) {
				knots <- seq.int(from = 0, to = 1, length.out = nIknots + 2)[-c(1, nIknots + 2)]
				stats::quantile(seq(0,span), knots)
			} else {
				0
			}
	
	if (any(t < 0)) {
		t[t < 0] <- 0
	}
	
	if(any(t > span)) {
		t[t > span] <- 0
	}
	
	splines::bs(t, df=N, knots=knots, degree=degree, Boundary.knots=c(0,span),...)
}


#' Gamma HRF (hemodynamic response function)
#'
#' The `hrf_gamma` function computes the gamma density-based HRF (hemodynamic response function) at given time points `t`.
#'
#' @param t A vector of time points.
#' @param shape A numeric value representing the shape parameter for the gamma probability density function. Default value is 6.
#' @param rate A numeric value representing the rate parameter for the gamma probability density function. Default value is 1.
#' @return A numeric vector representing the gamma HRF at the given time points `t`.
#' @family hrf_functions
#' @examples
#' # Compute the gamma HRF representation for time points from 0 to 20 with 0.5 increments
#' hrf_gamma_vals <- hrf_gamma(seq(0, 20, by = .5), shape = 6, rate = 1)
#' @export
hrf_gamma <- function(t, shape=6, rate=1) {
  stats::dgamma(t, shape=shape, rate=rate)
}

#' Gaussian HRF (hemodynamic response function)
#'
#' The `hrf_gaussian` function computes the Gaussian density-based HRF (hemodynamic response function) at given time points `t`.
#'
#' @param t A vector of time points.
#' @param mean A numeric value representing the mean of the Gaussian probability density function. Default value is 6.
#' @param sd A numeric value representing the standard deviation of the Gaussian probability density function. Default value is 2.
#' @return A numeric vector representing the Gaussian HRF at the given time points `t`.
#' @family hrf_functions
#' @examples
#' # Compute the Gaussian HRF representation for time points from 0 to 20 with 0.5 increments
#' hrf_gaussian_vals <- hrf_gaussian(seq(0, 20, by = .5), mean = 6, sd = 2)
#' @export
hrf_gaussian <- function(t, mean=6, sd=2) {
	stats::dnorm(t, mean=mean, sd=sd)
}



#' Mexican Hat HRF (hemodynamic response function)
#'
#' The `hrf_mexhat` function computes the Mexican hat wavelet-based HRF (hemodynamic response function) at given time points `t`.
#'
#' @param t A vector of time points.
#' @param mean A numeric value representing the mean of the Mexican hat wavelet. Default value is 6.
#' @param sd A numeric value representing the standard deviation of the Mexican hat wavelet. Default value is 2.
#' @return A numeric vector representing the Mexican hat wavelet-based HRF at the given time points `t`.
#' @family hrf_functions
#' @examples
#' # Compute the Mexican hat HRF representation for time points from 0 to 20 with 0.5 increments
#' hrf_mexhat_vals <- hrf_mexhat(seq(0, 20, by = .5), mean = 6, sd = 2)
#' @export
hrf_mexhat <- function(t, mean = 6, sd = 2) {
  t0 <- t - mean
  a <- (1 - (t0 / sd)^2) * exp(-t0^2 / (2 * sd^2))
  scale <- sqrt(2 / (3 * sd * pi^(1/4)))
  return(scale * a)
}

#' hrf_spmg1
#'
#' A hemodynamic response function based on the SPM canonical double gamma parameterization.
#'
#' This function models the hemodynamic response using the canonical double gamma parameterization
#' in the SPM software. The HRF is defined by a linear combination of two gamma functions with
#' different exponents (P1 and P2) and amplitudes (A1 and A2). It is commonly used in fMRI data
#' analysis to estimate the BOLD (blood-oxygen-level-dependent) signal changes associated with
#' neural activity.
#'
#' @param t A vector of time points.
#' @param P1 The first exponent parameter (default: 5).
#' @param P2 The second exponent parameter (default: 15).
#' @param A1 Amplitude scaling factor for the positive gamma function component; normally fixed at .0833
#' @return A vector of HRF values at the given time points.
#' @family hrf_functions
#' @export
#' @examples
#' # Generate a time vector
#' time_points <- seq(0, 30, by=0.1)
#' # Compute the HRF values using the SPM canonical double gamma parameterization
#' hrf_values <- hrf_spmg1(time_points)
#' # Plot the HRF values
#' plot(time_points, hrf_values, type='l', main='SPM Canonical Double Gamma HRF')
hrf_spmg1 <- function(t, P1=5, P2=15,A1=.0833) {
 	ifelse(t < 0, 0, exp(-t)*(A1*t^P1 - 1.274527e-13*t^P2))
	
}


# Fast analytic first derivative for hrf_spmg1
#' @keywords internal
#' @noRd
hrf_spmg1_deriv <- function(t, P1 = 5, P2 = 15, A1 = .0833) {
  C <- 1.274527e-13
  ret <- numeric(length(t))
  pos <- t >= 0
  if (any(pos)) {
    t_pos <- t[pos]
    ret[pos] <- exp(-t_pos) * (A1 * t_pos^(P1 - 1) * (P1 - t_pos) -
                                 C   * t_pos^(P2 - 1) * (P2 - t_pos))
  }
  ret
}

# Fast analytic second derivative for hrf_spmg1
#' @keywords internal
#' @noRd
hrf_spmg1_second_deriv <- function(t, P1 = 5, P2 = 15, A1 = .0833) {
  C <- 1.274527e-13
  ret <- numeric(length(t))
  pos <- t >= 0
  if (any(pos)) {
    t_pos <- t[pos]
    # Let D1 = A1 * t^(P1-1) * (P1 - t) and D2 = C * t^(P2-1) * (P2 - t)
    D1 <- A1 * t_pos^(P1 - 1) * (P1 - t_pos)
    D2 <- C   * t_pos^(P2 - 1) * (P2 - t_pos)
    # Their derivatives:
    D1_prime <- A1 * ((P1 - 1) * t_pos^(P1 - 2) * (P1 - t_pos) - t_pos^(P1 - 1))
    D2_prime <- C   * ((P2 - 1) * t_pos^(P2 - 2) * (P2 - t_pos) - t_pos^(P2 - 1))
    ret[pos] <- exp(-t_pos) * (D1_prime - D2_prime - (D1 - D2))
  }
  ret
}

#' hrf_sine
#'
#' A hemodynamic response function using the Sine Basis Set.
#'
#' @param t A vector of times.
#' @param span The temporal window over which the basis sets span (default: 24).
#' @param N The number of basis functions (default: 5).
#' @return A matrix of sine basis functions.
#' @family hrf_functions
#' @export
#' @examples
#' hrf_sine_basis <- hrf_sine(seq(0, 20, by = 0.5), N = 4)
hrf_sine <- function(t, span = 24, N = 5) {
  sine_basis <- sapply(1:N, function(n) {
    sin(2 * pi * n * t / span)
  })
  return(sine_basis)
}

#' hrf_inv_logit
#'
#' A hemodynamic response function using the difference of two Inverse Logit functions.
#'
#' @param t A vector of times.
#' @param mu1 The time-to-peak for the rising phase (mean of the first logistic function).
#' @param s1 The width (slope) of the first logistic function.
#' @param mu2 The time-to-peak for the falling phase (mean of the second logistic function).
#' @param s2 The width (slope) of the second logistic function.
#' @param lag The time delay (default: 0).
#' @return A vector of the difference of two Inverse Logit HRF values.
#' @family hrf_functions
#' @export
#' @examples
#' hrf_inv_logit_basis <- hrf_inv_logit(seq(0, 20, by = 0.5), mu1 = 6, s1 = 1, mu2 = 16, s2 = 1)
hrf_inv_logit <- function(t, mu1 = 6, s1 = 1, mu2 = 16, s2 = 1, lag = 0) {
  inv_logit1 <- 1 / (1 + exp(-(t - lag - mu1) / s1))
  inv_logit2 <- 1 / (1 + exp(-(t - lag - mu2) / s2))
  return(inv_logit1 - inv_logit2)
}


#' Hemodynamic Response Function with Half-Cosine Basis
#'
#' This function models a hemodynamic response function (HRF) using four half-period cosine basis functions.
#' The HRF consists of an initial dip, a rise to peak, a fall and undershoot, and a recovery to the baseline.
#'
#' @param t A vector of time values.
#' @param h1 Duration of the initial dip in seconds.
#' @param h2 Duration of the rise to peak in seconds.
#' @param h3 Duration of the fall and undershoot in seconds.
#' @param h4 Duration of the recovery to baseline in seconds.
#' @param f1 Height of the starting point.
#' @param f2 Height of the end point.
#' @return A vector of HRF values corresponding to the input time values.
#' @references Woolrich, M. W., Behrens, T. E., & Smith, S. M. (2004). Constrained linear basis sets for HRF modelling using Variational Bayes. NeuroImage, 21(4), 1748-1761.
#' @export
hrf_half_cosine <- function(t, h1=1, h2=5, h3=7,h4=7, f1=0, f2=0) {
  rising_half_cosine <- function(t, f1, t0, w) {
    return(f1/2 * (1 - cos(pi * (t - t0) / w)))
  }
  
  falling_half_cosine <- function(t, f1, t0, w) {
    return(f1/2 * (1 + cos(pi * (t - t0) / w)))
  }
  
  ret = dplyr::case_when(
    t < 0 ~ 0,
    t <= h1 ~ falling_half_cosine(t, f1, 0, h1),
    (t > h1) & t <= (h1+h2) ~ rising_half_cosine(t, 1, h1, h2),
    (t > (h1+h2)) & t <= (h1+h2+h3) ~ falling_half_cosine(t,1,(h1+h2), h3),
    (t > (h1+h2+h3)) & t <= (h1+h2+h3+h4) ~ rising_half_cosine(t,f2,(h1+h2+h3), h4),
    (t > h1+h2+h3+h4) ~ f2,
  )
  return(ret)
}

#' Fourier basis for HRF modeling
#'
#' Generates a set of Fourier basis functions (sine and cosine pairs) over a given span.
#'
#' @param t A vector of time points.
#' @param span The temporal window over which the basis functions span (default: 24).
#' @param nbasis The number of basis functions (default: 5). Should be even for full sine-cosine pairs.
#' @return A matrix of Fourier basis functions with nbasis columns.
#' @export
hrf_fourier <- function(t, span = 24, nbasis = 5) {
  freqs <- ceiling(seq_len(nbasis) / 2)
  basis <- sapply(seq_len(nbasis), function(k) {
    n <- freqs[k]
    if (k %% 2 == 1) {
      sin(2 * pi * n * t / span)
    } else {
      cos(2 * pi * n * t / span)
    }
  })
  return(basis)
}



#' HRF Toeplitz Matrix
#' 
#' @description
#' Create a Toeplitz matrix for hemodynamic response function (HRF) convolution.
#' 
#' @param hrf The hemodynamic response function.
#' @param time A numeric vector representing the time points.
#' @param len The length of the output Toeplitz matrix.
#' @param sparse Logical, if TRUE, the output Toeplitz matrix is returned as a sparse matrix (default: FALSE).
#' 
#' @return A Toeplitz matrix for HRF convolution.
#' @export
hrf_toeplitz <- function(hrf, time, len, sparse=FALSE) {
  hreg <- hrf(time)
  padding <- len - length(hreg)
  H <- pracma::Toeplitz(c(hreg, rep(0, padding)), c(hreg[1], rep(0, len-1)))
  H <- Matrix::Matrix(H, sparse=sparse)
  H
}


#' Generate Daguerre spherical basis functions
#' 
#' @description
#' Creates a set of Daguerre spherical basis functions. These are orthogonal 
#' polynomials on [0,∞) with respect to the weight function w(x) = x^2 * exp(-x).
#' They are particularly useful for modeling hemodynamic responses as they naturally
#' decay to zero and can capture various response shapes.
#'
#' @param t Time points at which to evaluate the basis functions
#' @param n_basis Number of basis functions to generate (default: 3)
#' @param scale Scale parameter for the time axis (default: 1)
#' @return A matrix with columns containing the basis functions
#' @keywords internal
#' @noRd
daguerre_basis <- function(t, n_basis = 3, scale = 1) {
  # Scale time
  x <- t/scale
  
  # Initialize basis matrix
  basis <- matrix(0, length(x), n_basis)
  
  # First basis function (n=0)
  basis[,1] <- exp(-x/2)
  
  if(n_basis > 1) {
    # Second basis function (n=1)
    basis[,2] <- (1 - x) * exp(-x/2)
  }
  
  if(n_basis > 2) {
    # Higher order basis functions using recurrence relation
    for(n in 3:n_basis) {
      k <- n - 1
      basis[,n] <- ((2*k - 1 - x) * basis[,n-1] - (k - 1) * basis[,n-2]) / k
    }
  }
  
  # Normalize basis functions
  for(i in 1:n_basis) {
    # Avoid division by zero if a basis function is all zero
    max_abs_val <- max(abs(basis[,i]))
    if (max_abs_val > 1e-10) {
      basis[,i] <- basis[,i] / max_abs_val
    }
  }
  
  basis
}

#' Lag-Width-Undershoot (LWU) HRF
#'
#' Computes the Lag-Width-Undershoot (LWU) hemodynamic response function.
#' This model uses two Gaussian components to model the main response and an optional undershoot.
#' The formula is:
#' \\deqn{h(t; \\tau, \\sigma, \\rho) = e^{-\\frac{(t-\\tau)^2}{2\\sigma^{2}}} - \\rho e^{-\\frac{(t-\\tau-2\\sigma)^2}{2(1.6\\sigma)^{2}}}}
#'
#' @param t A numeric vector of time points (in seconds).
#' @param tau Lag of the main Gaussian component (time-to-peak of the positive lobe, in seconds). Default: 6.
#' @param sigma Width (standard deviation) of the main Gaussian component (in seconds). Must be > 0.05. Default: 2.5.
#' @param rho Amplitude of the undershoot Gaussian component, relative to the main component. Must be between 0 and 1.5. Default: 0.35.
#' @param normalize Character string specifying normalization type:
#'   \\itemize{
#'     \\item{\\code{"none"}: No normalization is applied (default).}
#'     \\item{\\code{"height"}: The HRF is scaled so that its maximum absolute value is 1.}
#'   }
#' @return A numeric vector representing the LWU HRF values at the given time points `t`.
#' @family hrf_functions
#' @export
#' @examples
#' t_points <- seq(0, 30, by = 0.1)
#'
#' # Default LWU HRF
#' lwu_default <- hrf_lwu(t_points)
#' plot(t_points, lwu_default, type = "l", main = "LWU HRF (Default Params)", ylab = "Amplitude")
#'
#' # LWU HRF with no undershoot
#' lwu_no_undershoot <- hrf_lwu(t_points, rho = 0)
#' lines(t_points, lwu_no_undershoot, col = "blue")
#'
#' # LWU HRF with a wider main peak and larger undershoot
#' lwu_custom <- hrf_lwu(t_points, tau = 7, sigma = 1.5, rho = 0.5)
#' lines(t_points, lwu_custom, col = "red")
#' legend("topright", c("Default", "No Undershoot (rho=0)", "Custom (tau=7, sigma=1.5, rho=0.5)"),
#'        col = c("black", "blue", "red"), lty = 1, cex = 0.8)
#'
#' # Height-normalized HRF
#' lwu_normalized <- hrf_lwu(t_points, tau = 6, sigma = 1, rho = 0.35, normalize = "height")
#' plot(t_points, lwu_normalized, type = "l", main = "Height-Normalized LWU HRF", ylab = "Amplitude")
#' abline(h = c(-1, 1), lty = 2, col = "grey") # Max absolute value should be 1
hrf_lwu <- function(t, tau = 6, sigma = 2.5, rho = 0.35, normalize = "none") {
  assertthat::assert_that(is.numeric(t), msg = "`t` must be numeric.")
  assertthat::assert_that(is.numeric(tau) && length(tau) == 1, msg = "`tau` must be a single numeric value.")
  assertthat::assert_that(is.numeric(sigma) && length(sigma) == 1, msg = "`sigma` must be a single numeric value.")
  assertthat::assert_that(sigma > 0.05, msg = "`sigma` must be > 0.05.")
  assertthat::assert_that(is.numeric(rho) && length(rho) == 1, msg = "`rho` must be a single numeric value.")
  assertthat::assert_that(rho >= 0 && rho <= 1.5, msg = "`rho` must be between 0 and 1.5.")
  assertthat::assert_that(normalize %in% c("none", "height", "area"),
                        msg = "`normalize` must be one of 'none', 'height', or 'area'.")

  if (normalize == "area") {
    warning("`normalize = \"area\"` is not yet fully implemented for hrf_lwu and will behave like `normalize = \"none\"`. Area normalization typically requires numerical integration and careful definition of the integration window for HRFs.", call. = FALSE)
    normalize <- "none"
  }

  # Main positive Gaussian component
  term1_exponent <- -((t - tau)^2) / (2 * sigma^2)
  term1 <- exp(term1_exponent)

  # Undershoot Gaussian component
  # tau_u = tau + 2*sigma (peak of undershoot relative to stimulus onset)
  # sigma_u = 1.6*sigma (width of undershoot)
  term2_exponent <- -((t - (tau + 2 * sigma))^2) / (2 * (1.6 * sigma)^2)
  term2 <- rho * exp(term2_exponent)

  response <- term1 - term2

  if (normalize == "height") {
    max_abs_val <- max(abs(response), na.rm = TRUE)
    if (max_abs_val > 1e-10) { # Avoid division by zero or tiny numbers
      response <- response / max_abs_val
    }
  }

  return(response)
}

#' LWU HRF Basis for Taylor Expansion
#'
#' Constructs the basis set for the Lag-Width-Undershoot (LWU) HRF model,
#' intended for Taylor expansion-based fitting. The basis consists of the
#' LWU HRF evaluated at a given expansion point \code{theta0}, and its
#' partial derivatives with respect to its parameters (tau, sigma, rho).
#'
#' @param theta0 A numeric vector of length 3 specifying the expansion point
#'   \code{c(tau0, sigma0, rho0)} for the LWU parameters.
#' @param t A numeric vector of time points (in seconds) at which to evaluate the basis.
#' @param normalize_primary Character string, one of \code{"none"} or \code{"height"}.
#'   If \code{"height"}, the primary HRF column (\code{h0(t)}) is normalized to have a
#'   peak absolute value of 1. For Taylor expansion fitting as described in Fit_LRU.md,
#'   this should typically be \code{"none"} as the scaling is absorbed by the beta coefficient.
#'   Default is \code{"none"}.
#' @return A numeric matrix of dimension \code{length(t) x 4}. Columns are:
#'   \\itemize{
#'     \\item{\\code{h0}: LWU HRF evaluated at \code{theta0}, \\eqn{h(t; \\tau_0, \\sigma_0, \\rho_0)}}
#'     \\item{\\code{d_tau}: Partial derivative \\eqn{\\partial h / \\partial \\tau} evaluated at \code{theta0}}
#'     \\item{\\code{d_sigma}: Partial derivative \\eqn{\\partial h / \\partial \\sigma} evaluated at \code{theta0}}
#'     \\item{\\code{d_rho}: Partial derivative \\eqn{\\partial h / \\partial \\rho} evaluated at \code{theta0}}
#'   }
#' @family hrf_functions
#' @seealso \code{\link{hrf_lwu}}, \code{\link[numDeriv]{grad}}
#' @export
#' @importFrom numDeriv grad
#' @examples
#' t_points <- seq(0, 30, by = 0.5)
#' theta0_default <- c(tau = 6, sigma = 1, rho = 0.35)
#'
#' # Generate the basis set
#' lwu_basis <- hrf_basis_lwu(theta0_default, t_points)
#' dim(lwu_basis) # Should be length(t_points) x 4
#' head(lwu_basis)
#'
#' # Plot the basis functions
#' matplot(t_points, lwu_basis, type = "l", lty = 1,
#'         main = "LWU HRF Basis Functions", ylab = "Value", xlab = "Time (s)")
#' legend("topright", colnames(lwu_basis), col = 1:4, lty = 1, cex = 0.8)
#'
#' # Example with primary HRF normalization (not typical for Taylor fitting step)
#' lwu_basis_norm_h0 <- hrf_basis_lwu(theta0_default, t_points, normalize_primary = "height")
#' plot(t_points, lwu_basis_norm_h0[,1], type="l", main="Normalized h0 in Basis")
#' max(abs(lwu_basis_norm_h0[,1])) # Should be 1
hrf_basis_lwu <- function(theta0, t, normalize_primary = "none") {
  assertthat::assert_that(is.numeric(theta0) && length(theta0) == 3,
                        msg = "`theta0` must be a numeric vector of length 3: c(tau, sigma, rho).")
  names(theta0) <- c("tau", "sigma", "rho") # Ensure names for numDeriv::grad
  assertthat::assert_that(is.numeric(t), msg = "`t` must be numeric.")
  assertthat::assert_that(normalize_primary %in% c("none", "height"),
                        msg = "`normalize_primary` must be one of 'none' or 'height'.")

  # Safety checks for sigma0 and rho0 from theta0, consistent with hrf_lwu
  assertthat::assert_that(theta0["sigma"] > 0.05, msg = "sigma in `theta0` must be > 0.05.")
  assertthat::assert_that(theta0["rho"] >= 0 && theta0["rho"] <= 1.5,
                        msg = "rho in `theta0` must be between 0 and 1.5.")

  # Function to pass to numDeriv::grad - parameters must be the first argument
  # and it must return a scalar or vector (hrf_lwu returns a vector of length(t_val))
  target_func_for_grad <- function(params_vec, t_val) {
    hrf_lwu(t = t_val, tau = params_vec[1], sigma = params_vec[2], rho = params_vec[3], normalize = "none")
  }

  # Calculate h0 (the HRF at theta0)
  h0 <- hrf_lwu(t = t, tau = theta0["tau"], sigma = theta0["sigma"], rho = theta0["rho"], normalize = "none")

  if (normalize_primary == "height") {
    max_abs_h0 <- max(abs(h0), na.rm = TRUE)
    if (max_abs_h0 > 1e-10) {
      h0 <- h0 / max_abs_h0
    }
  }

  # Calculate partial derivatives using numDeriv::grad
  # grad() will iterate over each element of `t` if `target_func_for_grad` is vectorized over t,
  # which it is. We want the gradient for each time point.
  # However, numDeriv::grad expects the function to return a single scalar for jacobian calculation.
  # So, we must loop over t points for numDeriv.

  deriv_matrix <- matrix(NA, nrow = length(t), ncol = 3)
  colnames(deriv_matrix) <- c("d_tau", "d_sigma", "d_rho")

  for (i in seq_along(t)) {
    # numDeriv::grad needs a function that takes params and returns a SINGLE value
    # So we create a wrapper for each time point t[i]
    current_t_func <- function(params_vec) {
      hrf_lwu(t = t[i], tau = params_vec[1], sigma = params_vec[2], rho = params_vec[3], normalize = "none")
    }
    # Calculate gradient (vector of 3 partial derivatives) at t[i] w.r.t theta0
    grad_at_t_i <- numDeriv::grad(func = current_t_func, x = theta0)
    deriv_matrix[i, ] <- grad_at_t_i
  }

  basis_mat <- cbind(h0 = h0, deriv_matrix)
  return(basis_mat)
}
</file>

<file path="tests/testthat/test_runwise_ar_fit.R">
context("runwise AR prewhitening")

options(mc.cores=1)

etab <- data.frame(onset=c(1,10), repnum=factor(c("A","B")), run=c(1,1))
Y <- matrix(rnorm(20*3), 20, 3)
dset <- matrix_dataset(Y, TR=1, run_length=20, event_table=etab)

test_that("fmri_lm runwise AR1 fits without error", {
  expect_error(
    fmri_lm(onset ~ hrf(repnum), block = ~ run, dataset = dset,
            use_fast_path = TRUE,
            cor_struct = "ar1", cor_iter = 2, ar1_exact_first = TRUE),
    NA
  )
})

test_that("fmri_lm runwise AR1 global fits without error", {
  expect_error(
    fmri_lm(onset ~ hrf(repnum), block = ~ run, dataset = dset,
            use_fast_path = TRUE,
            cor_struct = "ar1", cor_global = TRUE),
    NA
  )
})
</file>

<file path="R/reg-methods.R">
# Evaluate method for Reg objects
#' 
#' This is the primary method for evaluating regressor objects created by the `Reg` constructor
#' (and thus also works for objects created by `regressor`).
#' It dispatches to different internal methods based on the `method` argument.
#' 
#' @rdname evaluate
#' @param x A `Reg` object (or an object inheriting from it, like `regressor`).
#' @param grid Numeric vector specifying the time points (seconds) for evaluation.
#' @param precision Numeric sampling precision for internal HRF evaluation and convolution (seconds).
#' @param method The evaluation method: 
#'   \itemize{
#'     \item{"conv"}{ (Default) Uses the C++ direct convolution (`evaluate_regressor_convolution`). Generally safer and more predictable.}
#'     \item{"fft"}{ Uses the fast C++ FFT convolution (`evaluate_regressor_fast`). Can be faster but may fail with very fine precision or wide grids.  
#'       Extremely fine `precision` or wide `grid` ranges may trigger an internal FFT size exceeding ~1e7, which results in an error.}
#'     \item{"Rconv"}{ Uses an R-based convolution (`stats::convolve`). Requires constant event durations and a regular sampling grid. Can be faster than the R loop for many events meeting these criteria.}
#'     \item{"loop"}{ Uses a pure R implementation involving looping through onsets. Can be slower, especially for many onsets.}
#'   }
#' @param sparse Logical indicating whether to return a sparse matrix (from the Matrix package). Default is FALSE.
#' @param ... Additional arguments passed down (e.g., to `evaluate.HRF` in the loop method).
#' @return A numeric vector or matrix of evaluated regressor values. If `sparse=TRUE`, a `dgCMatrix` object.
#' @export
#' @method evaluate Reg
#' @importFrom Matrix Matrix
#' @importFrom memoise memoise
#' @importFrom stats approx median convolve
#' @importFrom Rcpp evalCpp
evaluate.Reg <- function(x, grid, precision=.33, method=c("conv", "fft", "Rconv", "loop"), sparse = FALSE, ...) {
  
  method <- match.arg(method)
  
  # Prepare inputs using the helper function
  prep_data <- prep_reg_inputs(x, grid, precision)
  
  # Check if prep_reg_inputs indicated no relevant events
  if (length(prep_data$valid_ons) == 0) {
    return(matrix(0, length(grid), prep_data$nb)) 
  }
  
  # --- Method Dispatch to Internal Engines ---
  eng_fun <- switch(method,
     conv  = eval_conv,   # Now the default - safer direct convolution
     fft   = eval_fft,    # FFT-based (faster but can fail with large FFT sizes)
     Rconv = eval_Rconv,  # R-based convolution
     loop  = eval_loop,   # Pure R loop implementation
     stop("Invalid evaluation method: ", method) # Should not happen due to match.arg
  )
  
  # Call the selected engine function with prepared data
  # Pass ... through to the engine, which might pass it to evaluate.HRF in loop
  result <- eng_fun(prep_data, ...) 
  
  # --- Final Formatting ---
  nb <- prep_data$nb
  final_result <- if (nb == 1 && is.matrix(result)) {
    as.vector(result)
  } else if (nb > 1 && !is.matrix(result)) {
    matrix(result, nrow=length(grid), ncol=nb)
  } else {
      result
  }
  
  # Convert to sparse matrix if requested
  if (sparse) {
    if (is.vector(final_result)) {
      return(Matrix::Matrix(final_result, sparse=TRUE))
    } else {
      return(Matrix::Matrix(final_result, sparse=TRUE))
    }
  } else {
    return(final_result)
  }
}


#' Shift method for the Reg class (and thus regressor)
#'
#' Modifies a regressor object by shifting all its event onsets by a specified amount.
#'
#' @param x the Reg or regressor object to shift.
#' @param shift_amount A numeric value indicating the amount of time (in the same units as onsets, typically seconds) 
#'   to shift the onsets by. Positive values shift events later in time, negative values shift them earlier.
#' @param ... extra args (unused).
#' @return A new object of the same class as `x` but with the `onsets` field adjusted by `shift_amount`.
#' @export
#' @family regressor_methods
#' @importFrom assertthat assert_that
shift.Reg <- function(x, shift_amount, ...) {
  if (!inherits(x, "Reg")) {
    # This check might be redundant if S3 dispatch works, but good safety
    stop("Input 'x' must inherit from class 'Reg'")
  }

  if (!is.numeric(shift_amount) || length(shift_amount) != 1) {
    stop("`shift_amount` must be a single numeric value")
  }

  # Handle empty regressor case
  if (length(x$onsets) == 0 || (length(x$onsets) == 1 && is.na(x$onsets[1]))) {
    # Returning the original empty object is appropriate for a shift
    return(x)
  }

  # Shift the valid onsets
  shifted_onsets <- x$onsets + shift_amount

  # Reconstruct the object using the core Reg constructor 
  out <- Reg(onsets = shifted_onsets,
             hrf = x$hrf,
             duration = x$duration,
             amplitude = x$amplitude,
             span = x$span,
             summate = x$summate)
             
  return(out)
}

#' Print method for Reg objects
#' 
#' Provides a concise summary of the regressor object using the cli package.
#' 
#' @param x A `Reg` object.
#' @param ... Not used.
#' @importFrom cli cli_h1 cli_text cli_div cli_li
#' @importFrom assertthat assert_that
#' @export
#' @method print Reg
#' @rdname print
print.Reg <- function(x, ...) {
  
  n_ons <- length(x$onsets)
  hrf_name <- attr(x$hrf, "name") %||% "custom function"
  nb <- nbasis(x$hrf)
  hrf_span <- attr(x$hrf, "span") %||% x$span
  
  cli::cli_h1("fMRI Regressor Object")
  
  # Use cli_div for potentially better alignment than cli_ul
  cli::cli_div(theme = list(ul = list("margin-left" = 2), li = list("margin-bottom" = 0.5)))
  cli::cli_li("Type: {.cls {class(x)[1]}} {if(inherits(x, 'regressor')) cli::cli_text('(Legacy compatible)')}")
  if (n_ons == 0) {
    cli::cli_li("Events: 0 (Empty Regressor)")
  } else {
    cli::cli_li("Events: {n_ons}")
    cli::cli_li("Onset Range: {round(min(x$onsets), 2)}s to {round(max(x$onsets), 2)}s")
    if (any(x$duration != 0)) {
      cli::cli_li("Duration Range: {round(min(x$duration), 2)}s to {round(max(x$duration), 2)}s")
    }
    if (!all(x$amplitude == 1)) {
      cli::cli_li("Amplitude Range: {round(min(x$amplitude), 2)} to {round(max(x$amplitude), 2)}")
    }
  }
  cli::cli_li("HRF: {hrf_name} ({nb} basis function{?s})")
  cli::cli_li("HRF Span: {hrf_span}s")
  cli::cli_li("Summation: {x$summate}")
  # cli_end() is not needed for cli_div
  
  invisible(x)
}

# S3 Methods for Reg class -----

#' @export
#' @rdname nbasis
#' @method nbasis Reg
nbasis.Reg <- function(x, ...) nbasis(x$hrf)

#' @export
#' @rdname onsets
#' @method onsets Reg
onsets.Reg <- function(x) x$onsets

#' @export
#' @rdname durations
#' @method durations Reg
durations.Reg <- function(x) x$duration

#' @export
#' @rdname amplitudes
#' @method amplitudes Reg
amplitudes.Reg <- function(x) x$amplitude
</file>

<file path="tests/testthat/test_afni_hrf.R">
facedes <- read.table(system.file("extdata", "face_design.txt", package = "fmrireg"), header=TRUE)
library(assertthat)
options(mc.cores=2)

# Helper function to assign a dummy mask to a dataset object
# This prevents errors when tests use dummy file paths for masks/scans
# with fmri_file_dataset, as some operations might try to access dset$mask.
.assign_dummy_mask_to_dataset <- function(dset) {
  dummy_mask_space <- neuroim2::NeuroSpace(dim = c(5L, 5L, 5L)) # Arbitrary small dimensions
  dset$mask <- neuroim2::NeuroVol(array(1L, dim = dim(dummy_mask_space)), dummy_mask_space)
  return(dset) # Return the modified dataset
}

context("afni")

test_that("can construct an simple afni native stimulus model", {
  
  facedes$repnum <- factor(facedes$rep_num)
  scans <- paste0("rscan0", 1:6, ".nii")
  dset <- fmri_dataset(scans=scans,
                       mask="mask.nii",
                       TR=1.5,
                       run_length=rep(436,6),
                       event_table=facedes)
  
  dset <- .assign_dummy_mask_to_dataset(dset)
  
  espec <- event_model(onset ~ afni_hrf(repnum, basis="csplin", nbasis=8, start=0, stop=18), data=facedes, block=~run, sampling_frame=dset$sampling_frame)
  bspec <- baseline_model(basis="bs", degree=5, sframe=dset$sampling_frame)
  fmod <- fmri_model(espec, bspec)
  alm <- afni_lm(fmod, dset)
  
  expect_true(!is.null(fmod))
  expect_equal(length(terms(fmod)), 3)
  
  # Check that design_matrix(fmod) does not error, but gives warnings due to AFNI term
  # and that the resulting matrix effectively only contains the baseline model columns
  dm_baseline <- design_matrix(bspec)
  dm_fmod <- design_matrix(fmod)
  expect_equal(ncol(dm_fmod), ncol(dm_baseline))
  expect_equal(colnames(dm_fmod), colnames(dm_baseline))
  
  expect_equal(2, length(baseline_terms(fmod)))
  expect_null(contrast_weights(fmod)$repnum)
 
})

test_that("can construct an an afni model with trialwise regressor", {
  
  facedes$repnum <- factor(facedes$rep_num)
  facedes$constant <- rep(1, nrow(facedes))
  scans <- paste0("rscan0", 1:6, ".nii")
  dset <- fmri_dataset(scans=scans,
                       mask="mask.nii",
                       TR=1.5,
                       run_length=rep(436,6),
                       event_table=facedes)
  
  dset <- .assign_dummy_mask_to_dataset(dset)
  
  espec <- event_model(onset ~ hrf(constant, basis="spmg1") + afni_trialwise("trial", basis="spmg1"), data=facedes, block=~run, sampling_frame=dset$sampling_frame)
  bspec <- baseline_model(basis="bs", degree=5, sframe=dset$sampling_frame)
  fmod <- fmri_model(espec, bspec)
  alm <- afni_lm(fmod, dset)
  
  expect_true(!is.null(fmod))
  expect_equal(length(terms(fmod)), 4)
  
  # Check design matrix behavior for mixed model
  dm_baseline <- design_matrix(bspec)
  # Expect columns from hrf(constant) + baseline. AFNI term should warn and not add columns.
  # Find the non-AFNI term (hrf(constant)) specifically
  event_terms <- terms(espec)
  hrf_constant_term <- NULL
  for (term_name in names(event_terms)) {
    term <- event_terms[[term_name]]
    if (!inherits(term, c("afni_hrf_convolved_term", "afni_trialwise_convolved_term"))) {
      hrf_constant_term <- term
      break
    }
  }
  
  expect_true(!is.null(hrf_constant_term), "Should find at least one non-AFNI term")
  dm_hrf_constant <- design_matrix(hrf_constant_term, sampling_frame=dset$sampling_frame)
  expected_event_cols <- ncol(dm_hrf_constant)

  dm_fmod_mixed <- design_matrix(fmod)
  expect_equal(ncol(dm_fmod_mixed), expected_event_cols + ncol(dm_baseline))
  
  expect_equal(2, length(baseline_terms(fmod)))
  expect_null(contrast_weights(fmod)$repnum)
  
})

test_that("can construct an an afni model with a constant", {
  
  facedes$repnum <- factor(facedes$rep_num)
  facedes$constant <- factor(rep(1, nrow(facedes)))
  scans <- paste0("rscan0", 1:6, ".nii")
  dset <- fmri_dataset(scans=scans,
                       mask="mask.nii",
                       TR=1.5,
                       run_length=rep(436,6),
                       event_table=facedes)
  
  dset <- .assign_dummy_mask_to_dataset(dset)
  
  espec <- event_model(onset ~ afni_hrf(constant, basis="spmg1"), data=facedes, 
                       block=~run, sampling_frame=dset$sampling_frame)
  bspec <- baseline_model(basis="bs", degree=5, sframe=dset$sampling_frame)
  fmod <- fmri_model(espec, bspec)
  alm <- afni_lm(fmod, dset)
  
  expect_true(!is.null(fmod))
 
  
})

test_that("can construct an an afni model with trialwise regressor and a Polynomial modulator", {
  
  facedes$repnum <- as.numeric(as.character(facedes$rep_num))
  scans <- paste0("rscan0", 1:6, ".nii")
  dset <- fmri_dataset(scans=scans,
                       mask="mask.nii",
                       TR=1.5,
                       run_length=rep(436,6),
                       event_table=facedes)
  
  dset <- .assign_dummy_mask_to_dataset(dset)
  
  espec <- event_model(onset ~ afni_trialwise("trial") + hrf(fmrireg::Poly(repnum,2)), 
                      data=facedes, 
                      block=~run, 
                      sampling_frame=dset$sampling_frame)
  bspec <- baseline_model(basis="bs", degree=5, sframe=dset$sampling_frame)
  fmod <- fmri_model(espec, bspec)
  alm <- afni_lm(fmod, dset)
  
  expect_true(!is.null(fmod))
  expect_equal(length(terms(fmod)), 4)
  
  dm_baseline <- design_matrix(bspec)
  # Find the non-AFNI term (hrf(Poly...)) specifically
  event_terms <- terms(espec)
  hrf_poly_term <- NULL
  for (term_name in names(event_terms)) {
    term <- event_terms[[term_name]]
    if (!inherits(term, c("afni_hrf_convolved_term", "afni_trialwise_convolved_term"))) {
      hrf_poly_term <- term
      break
    }
  }
  
  expect_true(!is.null(hrf_poly_term), "Should find at least one non-AFNI term")
  dm_hrf_poly <- design_matrix(hrf_poly_term, sampling_frame=dset$sampling_frame)
  expected_event_cols_poly <- ncol(dm_hrf_poly)
  
  dm_fmod_poly <- design_matrix(fmod)
  expect_equal(ncol(dm_fmod_poly), expected_event_cols_poly + ncol(dm_baseline))
  
  expect_equal(2, length(baseline_terms(fmod)))
  expect_null(contrast_weights(fmod)$repnum)
})
</file>

<file path="R/event_vector.R">
###############################################################################
# EVENT_VECTOR.R
#
# This file contains helper routines for cleaning names, checking ordering,
# constructing event model terms (and various event types), extracting design
# matrices, computing contrasts, and printing event-related objects for fMRI.
#
###############################################################################

## ============================================================================
## Section 1: Helper Functions (Moved to R/utils-internal.R)
## ============================================================================

# Removed .sanitizeName
# Removed is.increasing
# Removed is.strictly.increasing
# Removed .checkEVArgs

## ============================================================================
## Section 2: Event Term Construction
## ============================================================================

#' Create an event model term from a named list of variables.
#'
#' Generates an `event_term` object which represents the combination of one 
#' or more event sequences (e.g., a factor crossed with a numeric modulator).
#' It takes a list of variables (factors, numeric vectors, matrices, basis objects)
#' along with shared onsets, block IDs, and durations.
#' It uses the `EV` factory internally to create standardized `event` objects for each variable.
#'
#' @param evlist A named list of variables (factors, numeric, matrices, ParametricBasis objects).
#'        The names are used as variable identifiers within the term.
#' @param onsets Numeric vector of onset times (in seconds).
#' @param blockids Numeric vector of block numbers (non-decreasing integers).
#' @param durations Numeric vector of event durations (seconds, default is 0). 
#'        Can be scalar (recycled) or vector matching length of `onsets`.
#' @param subset Optional logical vector indicating which events to retain (applied before processing).
#'
#' @return A list object with class `c("event_term", "event_seq")`. Contains:
#'   \item{varname}{Concatenated variable names from `evlist`.} 
#'   \item{events}{A named list of the processed `event` objects.} 
#'   \item{subset}{The `subset` vector used.} 
#'   \item{event_table}{A tibble representing the combinations of descriptive levels/names 
#'                    for each event in the term, constructed using `elements(..., values=FALSE)`.} 
#'   \item{onsets}{Numeric vector of onsets (after processing/subsetting).} 
#'   \item{blockids}{Numeric vector of block IDs (after processing/subsetting).} 
#'   \item{durations}{Numeric vector of durations (after processing/subsetting).} 
#'
#' @examples 
#' x1 <- factor(rep(letters[1:3], 10))
#' x2 <- factor(rep(1:3, each = 10))
#' onsets <- seq(1, 100, length.out = 30)
#' blockids <- rep(1:3, each = 10)
#' 
#' eterm <- event_term(list(Condition = x1, Group = x2),
#'                     onsets = onsets,
#'                     blockids = blockids)
#' print(eterm)
#' head(event_table(eterm))
#' levels(eterm)
#' head(design_matrix(eterm))
#'
#' @export
#' @import assertthat
#' @importFrom tibble as_tibble tibble
event_term <- function(evlist, onsets, blockids, durations = 0, subset = NULL) {
  
  # Convert blockids to numeric if they are factors.
  if (is.factor(blockids)) {
    blockids <- as.numeric(as.character(blockids))
  }
  
  # Ensure blockids are non-decreasing.
  # Use base R equivalent of is.increasing
  assert_that(!is.unsorted(blockids), msg = "'blockids' must consist of non-decreasing integers")
  
  # NOTE: subset handling is now primarily inside event(), 
  # but event_term might still need its own subset logic if it uses it before calling EV?
  # Currently, it passes subset down to EV.
  if (is.null(subset)) { 
    subset <- rep(TRUE, length(onsets)) 
  }
  
  # Duration recycling is handled inside event() via .checkEVArgs
  # if (length(durations) == 1) {
  #   durations <- rep(durations, length(onsets))
  # }
  
  vnames <- names(evlist)
  onlen <- length(onsets)
  
  # Basic check on input lengths before calling EV factory
  getlen <- function(v) {
    if (is.matrix(v)) nrow(v)
    else if (inherits(v, "ParametricBasis")) nrow(v$y) # Check basis matrix dim
    else length(v)
  }
  for(i in seq_along(evlist)) {
      assert_that(getlen(evlist[[i]]) == onlen, 
                  msg=sprintf("Length mismatch between onsets (%d) and variable '%s' (%d)", 
                              onlen, vnames[i], getlen(evlist[[i]])))
  }
  
  # Create event objects by dispatching to the appropriate public wrapper
  evs <- lapply(seq_along(evlist), function(i) {
    vals <- evlist[[i]]
    vname_i <- vnames[i]
    
    # Type checking and dispatching (replaces EV factory logic)
    if (inherits(vals, "ParametricBasis")) {
        event_basis(basis = vals, name = vname_i, onsets = onsets, blockids = blockids, durations = durations, subset = subset)
    } else if (is.factor(vals) || is.character(vals)) {
        event_factor(fac = vals, name = vname_i, onsets = onsets, blockids = blockids, durations = durations, subset = subset)
    } else if (is.matrix(vals)) {
        # Handle single-column matrices as vectors for event_variable?
        # No, event_matrix handles matrices directly now.
        event_matrix(mat = vals, name = vname_i, onsets = onsets, blockids = blockids, durations = durations, subset = subset)
    } else if (is.numeric(vals) && (is.vector(vals) || length(dim(vals)) <= 1)) {
         # Check specifically for numeric vectors (or 1D arrays)
        event_variable(vec = vals, name = vname_i, onsets = onsets, blockids = blockids, durations = durations, subset = subset)
    } else {
        stop(sprintf("Unsupported value type '%s' for variable '%s' in event_term", class(vals)[1], vname_i))
    }
  })
  
  names(evs) <- sapply(evs, function(ev) ev$varname)
  pterms <- unlist(lapply(evs, function(ev) ev$varname))
  
  # Check if any event object creation resulted in zero events after subsetting
  if (length(evs) > 0 && length(evs[[1]]$onsets) == 0) {
      warning(sprintf("Event term '%s' resulted in zero events after subsetting/processing.", 
                      paste(vnames, collapse=":")))
      # Return an empty structure? Or let downstream fail? Let downstream handle for now.
      # It should have empty onsets, durations, blockids, value matrix. 
  }
  
  # Rebuild event_table based on the *actual* content of the event objects
  # event() now handles the internal structure, so we use elements()
  # This relies on elements.event(..., values=FALSE) returning the appropriate factor levels/names
  
  # Get descriptive elements (levels/names) for each event
  descriptive_elements <- elements(evs[[1]], values = FALSE) # Need a way to call elements on list 'evs'? 
  # No, elements.event_term works on the term object after it's built.
  # Let's reconstruct the table *after* building the initial list. 

  varname <- paste(sapply(evs, function(x) x$varname), collapse = ":")
  
  # Create the list structure first
  ret <- list(varname = varname, 
              events = evs, 
              subset = subset, # Keep original subset for reference?
              # Placeholder for event_table, rebuild below
              event_table = NULL, 
              # Use onsets/blockids/durations from the *first* processed event object
              # Assumes they are consistent across all events after processing (checked by event())
              onsets = if(length(evs) > 0) evs[[1]]$onsets else numeric(0), 
              blockids = if(length(evs) > 0) evs[[1]]$blockids else numeric(0), 
              durations = if(length(evs) > 0) evs[[1]]$durations else numeric(0))
  
  class(ret) <- c("event_term", "event_seq")
  
  # Now build the event_table using elements()
  # Get descriptive elements (levels/names) for the term
  descriptive_elements_list <- elements(ret, what = "labels") # Explicitly request labels
  # Combine into a tibble directly from the list
  etab <- try(tibble::as_tibble(descriptive_elements_list), silent = TRUE)
  if (inherits(etab, "try-error")) {
      warning("Failed to create event_table for term: ", varname)
      etab <- tibble::tibble()
  }
  ret$event_table <- etab
  
  ret
}

#' @export
event_table.event_term <- function(x) x$event_table

## ============================================================================
## Section 3: EV Factory and Event Constructors (REMOVE EV Factory)
## ============================================================================

# Removed EV factory function. Logic is now inlined in event_term.

# Removed event_factor, event_variable, event_matrix, event_basis wrappers.
# They are now located in R/event-classes.R

## ============================================================================
## Section 4: Levels and Formula Methods
## ============================================================================

#' Build a formula for an event term.
#'
#' Creates a formula suitable for `model.matrix` (e.g., `~ Var1:Var2 - 1`).
#' 
#' @param x An `event_term` object.
#' @param ... Additional arguments (unused).
#' @return A formula object.
#' @export
formula.event_term <- function(x, ...) {
  # NOTE: This uses parent_terms.event_term which still exists below
  #       It might need adjustment if parent_terms logic changes.
  as.formula(paste("~ (", paste(parent_terms(x), collapse = ":"), "-1)"))
}

#' @noRd
.vector_of_labels <- function(ev) {
  # Helper to generate the vector of condition labels for a single event.
  # Uses levels.event() for the actual levels/column names.
  lvls <- levels(ev) # Get levels/colnames from levels.event
  
  if (is_continuous(ev) && length(lvls) > 1) {
    # Continuous multi-column (matrix/basis): Use index 1:ncol
    vapply(seq_along(lvls), 
           \(k) .label_component(ev, k), 
           character(1))
  } else if (is_categorical(ev)) {
    # Categorical: Use actual levels
    vapply(lvls, \(lvl) .label_component(ev, lvl), character(1))
  } else {
    # Single continuous variable (vector): Just the variable name
    .label_component(ev)
  }
}

## ============================================================================
## Section 5: Cells Extraction
## ============================================================================

#' Retrieve cells of an event_term object.
#'
#' Calculates all unique combinations (cells) of levels across all event variables 
#' in the term. It uses `levels.event` for each event and `expand.grid`.
#' It then calculates the number of observed events corresponding to each cell
#' by comparing against the output of `elements(x, values=FALSE)` and attaches this
#' as a `count` attribute to the resulting tibble.
#' Relies on `levels.event`, `is_categorical.event`, and `elements.event`.
#'
#' @param x An event_term object.
#' @param drop.empty Logical; if TRUE (default), remove cells with zero observed events.
#' @param ... Additional arguments (unused).
#'
#' @details
#' Note: For designs with many interacting factors each having many levels, 
#' the internal calculation based on `expand.grid` might become slow.
#'
#' @return A tibble where rows represent unique cells and columns represent the event 
#'         variables in the term. Has a `count` attribute.
#'
#' @export
#' @rdname cells
#' @examples
#' x1 <- factor(rep(letters[1:3], 4))
#' x2 <- factor(rep(1:2, each = 6))
#' onsets <- seq(1, 100, length.out = 12)
#' blockids <- rep(1, 12)
#' eterm <- event_term(list(Condition = x1, Group = x2), onsets=onsets, blockids=blockids)
#' cells(eterm)
#' cells(eterm, drop.empty=FALSE)
cells.event_term <- function(x, drop.empty = TRUE, ...) {
  ## ----------------------------------------------------------------
  ## 0. fast cache ---------------------------------------------------
  # Use fixed name as levels rarely change post-construction
  cache_attr_name <- "..cells" 
  if (!is.null(cached <- attr(x, cache_attr_name))) {
    cnt <- attr(cached, "count")
    # Need to handle potential NULL count if cache is invalid
    if(is.null(cnt)) {
        warning("Invalid cache detected for cells.event_term, recomputing.")
    } else {
        return(if (drop.empty) cached[cnt > 0, , drop = FALSE] else cached)
    }
  }

  ## ----------------------------------------------------------------
  ## 1. categorical events only -------------------------------------
  # Use Filter and Negate for conciseness
  cats <- Filter(Negate(is_continuous), x$events)

  if (length(cats) == 0) {                  # no factors ⇒ one big cell
    # Use a more descriptive name if needed, maybe based on varname
    # Consistent with cells.event: use the (first/only) varname
    var_name_cont <- if (length(x$events) > 0) x$events[[1]]$varname else "all_events"
    out <- tibble::tibble(!!var_name_cont := var_name_cont) # Use varname for column
    count_val <- length(x$onsets)
    attr(out, "count") <- count_val
    # Assign name to the count attribute
    names(attr(out, "count")) <- var_name_cont 
    
    attr(x, cache_attr_name) <- out # Cache the result
    return(out)
  }

  ## ----------------------------------------------------------------
  ## 2. observed combination counts ---------------------------------
  # Reconstruct factors from internal representation
  obs_list <- lapply(cats, \(ev) {
      # Add checks for valid meta$levels and value structure
      if (is.null(ev$meta$levels) || !is.matrix(ev$value) || ncol(ev$value) != 1) {
           stop(paste("Invalid internal structure for categorical event:", ev$varname), call.=FALSE)
      }
      factor(ev$value[, 1L], levels = seq_along(ev$meta$levels), labels = ev$meta$levels)
  })
  # Create data frame of observed factor combinations
  obs <- do.call(data.frame, c(obs_list, stringsAsFactors = FALSE))
  
  # Use table() for efficient contingency counting (if few factors)
  # For many factors, alternative might be needed 
  # tbl <- as.data.frame.matrix(table(obs)) # This creates wide format, not needed directly
  
  # Generate the grid of all possible level combinations
  levels_list <- lapply(cats, levels)
  grid <- expand.grid(levels_list, stringsAsFactors = FALSE) # Use FALSE then convert relevant columns
  # Ensure column names match original variable names
  colnames(grid) <- names(cats)
  # Convert grid columns to factors matching the levels in obs_list
  for(i in seq_along(grid)){
      grid[[i]] <- factor(grid[[i]], levels=levels(obs_list[[i]]))
  }

  ## match() much faster than join for simple cases ------------------
  # Create unique string keys for observed and grid rows
  # Use sep that's unlikely to appear in levels
  key_obs  <- do.call(paste, c(obs, sep = "\001")) 
  key_grid <- do.call(paste, c(grid, sep = "\001"))
  # Count occurrences by matching observed keys to grid keys
  count    <- tabulate(match(key_obs, key_grid), nbins = nrow(grid))

  ## ----------------------------------------------------------------
  ## 3. assemble result ---------------------------------------------
  out <- tibble::as_tibble(grid) # Convert final grid to tibble

  # --- Add names to the count vector ---
  # Generate names for the counts based on the grid rows (factor level combinations)
  if (nrow(grid) > 0) {
      # Use a separator consistent with how interactions might be named elsewhere
      cell_names <- apply(grid, 1, paste, collapse = ":")
      # Ensure counts has names before attaching
      if (length(count) == length(cell_names)) {
         names(count) <- cell_names
      } else {
         # This shouldn't happen if logic above is correct, but add a warning
         warning("Mismatch between number of cells and counts calculated in cells.event_term")
      }
  } # Else count is likely integer(0) and doesn't need names
  # --- End adding names ---

  attr(out, "count") <- count # Attach the now named count vector

  attr(x, cache_attr_name) <- out # Cache the result (with named counts)

  # Filter based on drop.empty
  if (drop.empty) {
      keep_idx <- count > 0
      filtered_out <- out[keep_idx, , drop = FALSE]
      # Ensure the count attribute on the filtered output is also correct
      attr(filtered_out, "count") <- count[keep_idx]
      filtered_out
  } else {
       out
  }
}

#' @noRd
.event_set <- function(x, exclude_basis = FALSE) {
  evtab <- event_table(x)
  
  evset <- if (nbasis(x) > 1 & !exclude_basis) {
    ncond <- nbasis(x)
    # Construct a zero-padded string for basis labels.
    zstr <- paste0(rep("0", ceiling(log10(ncond + 1e-6))), collapse = "")
    
    evlist <- c(list(factor(paste("basis", zstr, 1:nbasis(x), sep = ""))), cells(x$evterm))
    names(evlist) <- c("basis", parent_terms(x$evterm))
    evlist <- lapply(evlist, levels)
    ret <- expand.grid(evlist, stringsAsFactors = TRUE)
    ret[c(2:length(ret), 1)]
  } else {
    cells(x$evterm)
  }
}

#' @export
#' @rdname cells
cells.covariate_convolved_term <- function(x, ...) {
  unique(event_table(x))
}

#' @export
#' @importFrom stringr str_trim
cells.convolved_term <- function(x, exclude_basis = FALSE, ...) {
  evtab <- event_table(x)
  evset <- .event_set(x, exclude_basis = exclude_basis)
  
  strels <- apply(apply(evtab, 2, stringr::str_trim), 1, paste, collapse = ":")
  
  strlevs <- if (nrow(evset) > 1) {
    apply(apply(evset, 2, stringr::str_trim), 1, paste, collapse = ":")
  } else {
    as.character(evset[1, 1])
  }
  
  attr(evset, "rownames") <- strlevs
  
  counts <- if (exclude_basis) {
    rep(attr(cells(x$evterm), "count"), each = 1)
  } else {
    rep(attr(cells(x$evterm), "count"), each = nbasis(x))
  }
  
  ret <- evset[counts > 0, , drop = FALSE]
  attr(ret, "count") <- counts[counts > 0]
  ret
}

## ============================================================================
## Section 6: Conditions and Parent Terms
## ============================================================================

#' Extract conditions from an event_term.
#'
#' Constructs a vector of condition tags representing all unique combinations
#' of levels/columns across the events in the term. The format follows the 
#' new naming grammar: `Token1_Token2...` where tokens are `Var.Level` or 
#' `basis_var_k`, using `_` as a separator for interactions.
#' 
#' This function is central to generating names for the design matrix columns.
#'
#' @param x An `event_term` object.
#' @param drop.empty Logical; if TRUE (default), conditions corresponding to 
#'        combinations with zero observed events (based on `cells()`) are dropped.
#' @param expand_basis Logical; if FALSE (default), returns the base condition tags 
#'        (e.g., `cond.A_poly_RT_01`). If TRUE, adds basis suffixes (`_b##`) 
#'        based on the term's HRF specification (e.g., `cond.A_poly_RT_01_b01`).
#' @param ... Additional arguments (unused).
#' @return A character vector of condition tags.
#' @export
#' @importFrom tibble tibble
conditions.event_term <- function(x, drop.empty = TRUE, expand_basis = FALSE, ...) {
  
  # --- Caching --- 
  opts_key <- paste(drop.empty, expand_basis, sep="|") # Keep drop.empty in key for now
  cached_val <- attr(x, "..conds")
  cached_opts <- attr(x, "..conds_opts")
  
  # --- RE-ENABLE CACHE --- 
  if (!is.null(cached_val) && !is.null(cached_opts) && identical(cached_opts, opts_key)) {
    return(cached_val)
  }
  # message("--- conditions.event_term: Cache bypassed/missed, recalculating ---") # Keep commented out
  # --- END RE-ENABLE ---
  
  # --- Shortcut for single continuous event with one column --- 
  if (length(x$events) == 1 && is_continuous(x$events[[1]])) {
    cols <- try(columns(x$events[[1]]), silent=TRUE)
    if (!inherits(cols, "try-error") && length(cols) == 1) {
        base_cond_tags <- cols 
        if (expand_basis) {
            hrfspec <- attr(x, "hrfspec")
            nb <- if (!is.null(hrfspec) && !is.null(hrfspec$hrf)) nbasis(hrfspec$hrf) else 1L
            final_cond_tags <- add_basis(base_cond_tags, nb)
        } else {
            final_cond_tags <- base_cond_tags
        }
        attr(x, "..conds") <- final_cond_tags
        attr(x, "..conds_opts") <- opts_key
        return(final_cond_tags)
    }
  }
  
  # --- Generate Tokens for Each Component --- 
  comp_tokens_list <- lapply(x$events, function(ev) {
      if (is_categorical(ev)) {
          levs <- levels(ev) 
          # Handle case where factor might have no levels after subsetting? levels() should return character(0)
          if (length(levs) == 0) return(character(0))
          level_token(ev$varname, levs)
      } else {
          columns(ev) 
      }
  })
  
  # Filter out components that returned empty tokens (e.g., factors with no levels)
  comp_tokens_list <- Filter(function(tk) length(tk) > 0, comp_tokens_list)
  
  if (length(comp_tokens_list) == 0) { # If ALL components became empty
       final_out <- character(0)
       attr(x, "..conds") <- final_out
       attr(x, "..conds_opts") <- opts_key
       return(final_out)
  }
  
  # --- Combine Tokens using expand.grid and make_cond_tag --- 
  names(comp_tokens_list) <- names(Filter(function(tk) length(tk) > 0, x$events)) # Match names to filtered tokens
  full_grid <- expand.grid(comp_tokens_list, stringsAsFactors = FALSE)
  base_cond_tags_all <- apply(full_grid, 1, make_cond_tag)
  
  # --- REMOVED drop.empty LOGIC BLOCK --- 
  # The logic relying on cells() was flawed for mixed continuous/categorical terms.
  # Dropping based on actual matrix rank deficiency is handled by design_matrix() / model.matrix().
  base_cond_tags_final <- base_cond_tags_all
  
  # --- Handle expand_basis --- 
  if (expand_basis) {
      hrfspec <- attr(x, "hrfspec")
      nb <- if (!is.null(hrfspec) && !is.null(hrfspec$hrf)) nbasis(hrfspec$hrf) else 1L
      final_cond_tags <- add_basis(base_cond_tags_final, nb)
  } else {
      final_cond_tags <- base_cond_tags_final
  }
  
  # --- Cache and Return --- 
  final_out <- as.vector(final_cond_tags)
  attr(x, "..conds") <- final_out
  attr(x, "..conds_opts") <- opts_key
  
  return(final_out)
}

#' @noRd
parent_terms.event_term <- function(x) unlist(lapply(x$events, function(ev) ev$varname))

## ============================================================================
## Section 7: Continuous/Categorical Checks and Elements Extraction
## ============================================================================

#' @export
is_continuous.event_term <- function(x) all(sapply(x$events, function(x) is_continuous(x)))

#' @export
is_categorical.event_term <- function(x) !is_continuous(x)

#' @name elements.event_term
#' @title Extract Elements (Values or Labels) from an Event Term
#' @export
#' @param x event_term object
#' @param what Character, either "values" to return numeric data or "labels" for descriptive names.
#' @param ... Additional arguments passed down (e.g., `transformed` for `elements.event`).
elements.event_term <- function(x, what = c("values", "labels"), ...) {
  # Ensure 'what' is determined correctly, respecting 'values' if passed via ...
  dots <- list(...)
  if (!missing(what)) {
      what <- match.arg(what)
  } else if (!is.null(dots$values)) {
      what <- if (dots$values) "values" else "labels"
  } else {
      what <- "values" # Default if neither 'what' nor 'values' is specified
  }
  
  # Pass the determined 'what' argument and any other arguments down
  # lapply will now create a named list directly as elements.event returns vectors/matrices
  els <- lapply(x$events, elements, what = what, ...)
  
  # Sanitize names of the resulting list (which should already be named by lapply)
  # If lapply didn't preserve names from x$events, this is needed.
  names(els) <- vapply(names(x$events), .sanitizeName, character(1))
  els
}

## ============================================================================
## Section 8: Onsets and Block IDs
## ============================================================================

#' @export
onsets.convolved_term <- function(x) {
  onsets(x$evterm)
}

#' @export
onsets.event_term <- function(x) {
  x$onsets
}

#' @export
blockids.event_term <- function(x) {
  x$blockids
}

#' @export
blockids.convolved_term <- function(x) {
  blockids(x$evterm)
}

## ============================================================================
## Section 9: Splitting Onsets
## ============================================================================

#' Split onsets of an event_term object.
#'
#' Splits the onsets based on factor levels or block IDs.
#'
#' @param x An event_term object.
#' @param sframe A data frame representing the sampling frame.
#' @param global Logical; if TRUE, use global onsets (default: FALSE).
#' @param blocksplit Logical; if TRUE, split onsets by block IDs (default: FALSE).
#' @param ... Additional arguments.
#'
#' @return A list of numeric vectors for each factor level or block.
#'
#' @export
split_onsets.event_term <- function(x, sframe, global = FALSE, blocksplit = FALSE, ...) {
  # Get categorical events.
  facs <- x$events[!sapply(x$events, is_continuous)]
  
  if (length(facs) == 0) {
    ons <- if (global) {
      global_onsets(sframe, onsets(x), blockids(x))
    } else {
      onsets(x)
    }
    return(list(split(ons, blockids(x))))
  }
  
  # For categorical events, construct a crossed factor.
  facs <- lapply(facs, function(fac) unlist(elements(fac)))
  
  f <- function(...) {
    interaction(..., drop = TRUE, sep = ":")
  }
  
  cfac <- try(do.call(f, facs))
  # If error, a more informative error message might be warranted.
  
  ret <- if (global) {
    split(global_onsets(sframe, onsets(x), blockids(x)), cfac)
  } else {
    split(onsets(x), cfac)
  }
  
  if (blocksplit) {
    bsplit <- split(blockids(x), cfac)
    ret <- lapply(seq_along(ret), function(i) {
      split(ret[[i]], bsplit[[i]])
    })
  }
  
  names(ret) <- longnames(x)
  ret
}

## ============================================================================
## Section 10: Convolution and Regressor Generation
## ============================================================================

#' Convolve HRF with Design Matrix.
#'
#' Convolves a HRF with a design matrix (one column per condition) to produce a
#' list of regressors.
#'
#' @param hrf A function representing the HRF.
#' @param dmat Design matrix (with named columns).
#' @param globons Numeric vector of global onsets.
#' @param durations Numeric vector of event durations.
#' @param summate Logical; if TRUE, summate the convolved HRF (default: TRUE).
#'
#' @return A list of regressors (one for each column).
#' @export
convolve_design <- function(hrf, dmat, globons, durations, summate = TRUE) {
  cond.names <- names(dmat)
  
  # Remove rows with NA values.
  if (any(is.na(dmat)) || any(is.na(globons))) {
    keep <- apply(dmat, 1, function(vals) all(!is.na(vals)))
    keep[is.na(globons)] <- FALSE
    dmat <- dmat[keep, ]
    durations <- durations[keep]
    globons <- globons[keep]
  }
  
  reglist <- purrr::map(1:ncol(dmat), function(i) {
    amp <- dmat[, i][[1]]
    nonzero <- which(amp != 0)
    if (length(nonzero) == 0) {
      # Call Reg directly to create an empty regressor object
      Reg(onsets = numeric(0), hrf = hrf, amplitude = 0)
    } else {
      # Call Reg directly here as well
      Reg(onsets = globons[nonzero], hrf = hrf, amplitude = amp[nonzero], duration = durations[nonzero], summate = summate)
    }
  })
  
  reglist
}

#' Extract regressors for an event term
#'
#' Convolve the event-term design matrix with an HRF and return the
#' resulting regressors.
#'
#' @rdname regressors
#' @param hrf HRF function
#' @param sampling_frame sampling_frame object
#' @param summate Logical; sum HRF responses
#' @param drop.empty Logical; drop empty conditions
#' @export
regressors.event_term <- function(x, hrf, sampling_frame, summate = FALSE, drop.empty = TRUE, ...) {
  globons <- global_onsets(sampling_frame, x$onsets, x$blockids)
  durations <- x$durations
  blockids <- x$blockids
  nimages <- sum(sampling_frame$blocklens)
  cnames <- conditions(x)
  dmat <- design_matrix(x, drop.empty)
  ncond <- ncol(dmat)
  
  reg <- convolve_design(hrf, dmat, globons, durations, summate = summate)
  names(reg) <- colnames(dmat)
  reg
}

#' Convolve an event-related design matrix with an HRF.
#'
#' This function takes an event-related design matrix and convolves it with a given
#' HRF to produce a new design matrix suitable for fMRI analysis.
#' It is responsible for applying the final column naming scheme 
#' (`term_tag_condition_tag_b##`) using the `make_column_names` helper.
#'
#' @importFrom tibble as_tibble
#' @importFrom dplyr %>% group_by select do ungroup
#' @autoglobal
#' @export
#' @param x An `event_term` object. Must have `term_tag` and `hrfspec` attributes set.
#' @param hrf The HRF function (typically from `attr(x, "hrfspec")$hrf`).
#' @param sampling_frame Data frame specifying the sampling frame.
#' @param drop.empty Logical; passed to `conditions()` and `design_matrix()` to determine 
#'        which conditions/columns to include in the convolution.
#' @param summate Logical; if TRUE, sum the convolved HRF.
#' @param precision Numeric; the convolution precision (default: 0.3).
#' @param ... Additional arguments (unused).
#'
#' @return A tibble of the convolved design matrix with columns named according to the standard grammar.
convolve.event_term <- function(x, hrf, sampling_frame, drop.empty = TRUE, 
                                summate = TRUE, precision = 0.3, ...) {
  # Check for term_tag attribute (should have been added in realise_event_terms)
  term_tag <- attr(x, "term_tag")
  # --- REMOVED FALLBACK LOGIC FOR term_tag ---
  # If term_tag is NULL (e.g., for Ident()-only terms), make_column_names will handle it 
  # by not prepending a term_tag, resulting in direct variable names.
  # if (is.null(term_tag)) {
  #     warning(sprintf("Missing 'term_tag' attribute on event_term '%s'. Using $varname as fallback.", x$varname %||% "Unnamed"), call.=FALSE)
  #     term_tag <- x$varname %||% "UnnamedTerm"
  # }
  
  # --- Basic Setup --- 
  globons <- global_onsets(sampling_frame, x$onsets, x$blockids)
  durations <- x$durations
  blockids <- x$blockids
  nimages <- sum(sampling_frame$blocklens)
  
  # --- Get Unconvolved Design Matrix (dmat) --- 
  # design_matrix handles dropping empty/rank-deficient columns based on drop.empty
  dmat <- design_matrix(x, drop.empty = drop.empty)
  
  # --- Get Base Condition Names from the *actual* matrix columns --- 
  # This ensures names match the columns being convolved
  base_cnames <- colnames(dmat)
  
  # Check if dmat became empty after dropping
  if (ncol(dmat) == 0 || nrow(dmat) == 0) {
      warning(sprintf("Design matrix for term '%s' became empty after dropping. Convolution will result in an empty matrix.", term_tag), call.=FALSE)
      # Proceed to generate names for an empty matrix
      base_cnames <- character(0) # Use empty names
  }
  
  # --- Convolution per Block --- 
  block_ids <- unique(blockids)
  cmat_list <- lapply(block_ids, function(bid) {
    idx <- which(blockids == bid)
    # Ensure we subset the correct dmat based on drop.empty consistency
    dblock <- dmat[idx, , drop = FALSE] 
    globons_block <- globons[idx]
    durations_block <- durations[idx]
    
    # Skip block if dblock is empty (e.g., no events for this term in this block)
    if(nrow(dblock) == 0 || ncol(dblock) == 0) return(NULL) 
    
    reg <- convolve_design(hrf, dblock, globons_block, durations_block, summate = summate)
    sam <- samples(sampling_frame, blockids = as.integer(bid), global = TRUE)
    
    # Combine regressors for this block
    block_mat <- do.call(cbind, lapply(reg, function(r) evaluate(r, sam, precision = precision)))
    block_mat
  })
  
  # Remove NULLs (from blocks with no events/cols) and rbind
  cmat_list <- Filter(Negate(is.null), cmat_list)
  
  # --- Generate Final Column Names --- 
  nb <- nbasis(hrf)
  # Use the base_cnames derived directly from the dmat that was convolved
  cn <- make_column_names(term_tag, base_cnames, nb)
  
  # Handle case where convolution results in an empty matrix
  if (length(cmat_list) == 0) {
      warning(sprintf("Convolution resulted in an empty matrix for term '%s\'.\n  Returning tibble with correct names but 0 rows.", term_tag), call.=FALSE)
      # Return empty tibble with correct names and 0 rows
      return(tibble::as_tibble(matrix(numeric(0), nrow=0, ncol=length(cn)), 
                               .name_repair="minimal", .names_minimal = cn))
  }
  cmat <- do.call(rbind, cmat_list)
  
  # Handle add_sum flag if present (set by trialwise)
  if (isTRUE(attr(x, "add_sum"))) {
    if (ncol(cmat) > 0) { # Ensure there are columns to average
      mean_col <- matrix(rowMeans(cmat, na.rm = TRUE), ncol = 1)
      mean_col_name <- make.names(paste0(attr(x, "add_sum_label") %||% term_tag, "_mean"))
      colnames(mean_col) <- mean_col_name
      cmat <- cbind(cmat, mean_col)
      # Update column names to include the new mean column
      cn <- c(cn, mean_col_name)
    } else {
      warning(sprintf("Cannot add sum column for term '%s': no base columns generated.", term_tag))
    }
  }
  
  # Assign names, checking for length consistency
  if (length(cn) == ncol(cmat)) {
    colnames(cmat) <- cn
  } else {
      warning(sprintf("Final column name count (%d) mismatch with convolved matrix columns (%d) for term '%s'. Using generic names.", 
                      length(cn), ncol(cmat), term_tag), call. = FALSE)
      colnames(cmat) <- make.names(paste0("col_", seq_len(ncol(cmat))), unique=TRUE)
  }
  
  # --- Optional Debug Validation --- 
  if (getOption("fmrireg.debug", FALSE)) {
     if (exists("is_valid_heading", mode="function")){
        stopifnot(all(is_valid_heading(colnames(cmat))))
     } else {
        warning("fmrireg.debug=TRUE: is_valid_heading helper not found for validation.")
     }
  }
  
  # --- Return Result --- 
  suppressMessages(tibble::as_tibble(cmat, .name_repair = "minimal"))
}

## ============================================================================
## Section 11: F-Contrast Computation
## ============================================================================

#' @export
Fcontrasts.event_term <- function(x, max_inter = 4L, ...) {

  ## --- helpers -------------------------------------------------------------
  .is_cat <- function(ev) !is_continuous(ev)
  .Dmat   <- function(n) {
      if (n < 2) stop("Need at least 2 levels for contrasts.")
      con <- contr.sum(n)
      colnames(con) <- paste0("c", 1:(n - 1))
      con
  }
  .Cvec   <- function(n) matrix(1, nrow = n, ncol = 1)

  ## --- preparation ---------------------------------------------------------
  evs_cat <- Filter(.is_cat, x$events)
  if (!length(evs_cat)) stop("No categorical variables found in term '", x$varname, "' for Fcontrasts.", call.=FALSE)

  C <- lapply(evs_cat, function(ev) .Cvec(length(levels(ev))))
  D <- lapply(evs_cat, function(ev) .Dmat(length(levels(ev))))
  names(C) <- names(D) <- names(evs_cat)

  # --- Get expected row names in Kronecker order ---------------------------
  cat_levels_list <- lapply(evs_cat, levels)
  # --- build Cartesian product of levels (Kronecker order) ------------------ 
  lvl_grid        <- do.call(expand.grid, cat_levels_list)
  cat_cond_names  <- apply(lvl_grid, 1, paste, collapse = ":")
  expected_rows   <- nrow(lvl_grid)
  # ---------------------------------------------------------------------- 

  ## --- Compute main effects matrices (without rownames yet) ---------------
  main <- Map(function(i) {
      mat_list <- C
      mat_list[[i]] <- D[[i]] 
      Reduce(kronecker, mat_list)
  }, seq_along(D)) |> 
    stats::setNames(names(evs_cat))

  ## --- Compute interaction effects matrices (without rownames yet) -------
  final_contrasts_list <- if (length(D) > 1 && length(D) <= max_inter) {
      inter <- unlist(lapply(2:length(D), function(k) {
          combn(length(D), k, simplify = FALSE, FUN = function(ix) {
              mat_list <- C
              mat_list[ix] <- D[ix] 
              M <- Reduce(kronecker, mat_list)
              attr(M, "name") <- paste(names(evs_cat)[ix], collapse=":")
              M
          })
      }), recursive = FALSE)
      names(inter) <- vapply(inter, attr, "", "name")
      c(main, inter)
  } else {
      main
  }
  
  ## --- Assign correct categorical rownames to all matrices -------
  final_contrasts_named <- lapply(seq_along(final_contrasts_list), function(i) {
       M <- final_contrasts_list[[i]]
       mat_name <- names(final_contrasts_list)[i]
       if (!is.matrix(M)) { 
            warning(paste("Skipping rownames for invalid matrix in Fcontrasts list element:", mat_name))
            return(M)
       }
       # Compare nrow(M) to expected rows from CATEGORICAL grid/interaction
       if (nrow(M) == expected_rows) {
            # Use dimnames[[1]] <- assignment (should be correct now)
            dimnames(M)[[1]] <- cat_cond_names
       } else {
           # This warning should be less likely now, but keep for safety
           warning(paste("Dimension mismatch for contrast '", mat_name, "': expected ", 
                         expected_rows, " rows (from categorical interaction), but matrix has ", nrow(M), ". Rownames not assigned."))
       }
       M # Return matrix (modified in place)
  })
  
  names(final_contrasts_named) <- names(final_contrasts_list)
  
  final_contrasts_named
}

## ============================================================================
## Section 12: Design Matrix Construction
## ============================================================================

#' Construct a design matrix for an event_term.
#'
#' This function creates a design matrix from an event_term object by first
#' building a data frame containing columns for each event variable and then 
#' applying `model.matrix` using the term's formula.
#'
#' @param x An `event_term` object.
#' @param drop.empty Logical; if TRUE (default), columns with zero variance (or all zeros)
#'        that are not part of an intercept term are removed.
#' @param ... Additional arguments (unused).
#'
#' @return A tibble representing the design matrix.
#' @importFrom tibble as_tibble
#' @export
design_matrix.event_term <- function(x, drop.empty = TRUE, ...) {

  # --- Special case: term contains only one continuous event --- 
  # This includes single numeric variables and multi-column basis functions.
  # Bypass model.matrix and return the value matrix directly.
  if (is_continuous(x) && length(x$events) == 1) {
    ev      <- x$events[[1]]
    # Directly use the value matrix (N x K)
    out_mat <- ev$value 
    # Ensure it's a data frame before naming
    out_df <- as.data.frame(out_mat) # Convert matrix to data frame
    
    # Use columns() to get the base condition tags for naming intermediate matrix
    # These tags represent the *parts* of the final name (e.g., "01", "02" for Poly)
    # Do NOT sanitize with make.names here, as these are intermediate component names.
    intermediate_cond_tags <- try(columns(ev), silent = TRUE)

    if (inherits(intermediate_cond_tags, "try-error") || length(intermediate_cond_tags) != ncol(out_df)) {
      warning(sprintf("Failed to get valid condition tags via columns() or column count mismatch for event term '%s' (varname: '%s'). Using generic V# names for intermediate matrix.", 
                      x$varname %||% "UnnamedTerm", ev$varname %||% "UnnamedEventVar"), call. = FALSE)
      # Fallback to generic, sanitized names if columns() fails or gives wrong number
      cnames <- make.names(paste0("V", seq_len(ncol(out_df))), unique = TRUE) 
    } else {
      # Use the raw condition tags (e.g., "01", "02") directly as intermediate names.
      # These are not necessarily valid full R names yet but are components.
      cnames <- intermediate_cond_tags 
    }
    
    names(out_df) <- cnames
    # Return as a tibble
    return(tibble::as_tibble(out_df, .name_repair = "minimal"))
  }
  
  ## ----------------------------------------------------------------
  ## 1. Build the "data" data-frame that model.matrix() needs
  ## ----------------------------------------------------------------
  #   * For categorical events → factor column (1 per event)
  #   * For continuous events  → numeric column(s) (one per matrix column)
  
  # Helper to extract appropriate column(s) from an event object
  build_cols <- function(ev) {
    if (is_categorical(ev)) {
      # Categorical: return data frame with factor column named ev$varname
      fac <- factor(ev$value[, 1L],
                    levels = seq_along(ev$meta$levels),
                    labels = ev$meta$levels)
      df_out <- data.frame(fac, check.names=FALSE)
      colnames(df_out) <- ev$varname 
      df_out
    } else {
      # Continuous/Basis: return data frame with a single matrix column named ev$varname
      mat_col <- ev$value # This is the N x K matrix
      df_out <- data.frame(I(mat_col)) # Use I() to store matrix in one column
      colnames(df_out) <- ev$varname # Name the column containing the matrix
      df_out
    }
  }
  
  # Combine columns from all events into a single data frame
  # cbind should now handle the mix of factor columns and matrix columns
  df_list <- lapply(x$events, build_cols)
  df <- try(do.call(cbind, df_list), silent=TRUE)
  if (inherits(df, "try-error")) {
      stop("Failed to construct data frame for model.matrix from event term: ", x$varname, 
           "\n  Original error: ", attr(df, "condition")$message)
  }
  
  # === DEBUG PRINT ===
  #message(sprintf("Term: %s, nrow(df): %d, length(x$onsets): %d", x$varname, nrow(df), length(x$onsets)))
  # === END DEBUG ===
  
  if (nrow(df) != length(x$onsets)) {
      stop("Internal error: Row mismatch when building data frame for event term: ", x$varname)
  }

  ## ----------------------------------------------------------------
  ## 2. model.matrix() with the term's formula
  ## ----------------------------------------------------------------
  # Get the formula (e.g., ~ Condition:Modulator - 1)
  form <- formula(x)
  
  # Special case: Check for single-level factors which cause model.matrix to fail
  # If any factor column has only one level, handle it specially
  has_single_level_factor <- FALSE
  for (col_name in colnames(df)) {
    col_data <- df[[col_name]]
    if (is.factor(col_data) && nlevels(col_data) <= 1) {
      has_single_level_factor <- TRUE
      break
    }
  }
  
  if (has_single_level_factor) {
    # For single-level factors, create a simple matrix of ones
    # This represents the constant effect of that single level
    n_rows <- nrow(df)
    mm <- matrix(1, nrow = n_rows, ncol = 1)
    # Use the condition name from conditions() for naming
    expected_colnames_raw <- conditions(x, drop.empty = FALSE)
    if (length(expected_colnames_raw) > 0) {
      colnames(mm) <- make.names(expected_colnames_raw[1], unique = TRUE)
    } else {
      colnames(mm) <- make.names(x$varname, unique = TRUE)
    }
  } else {
    # Normal case: use model.matrix
    # Ensure the data frame column names match what the formula expects
    # (formula uses original names, df uses sanitized/numbered names)
    # model.matrix should handle this via the data=df argument.
    
    mm <- try(model.matrix(form, data = df), silent=TRUE)
    if (inherits(mm, "try-error")) {
         stop("Failed to create model matrix for event term: ", x$varname, 
              "\n  Formula was: ", deparse(form),
              "\n  Data frame columns: ", paste(colnames(df), collapse=", "),
              "\n  Original error: ", attr(mm, "condition")$message)
    }
    
    # --- SET COLNAMES using conditions() as the single source of truth --- 
    # Get potentially *all* condition names first (before drop.empty)
    expected_colnames_raw <- conditions(x, drop.empty = FALSE)
    
    # Sanitize the raw names using make.names
    expected_colnames <- make.names(expected_colnames_raw, unique = TRUE)
    
    # Basic check: Does the number of columns match?
    # model.matrix might produce fewer columns if rank-deficient, 
    # but conditions() should produce the full set based on expand.grid.
    # This mismatch needs careful handling. For now, assume model.matrix is correct
    # in terms of *which* columns are estimable, and use conditions() to name them.
    # If ncol(mm) < length(expected_colnames), it implies model.matrix dropped some.
    
    # TODO: How to robustly map expected_colnames to the columns present in mm?
    # This is tricky. model.matrix column names (e.g., ConditionB:Modulator1)
    # don't directly map to conditions() output (e.g., Condition[B]:Modulator[1]).
    # For now, we ASSUME the order is the same and the number of columns matches 
    # *if the design is full rank*. If not, this naming will be wrong.
    # A more robust solution might involve parsing model.matrix colnames or attributes.
    # Let's proceed with the direct assignment as per the reviewer's suggestion, 
    # but acknowledge this fragility.
    if (ncol(mm) != length(expected_colnames)) {
        warning(sprintf("Column count mismatch for '%s': model.matrix (%d) vs conditions (%d). Naming may be incorrect due to rank deficiency.",
                        x$varname, ncol(mm), length(expected_colnames_raw)), call. = FALSE)
        # Attempt to name the existing columns anyway, hoping the order matches
        # This might fail if length(expected_colnames) is shorter, though unlikely.
        colnames(mm) <- expected_colnames[1:ncol(mm)] 
    } else {
        colnames(mm) <- expected_colnames
    }
  }
  
  ## ----------------------------------------------------------------
  ## 3. Drop empty columns if requested (optional)
  ## ----------------------------------------------------------------
  # model.matrix might return fewer columns than expected if interactions 
  # lead to rank deficiency. drop.empty applies to the *output* matrix.
  if (isTRUE(drop.empty)) {
      # Check for intercept columns and constant columns
      # Intercept columns are named "(Intercept)" 
      # Constant columns have zero variance but non-zero values (e.g., all ones)
      is_intercept <- (colnames(mm) == "(Intercept)")
      
      # Calculate variance and check for all-zero columns
      col_vars <- apply(mm, 2, var, na.rm = TRUE)
      col_all_zero <- colSums(abs(mm), na.rm = TRUE) == 0
      
      # A column should be kept if:
      # 1. It's an intercept column, OR
      # 2. It has non-zero variance (not constant), OR  
      # 3. It's a constant non-zero column (zero variance but not all zeros)
      is_constant_nonzero <- (col_vars < 1e-8 | is.na(col_vars)) & !col_all_zero
      keep_cols <- which(is_intercept | col_vars > 1e-8 | is.na(col_vars) | is_constant_nonzero)
      
      if (length(keep_cols) < ncol(mm)){
          # message("Dropping empty columns: ", paste(colnames(mm)[! (1:ncol(mm)) %in% keep_cols], collapse=", "))
          mm <- mm[, sort(keep_cols), drop = FALSE]
      }
  }
  
  # Optional: Handle NAs by zero-filling (historical behavior)
  # mm[is.na(mm)] <- 0 

  tibble::as_tibble(mm, .name_repair = "check_unique")
}

## ============================================================================
## Section 13: Print Methods
## ============================================================================

#' Print fmri_term objects.
#'
#' @param x An fmri_term object.
#' @param ... Additional arguments.
#' @export
#' @rdname print
print.fmri_term <- function(x, ...) {
  cat("fmri_term: ", class(x)[[1]], "\n")
  cat("  Term Name: ", x$varname, "\n")
  cat("  Num Rows: ", nrow(design_matrix(x)), "\n")
  cat("  Num Columns: ", ncol(design_matrix(x)), "\n")
}

#' Print convolved_term objects.
#'
#' @param x A convolved_term object.
#' @param ... Additional arguments.
#' @export
#' @rdname print
print.convolved_term <- function(x, ...) {
  cat("fmri_term: ", class(x)[[1]], "\n")
  cat("  Term Name: ", x$varname, "\n")
  cat("  Formula:  ", as.character(formula(x$evterm)), "\n")
  cat("  Num Events: ", nrow(x$evterm$event_table), "\n")
  cat("  Num Rows: ", nrow(design_matrix(x)), "\n")
  cat("  Num Columns: ", ncol(design_matrix(x)), "\n")
  cat("  Conditions: ", conditions(x), "\n")
  cat("  Term Types: ", paste(purrr::map_chr(x$evterm$events, ~ class(.)[[1]])), "\n")
}

#' Print afni_hrf_convolved_term objects.
#'
#' @param x An afni_hrf_convolved_term object.
#' @param ... Additional arguments.
#' @export
#' @rdname print
print.afni_hrf_convolved_term <- function(x, ...) {
  cat("fmri_term: ", class(x)[[1]], "\n")
  cat("  Term Name: ", x$varname, "\n")
  cat("  Formula:  ", as.character(formula(x$evterm)), "\n")
  cat("  Num Events: ", nrow(x$evterm$event_table), "\n")
  cat("  Conditions: ", conditions(x), "\n")
  cat("  Term Types: ", paste(purrr::map_chr(x$evterm$events, ~ class(.)[[1]])), "\n")
}

#' Print event_term objects
#'
#' Provides a concise summary of an event_term object using cli.
#'
#' @param x An event_term object.
#' @param ... Additional arguments (unused).
#' @import cli
#' @export
#' @rdname print
print.event_term <- function(x, ...) {
  nevents <- length(x$onsets)
  nvars <- length(x$events)
  
  cli::cli_h1("Event Term: {.field {x$varname}}")
  
  cli::cli_div(theme = list(span.info = list(color = "blue")))
  cli::cli_text("{.info • Number of Events:} {nevents}")
  cli::cli_text("{.info • Variables:} {paste(names(x$events), collapse = ", ")}")

  cli::cli_h2("Variable Types")
  if (nvars > 0) {
    for (name in names(x$events)) {
      # Use is_continuous generic method
      type <- if (is_continuous(x$events[[name]])) "Continuous" else "Categorical"
      # Use {.field {name}} for safer interpolation of the variable name
      cli::cli_text("{.info  • {.field {name}}:} {type}")
    }
  } else {
     cli::cli_text(" (No variables in term)")
  }
  
  if (nevents > 0) {
    cli::cli_h2("Timing")
    onset_range <- range(x$onsets, na.rm = TRUE)
    dur_range <- range(x$durations, na.rm = TRUE)
    # Evaluate sprintf outside cli::cli_text to avoid interpolation issues
    onset_range_str <- sprintf("%.2f - %.2f sec", onset_range[1], onset_range[2])
    dur_range_str <- sprintf("%.2f - %.2f sec", dur_range[1], dur_range[2])
    cli::cli_text("{.info • Onset Range:} {onset_range_str}")
    cli::cli_text("{.info • Duration Range:} {dur_range_str}")
    
    cli::cli_h2("Blocks")
    blocks_table <- table(x$blockids)
    nblocks <- length(blocks_table)
    cli::cli_text("{.info • Number of Blocks:} {nblocks}")
    # Truncate long block lists
    max_show_blocks <- 10
    blocks_display <- if(nblocks > max_show_blocks) {
                          paste(c(names(blocks_table)[1:max_show_blocks], "..."), collapse = ", ")
                      } else {
                          paste(names(blocks_table), collapse = ", ")
                      }
    cli::cli_text("{.info • Block IDs:} {blocks_display}")
    events_per_block_display <- if(nblocks > max_show_blocks) {
                                     paste(c(blocks_table[1:max_show_blocks], "..."), collapse = ", ")
                                 } else {
                                     paste(blocks_table, collapse = ", ")
                                 }
    cli::cli_text("{.info • Events per Block:} {events_per_block_display}")
  } else {
      cli::cli_alert_info("Event term is empty.")
  }
  cli::cli_end()
  
  invisible(x)
}

## ============================================================================
## Section 14: End of File
###############################################################################
# End of event_vector.R
</file>

<file path="R/basis.R">
#' @noRd 
#' @keywords internal
dctbasis <- function(n, p=n, const=FALSE) {
  m <- 1:n
  ret <- do.call(cbind, lapply(2:p, function(k) {
    (2/n)^(1/2) * cos(((2*m-1)*k*pi)/(2*n))
  }))
  
  if (const) {
    ret <- cbind((1/n)^.5, ret)
  }
  
  ret
}


#' sub_basis
#' 
#' subset a parametric basis regressor
#' 
#' 
#' @param x the object
#' @param subset the subset
#' @export
sub_basis <-  function(x, subset) UseMethod("sub_basis")


#' Predict from a ParametricBasis object
#'
#' Dispatch to the appropriate method for transforming new data
#' according to a specific parametric basis.
#'
#' @param object ParametricBasis object.
#' @param newdata Numeric vector to transform.
#' @param ... Additional arguments.
#' @param newgroup Optional factor for group-dependent bases.
#' @rdname predict.ParametricBasis
#' @export
predict.ParametricBasis <- function(object, newdata, ...) {
  UseMethod("predict", object)
}


#' Ident
#' 
#' A basis that applies identity transform to a set of raw variables.
#' 
#' @param ... a list of variable names
#' @return an instance of class \code{Ident} extending \code{ParametricBasis}
#' @export 
Ident <- function(...) {
  vlist <- list(...)

  varnames <- as.list(substitute(list(...)))[-1]
  varnames <- unlist(lapply(varnames, as.character))
  names(vlist) <- varnames
  y <- do.call(cbind, vlist)
  
  ret <- list(vlist=vlist, y=y, varnames=varnames, name=paste(varnames, collapse="_"))
  class(ret) <- c("Ident", "ParametricBasis")
  ret
}


#' Polynomial basis
#' 
#' Orthogonal polynomial expansion of a linear term based on \code{\link[stats]{poly}}
#' 
#' @param x a numeric vector at which to evaluate the polynomial. Missing values are not allowed in x.
#' @param degree the degree of the polynomial. Must be less than the number of unique points.
#' @return an instance of class \code{Poly} extending \code{ParametricBasis}
#' 
#' @seealso \link[stats]{poly}
#' @export 
Poly <- function(x, degree) {
  mc <- match.call()
  argname <- as.character(mc[["x"]])
  pres <- poly(x,degree)
  n <- paste0("poly_", argname)
  ret <- list(x=x,y=pres,fun="poly",argname=argname, 
              name=n,
              degree=degree)
  class(ret) <- c("Poly", "ParametricBasis")
  ret
}

# Poly <- function(x, degree) {
#   mc <- match.call()
#   
#   # If x is already numeric, do the polynomial expansion now (old behavior)
#   if (is.numeric(x)) {
#     pres <- stats::poly(x, degree)
#   } else {
#     # If x is not numeric (likely a symbol like `modulator`),
#     # defer actual polynomial expansion until sub_basis.Poly() or similar.
#     pres <- NULL
#   }
#   
#   n <- paste0("poly_", as.character(mc[["x"]]), "_", degree)
#   
#   ret <- list(
#     x       = x,       # might be a numeric vector or a symbol
#     y       = pres,    # either the poly(...) matrix OR NULL
#     fun     = "poly",
#     argname = as.character(mc[["x"]]),
#     name    = n,
#     degree  = degree,
#     call    = mc       # store original call for lazy eval
#   )
#   
#   class(ret) <- c("Poly", "ParametricBasis")
#   ret
# }

#' Standardized basis
#' 
#' Standardize a numeric vector by centering and scaling, handling NAs appropriately.
#' If the computed standard deviation is \code{NA} or zero, a small constant
#' (\code{1e-6}) is used instead to avoid division by zero.
#' The returned basis matrix has one column with this standardized name.
#' 
#' @param x a numeric vector to standardize. Missing values are allowed and will be replaced with 0 after standardization.
#' @return an instance of class \code{Standardized} extending \code{ParametricBasis}
#' @export 
Standardized <- function(x) {
  mc <- match.call()
  
  # Remove NAs for computing mean and sd
  x_clean <- x[!is.na(x)]
  x_mean <- mean(x_clean)
  x_sd <- sd(x_clean)
  if (is.na(x_sd) || x_sd == 0) x_sd <- 1e-6
  
  # Standardize, replacing NAs with 0
  standardized <- (x - x_mean) / x_sd
  standardized[is.na(standardized)] <- 0
  
  n <- paste0("std", "_", as.character(mc[["x"]]))
  ret <- list(x=x, y=matrix(standardized, ncol=1, dimnames=list(NULL, n)),
              mean=x_mean, sd=x_sd,
              fun="standardized", 
              argname=as.character(mc[["x"]]), 
              name=n)
  class(ret) <- c("Standardized", "ParametricBasis")
  ret
}

#' @export
#' @rdname predict.ParametricBasis
predict.Standardized <- function(object, newdata, ...) {
  # Standardize new data using stored mean and sd
  sd_val <- object$sd
  if (is.na(sd_val) || sd_val == 0) sd_val <- 1e-6
  standardized <- (newdata - object$mean) / sd_val
  # Replace NAs with 0 to match training behavior
  standardized[is.na(standardized)] <- 0
  matrix(standardized, ncol=1, dimnames=list(NULL, object$name))
}

#' @export
sub_basis.Standardized <- function(x, subset) {
  ret <- list(x=x$x[subset],
              y=x$y[subset, , drop = FALSE],
              fun=x$fun,
              argname=x$argname,
              name=x$name,
              mean=x$mean,
              sd=x$sd)
  class(ret) <- c("Standardized", "ParametricBasis")
  ret
}

#' @export
levels.Standardized <- function(x) {
  x$argname 
}

#' @export
columns.Standardized <- function(x) {
  continuous_token(x$name)
}


#' B-spline basis
#' 
#' Generate the B-spline basis matrix for a polynomial spline.
#' 
#' @param x a numeric vector at which to evaluate the spline. Missing values are not allowed in x
#' @param degree the degree of the piecewise polynomial
#' @importFrom splines bs
#' @seealso \link[splines]{bs}
#' @export
#' @return an \code{BSpline} list instance
BSpline <- function(x, degree) {
  mc <- match.call()
  argname <- as.character(mc[["x"]])[1]
  pres <- bs(x, degree = degree)
  n <- paste0("bs_", argname)
  ret <- list(x=x, y=pres, fun="bs", argname=argname, 
              name=n,
              degree=degree)
  class(ret) <- c("BSpline", "ParametricBasis")
  
  ret
}


#' @export
#' @rdname predict.ParametricBasis
predict.Poly <- function(object,newdata,...) {
  predict(object$y, newdata)
}

#' @export
sub_basis.Poly <- function(x, subset) {
  ret <- list(x=x$x[subset],
       y=x$y[subset,],
       fun=x$fun,
       argname=x$argname,
       degree=x$degree)
  class(ret) <- c("Poly", "ParametricBasis")
  ret
}

#' @export
sub_basis.BSpline <- function(x, subset) {
  ret <- list(x=x$x[subset],
              y=x$y[subset, , drop=FALSE],
              fun=x$fun,
              argname=x$argname,
              degree=x$degree)
  class(ret) <- c("BSpline", "ParametricBasis")
  ret
}

#' @export
sub_basis.Ident <- function(x, subset) {
  ret <- list(y = x$y[subset, , drop = FALSE], 
              varnames = x$varnames, 
              fun = "ident")
  class(ret) <- c("Ident", "ParametricBasis")
  ret
}

#' @export
#' @rdname predict.ParametricBasis
predict.BSpline <- function(object, newdata, ...) {
  # Rebuild using bs() and stored attributes
  splines::bs(newdata, degree = object$degree,
     knots = attr(object$y, "knots"),
     Boundary.knots = attr(object$y, "Boundary.knots"))
}

#' @export
#' @rdname predict.ParametricBasis
predict.Ident <- function(object,newdata,...) {
  if (!is.matrix(newdata) && !is.data.frame(newdata)) {
      stop("newdata for predict.Ident should be matrix or data.frame containing necessary columns")
  }
  return(as.matrix(newdata[, object$varnames, drop=FALSE]))
}

#' @export
levels.Ident <- function(x) {
  x$varnames
}

#' @export
levels.BSpline <- function(x) {
  ncols <- ncol(x$y)
  if (is.null(ncols) || ncols == 0) {
    return(character(0))
  }
  indices <- seq_len(ncols)
  zeropad(indices, ncols) # Pad based on the number of columns
}

#' @export
levels.Poly <- function(x) {
  ncols <- ncol(x$y) 
  if (is.null(ncols) || ncols == 0) {
    return(character(0))
  }
  indices <- seq_len(ncols) # Or seq_len(x$degree)
  zeropad(indices, x$degree) 
}

#' @export
columns.Poly <- function(x) {
  # Use degree for padding width
  indices <- seq_len(x$degree)
  padded_indices <- zeropad(indices, x$degree) # Enforces min width 
  # Return only the padded index as the condition tag component
  continuous_token(padded_indices)
}

#' @export
columns.BSpline <- function(x) {
  # Use degree for padding width
  indices <- seq_len(x$degree)
  padded_indices <- zeropad(indices, x$degree) # Enforces min width 
  # Return only the padded index as the condition tag component
  continuous_token(padded_indices)
}

#' @export
columns.Ident <- function(x) {
  continuous_token(x$varnames)
}


#' @rdname nbasis
#' @export
nbasis.BSpline <- function(x, ...) {
  x$degree
}

#' @rdname nbasis
#' @export
nbasis.Poly <- function(x,...) {
  x$degree
}

#' Z-score (global) basis
#'
#' @param x numeric vector (NAs allowed)
#' @return object of class c("Scale","ParametricBasis")
#' @export
Scale <- function(x) {
  mc <- match.call()
  varname <- as.character(mc[["x"]])
  mu <- mean(x, na.rm = TRUE)
  sd_ <- stats::sd(x, na.rm = TRUE)
  if (is.na(sd_) || sd_ == 0) sd_ <- 1e-6 # Add guard for sd_ == 0 or NA
  z  <- (x - mu)/sd_
  z[is.na(z)] <- 0
  
  final_name <- paste0("z_", varname)
  ret <- list(x = x,
              y = matrix(z, ncol = 1, dimnames=list(NULL, final_name)),
              mean = mu,
              sd   = sd_,
              fun  = "scale",
              argname = varname,
              name = final_name)
  class(ret) <- c("Scale","ParametricBasis")
  ret
}

#' @export
#' @param object ParametricBasis object
#' @param newdata Numeric vector of new values
#' @param ... Additional arguments
#' @name predict.ParametricBasis
#' @title Predict Method for ParametricBasis Objects
#' @rdname predict.ParametricBasis
predict.Scale <- function(object, newdata, ...) {
  z <- (newdata - object$mean)/object$sd
  z[is.na(z)] <- 0
  matrix(z, ncol = 1, dimnames=list(NULL, object$name))
}

#' @export
#' @rdname sub_basis
sub_basis.Scale <- function(x, subset) {
  ret <- x
  ret$x <- x$x[subset]
  # Perform subsetting
  subsetted_y <- x$y[subset, , drop = FALSE]
  # Ensure the result is a matrix, specifically N x 1 if it was originally
  if (!is.matrix(subsetted_y)) {
    # This case indicates an unexpected dimension drop.
    # Reform it into an N x 1 matrix.
    # The number of rows should be length(ret$x) if subsetting was consistent.
    # warning("Dimension dropped unexpectedly during Standardized/Scale basis subsetting. Re-casting to matrix.", call.=FALSE)
    ret$y <- matrix(subsetted_y, ncol = 1, dimnames = list(NULL, colnames(x$y)))
  } else {
    ret$y <- subsetted_y
  }
  class(ret) <- class(x)
  ret
}

#' @export
#' @param x ParametricBasis object
#' @name levels.ParametricBasis
#' @title Get Levels/Names for ParametricBasis Objects
#' @param x ParametricBasis object
#' @rdname levels.ParametricBasis
levels.Scale  <- function(x) x$argname

#' @export
#' @param x ParametricBasis object
#' @name columns.ParametricBasis
#' @title Get Column Name Information for ParametricBasis Objects
#' @rdname columns.ParametricBasis
columns.Scale <- function(x) {
  continuous_token(x$name)
}


#' Z-score within groups
#' 
#' @param x numeric vector
#' @param g grouping factor / character / integer of same length as x
#' @export
ScaleWithin <- function(x, g) {
  mc <- match.call()
  varname <- as.character(mc[["x"]])
  grpname <- as.character(mc[["g"]])
  stopifnot(length(x) == length(g))
  g <- as.factor(g)
  
  # pre-compute means/sds per group (ignoring NAs)
  stats <- tapply(seq_along(x), g, function(idx) {
    mu <- mean(x[idx], na.rm = TRUE)
    sd_ <- stats::sd(x[idx], na.rm = TRUE)
    # Handle groups with sd=0 or only one non-NA value
    if (is.na(sd_) || sd_ == 0) sd_ <- 1e-6 # Use small value instead of 0 or NA
    c(mean = mu, sd = sd_)
  })
  mus <- sapply(stats, `[[`, "mean")
  sds <- sapply(stats, `[[`, "sd")
  
  z <- mapply(function(val, grp) {
              grp_name <- as.character(grp) # Ensure factor level name is used
              mu <- mus[grp_name]; sd_ <- sds[grp_name]
              if (is.na(val) || is.na(mu) || is.na(sd_)) 0
              else (val - mu) / sd_
            },
            x, g, SIMPLIFY = TRUE)
  
  final_name <- paste0("z_", varname, "_by_", grpname)
  ret <- list(x = x,
              group = g,
              y = matrix(z, ncol = 1, dimnames=list(NULL, final_name)),
              means = mus,
              sds   = sds,
              fun   = "scale_within",
              argname = varname,
              grpname = grpname,
              name = final_name)
  class(ret) <- c("ScaleWithin","ParametricBasis")
  ret
}

#' @export
#' @rdname predict.ParametricBasis
predict.ScaleWithin <- function(object, newdata, newgroup, ...) {
  stopifnot(length(newdata) == length(newgroup))
  newgroup <- as.factor(newgroup)
  
  z <- mapply(function(val, grp) {
      grp_name <- as.character(grp) # Ensure factor level name used for indexing
      mu <- object$means[grp_name]; sd_ <- object$sds[grp_name]
      if (is.na(val) || is.na(mu) || is.na(sd_)) 0 # Handle missing group stats in newdata
      else (val - mu)/sd_
    },
    newdata, newgroup, SIMPLIFY = TRUE)
  matrix(z, ncol = 1, dimnames=list(NULL, object$name))
}

#' @export
#' @rdname sub_basis
sub_basis.ScaleWithin <- function(x, subset) {
  ret <- x
  ret$x     <- x$x[subset]
  ret$group <- x$group[subset]
  ret$y     <- x$y[subset,,drop = FALSE]
  class(ret) <- class(x)
  ret
}

#' @export
#' @rdname levels.ParametricBasis
levels.ScaleWithin  <- function(x) x$argname

#' @export
#' @rdname columns.ParametricBasis
columns.ScaleWithin <- function(x) {
  continuous_token(x$name)
}


#' Robust Scaling (Median/MAD)
#'
#' @param x numeric vector (NAs allowed)
#' @return object of class c("RobustScale","ParametricBasis")
#' @export
RobustScale <- function(x) {
  mc <- match.call()
  varname <- as.character(mc[["x"]])
  med <- stats::median(x, na.rm = TRUE)
  mad_ <- stats::mad(x, na.rm = TRUE)  # Default constant=1.4826
  if (is.na(mad_) || mad_ == 0) mad_ <- 1e-6 # Handle zero MAD
  z <- (x - med)/mad_
  z[is.na(z)] <- 0
  
  final_name <- paste0("robz_", varname)
  ret <- list(x = x,
              y = matrix(z,  ncol = 1, dimnames=list(NULL, final_name)),
              median = med,
              mad    = mad_,
              fun = "robust_scale",
              argname = varname,
              name = final_name)
  class(ret) <- c("RobustScale","ParametricBasis")
  ret
}

#' @export
#' @rdname predict.ParametricBasis
predict.RobustScale <- function(object, newdata, ...) {
  z <- (newdata - object$median)/object$mad
  z[is.na(z)] <- 0
  matrix(z, ncol = 1, dimnames=list(NULL, object$name))
}

#' @export
#' @rdname sub_basis
# Use the same logic as Scale
sub_basis.RobustScale <- sub_basis.Scale

#' @export
#' @rdname levels.ParametricBasis
levels.RobustScale  <- function(x) x$argname

#' @export
#' @rdname columns.ParametricBasis
columns.RobustScale <- columns.Scale

# Add nbasis methods -----

#' @rdname nbasis
#' @export
nbasis.Scale        <- function(x,...) 1L

#' @rdname nbasis
#' @export
nbasis.ScaleWithin  <- function(x,...) 1L

#' @rdname nbasis
#' @export
nbasis.RobustScale  <- function(x,...) 1L

#' @rdname nbasis
#' @export
nbasis.Standardized <- function(x,...) 1L

#' @rdname nbasis
#' @export
nbasis.Ident        <- function(x, ...) ncol(x$y)
</file>

<file path="R/fmri_betas.R">
#' @noRd
#' @keywords internal
ridge_betas <- function(X, Y, penalty_factor=rep(1,ncol(X)), lambda=.01) {
  with_package("glmnet")
  fit <- glmnet::glmnet(X, Y, penalty.factor=penalty_factor, alpha=0,lambda=lambda)
  coef(fit)[,1,drop=FALSE]
}


#' @noRd
#' @keywords internal
pls_betas <- function(X, Y, ncomp=3) {
  with_package("pls")
  dx <- list(X=as.matrix(X), Y=Y)
  fit <- pls::plsr(Y ~ X, data=dx, ncomp=ncomp, method="simpls", scale=TRUE, maxit=1500)
  coef(fit, ncomp=ncomp)[,,1]
}


#' @keywords internal
#' @noRd
pls_global_betas <- function(X, Y, ncomp=3) {
  with_package("pls")
  dx <- list(X=as.matrix(X), Y=Y)
  fit <- pls::plsr(Y ~ X, data=dx, ncomp=ncomp, method="widekernelpls", scale=TRUE, maxit=1500)
  coef(fit, ncomp=ncomp)[,,1]
}


#' @keywords internal
#' @noRd
ols_betas <- function(X, Y) {
  fit <- lm.fit(as.matrix(X),Y)
  coef(fit)
}


#' @keywords internal
#' @noRd
slm_betas <- function(X, Y) {
  with_package("care")
  slm.1 <- care::slm(X, Y, verbose=FALSE)
  b2 <- coef(slm.1)[,-(1:2)]
  b1 <- coef(slm.1)[,1]
  b1 + b2
}


#' @keywords internal
#' @noRd
mixed_betas <- function(X, Y, ran_ind, fixed_ind) {
  # Ensure X is a matrix
  X <- as.matrix(X)
  
  # Check dimensions and prevent 0-dim matrices
  if (ncol(X) == 0 || nrow(X) == 0) {
    stop("Design matrix X has zero rows or columns")
  }
  
  # Ensure ran_ind has proper values
  if (length(ran_ind) == 0) {
    stop("No random effect indices specified")
  }
  
  # Handle case when fixed_ind is NULL
  if (is.null(fixed_ind)) {
    fixed_ind <- integer(0)  # Empty integer vector
  }
  
  # Check if indices are out of bounds
  if (max(c(ran_ind, fixed_ind)) > ncol(X)) {
    stop("Index out of bounds: indices exceed number of columns in X")
  }
  
  # Ensure Y is a vector
  if (!is.vector(Y)) {
    Y <- as.vector(Y)
  }
  
  # Try to use rrBLUP if available
  tryCatch({
    with_package("rrBLUP")
    
    # If fixed_ind is empty, use a minimal X matrix (intercept only)
    X_fixed <- if (length(fixed_ind) == 0) {
      matrix(1, nrow = nrow(X), ncol = 1)
    } else {
      X[, fixed_ind, drop = FALSE]
    }
    
    
    fit <- rrBLUP::mixed.solve(Y, 
                               Z = X[, ran_ind, drop = FALSE], 
                               X = X_fixed) 
                               #bounds = c(1e-07, 0.5))
    
    # Return results, handling the case where fixed_ind is empty
    if (length(fixed_ind) == 0) {
      return(fit$u)  # Only return random effects
    } else {
      return(c(fit$u, fit$b))  # Return both random and fixed effects
    }
  }, 
  error = function(e) {
    # If rrBLUP fails, try using our C++ implementation if available
    message("rrBLUP mixed.solve failed, attempting alternative: ", e$message)
    
    if (requireNamespace("Rcpp", quietly = TRUE) && 
        exists("mixed_solve_cpp", mode = "function")) {
      
      # Use the C++ implementation with proper input validation
      X_fixed <- if (length(fixed_ind) == 0) {
        matrix(1, nrow = nrow(X), ncol = 1)
      } else {
        X[, fixed_ind, drop = FALSE]
      }
      
      fit <- tryCatch({
        mixed_solve_cpp(y = Y, 
                        Z = X[, ran_ind, drop = FALSE], 
                        X = X_fixed)
      }, error = function(e2) {
        # If even that fails, use a fallback
        message("C++ mixed model solver also failed: ", e2$message)
        if (length(fixed_ind) == 0) {
          return(list(u = rep(0, length(ran_ind))))
        } else {
          return(list(
            u = rep(0, length(ran_ind)),
            beta = rep(0, length(fixed_ind))
          ))
        }
      })
      
      # Return results based on whether fixed_ind is empty
      if (length(fixed_ind) == 0) {
        return(fit$u)
      } else {
        return(c(fit$u, fit$beta))
      }
    } else {
      # Last resort - return zeros
      message("No alternative mixed model solver available")
      if (length(fixed_ind) == 0) {
        return(rep(0, length(ran_ind)))
      } else {
        return(rep(0, length(c(ran_ind, fixed_ind))))
      }
    }
  })
}

mixed_betas_cpp <- function(X, Y, ran_ind, fixed_ind) {
  # Handle case when fixed_ind is NULL by using a constant
  X_fixed <- if (is.null(fixed_ind) || length(fixed_ind) == 0) {
    matrix(1, nrow = nrow(X), ncol = 1)
  } else {
    X[, fixed_ind, drop = FALSE]
  }
  
  fit <- mixed_solve_internal(as.matrix(Y), Z = X[, ran_ind, drop = FALSE], 
                             X = X_fixed, bounds = c(1e-05, .2))
  c(fit$u, fit$b)
}



#' Estimate betas using various regression methods
#'
#' This function estimates betas (regression coefficients) for fixed and random effects
#' using various regression methods including mixed models, least squares, and PLS.
#'
#' @param x An object of class `fmri_dataset` representing the fMRI dataset.
#' @param fixed A formula specifying the fixed regressors that model constant effects (i.e., non-varying over trials).
#' @param ran A formula specifying the random (trialwise) regressors that model single trial effects.
#' @param block A formula specifying the block factor.
#' @param method The regression method for estimating trialwise betas; one of "mixed", "mixed_cpp", "lss", "lss_naive", "lss_cpp", "pls", "pls_global", or "ols".
#' @param basemod A `baseline_model` instance to regress out of data before beta estimation (default: NULL).
#' @param maxit Maximum number of iterations for optimization methods (default: 1000).
#' @param fracs Fraction of voxels used for prewhitening.
#' @param progress Logical; show progress bar.
#' @param ... Additional arguments passed to the estimation method.
#'
#' @return A list of class "fmri_betas" containing the following components:
#'   * betas_fixed: NeuroVec object representing the fixed effect betas.
#'   * betas_ran: NeuroVec object representing the random effect betas.
#'   * design_ran: Design matrix for random effects.
#'   * design_fixed: Design matrix for fixed effects.
#'   * design_base: Design matrix for baseline model.
#'   * basemod: Baseline model object.
#'   * fixed_model: Fixed effect model object.
#'   * ran_model: Random effect model object.
#'   * estimated_hrf: The estimated HRF vector (NULL for most methods).
#'
#' @seealso \code{\link{fmri_dataset}}, \code{\link{baseline_model}}, \code{\link{event_model}}
#'
#' @examples
#' \dontrun{
#' facedes <- read.table(system.file("extdata", "face_design.txt", package = "fmrireg"), header=TRUE)
#' facedes$frun <- factor(facedes$run)
#' scans <- paste0("rscan0", 1:6, ".nii")
#'
#' dset <- fmri_dataset(scans=scans, mask="mask.nii", TR=1.5, 
#'         run_length=rep(436,6), event_table=facedes)
#' fixed = onset ~ hrf(run)
#' ran = onset ~ trialwise()
#' block = ~ run
#'
#' betas <- estimate_betas(dset, fixed=fixed, ran=ran, block=block, method="mixed")
#' }
#' @export
estimate_betas.fmri_dataset <- function(x, fixed = NULL, ran, block,
                                        method = c("mixed", "mixed_cpp", "lss", "lss_naive", "lss_cpp",
                                                   "pls",  "pls_global", "ols"),
                                        basemod = NULL,
                                        maxit = 1000,
                                        fracs = 0.5,
                                        progress = TRUE,
                                        ...) {
  method <- match.arg(method)
  dset <- x
  bvec <- get_data(dset)
  mask <- get_mask(dset)
  
  bmod <- if (is.null(basemod)) {
    baseline_model("constant", sframe = dset$sampling_frame)
  } else {
    basemod
  }
  
  bdes <- gen_beta_design(fixed, ran, block, bmod, dset, method = method)
  betas <- run_estimate_betas(bdes, dset, method, block = block,
                              maxit = maxit, fracs = fracs,
                              progress = progress, ...)
  
  # Check dimensions before indexing
  message(sprintf("beta_matrix dimensions: %d x %d", 
                  nrow(betas$beta_matrix), ncol(betas$beta_matrix)))
  message(sprintf("ran_ind length: %d", length(bdes$ran_ind)))
  
  
  nbetas <- nrow(betas$beta_matrix)
  ospace_ran <- neuroim2::add_dim(neuroim2::space(mask), length(bdes$ran_ind))
  
  if (!is.null(bdes$fixed_ind)) {
    ospace_fixed <- neuroim2::add_dim(neuroim2::space(mask), length(bdes$fixed_ind))
    fixed <- neuroim2::NeuroVec(as.matrix(betas$beta_matrix[bdes$fixed_ind, , drop = FALSE]), ospace_fixed, mask = mask)
  } else {
    fixed <- NULL
  }
  
  ran <- neuroim2::NeuroVec(as.matrix(betas$beta_matrix[bdes$ran_ind, , drop = FALSE]), ospace_ran, mask = mask)
  
  ret <- list(betas_fixed = fixed,
              betas_ran = ran,
              design_ran = bdes$dmat_ran,
              design_fixed = bdes$dmat_fixed,
              design_base = bdes$dmat_base,
              basemod = basemod,
              fixed_model = bdes$emod_fixed,
              ran_model = bdes$emod_ran,
              estimated_hrf = betas$estimated_hrf)
  
  class(ret) <- "fmri_betas"
  ret
}


#' @keywords internal
run_estimate_betas <- function(bdes, dset, method,
                               block, maxit = 100,
                               ncomp = 4, fracs = .5,
                               progress = TRUE,
                               ...) {
  method <- match.arg(method, c("lss", "lss_naive", "lss_cpp", "mixed", "mixed_cpp", "pls", "pls_global", "ols"))
  
  # Capture ... into dotargs
  dotargs <- list(...)
  
  xdat <- build_design_data(bdes)

  if (method == "mixed") {
    vecs <- masked_vectors(dset)
    res <- map_voxels(vecs, function(v) {
      v0 <- resid(lsfit(xdat$Base, v, intercept = FALSE))
      mixed_betas(xdat$X, v0, ran_ind = seq_len(ncol(bdes$dmat_ran)),
                  fixed_ind = if (!is.null(bdes$dmat_fixed)) {
                    (ncol(bdes$dmat_ran) + 1):(ncol(bdes$dmat_ran) + ncol(bdes$dmat_fixed))
                  } else {
                    NULL
                  })
    }, .progress = progress)
    list(beta_matrix = as.matrix(res), estimated_hrf = NULL)
  } else if (method == "mixed_cpp") {
    vecs <- masked_vectors(dset)
    res <- map_voxels(vecs, function(v) {
      v0 <- resid(lsfit(xdat$Base, v, intercept = FALSE))
      mixed_betas_cpp(as.matrix(xdat$X), v0,
                  ran_ind = seq_len(ncol(bdes$dmat_ran)),
                  fixed_ind = if (!is.null(bdes$dmat_fixed)) {
                    (ncol(bdes$dmat_ran) + 1):(ncol(bdes$dmat_ran) + ncol(bdes$dmat_fixed))
                  } else {
                    NULL
                  })
    }, .progress = progress)

    list(beta_matrix = as.matrix(res), estimated_hrf = NULL)
    
  
  }  else if (method == "lss_naive") {
    lss_naive(dset, bdes)
  } else if (method == "lss") {
    # Estimate random effects using LSS
    beta_matrix_ran <- lss_fast(dset, bdes, use_cpp = FALSE)
    
    # If fixed effects are present, estimate them separately with OLS
    if (!is.null(bdes$fixed_ind) && length(bdes$fixed_ind) > 0) {
      # Get data and design matrices
      data_matrix <- get_data_matrix(dset)
      mask_idx <- which(get_mask(dset) > 0)
      vecs <- neuroim2::vectors(data_matrix, subset = mask_idx)
      
      # Prepare the full design matrix (base + fixed)
      X_base_fixed <- cbind(as.matrix(bdes$dmat_base), as.matrix(bdes$dmat_fixed))
      
      # Estimate fixed effects with OLS
      beta_matrix_fixed <- map_voxels(vecs, function(v) {
        fit <- lm.fit(X_base_fixed, v)
        coef(fit)[(ncol(bdes$dmat_base) + 1):length(coef(fit))]
      }, .progress = progress)
      
      # Combine random and fixed effects into a single beta matrix
      # Order: [random effects, fixed effects]
      beta_matrix <- rbind(beta_matrix_ran, beta_matrix_fixed)
    } else {
      # No fixed effects, just return random effects
      beta_matrix <- beta_matrix_ran
    }
    
    list(beta_matrix = beta_matrix, estimated_hrf = NULL)
  } else if (method == "lss_cpp") {
    beta_matrix <- lss_fast(dset, bdes, use_cpp = TRUE)
    list(beta_matrix = beta_matrix, estimated_hrf = NULL)
  } else if (method == "pls") {
    vecs <- masked_vectors(dset)

    res <- map_voxels(vecs, function(v) {
        v0 <- resid(lsfit(xdat$Base, v, intercept = FALSE))
        pls_betas(xdat$X, v0, ncomp = ncomp)
    }, .progress = progress)

    list(beta_matrix = as.matrix(res), estimated_hrf = NULL)
  } else if (method == "pls_global") {
    vecs <- masked_vectors(dset)
    Y <- map_voxels(vecs, function(v) v, .progress = progress)

    if (ncomp < log(ncol(Y))) {
      warning("'ncomp' for pls_global method is less than log(nvoxels), consider increasing.")
    }
    
    Y0 <- resid(lsfit(xdat$Base, Y, intercept = FALSE))
    list(beta_matrix=pls_global_betas(xdat$X, Y0, ncomp=ncomp), estimated_hrf=NULL)
  } else if (method == "ols") {
    vecs <- masked_vectors(dset)
    Y <- map_voxels(vecs, function(v) v, .progress = progress)
    Y0 <- resid(lsfit(xdat$Base, Y, intercept = FALSE))
    beta_matrix <- ols_betas(xdat$X, Y0)
    # Ensure we return a list with beta_matrix as a named component
    list(beta_matrix = as.matrix(beta_matrix), estimated_hrf = NULL)
  } else {
    stop("Invalid method. Supported methods are 'lss', 'lss_naive', 'mixed', 'mixed_cpp', 'pls', 'pls_global', and 'ols'")
  }
}


#' @keywords internal
gen_beta_design <- function(fixed = NULL, ran, block, bmod, dset, method = NULL) {
  # Get the base design matrices
  if (!is.null(fixed)) {
    emod_fixed <- event_model(fixed, data = dset$event_table, block = block, sampling_frame = dset$sampling_frame)
    dmat_fixed <- design_matrix(emod_fixed)
  } else {
    emod_fixed <- NULL
    dmat_fixed <- NULL
  }
  
  emod_ran <- event_model(ran, data = dset$event_table, block = block, sampling_frame = dset$sampling_frame)
  dmat_ran <- design_matrix(emod_ran)
  dmat_base <- design_matrix(bmod)
  
  # Standard indices for all methods
  ran_ind <- 1:ncol(dmat_ran)
  ran_ind_expanded <- ran_ind
  
  # Combine design matrices
  dmat_all <- if (is.null(fixed)) {
    cbind(dmat_ran, dmat_base)
  } else {
    cbind(dmat_ran, dmat_fixed, dmat_base)
  }
  
  # Calculate fixed and base indices
  start_fixed <- ncol(dmat_ran) + 1
  if (is.null(fixed)) {
    start_base <- start_fixed
    fixed_ind <- NULL
  } else {
    start_base <- start_fixed + ncol(dmat_fixed)
    fixed_ind <- start_fixed:(start_base - 1)
  }
  base_ind <- start_base:ncol(dmat_all)
  
  # Return list with indices
  list(
    bmod = bmod,
    emod_fixed = emod_fixed,
    emod_ran = emod_ran,
    dmat_fixed = dmat_fixed,
    dmat_ran = dmat_ran,
    dmat_base = dmat_base,
    ran_ind = ran_ind,
    ran_ind_expanded = ran_ind_expanded,
    fixed_ind = fixed_ind,
    base_ind = base_ind
  )
}

#' Estimate betas for a matrix dataset
#'
#' This function estimates betas (regression coefficients) for fixed and random effects
#' in a matrix dataset using various methods.
#'
#' @param x An object of class `matrix_dataset` representing the matrix dataset
#' @param fixed A formula specifying the fixed regressors that model constant effects (i.e., non-varying over trials)
#' @param ran A formula specifying the random (trialwise) regressors that model single trial effects
#' @param block A formula specifying the block factor
#' @param method The regression method for estimating trialwise betas; one of "mixed", "pls", "pls_global", or "ols" (default: "mixed")
#' @param basemod A `baseline_model` instance to regress out of data before beta estimation (default: NULL)
#' @param ncomp Number of PLS components for the "pls" and "pls_global" methods (default: 4)
#' @param lambda Lambda parameter (not currently used; default: 0.01)
#' @param fracs Fraction of voxels used for prewhitening.
#' @param progress Logical; show progress bar.
#' @param ... Additional arguments passed to the estimation method
#' 
#' @family estimate_betas
#'
#' @return A list of class "fmri_betas" containing the following components:
#'   * betas_fixed: Matrix representing the fixed effect betas
#'   * betas_ran: Matrix representing the random effect betas
#'   * design_ran: Design matrix for random effects
#'   * design_fixed: Design matrix for fixed effects
#'   * design_base: Design matrix for baseline model
#'
#' @seealso \code{\link{matrix_dataset}}, \code{\link{baseline_model}}
#'
#' @export
estimate_betas.matrix_dataset <- function(x, fixed = NULL, ran, block,
                                        method = c("lss", "lss_cpp", "lss_naive", "mixed", "mixed_cpp", "pls", "pls_global", "ols"),
                                        basemod = NULL,
                                        ncomp = 4, lambda = .01,
                                        fracs = .5, progress = TRUE, ...) {
  
  method <- match.arg(method)
  dset <- x
  mask <- get_mask(dset)
 
  bmod <- if (is.null(basemod)) {
    baseline_model("constant", sframe=dset$sampling_frame)
  } else {
    basemod
  }


  bdes <- gen_beta_design(fixed, ran, block, bmod, dset)
  betas <- run_estimate_betas(bdes, dset, method, ncomp = ncomp,
                              fracs = fracs, progress = progress)
  
  # Access beta_matrix from the list returned by run_estimate_betas
  beta_matrix <- betas$beta_matrix
  
  # Extract random and fixed effects from the beta matrix
  if (length(bdes$ran_ind) > 0) {
    ran <- as.matrix(beta_matrix[bdes$ran_ind,,drop=FALSE])
  } else {
    ran <- NULL
  }
  
  if (length(bdes$fixed_ind) > 0) {
    fixed <- as.matrix(beta_matrix[bdes$fixed_ind,,drop=FALSE])
  } else {
    fixed <- NULL
  }
  
  ret <- list(betas_fixed=fixed,
              betas_ran=ran,
              design_ran=bdes$dmat_ran,
              design_fixed=bdes$dmat_fixed,
              design_base=bdes$dmat_base)
  
  class(ret) <-  c("fmri_betas")
  ret
}

#' Estimate betas for a latent dataset
#'
#' This function estimates betas (regression coefficients) for fixed and random effects
#' in a matrix dataset using various methods.
#'
#' @param x An object of class `matrix_dataset` representing the matrix dataset
#' @param fixed A formula specifying the fixed regressors that model constant effects (i.e., non-varying over trials)
#' @param ran A formula specifying the random (trialwise) regressors that model single trial effects
#' @param block A formula specifying the block factor
#' @param method The regression method for estimating trialwise betas; one of "mixed", "pls", "pls_global", or "ols" (default: "mixed")
#' @param basemod A `baseline_model` instance to regress out of data before beta estimation (default: NULL)
#' @param ncomp Number of PLS components for the "pls" and "pls_global" methods (default: 4)
#' @param lambda Lambda parameter (not currently used; default: 0.01)
#' @param prewhiten currently experimental, default to \code{FALSE}.
#' @param ... Additional arguments passed to the estimation method
#'
#' @return A list of class "fmri_betas" containing the following components:
#'   * betas_fixed: Matrix representing the fixed effect betas
#'   * betas_ran: Matrix representing the random effect betas
#'   * design_ran: Design matrix for random effects
#'   * design_fixed: Design matrix for fixed effects
#'   * design_base: Design matrix for baseline model
#'
#' @seealso \code{\link{matrix_dataset}}, \code{\link{baseline_model}}
#'
#' @family estimate_betas
#'
#' @export
#' @rdname estimate_betas
estimate_betas.latent_dataset <- function(x, fixed = NULL, ran, block,
                                         method = c("mixed", "pls", "pls_global", "ols"),
                                         basemod = NULL, ncomp = 4, lambda = .01,
                                         prewhiten = FALSE, progress = TRUE, ...) {
  
  method <- match.arg(method)
  dset <- x
  mask <- get_mask(dset)
  
  bmod <- if (is.null(basemod)) {
    baseline_model("constant", sframe=dset$sampling_frame)
  } else {
    basemod
  }
  
  bdes <- gen_beta_design(fixed, ran, block, bmod, dset)
  
  if (prewhiten) {
    wmat <- auto_whiten(dset@basis, fixed)
    ## hack
    ## swap in whitened matrix
    dset@basis <- wmat
    ###
  }
  
  betas <- run_estimate_betas(bdes, dset, method, ncomp = ncomp,
                              progress = progress)
  
  # Access beta_matrix from the list returned by run_estimate_betas
  beta_matrix <- betas$beta_matrix
  
  # Extract random and fixed effects from the beta matrix
  if (length(bdes$ran_ind) > 0) {
    ran <- as.matrix(beta_matrix[bdes$ran_ind,,drop=FALSE])
  } else {
    ran <- NULL
  }
  
  if (length(bdes$fixed_ind) > 0) {
    fixed <- as.matrix(beta_matrix[bdes$fixed_ind,,drop=FALSE])
  } else {
    fixed <- NULL
  }
  
  ret <- list(betas_fixed=fixed,
              betas_ran=ran,
              design_ran=bdes$dmat_ran,
              design_fixed=bdes$dmat_fixed,
              design_base=bdes$dmat_base,
              prewhiten=prewhiten)
  
  class(ret) <-  c("fmri_latent_betas", "fmri_betas")
  ret
}


#' Estimate hemodynamic response function (HRF) using Generalized Additive Models (GAMs)
#'
#' This function estimates the HRF using GAMs from the `mgcv` package.
#' The HRF can be estimated with or without fixed effects.
#'
#' @param form A formula specifying the event model for the conditions of interest
#' @param fixed A formula specifying the fixed regressors that model constant effects (i.e., non-varying over trials); default is NULL
#' @param block A formula specifying the block factor
#' @param dataset An object representing the fMRI dataset
#' @param bs Basis function for the smooth term in the GAM; one of "tp" (default), "ts", "cr", or "ps"
#' @param rsam A sequence of time points at which the HRF is estimated (default: seq(0, 20, by = 1))
#' @param basemod A `baseline_model` instance to regress out of data before HRF estimation (default: NULL)
#' @param k the dimension of the basis, default is 8
#' @param fx indicates whether the term is a fixed d.f. regression spline (TRUE) or a penalized regression spline (FALSE); default is TRUE.
#' @param progress Logical; display progress during estimation.
#'
#' @return A matrix with the estimated HRF values for each voxel
#'
#' @importFrom neuroim2 vectors
#' @importFrom furrr future_map
#' @seealso \code{\link{baseline_model}}, \code{\link{event_model}}, \code{\link{design_matrix}}
#' @examples 
#' 
#' # To be added
#'
#' @export 
#' @autoglobal
estimate_hrf <- function(form, fixed = NULL, block, dataset,
                           bs = c("tp", "ts", "cr", "ps"),
                           rsam = seq(0, 20, by = 1),
                           basemod = NULL,
                           k = 8,
                           fx = TRUE,
                           progress = TRUE) {
  with_package("mgcv")
  dset <- dataset
  
  onset_var <- lazyeval::f_lhs(form)
  dvars <- lazyeval::f_rhs(form)
  
  bmod <- if (is.null(basemod)) {
    baseline_model("constant", sframe=dset$sampling_frame)
  } else {
    basemod
  }
  
  if (!is.null(fixed)) {
    emod_fixed <- event_model(fixed, data=dset$event_table, block=block, sampling_frame=dset$sampling_frame)
    X_fixed <- as.matrix(design_matrix(emod_fixed))
    has_fixed=TRUE
  } else {
    has_fixed=FALSE
  }
  
  emat_cond <- event_model(form, data=dset$event_table, block=block, 
                           sampling_frame=dset$sampling_frame)
  

  X_base <- as.matrix(design_matrix(bmod))
  X_cond <- as.matrix(design_matrix(emat_cond))
  #browser()
  
  vecs <- masked_vectors(dset)
  res <- map_voxels(vecs, function(v) {
    gam.1 <- if (has_fixed) {
      mgcv::gam(v ~ mgcv::s(X_cond, bs=bs, fx=TRUE, k=8) + X_fixed + X_base)
    } else {
      mgcv::gam(v ~ mgcv::s(X_cond, bs=bs, fx=TRUE, k=8) + X_base)
    }
    
    time <- rsam
    xb <- matrix(colMeans(X_base), length(time),ncol(X_base), byrow=TRUE)
    ##xf <- matrix(colMeans(X_fixed), length(time),ncol(X_fixed), byrow=TRUE)
    predict(gam.1, list(X_cond = time, X_base = xb, X_fixed = xf))
  }, .progress = progress)
  
  res
  
}



#' @noRd 
#' @keywords internal
#' @importFrom rlang new_formula
inject_basis <- function(oldform, new_basis, fun_names = c("hrf", "trialwise")) {
  stopifnot(is.formula(oldform))
  
  # A recursive helper that descends through an expression
  # and injects `basis=new_basis` into calls named in fun_names.
  recfun <- function(expr) {
    if (!is_call(expr)) {
      return(expr)  # If it's not a call, return as is
    }
    thisfun <- call_name(expr)
    
    # If this call is one of the functions we want to modify:
    if (thisfun %in% fun_names) {
      # 1) Recursively transform sub-expressions
      expr_args <- as.list(expr)
      for (i in seq_along(expr_args)[-1]) {
        expr_args[[i]] <- recfun(expr_args[[i]])
      }
      # 2) Rebuild the call, then override/add `basis = new_basis`
      call_rebuilt <- as.call(expr_args)
      # Manually add the basis argument
      call_rebuilt$basis <- new_basis
      return(call_rebuilt)
    } else {
      # Not hrf() or trialwise(), so keep walking
      expr_args <- as.list(expr)
      for (i in seq_along(expr_args)[-1]) {
        expr_args[[i]] <- recfun(expr_args[[i]])
      }
      return(as.call(expr_args))
    }
  }
  
  # Extract old LHS, RHS, and environment
  lhs     <- f_lhs(oldform)
  rhs_old <- f_rhs(oldform)
  f_env   <- f_env(oldform)
  
  # Recursively transform the RHS
  rhs_new <- recfun(rhs_old)
  
  # Build the new formula with the same environment
  newform <- new_formula(lhs = lhs, rhs = rhs_new, env = f_env)
  newform
}

#' GLM OLS Estimation Convenience Function
#'
#' A convenience wrapper around `estimate_betas` for ordinary least squares (OLS) estimation.
#' This function provides a simplified interface for fitting GLMs using OLS on matrix datasets.
#' 
#' **Use Cases:**
#' - **Condition-level estimation**: Estimates average responses for each experimental condition
#' - **General linear modeling**: Standard GLM approach for group-level or condition-level effects
#' - **Multi-trial averaging**: Combines trials of the same condition to estimate mean responses
#' 
#' For single-trial estimation where each trial gets its own beta estimate, use `glm_lss()` instead.
#'
#' @param dataset A `matrix_dataset` object containing the fMRI time series data
#' @param model_obj An `event_model` object specifying the experimental design
#' @param basis_obj An HRF basis object (e.g., from `HRF_SPMG1`, `HRF_FIR`, etc.)
#' @param basemod A `baseline_model` instance to regress out of data before beta estimation (default: NULL)
#' @param block A formula specifying the block factor (default: ~ 1 for single block)
#' @param progress Logical; show progress bar (default: TRUE)
#' @param ... Additional arguments passed to `estimate_betas`
#'
#' @return A list of class "fmri_betas" containing the estimated coefficients
#'
#' @examples
#' \dontrun{
#' # Create event model and data
#' event_data <- data.frame(
#'   onset = c(10, 30, 50, 70),
#'   condition = factor(c("A", "B", "A", "B")),
#'   run = rep(1, 4)
#' )
#' sframe <- sampling_frame(blocklens = 100, TR = 2)
#' model_obj <- event_model(onset ~ hrf(condition), 
#'                         data = event_data, 
#'                         block = ~ run, 
#'                         sampling_frame = sframe)
#' 
#' # Create data matrix (100 timepoints, 10 voxels)
#' Y <- matrix(rnorm(1000), 100, 10)
#' 
#' # Create matrix_dataset with event table
#' dset <- matrix_dataset(Y, TR = 2, run_length = 100, event_table = event_data)
#' 
#' # Fit with OLS - estimates average response for each condition
#' fit <- glm_ols(dset, model_obj, HRF_SPMG1)
#' dim(fit$betas_ran)  # 2 conditions x 10 voxels
#' }
#'
#' @export
#' @seealso \code{\link{estimate_betas}} for the underlying estimation function, 
#'   \code{\link{glm_lss}} for single trial estimation
glm_ols <- function(dataset, model_obj, basis_obj, basemod = NULL, 
                    block = ~ 1, progress = TRUE, ...) {
  
  # Validate inputs
  if (!inherits(dataset, "matrix_dataset")) {
    stop("dataset must be a matrix_dataset object. Use matrix_dataset() to create one from your data matrix.")
  }
  
  if (!inherits(model_obj, "event_model")) {
    stop("model_obj must be an event_model object")
  }
  
  # Extract the formula from the event model and inject the new basis
  original_formula <- model_obj$model_spec$formula_or_list
  if (is.null(original_formula)) {
    stop("Cannot extract formula from event_model")
  }
  
  # Inject the new basis into the formula
  updated_formula <- inject_basis(original_formula, basis_obj)
  
  # Call estimate_betas with the updated formula and the dataset's event table
  estimate_betas(dataset, 
                fixed = NULL,
                ran = updated_formula, 
                block = block,
                method = "ols",
                basemod = basemod,
                progress = progress,
                ...)
}

#' GLM LSS Estimation Convenience Function (Single Trial Estimation)
#'
#' A convenience wrapper around `estimate_betas` for least squares separate (LSS) estimation.
#' **This is primarily designed for single trial estimation**, where each individual trial/event 
#' gets its own separate beta estimate rather than averaging across trials of the same condition.
#' 
#' **Primary Use Case - Single Trial Estimation:**
#' - **Trial-wise beta estimation**: Each trial gets its own beta coefficient
#' - **Single trial analysis**: Useful for decoding, representational similarity analysis (RSA)
#' - **Trial-by-trial variability**: Captures individual trial responses rather than condition averages
#' - **Avoiding trial averaging**: Preserves trial-specific information that would be lost in standard GLM
#' 
#' **Method Details:**
#' LSS (Least Squares Separate) fits a separate model for each trial, where the trial of interest 
#' gets its own regressor while all other trials of the same condition are modeled together. This 
#' approach avoids the collinearity issues that would arise from including separate regressors 
#' for every trial simultaneously.
#' 
#' For standard condition-level estimation (averaging trials within conditions), use `glm_ols()` instead.
#'
#' @param dataset A `matrix_dataset` object containing the fMRI time series data
#' @param model_obj An `event_model` object specifying the experimental design
#' @param basis_obj An HRF basis object (e.g., from `HRF_SPMG1`, `HRF_FIR`, etc.)
#' @param basemod A `baseline_model` instance to regress out of data before beta estimation (default: NULL)
#' @param block A formula specifying the block factor (default: ~ 1 for single block)
#' @param use_cpp Logical; whether to use C++ implementation for speed (default: TRUE)
#' @param progress Logical; show progress bar (default: TRUE)
#' @param ... Additional arguments passed to `estimate_betas`
#'
#' @return A list of class "fmri_betas" containing the estimated trial-wise coefficients
#'
#' @examples
#' \dontrun{
#' # Create event model and data
#' event_data <- data.frame(
#'   onset = c(10, 30, 50, 70),
#'   condition = factor(c("A", "B", "A", "B")),
#'   run = rep(1, 4)
#' )
#' sframe <- sampling_frame(blocklens = 100, TR = 2)
#' model_obj <- event_model(onset ~ hrf(condition), 
#'                         data = event_data, 
#'                         block = ~ run, 
#'                         sampling_frame = sframe)
#' 
#' # Create data matrix (100 timepoints, 10 voxels)
#' Y <- matrix(rnorm(1000), 100, 10)
#' 
#' # Create matrix_dataset with event table
#' dset <- matrix_dataset(Y, TR = 2, run_length = 100, event_table = event_data)
#' 
#' # Fit with LSS - estimates separate beta for each individual trial
#' fit <- glm_lss(dset, model_obj, HRF_SPMG1)
#' dim(fit$betas_ran)  # 4 trials x 10 voxels (NOT averaged by condition)
#' 
#' # This is useful for:
#' # - Decoding analysis (predicting condition from single trial patterns)
#' # - RSA (representational similarity analysis)
#' # - Studying trial-by-trial variability
#' }
#'
#' @export
#' @seealso \code{\link{estimate_betas}} for the underlying estimation function, 
#'   \code{\link{glm_ols}} for condition-level estimation
glm_lss <- function(dataset, model_obj, basis_obj, basemod = NULL, 
                    block = ~ 1, use_cpp = TRUE, progress = TRUE, ...) {
  
  # Validate inputs
  if (!inherits(dataset, "matrix_dataset")) {
    stop("dataset must be a matrix_dataset object. Use matrix_dataset() to create one from your data matrix.")
  }
  
  if (!inherits(model_obj, "event_model")) {
    stop("model_obj must be an event_model object")
  }
  
  # Extract the formula from the event model and inject the new basis
  original_formula <- model_obj$model_spec$formula_or_list
  if (is.null(original_formula)) {
    stop("Cannot extract formula from event_model")
  }
  
  # Inject the new basis into the formula
  updated_formula <- inject_basis(original_formula, basis_obj)
  
  # Choose method based on use_cpp parameter
  method <- if (use_cpp) "lss_cpp" else "lss"
  
  # Call estimate_betas with the updated formula
  estimate_betas(dataset, 
                fixed = NULL,
                ran = updated_formula, 
                block = block,
                method = method,
                basemod = basemod,
                progress = progress,
                ...)
}
</file>

<file path="R/hrf.R">
#' Turn any function into an HRF object
#'
#' This is the core constructor for creating HRF objects in the refactored system.
#' It takes a function `f(t)` and attaches standard HRF attributes.
#'
#' @param f The function to be turned into an HRF object. It must accept a single argument `t` (time).
#' @param name The name for the HRF object. Defaults to the deparsed name of `f`.
#' @param nbasis The number of basis functions represented by `f`. Defaults to 1L.
#' @param span The nominal time span (duration in seconds) of the HRF. Defaults to 24.
#' @param params A named list of parameters associated with the HRF function `f`. Defaults to an empty list.
#' @param ... Additional arguments to pass to the function f.
#' @return A new HRF object.
#' @keywords internal
#' @export
as_hrf <- function(f, name = deparse(substitute(f)), nbasis = 1L, span = 24,
                   params = list()) {
  assertthat::assert_that(is.function(f))
  assertthat::assert_that(is.character(name), length(name) == 1)
  assertthat::assert_that(is.numeric(nbasis), length(nbasis) == 1)
  assertthat::assert_that(is.numeric(span), length(span) == 1)
  assertthat::assert_that(is.list(params))

  structure(
    f,
    class        = c("HRF", "function"),
    name         = name,
    nbasis       = as.integer(nbasis),
    span         = span,
    param_names  = names(params),
    params       = params
  )
}


#' Bind HRFs into a Basis Set
#'
#' Combines multiple HRF objects into a single multi-basis HRF object.
#' The resulting function evaluates each input HRF at time `t` and returns the results column-bound together.
#'
#' @param ... One or more HRF objects created by `as_hrf` or other HRF constructors/decorators.
#'
#' @return A new HRF object representing the combined basis set.
#'
#' @keywords internal
#' @export
#' @importFrom assertthat assert_that
bind_basis <- function(...) {
  xs <- list(...)
  assertthat::assert_that(length(xs) > 0, msg = "bind_basis requires at least one HRF object.")
  assertthat::assert_that(all(sapply(xs, inherits, "HRF")), msg = "All inputs to bind_basis must be HRF objects.")

  # Handle single HRF case explicitly
  if (length(xs) == 1) {
    return(xs[[1]])
  }

  # Calculate combined attributes
  combined_nbasis <- sum(vapply(xs, attr, 0L, "nbasis"))
  combined_span <- max(vapply(xs, attr, 0, "span"))
  combined_name <- paste(sapply(xs, attr, "name"), collapse = " + ")

  # Create the combined function
  combined_func <- function(t) {
    do.call(cbind, lapply(xs, function(f) f(t)))
  }

  # Use as_hrf to create the new HRF object
  as_hrf(
    f = combined_func,
    name = combined_name,
    nbasis = combined_nbasis,
    span = combined_span,
    params = list() # Params usually don't combine meaningfully
  )
}


#' Construct an HRF Instance using Decorators
#' 
#' @description
#' `gen_hrf` takes a base HRF function or object and applies optional lag,
#' blocking, and normalization decorators based on arguments.
#'
#' @param hrf A function `f(t)` or an existing `HRF` object.
#' @param lag Optional lag in seconds. If non-zero, applies `lag_hrf`.
#' @param width Optional block width in seconds. If non-zero, applies `block_hrf`.
#' @param precision Sampling precision for block convolution (passed to `block_hrf`). Default is 0.1.
#' @param summate Whether to summate within blocks (passed to `block_hrf`). Default is TRUE.
#' @param normalize If TRUE, applies `normalise_hrf` at the end. Default is FALSE.
#' @param name Optional name for the *final* HRF object. If NULL (default), a name is generated based on the base HRF and applied decorators.
#' @param span Optional span for the *final* HRF object. If NULL (default), the span is determined by the base HRF and decorators.
#' @param ... Extra arguments passed to the *base* HRF function if `hrf` is a function.
#'
#' @return A final `HRF` object, potentially modified by decorators.
#' 
#' @examples 
#' # Lagged SPMG1
#' grf_lag <- gen_hrf(HRF_SPMG1, lag=3)
#' # Blocked Gaussian
#' grf_block <- gen_hrf(hrf_gaussian, width=5, precision=0.2)
#' # Lagged and Blocked, then Normalized
#' grf_both_norm <- gen_hrf(HRF_SPMG1, lag=2, width=4, normalize=TRUE)
#'
#' @export
gen_hrf <- function(hrf, lag=0, width=0, precision=.1, 
                    summate=TRUE, normalize=FALSE, name=NULL, span=NULL, ...) {

  # 1. Ensure we start with an HRF object
  if (is.function(hrf) && !inherits(hrf, "HRF")) {
    # If it's a plain function, convert it using as_hrf
    # Determine nbasis by evaluating the function
    test_t <- 1:10 # A small sample range
    test_val <- try(hrf(test_t, ...), silent = TRUE)
    determined_nbasis <- if (!inherits(test_val, "try-error") && !is.null(test_val)) {
      if (is.matrix(test_val)) ncol(test_val) else 1L
    } else {
      warning(paste("Could not determine nbasis for function", deparse(substitute(hrf)), "- defaulting to 1. Evaluation failed."))
      1L
    }
    
    # Pass extra args (...) here if they are meant for the base function construction
    base_hrf <- as_hrf(f = function(t) hrf(t, ...),
                       name = deparse(substitute(hrf)),
                       nbasis = determined_nbasis) # Pass determined nbasis
                       # Let as_hrf determine default span, params
  } else if (inherits(hrf, "HRF")) {
    # If already an HRF object, use it directly
    base_hrf <- hrf
    if (length(list(...)) > 0) {
      warning("Ignoring extra arguments (...) because 'hrf' is already an HRF object.")
    }
  } else {
    stop("'hrf' must be a function or an HRF object.")
  }

  # Apply decorators conditionally
  decorated_hrf <- base_hrf

  # Apply width decorator first if needed
  if (width != 0) {
    # Check positivity *before* applying
    stopifnot(width > 0)
    # Note: block_hrf handles normalize=FALSE internally by default
    decorated_hrf <- block_hrf(decorated_hrf, width=width, precision=precision,
                               summate=summate, normalize=FALSE)
  }

  # Apply lag decorator if needed
  if (lag != 0) {
    decorated_hrf <- lag_hrf(decorated_hrf, lag=lag)
  }

  # Apply normalization decorator last if needed
  if (normalize) {
    decorated_hrf <- normalise_hrf(decorated_hrf)
  }

  # Override name and span if provided by user
  if (!is.null(name)) {
    attr(decorated_hrf, "name") <- name
  }
  if (!is.null(span)) {
    attr(decorated_hrf, "span") <- span
  }

  # Return the final (potentially decorated) HRF object
  return(decorated_hrf)
}


#' Generate an Empirical Hemodynamic Response Function
#' 
#' @description
#' `empirical_hrf` generates an empirical HRF using provided time points and values.
#' 
#' @param t Time points.
#' @param y Values of HRF at time `t[i]`.
#' @param name Name of the generated HRF.
#' @return An instance of type `HRF`.
#' @export
empirical_hrf <- function(t, y, name = "empirical_hrf") {
  as_hrf(stats::approxfun(t, y, yright = 0, yleft = 0),
         name = name, nbasis = 1L, span = max(t, na.rm = TRUE))
}

#' @export
#' @rdname empirical_hrf
#' @keywords internal
gen_empirical_hrf <- function(...) {
  .Deprecated("empirical_hrf")
  empirical_hrf(...)
}


#' Generate an HRF Basis Set
#' 
#' @description
#' `hrf_set` constructs an HRF basis set from one or more component HRF objects.
#'
#' @param ... One or more HRF objects.
#' @param name The name for the combined HRF set.
#' @return A combined HRF object.
#' @export
hrf_set <- function(..., name = "hrf_set") {
  combined_hrf <- bind_basis(...)
  attr(combined_hrf, "name") <- name
  combined_hrf
}

#' @export
#' @rdname hrf_set
#' @keywords internal
gen_hrf_set <- function(...) {
  .Deprecated("hrf_set")
  hrf_set(...)
}


#' Generate an HRF library from a parameter grid
#'
#' @description
#' `hrf_library` applies a base HRF generating function to each row of a parameter grid.
#'
#' @param fun A function that generates an HRF, given a set of parameters.
#' @param pgrid A data frame where each row is a set of parameters.
#' @param ... Additional arguments passed to `fun`.
#' @return A combined HRF object representing the library.
#' @importFrom purrr pmap partial
#' @export
hrf_library <- function(fun, pgrid, ...) {
  # Ensure fun returns an HRF object
  hrf_list <- purrr::pmap(pgrid, function(...) {
      params <- list(...)
      # Assuming 'fun' is designed to take these params and return an HRF
      # If fun itself is just a base function, we need to wrap it
      # Let's assume fun already produces an HRF or can be wrapped by as_hrf
      # This part might need adjustment based on typical usage of 'fun'
      do.call(fun, c(params, list(...))) # Pass original dots as well?
      # Safest might be if 'fun' is expected to return an HRF object directly
      # Example: fun = function(lag) HRF_SPMG1 |> lag_hrf(lag)
  })
  # Bind the generated HRFs
  do.call(bind_basis, hrf_list)
}

#' @export
#' @rdname hrf_library
#' @keywords internal
gen_hrf_library <- function(...) {
  .Deprecated("hrf_library")
  hrf_library(...)
}


#' HRF Constructor Function
#'
#' The `HRF` function creates an object representing a hemodynamic response function (HRF). It is a class constructor for HRFs.
#'
#' @param fun A function representing the hemodynamic response, mapping from time to BOLD response.
#' @param name A string specifying the name of the function.
#' @param nbasis An integer representing the number of basis functions, e.g., the columnar dimension of the HRF. Default is 1.
#' @param span A numeric value representing the span in seconds of the HRF. Default is 24.
#' @param param_names A character vector containing the names of the parameters for the HRF function.
#'
#' @return An HRF object with the specified properties.
#'
#' @details
#' The package provides several pre-defined HRF types that can be used in modeling fMRI responses:
#'
#' **Canonical HRFs:**
#' * `"spmg1"` or `HRF_SPMG1`: SPM's canonical HRF (single basis function)
#' * `"spmg2"` or `HRF_SPMG2`: SPM canonical + temporal derivative (2 basis functions)
#' * `"spmg3"` or `HRF_SPMG3`: SPM canonical + temporal and dispersion derivatives (3 basis functions)
#' * `"gaussian"` or `HRF_GAUSSIAN`: Gaussian-shaped HRF with peak around 5-6s
#' * `"gamma"` or `HRF_GAMMA`: Gamma function-based HRF with longer tail
#'
#' **Flexible basis sets:**
#' * `"bspline"` or `"bs"` or `HRF_BSPLINE`: B-spline basis for flexible HRF modeling
#' * `"tent"`: Tent (triangular) basis functions for flexible HRF modeling
#' * `"daguerre"` or `HRF_DAGUERRE`: Daguerre basis functions
#'
#' To see a complete list of available HRF types with details, use the `list_available_hrfs()` function.
#'
#' @examples
#' hrf <- HRF(hrf_gamma, "gamma", nbasis=1, param_names=c("shape", "rate"))
#' resp <- evaluate(hrf, seq(0, 24, by=1))
#'
#' # List all available HRF types
#' list_available_hrfs(details = TRUE)
#'
#' @export
#' @rdname HRF-class
HRF <- function(fun, name, nbasis=1, span=24, param_names=NULL) {
  vals <- try(fun(seq(0, span)), silent = TRUE)

  peak <- if (!inherits(vals, "try-error") && !is.null(vals)) {
    if (nbasis == 1) {
      max(vals, na.rm = TRUE)
    } else if (is.matrix(vals)) {
      max(apply(vals, 2, max, na.rm = TRUE))
    } else {
      NA # Unable to determine peak
    }
  } else {
    NA # Error during evaluation or null result
  }

  scale_factor <- if (!is.na(peak) && peak != 0) {
    1 / peak
  } else {
    NA # Cannot compute scale_factor if peak is NA or zero
  }
  
  structure(fun, name=name, 
            nbasis=as.integer(nbasis), 
            span=span,
            param_names=param_names, 
            scale_factor=scale_factor, 
            class=c("HRF", "function"))
  
}

#' @rdname nbasis
#' @export
nbasis.HRF <- function(x,...) attr(x, "nbasis")



#' @keywords internal
#' @noRd
makeDeriv <- function(HRF, n=1) {
  #with_package("numDeriv")
  if (n == 1) {
    function(t) numDeriv::grad(HRF, t)
  } else {
    Recall(function(t) numDeriv::grad(HRF,t), n-1)
  }
}


#' Generate a Lagged HRF Function
#'
#' @description
#' The `gen_hrf_lagged` function takes an HRF function and applies a specified lag to it. This can be useful for modeling time-delayed hemodynamic responses.
#'
#' @param hrf A function representing the underlying HRF to be shifted.
#' @param lag A numeric value specifying the lag or delay in seconds to apply to the HRF. This can also be a vector of lags, in which case the function returns an HRF set.
#' @param normalize A logical value indicating whether to rescale the output so that the maximum absolute value is 1. Defaults to `FALSE`.
#' @param ... Extra arguments supplied to the `hrf` function.
#'
#' @return A function representing the lagged HRF. If `lag` is a vector of lags, the function returns an HRF set.
#' @family gen_hrf
#' @examples
#' \donttest{
#' hrf_lag5 <- gen_hrf_lagged(HRF_SPMG1, lag=5)
#' hrf_lag5(0:20)
#' }
#'
#' @export
gen_hrf_lagged <- function(hrf, lag=2, normalize=FALSE, ...) {
  force(hrf)
  # TODO deal with nbasis arg in ...
  if (length(lag)>1) {
    do.call(gen_hrf_set, lapply(lag, function(l) gen_hrf_lagged(hrf, l,...)))
  } else {
    function(t) {
      ret <- hrf(t-lag,...)
      if (normalize) {
        ret <- ret/max(abs(ret))
      } 
      
      ret
    }
  }
}

#' @export
#' @describeIn gen_hrf_lagged alias for gen_hrf_lagged
#' @family gen_hrf
#' @return an lagged hrf function
hrf_lagged <- gen_hrf_lagged


#' Generate a Blocked HRF Function
#'
#' @description
#' The `gen_hrf_blocked` function creates a blocked HRF by convolving the input HRF with a boxcar function. This can be used to model block designs in fMRI analysis.
#'
#' @param hrf A function representing the hemodynamic response function. Default is `hrf_gaussian`.
#' @param width A numeric value specifying the width of the block in seconds. Default is 5.
#' @param precision A numeric value specifying the sampling resolution in seconds. Default is 0.1.
#' @param half_life A numeric value specifying the half-life of the exponential decay function, used to model response attenuation. Default is `Inf`, which means no decay.
#' @param summate A logical value indicating whether to allow each impulse response function to "add" up. Default is `TRUE`.
#' @param normalize A logical value indicating whether to rescale the output so that the peak of the output is 1. Default is `FALSE`.
#' @param ... Extra arguments passed to the HRF function.
#' @family gen_hrf
#'
#' @return A \code{function} representing the blocked HRF.
#'
#' @importFrom purrr partial
#' @export
gen_hrf_blocked <- function(hrf=hrf_gaussian, width=5, precision=.1, 
                            half_life=Inf, summate=TRUE, normalize=FALSE, ...) {
  force(hrf)
  purrr::partial(convolve_block, hrf=hrf, width=width, 
                 precision=precision, half_life=half_life, 
                 summate=summate, normalize=normalize, ...)
}

#' @export
#' @aliases gen_hrf_blocked
#' @describeIn gen_hrf_blocked alias for gen_hrf_blocked
#' @return A \code{function} representing the blocked HRF.
hrf_blocked <- gen_hrf_blocked





#' Soft-threshold function
#'
#' This function applies soft-thresholding to the input values, setting values below the threshold to zero
#' and shrinking the remaining values by the threshold amount.
#'
#' @param x A numeric vector of input values
#' @param threshold A non-negative threshold value for the soft-thresholding operation
#'
#' @return A numeric vector with the soft-thresholded values
#'
#' @noRd
#' @keywords internal
soft_threshold <- function(x, threshold) {
  if (threshold < 0) {
    stop("Threshold value should be non-negative.")
  }

  sign(x) * pmax(0, abs(x) - threshold)
}



#' List all available hemodynamic response functions (HRFs)
#'
#' @description
#' Reads the internal HRF registry to list available HRF types.
#'
#' @param details Logical; if TRUE, attempt to add descriptions (basic for now).
#' @return A data frame with columns: name, type (object/generator), nbasis_default.
#' @export
list_available_hrfs <- function(details = FALSE) {
  # Get names directly from the registry
  hrf_names <- names(HRF_REGISTRY)
  
  # Determine type and default nbasis by inspecting registry entries
  hrf_info <- lapply(hrf_names, function(name) {
    entry <- HRF_REGISTRY[[name]]
    type <- if (inherits(entry, 'HRF')) "object" else if (is.function(entry)) "generator" else "unknown"
    
    nbasis_default <- NA
    if (type == "object") {
      nbasis_default <- tryCatch(nbasis(entry), error = function(e) NA)
    } else if (type == "generator") {
      fmls <- formals(entry)
      if ("nbasis" %in% names(fmls)) {
        nb_val <- fmls$nbasis
        if(is.numeric(nb_val)) nbasis_default <- nb_val 
      } 
      if(is.na(nbasis_default)) nbasis_default <- "variable"
    }
    
    # Check if this name is an alias (points to the same object/func as another primary name)
    is_alias <- FALSE
    if (type == "object") {
      primary_names <- names(HRF_REGISTRY)[sapply(HRF_REGISTRY, identical, entry)]
      is_alias <- length(primary_names) > 1 && name %in% primary_names[primary_names != name]
    } else if (type == "generator") {
      # More complex for functions, check if it points to the same generator function
      # For now, let's assume aliases only exist for objects, or mark known ones
      is_alias <- name %in% c("gam", "bs")
    }

    list(name = name, type = type, nbasis_default = as.character(nbasis_default), is_alias = is_alias) 
  })
  
  # Combine into a data frame
  hrf_df <- do.call(rbind.data.frame, c(hrf_info, list(stringsAsFactors = FALSE)))
  
  # Add basic descriptions if requested
  if (details) {
      hrf_df$description <- paste(hrf_df$name, "HRF", 
                                  ifelse(hrf_df$type == "generator", "(generator)", "(object)"),
                                  ifelse(hrf_df$is_alias, "(alias)", ""))
  }
  
  hrf_df
}

# Define Static HRF Objects -----

#' Pre-defined Hemodynamic Response Function Objects
#' 
#' A collection of pre-defined HRF objects for common fMRI analysis scenarios.
#' These objects can be used directly in model specifications or as templates
#' for creating custom HRFs.
#' 
#' @section Canonical HRFs:
#' \describe{
#'   \item{\code{HRF_SPMG1}}{SPM canonical HRF (single basis function)}
#'   \item{\code{HRF_SPMG2}}{SPM canonical HRF with temporal derivative (2 basis functions)}
#'   \item{\code{HRF_SPMG3}}{SPM canonical HRF with temporal and dispersion derivatives (3 basis functions)}
#'   \item{\code{HRF_GAMMA}}{Gamma function-based HRF}
#'   \item{\code{HRF_GAUSSIAN}}{Gaussian function-based HRF}
#' }
#' 
#' @section Flexible Basis Sets:
#' \describe{
#'   \item{\code{HRF_BSPLINE}}{B-spline basis HRF (5 basis functions)}
#'   \item{\code{HRF_FIR}}{Finite Impulse Response (FIR) basis HRF (default 12 basis functions)}
#' }
#' 
#' @section Usage:
#' All HRF objects can be:
#' \itemize{
#'   \item Called as functions with time argument: \code{HRF_SPMG1(t)}
#'   \item Used in model specifications: \code{hrf(condition, basis = HRF_SPMG1)}
#'   \item Evaluated with \code{evaluate()} method
#'   \item Combined with decorators like \code{lag_hrf()} or \code{block_hrf()}
#' }
#' 
#' @param t Numeric vector of time points (in seconds) at which to evaluate the HRF
#' @param P1,P2 Shape parameters for SPM canonical HRF (default: P1=5, P2=15)
#' @param A1 Amplitude parameter for SPM canonical HRF (default: 0.0833)
#' @param shape,rate Parameters for gamma distribution HRF (default: shape=6, rate=1)
#' @param mean,sd Parameters for Gaussian HRF (default: mean=6, sd=2)
#' 
#' @return 
#' When called as functions, return numeric vectors or matrices of HRF values.
#' When used as objects, they are HRF objects with class \code{c("HRF", "function")}.
#' 
#' @examples
#' # Evaluate HRFs at specific time points
#' times <- seq(0, 20, by = 0.5)
#' 
#' # Single basis canonical HRF
#' canonical_response <- HRF_SPMG1(times)
#' plot(times, canonical_response, type = "l", main = "SPM Canonical HRF")
#' 
#' # Multi-basis HRF with derivatives
#' multi_response <- HRF_SPMG3(times)  # Returns 3-column matrix
#' matplot(times, multi_response, type = "l", main = "SPM HRF with Derivatives")
#' 
#' # Gamma and Gaussian HRFs
#' gamma_response <- HRF_GAMMA(times)
#' gaussian_response <- HRF_GAUSSIAN(times)
#' 
#' # Compare different HRF shapes
#' plot(times, canonical_response, type = "l", col = "blue", 
#'      main = "HRF Comparison", ylab = "Response")
#' lines(times, gamma_response, col = "red")
#' lines(times, gaussian_response, col = "green")
#' legend("topright", c("SPM Canonical", "Gamma", "Gaussian"), 
#'        col = c("blue", "red", "green"), lty = 1)
#' 
#' # Use in model specification
#' \dontrun{
#' # In an event model
#' evmodel <- event_model(
#'   onsets ~ hrf(condition, basis = HRF_SPMG1),
#'   data = event_data,
#'   sampling_frame = sframe
#' )
#' 
#' # With multiple basis functions
#' evmodel2 <- event_model(
#'   onsets ~ hrf(condition, basis = HRF_SPMG3),
#'   data = event_data,
#'   sampling_frame = sframe
#' )
#' }
#' 
#' @name HRF_objects
#' @aliases HRF_SPMG1 HRF_SPMG2 HRF_SPMG3 HRF_GAMMA HRF_GAUSSIAN HRF_BSPLINE HRF_FIR
#' @family hrf
#' @seealso \code{\link{evaluate.HRF}}, \code{\link{gen_hrf}}, \code{\link{list_available_hrfs}}
NULL

#' @rdname HRF_objects
#' @export
HRF_GAMMA <- as_hrf(hrf_gamma, name="gamma", params=list(shape=6, rate=1))

#' @rdname HRF_objects
#' @export
HRF_GAUSSIAN <- as_hrf(hrf_gaussian, name="gaussian", params=list(mean=6, sd=2))

#' @rdname HRF_objects
#' @export
HRF_SPMG1 <- as_hrf(hrf_spmg1, name="SPMG1", params=list(P1=5, P2=15, A1=0.0833))

#' @rdname HRF_objects
#' @export
HRF_SPMG2 <- bind_basis(
  as_hrf(hrf_spmg1, name="SPMG1_canonical", params=list(P1=5, P2=15, A1=0.0833)),
  as_hrf(hrf_spmg1_deriv, name="SPMG1_temporal_deriv", params=list(P1=5, P2=15, A1=0.0833))
)
attr(HRF_SPMG2, "name") <- "SPMG2"

#' @rdname HRF_objects
#' @export
HRF_SPMG3 <- bind_basis(
  as_hrf(hrf_spmg1, name="SPMG1_canonical", params=list(P1=5, P2=15, A1=0.0833)),
  as_hrf(hrf_spmg1_deriv, name="SPMG1_temporal_deriv", params=list(P1=5, P2=15, A1=0.0833)),
  as_hrf(hrf_spmg1_second_deriv, name="SPMG1_dispersion_deriv", params=list(P1=5, P2=15, A1=0.0833))
)
attr(HRF_SPMG3, "name") <- "SPMG3"

# Define HRF Generators (Functions returning HRF objects) -----
hrf_bspline_generator <- function(nbasis=5, span=24) {
  # Validate inputs
  if (nbasis < 1) {
    stop("nbasis must be at least 1", call. = FALSE)
  }
  if (span <= 0) {
    stop("span must be positive", call. = FALSE)
  }
  
  # Ensure nbasis is integer
  nbasis <- as.integer(nbasis)
  
  degree <- 3 # Default cubic B-splines
  effective_nbasis <- max(1, nbasis) 
  
  f_bspline <- function(t) {
    valid_t_idx <- t >= 0 & t <= span
    if (!any(valid_t_idx)) {
      return(matrix(0, nrow = length(t), ncol = effective_nbasis))
    }
    
    res_mat <- matrix(0, nrow = length(t), ncol = effective_nbasis)
    
    bs_matrix <- tryCatch({
        splines::bs(t[valid_t_idx], df = effective_nbasis, degree = degree, 
                    Boundary.knots = c(0, span), intercept = FALSE)
    }, error = function(e) {
        warning(sprintf("splines::bs failed for effective_nbasis=%d, span=%d: %s", 
                        effective_nbasis, span, e$message), call. = FALSE)
        NULL 
    })

    if (!is.null(bs_matrix) && ncol(bs_matrix) == effective_nbasis) {
      res_mat[valid_t_idx, ] <- bs_matrix
    } else if (!is.null(bs_matrix)) {
       warning(sprintf("splines::bs returned %d columns, expected %d for effective_nbasis=%d, span=%d. Returning zeros.", 
                      ncol(bs_matrix), effective_nbasis, effective_nbasis, span), call. = FALSE)
    }
    return(res_mat)
  }

  as_hrf(
    f = f_bspline,
    name = "bspline", nbasis = as.integer(effective_nbasis), span = span,
    params = list(nbasis = effective_nbasis, degree = degree, span = span) 
  )
}

hrf_tent_generator <- function(nbasis=5, span=24) {
  as_hrf(
    f = function(t) hrf_bspline(t, span=span, N=nbasis, degree=1), # hrf_bspline from hrf-functions.R
    name="tent", nbasis=as.integer(nbasis), span=span,
    params=list(N=nbasis, degree=1, span=span)
  )
}

hrf_fourier_generator <- function(nbasis=5, span=24) {
  as_hrf(
    f = function(t) hrf_fourier(t, span=span, nbasis=nbasis), # hrf_fourier from hrf-functions.R
    name="fourier", nbasis=as.integer(nbasis), span=span,
    params=list(nbasis=nbasis, span=span)
  )
}

hrf_daguerre_generator <- function(nbasis=3, scale=4) {
  as_hrf(
    f = function(t) daguerre_basis(t, n_basis=nbasis, scale=scale), # daguerre_basis from hrf-functions.R
    name="daguerre", nbasis=as.integer(nbasis), span=24, # Default span, daguerre is time-scaled
    params=list(n_basis=nbasis, scale=scale)
  )
}

hrf_fir_generator <- function(nbasis = 12, span = 24) {
  assertthat::assert_that(
    is.numeric(nbasis) && length(nbasis) == 1 && nbasis >= 1,
    msg = "`nbasis` must be a single positive integer."
  )
  assertthat::assert_that(
    is.numeric(span) && length(span) == 1 && span > 0,
    msg = "`span` must be a single positive number."
  )
  nbasis <- as.integer(nbasis)
  bin_width <- span / nbasis

  f_fir <- function(t) {
    if (!is.numeric(t) || length(t) == 0) {
      return(matrix(0, nrow = 0, ncol = nbasis))
    }
    output_matrix <- matrix(0, nrow = length(t), ncol = nbasis)
    for (i in seq_along(t)) {
      current_t <- t[i]
      if (!is.na(current_t) && current_t >= 0 && current_t < span) {
        bin_index <- if (current_t == 0) 1 else floor(current_t / bin_width) + 1
        bin_index <- min(bin_index, nbasis) 
        output_matrix[i, bin_index] <- 1
      }
    }
    return(output_matrix)
  }

  as_hrf(
    f = f_fir,
    name = "fir",
    nbasis = nbasis,
    span = span,
    params = list(nbasis = nbasis, span = span, bin_width = bin_width)
  )
}

# Define HRF Registry -----

#' @keywords internal
HRF_REGISTRY <- list(
  spmg1    = HRF_SPMG1,
  spmg2    = HRF_SPMG2,
  spmg3    = HRF_SPMG3,
  gamma    = HRF_GAMMA,
  gaussian = HRF_GAUSSIAN,
  bspline  = hrf_bspline_generator,
  tent     = hrf_tent_generator,
  fourier  = hrf_fourier_generator,
  daguerre = hrf_daguerre_generator,
  fir      = hrf_fir_generator,
  lwu      = hrf_lwu 
)

HRF_REGISTRY$gam <- HRF_REGISTRY$gamma
HRF_REGISTRY$bs  <- HRF_REGISTRY$bspline

# getHRF function using the registry (Minimal Version) -----

#' getHRF
#'
#' Retrieves an HRF by name from the registry and applies decorators.
#'
#' @param ... Additional arguments passed to generator functions (e.g., `scale` for daguerre).
#' @return An HRF object.
#' @keywords internal
#' @noRd
getHRF <- function(name = "spmg1", # Default to spmg1
                   nbasis=5, span=24,
                   lag=0, width=0,
                   summate=TRUE, normalize=FALSE, ...) {

  key   <- match.arg(tolower(name), names(HRF_REGISTRY))
  entry <- HRF_REGISTRY[[key]]

  base <- if (inherits(entry, "HRF")) {
            entry # Use pre-defined object
      } else {
            # Call generator, passing nbasis, span, and any relevant ... args
            gen_args <- c(list(nbasis=as.integer(nbasis), span=span), list(...))
            # Only pass args the generator actually accepts
            valid_args <- gen_args[names(gen_args) %in% names(formals(entry))]
            do.call(entry, valid_args)
          }

  # Apply decorators
  if (width != 0) {
      stopifnot(width > 0)
      base <- block_hrf(base, width = width, summate = summate)
  }
  if (lag != 0) {
      base <- lag_hrf(base, lag = lag)
  }
  if (normalize) {
      base <- normalise_hrf(base)
  }

  attr(base, "name") <- key # Set name attribute to the matched registry key
  base
}

#' Evaluate an HRF Object
#'
#' This function evaluates a hemodynamic response function (HRF) object for a given set of time points (grid) and other parameters.
#' It handles both point evaluation (duration=0) and block evaluation (duration > 0).
#'
#' @param x The HRF object (inherits from `HRF` and `function`).
#' @param grid A numeric vector of time points at which to evaluate the HRF.
#' @param amplitude The scaling value for the event (default: 1).
#' @param duration The duration of the event (seconds). If > 0, the HRF is evaluated over this duration (default: 0).
#' @param precision The temporal resolution for evaluating responses when duration > 0 (default: 0.2).
#' @param summate Logical; whether the HRF response should accumulate over the duration (default: TRUE). If FALSE, the maximum response within the duration window is taken (currently only supported for single-basis HRFs).
#' @param normalize Logical; scale output so that the peak absolute value is 1 (default: FALSE). Applied *after* amplitude scaling and duration processing.
#' @param ... Additional arguments (unused).
#' @return A numeric vector or matrix of HRF values at the specified time points.
#' @export
evaluate.HRF <- function(x, grid, amplitude = 1, duration = 0,
                         precision = .2, summate = TRUE, normalize = FALSE, ...) {
  
  # Base function incorporating amplitude
  base <- function(g) amplitude * x(g)

  # Evaluate based on duration
  out <- if (duration < precision) {
      # Point evaluation
    base(grid)
  } else {
      # Block evaluation
    offs <- seq(0, duration, by = precision)
      # Evaluate HRF at shifted time points for each offset
      # Use lapply to handle potential matrix output from multi-basis HRFs
      hlist <- lapply(offs, function(o) base(grid - o))
      
      # Check if the result for the first offset is a matrix (multi-basis)
      is_multi_basis <- is.matrix(hlist[[1]])
      
      if (is_multi_basis) {
          # Combine matrices (summation is standard for multi-basis)
          if (summate) {
             Reduce("+", hlist)
    } else {
             # Taking max per-basis-column across offsets is non-standard and complex.
             # Sticking to summation for multi-basis block designs.
             warning("summate=FALSE is not typically used with multi-basis HRFs during block evaluation. Using summation.", call. = FALSE)
             Reduce("+", hlist)
          }
      } else {
          # Single basis HRF: hlist contains vectors, bind them into a matrix
        hmat <- do.call(cbind, hlist)
          if (summate) {
              rowSums(hmat)
          } else {
              # For single basis, take the max across the duration window at each grid point
              apply(hmat, 1, max, na.rm = TRUE) 
              # Alternative: find which offset gives max? apply(hmat, 1, function(vals) vals[which.max(vals)])
          }
      }
  }

  # Apply normalization if requested, handling matrix/vector case
  if (normalize) {
      if (is.matrix(out)) {
          apply(out, 2, function(col) {
              peak_val <- max(abs(col), na.rm = TRUE)
              if (!is.na(peak_val) && peak_val != 0) col / peak_val else col
          })
      } else {
          peak_val <- max(abs(out), na.rm = TRUE)
          if (!is.na(peak_val) && peak_val != 0) out / peak_val else out
      }
  } else {
    out
  }
}

# Create pre-defined HRF objects using generators -----

#' @rdname HRF_objects
#' @export
HRF_BSPLINE <- hrf_bspline_generator(nbasis=5, span=24)

#' @rdname HRF_objects  
#' @export
HRF_FIR <- hrf_fir_generator(nbasis=12, span=24)
</file>

<file path="R/sampling_frame.R">
# ---------------------------------------------------------------------
# low‑level constructor – never exported
#' @noRd
#' @keywords internal
new_sampling_frame <- function(blocklens, TR, start_time, precision) {
  structure(
    list(blocklens = blocklens,
         TR        = TR,
         start_time = start_time,
         precision = precision),
    class = "sampling_frame")
}

#'
#' A \code{sampling_frame} describes the block structure and temporal sampling of an fMRI paradigm.
#'
#' @param blocklens A numeric vector representing the number of scans in each block.
#' @param TR A numeric value or vector representing the repetition time in seconds (i.e., the spacing between consecutive image acquisitions).
#' @param start_time A numeric value or vector representing the offset of the first scan of each block (default is \code{TR/2}).
#' @param precision A numeric value representing the discrete sampling interval used for convolution with the hemodynamic response function (default is 0.1).
#'
#' @examples
#' frame <- sampling_frame(blocklens = c(100, 100, 100), TR = 2, precision = 0.5)
#'
#' # The relative time (with respect to the last block) in seconds of each sample/acquisition
#' sam <- samples(frame)
#' # The global time (with respect to the first block) of each sample/acquisition
#' gsam <- samples(frame, global = TRUE)
#'
#' @return A list with class "sampling_frame" describing the block structure and temporal sampling of an fMRI paradigm.
#' @export
sampling_frame <- function(blocklens, TR, start_time = TR / 2, precision = .1)
{
  # --- recycle & validate ------------------------------------------------
  # Ensure all vectors have the same length
  max_len <- max(length(blocklens), length(TR), length(start_time))
  blocklens <- rep_len(blocklens, max_len)
  TR <- rep_len(TR, max_len)
  start_time <- rep_len(start_time, max_len)
  
  # Validate inputs with proper error messages
  if (!all(blocklens > 0)) {
    stop("Block lengths must be positive")
  }
  if (!all(TR > 0)) {
    stop("TR values must be positive")
  }
  if (!all(start_time >= 0)) {
    stop("Start times must be non-negative")
  }
  if (precision <= 0) {
    stop("Precision must be positive")
  }
  if (precision >= min(TR)) {
    stop("Precision must be positive and less than the minimum TR")
  }

  new_sampling_frame(blocklens, TR, start_time, precision)
}

# ---------------------------------------------------------------------
# vectorised helpers (no memoise, no lapply)
#' Sampling times for a sampling frame
#'
#' @rdname samples
#' @param blockids Numeric vector specifying which blocks/runs to include.
#' @param global Logical; if TRUE, return cumulative times across runs.
#' @export
samples.sampling_frame <- function(x, blockids = NULL, global = FALSE,...) {
  if (is.null(blockids)) blockids <- seq_along(x$blocklens)

  # number of scans per selected block
  lens <- x$blocklens[blockids]

  # fast allocate
  idx <- sequence(lens) - 1                   # 0‑based within block
  
  # Calculate relative times within each block
  block_times <- rep(blockids, lens)  # which block each sample belongs to
  times <- x$start_time[block_times] + idx * x$TR[block_times]

  if (global) {
    # For global timing, add the cumulative time offset from previous blocks
    # Calculate cumulative time at the end of each block
    block_durations <- x$blocklens * x$TR
    cumulative_time <- c(0, cumsum(block_durations))
    
    # Add the cumulative time offset for each block
    time_offsets <- cumulative_time[block_times]
    times + time_offsets
  } else {
    times
  }
}

#' @rdname global_onsets
#' @param blockids Integer vector of block IDs
#' @export
global_onsets.sampling_frame <- function(x, onsets, blockids,...) {
  # Calculate cumulative time offsets for each block
  block_durations <- x$blocklens * x$TR
  cumulative_time <- c(0, cumsum(block_durations))
  
  blockids <- as.integer(blockids)
  stopifnot(length(onsets) == length(blockids),
            all(blockids >= 1L), all(blockids <= length(x$blocklens)))

  onsets + cumulative_time[blockids]
}

#' @export
#' @rdname print
print.sampling_frame <- function(x, ...) {
  n_blk <- length(x$blocklens)
  total_scans <- sum(x$blocklens)
  
  cat("Sampling Frame\n")
  cat("==============\n\n")
  
  cat("Structure:\n")
  cat(sprintf("  %d block%s\n", n_blk, if (n_blk > 1) "s" else ""))
  cat(sprintf("  Total scans: %d\n\n", total_scans))
  
  cat("Timing:\n")
  cat(sprintf("  TR: %s s\n", paste(unique(x$TR), collapse = ", ")))
  cat(sprintf("  Precision: %.3g s\n\n", x$precision))
  
  cat("Duration:\n")
  total_time <- sum(x$blocklens * x$TR)
  cat(sprintf("  Total time: %.1f s\n", total_time))
  
  invisible(x)
}

#' Extract Block IDs from a Sampling Frame
#'
#' Returns an integer vector indicating the block ID for each scan.
#'
#' @param x A sampling_frame object.
#' @return An integer vector.
#' @export
blockids.sampling_frame <- function(x) {
  rep(seq_along(x$blocklens), times = x$blocklens)
}

#' Get block lengths from a sampling frame
#'
#' @rdname blocklens
#' @return Numeric vector giving the number of scans in each block.
#' @export
blocklens.sampling_frame <- function(x,...) {
    x$blocklens
}
</file>

<file path="R/afni.R">
#' Generate an AFNI Linear Model from an fmri_config object
#'
#' This function takes an fmri_config object and generates an AFNI linear model
#' by reading the necessary files, creating an fmri_dataset, event_model,
#' baseline_model, and fmri_model, and fitting the model using afni_lm.
#'
#' @param x An fmri_config object containing the necessary configuration for the analysis
#' @param ... Additional arguments passed to the function
#' @return An afni_lm object representing the fitted linear model
#' @importFrom utils read.table
#' @keywords internal
#' @noRd
gen_afni_lm.fmri_config <- function(x, ...) {
  
  nuisance_list <- if (!is.null(x$baseline_model$nuisance_files)) {
    lapply(x$baseline_model$nuisance_files, read.table, header=TRUE)
  }
  
  dset <- fmri_dataset(scans=x$scans, 
                       mask=x$mask, 
                       TR=x$TR, 
                       run_length=x$run_length, 
                       event_table=x$design, 
                       base_path=x$base_path,
                       censor=if (is.null(x$censor_file)) NULL else scan(paste0(x$base_path, "/", x$censor_file)))

  emodel <- event_model(x$event_model, data=x$design, block=as.formula(paste("~", x$block_column)),
                        sampling_frame=dset$sampling_frame)
  
  bmodel <- baseline_model(basis=x$baseline_model$basis, 
                           degree=x$baseline_model$degree, 
                           sframe=dset$sampling_frame, 
                           nuisance_list=nuisance_list)
  
  fmodel <- fmri_model(emodel, bmodel)
  alm <- afni_lm(fmodel, dset, censor=dset$censor)
  
}

  

#' Set up an fMRI linear model for AFNI's 3dDeconvolve
#'
#' This function prepares an fMRI linear model for AFNI's 3dDeconvolve tool.
#' It takes an fmri_model object, an fmri_dataset object, and various options
#' to control the fitting process.
#'
#' @param fmri_mod An fmri_model object containing the event and baseline models
#' @param dataset An fmri_dataset object containing the scan data and other necessary information
#' @param working_dir The working directory (default is the current directory)
#' @param polort The number of polynomial baseline regressors (default is to suppress 'polort')
#' @param jobs The number of jobs to use with '3dDeconvolve' (default is 1)
#' @param censor A list of censoring vectors, one per run, or a single vector equal to the total number of scans (default is NULL)
#' @param options A list of options to be sent to 3dDeconvolve (default is an empty list)
#'
#' @return An afni_lm_spec object containing the fitted model, dataset, working directory, options, and command
#'
#' @examples 
#' etab <- data.frame(onset=c(1,30,15,25), fac=factor(c("A", "B", "A", "B")), 
#' run=c(1,1,2,2))
#' dset <- fmri_dataset(scans=c("s1.nii", "s2.nii"), mask="mask.nii", TR=1, 
#' run_length=c(50,50), event_table=etab)
#'
#' emodel <- event_model(onset ~ hrf(fac), block = ~ run, data=etab, 
#' sampling_frame=dset$sampling_frame)
#' bmodel <- baseline_model("bs", degree=4, sframe=dset$sampling_frame)
#' fmod <- fmri_model(emodel, bmodel)
#' alm <- afni_lm(fmod, dset, jobs=2, options=list(tout=TRUE, errts="residuals.nii.gz"))
#' @export
afni_lm <- function(fmri_mod, dataset, working_dir=".", polort=-1, jobs=1, 
                    censor=NULL, options=list()) {
  
  if (!is.null(censor)) {
    censor <- unlist(censor)
    assert_that(length(censor) == sum(dataset$sampling_frame$blocklens))
  }
  
  defopts <- list(noFDR=FALSE, 
                       fout=FALSE, 
                       rout=FALSE, 
                       tout=TRUE, 
                       float=TRUE, 
                       nocond=FALSE,
                       x1D_stop=FALSE,
                       cbucket="coefout", 
                       bucket="statout", 
                       jobs=jobs, 
                       polort=polort, 
                       censor=censor,
                       iresp=FALSE, 
                       noFDR=TRUE,
                       nofullf_atall=TRUE,
                       TR_times=1)
  
  for (optname in names(options)) {
    defopts[[optname]] <- options[[optname]]
  }
  
  cmd <- build_decon_command(model=fmri_mod, dataset,working_dir=working_dir,opts=defopts)
  
  structure(
    list(
      model=fmri_mod,
      dataset=dataset,
      working_dir=working_dir,
      options=defopts,
      cmd=cmd),
    class="afni_lm_spec")

}


#' @export
#' @rdname print
print.afni_lm_spec <- function(x,...) {
  cat("AFNI linear model via 3dDeconvolve \n")
  cat("  working_dir: ", x$working_dir, "\n")
  cat("  number of GLTs:", length(x$cmd$glts), "\n")
  cat("  command line: \n", x$cmd$cmd, "\n")
  
}


#' @keywords internal
#' @noRd
afni_stim_file <- function(label, file_name, values) {
  structure(
    list(label=label, file_name=file_name, values=values),
    class=c("afni_stim_file", "afni_stim")
  )
}

#' @keywords internal
#' @noRd
afni_stim_times <- function(label, file_name, hrf, onsets, blockids, iresp=FALSE, sresp=FALSE, tr_times=1) {
  structure(
    list(label=label, file_name=file_name, hrf=hrf, onsets=onsets, blockids, iresp=iresp, sresp=sresp, tr_times=tr_times),
    class=c("afni_stim_times","afni_stim")
  )
}


#' @keywords internal
#' @noRd
afni_stim_im_times <- function(label, file_name, hrf, onsets, blockids) {
  structure(
    list(label=label, file_name=file_name, hrf=hrf, onsets=onsets, blockids=blockids),
    class=c("afni_stim_im_times", "afni_stim_times","afni_stim")
  )
}


#' @keywords internal
#' @noRd
afni_command_switch <- function(x, ...) UseMethod("afni_command_switch")

#' @keywords internal
#' @noRd
write_afni_stim <- function(x, ...) UseMethod("write_afni_stim")


#' @keywords internal
#' @noRd
afni_command_switch.afni_stim_file <- function(x, k, type) {
  switch(type,
    label = paste(k, x$label, collapse = " "),
    file = paste(k, x$file_name, collapse = " "),
    ortvec = paste(x$file_name, x$label),
    times = NULL,
    iresp = NULL,
    sresp=NULL
  )
}


#' @keywords internal
#' @noRd
afni_command_switch.afni_stim_im_times <- function(x, k, type) {
  switch(type,
         label = paste(k, x$label, collapse = " "),
         times_IM = paste(k, x$file_name, as.character(x$hrf), collapse = " "),
         NULL
  )
}

#' @keywords internal
#' @noRd
afni_command_switch.afni_stim_times <- function(x, k, type) {
  switch(type,
         label = paste(k, x$label, collapse = " "),
         times=paste(k, x$file_name, as.character(x$hrf), collapse=" "),
         file=NULL,
         ortvec=NULL,
         iresp = if (x$iresp) paste(k, paste(paste(x$label, "_iresp", sep=""), collapse=" ")) else NULL,
         sresp = if (x$sresp) paste(k, paste(paste(x$label, "_sresp", sep=""), collapse=" ")) else NULL
  )
}

#' @keywords internal
#' @noRd
next_dir_name <- function(wd) {
  nd <- paste(wd, "+", sep="")
  if (!file.exists(nd)) {
    nd
  } else {
    Recall(nd)
  }
}


#' @noRd
#' @keywords internal
#' @importFrom utils write.table
write_baseline_mat <- function(stim, dir) {
  write.table(stim$mat, paste0(dir, "/", stim$file_name, sep=""), col.names=FALSE, row.names=FALSE)
}

#' @keywords internal
#' @noRd
write_baseline_mats <- function(blist) {
  purrr::walk(blist, ~ write_baseline_mat(., "."))
}
  
#' @keywords internal
#' @noRd
write_stim_files <- function(afni_stims) {
  purrr::walk(afni_stims, ~ write_afni_stim(., "."))
}

#' @keywords internal
#' @noRd
write_afni_stim.afni_stim_file <- function(stim, dir) {
  .write_values <- function(outname, vals) {
    hfile <- file(outname, "w")
    write(vals, file=hfile, ncolumns=1)
    close(hfile)
  }
  
  ## TODO stim$values is a data.frame sometimes (trialwise?), hence 'unlist' hack. Ensure uniformity.
  .write_values(paste0(dir, "/", stim$file_name, sep=""), unlist(stim$values))
}

#' @keywords internal
#' @noRd
write_afni_stim.afni_stim_times <- function(stim, dir) {
  ## TODO handle runs with no stimuli
  .write_onsets <- function(outname, vals) {
    hfile <- file(outname, "w")
    for (i in 1:length(vals)) {
      ons <- paste(stim$onsets[[i]], collapse=" ")
      writeLines(ons, con=hfile)
    }
    
    close(hfile)
  }
  
  .write_onsets(paste0(dir, "/", stim$file_name, sep=""), stim$onsets)
}



#' @keywords internal
#' @noRd
write_censor_file <- function(dir, censor) {
    outname <- paste0(dir, "/censor.1D")
    hfile <- file(outname, "w")
    write(censor, file=hfile, ncolumns=1)
    close(hfile)
}
  

#' @keywords internal
#' @noRd
#' @importFrom purrr imap
write_glts <- function(glts, gltfiles) {
  imap(glts, function(glt, i) {
    fout <- file(gltfiles[i], "w")
    write(glt, file=fout, sep="\n")
    close(fout)
  })
}

#' @keywords internal
#' @noRd
afni_baseline_matrix <- function(label, file_name, mat) {
  structure(
    list(label=label, file_name=file_name, mat=mat),
    class="afni_baseline_matrix"
  )
}

#' @keywords internal
#' @noRd
build_baseline_stims <- function(x) {
  blens <- blocklens(x)
  nblocks <- length(blens)
  
  bterms <- terms(x$baseline_model)
  
  ret <- lapply(bterms, function(bt) {
    lapply(1:nblocks, function(i) {
      mat <- design_matrix(bt, i, allrows=TRUE)
      afni_baseline_matrix(paste0(bt$varname, "_", i), paste0(bt$varname, "_", i, ".1D"), mat)
    })
  })
  
  unlist(ret, recursive=FALSE)
}

#' Build AFNI stimulus definitions
#'
#' Generate stimulus files for AFNI's 3dDeconvolve.
#' @param x Term object
#' @param ... Additional arguments
#' @param iresp Logical; generate -iresp files when TRUE
#' @param tr_times Numeric; TR timing for stimuli
#' @return List of stimulus descriptors or `NULL`
#' @export
#' @family AFNI
#' @rdname build_afni_stims
build_afni_stims <- function(x, ...) UseMethod("build_afni_stims")

#' @keywords internal
#' @noRd
build_afni_stims.convolved_term <- function(x, iresp=FALSE, tr_times=1) {
  stimlabels <- longnames(x)
  stimfiles <- paste(stimlabels, "_reg.1D", sep = "")
  desmat <- design_matrix(x)
  
  lapply(1:length(stimlabels), function(i) {
    afni_stim_file(stimlabels[i], stimfiles[i], desmat[, i])
  })
}

#' @keywords internal
#' @noRd
build_afni_stims.afni_hrf_convolved_term <- function(x, iresp=FALSE, tr_times=1) {

  stimlabels <- longnames(x)
  stimfiles <- paste(stimlabels, "_times.1D", sep = "")
  dmat <- design_matrix(x$evterm)
  
  hrf_name <- as.character(x$hrfspec$hrf)
  blids <- unique(blockids(x$evterm))
  split_ons <- split_onsets(x$evterm, x$sampling_frame, global=FALSE, blocksplit = TRUE)
  names(split_ons) <- stimlabels
  
  ret <- lapply(1:length(stimlabels), function(i) {
    afni_stim_times(stimlabels[i], stimfiles[i], hrf_name, 
                    split_ons[[stimlabels[[i]]]], blockids=blids, 
                    iresp=iresp, tr_times=tr_times)
  })
  
}

#' @keywords internal
#' @noRd
build_afni_stims.afni_trialwise_convolved_term <- function(x, iresp=FALSE, tr_times=1) {
  eterm <- x$evterm
  sf <- x$sampling_frame
  hrf_name <- as.character(x$hrfspec$hrf) # Get HRF name

  # Extract the trial variable name specified in afni_trialwise(TRIAL_VAR, ...)
  trial_var_name <- eterm$varname # This should be 'trial' or whatever was passed

  # Get the full event table associated with this term
  full_event_table <- event_table(eterm)

  # Ensure the trial variable and any modulators exist in the event table
  if (!(trial_var_name %in% names(full_event_table))) {
    stop(paste("Trial variable '", trial_var_name, "' not found in event table for term '", eterm$name, "'."))
  }
  
  # Get modulators if any. This part might need adjustment based on how modulators are stored.
  # For afni_trialwise, the main 'modulator' is the trial variable itself.
  # Additional parametric modulators would be columns in the event_table.
  # The -stim_times_IM format is onset*modulator1:modulator2 etc.
  # For basic afni_trialwise("trial"), the modulator is just the trial number (or a unique trial ID).
  # If the user supplied `afni_trialwise("trial", modulate_by="RT")`, then RT would be a modulator.
  # For now, let's assume the 'trial' column itself is the modulator if no other is specified.

  # Check if `x$hrfspec` contains explicit modulator names
  modulator_vars <- x$hrfspec$modulate_by
  if (is.null(modulator_vars)) {
      # If no explicit modulators, use the trial_var_name as the modulator for amplitude (common for -IM)
      # However, AFNI's -stim_times_IM expects onsets and *optional* modulators.
      # If only trial-wise HRFs are desired without amplitude modulation per trial,
      # we still need a 'modulator' for AFNI, often it's implicitly 1 for each trial.
      # For now, we will format it as onset*trial_value
      modulator_vars <- trial_var_name 
  }
  
  if (!all(modulator_vars %in% names(full_event_table))) {
      stop(paste("One or more modulator variables not found in event table:", paste(modulator_vars, collapse=", ")))
  }

  stim_label <- longnames(eterm) # Should be a unique label for this IM regressor
  stim_file_name <- paste0(stim_label, "_IM_times.1D")

  # Prepare onsets and modulators per run, in AFNI's asterisk format
  # e.g., run 1: "10*mod1a:mod2a 20*mod1b:mod2b ...", run 2: "5*mod1c:mod2c ..."
  onsets_IM_per_run <- lapply(unique(sf$blockids), function(run_id) {
    run_events <- full_event_table[full_event_table[[sf$block_name]] == run_id, , drop = FALSE]
    if (nrow(run_events) == 0) {
      return("*") # AFNI placeholder for empty run
    }
    
    sapply(1:nrow(run_events), function(i) {
      onset_val <- run_events$onset[i]
      mod_values <- sapply(modulator_vars, function(mvar) run_events[[mvar]][i])
      paste0(onset_val, "*", paste(mod_values, collapse=":"))
    }) |> paste(collapse = " ")
  })

  # Create the afni_stim_im_times object
  afni_stim_obj <- afni_stim_im_times(
    label = stim_label,
    file_name = stim_file_name,
    hrf = hrf_name, # HRF model string like 'SPMG1'
    onsets = onsets_IM_per_run, # This should be a list of character strings, one per run
    blockids = unique(sf$blockids) # The unique run/block identifiers
  )
  
  # build_afni_stims can return a single stim object or a list of them.
  # For afni_trialwise, it's typically one -stim_times_IM directive.
  return(list(afni_stim_obj)) # Ensure it's returned in a list as expected by build_decon_command processing
}

#' @export
#' @rdname build_afni_stims
build_afni_stims.event_term <- function(x, iresp=FALSE, tr_times=1,...) {
  # This method handles plain event_terms created from standard hrf() calls.
  # These are not directly translated into AFNI -stim_times or similar directives.
  # They might be relevant if we were generating -stim_regressor from an existing matrix,
  # but that's not the purpose of this function family.
  # We return NULL to indicate no AFNI-specific stimulus file for this term.
  # The calling function (build_decon_command) should filter out NULLs.
  
  # Optionally, issue a message if verbose debugging is needed.
  # message(paste("Skipping AFNI stimulus generation for standard event term:", x$name,"(class:", paste(class(x), collapse=", "), ") whose hrfspec is of class:", paste(class(hrfspec(x)), collapse=", ")))
  return(NULL)
}

# Helper function to extract HRF spec, safely returning NULL if not found
#' @keywords internal
if (!exists("hrfspec", mode = "function")) {
  hrfspec <- function(x) attr(x, "hrfspec")
}

#' @keywords internal
#' @noRd
.make_decon_command_str <- function(cmdlines) {
  cmdstr <- lapply(names(cmdlines), function(optname) {
    entry <- cmdlines[[optname]]
    if (is.list(entry)) {
      switchnames <- rep(paste("-", optname, sep=""), length(entry))
      paste(switchnames, entry, collapse=" ")
    } else if (is.null(entry) || length(entry) == 0) {
      ""
    } else if (is.numeric(entry[[1]])) {
      paste(paste("-", optname, sep=""), entry[[1]])
    } else if (entry[[1]] == TRUE) {
      paste("-", optname, sep="")
    } else if (entry[[1]] == FALSE) {
      paste("")
    } else {
      paste(paste("-", optname, sep=""), paste(entry, collapse=" "))
    }
  })

  cmdstr <- Filter(function(x) !is.null(x) & x != "", cmdstr)
  cmdstr <- paste(cmdstr, collapse=" ")
  cmdstr <- paste("3dDeconvolve", cmdstr)
  cmdstr
}



#' Build 3dDeconvolve command for an fMRI model
#'
#' This function constructs the command string and associated options required
#' to run 3dDeconvolve using the specified fMRI model, dataset, working directory,
#' and other options. This command string can then be used to perform the actual
#' fMRI analysis using the AFNI software.
#'
#' @param model The fMRI model, usually created using the fmri_model function
#' @param dataset The fMRI dataset, usually created using the fmri_dataset function
#' @param working_dir The working directory
#' @param opts A list of options for the 3dDeconvolve command
#'
#' @return A list containing:
#'         - cmd: The 3dDeconvolve command string
#'         - cmdlines: The command lines for the 3dDeconvolve command
#'         - afni_stims: A list of AFNI stimulus objects
#'         - afni_baseline_mats: A list of AFNI baseline matrices
#'         - gltfiles: A list of GLT (general linear test) filenames
#'         - gltnames: A list of GLT names
#'         - glts: A list of GLT objects
#'         - gltstr: A list of GLT strings
#'         - censor: The censoring vector
#'
#' @keywords internal
#' @noRd
build_decon_command <- function(model, dataset, working_dir, opts) {
  func_terms <- terms(model$event_model)
  message("number of functional terms: ", length(func_terms))
  
  # First, generate AFNI stims and filter out NULLs
  afni_stims <- lapply(func_terms, function(term) { build_afni_stims(term, iresp=opts[["iresp"]], tr_times=opts[["TR_times"]]) })
  afni_stims <- Filter(Negate(is.null), afni_stims) # Filter out NULLs
  afni_stims <- unlist(afni_stims, recursive = FALSE) # Unlist one level
  
  # Now get stimlabels only for terms that generated AFNI stims
  # We need to identify which terms generated stims
  terms_with_stims <- func_terms[!sapply(lapply(func_terms, function(term) { build_afni_stims(term, iresp=opts[["iresp"]], tr_times=opts[["TR_times"]]) }), is.null)]
  stimlabels <- unlist(lapply(terms_with_stims, longnames))
  
  ## all stims must be unique
  assert_that(length(unique(stimlabels)) == length(stimlabels))

  # Note: We can't assert stimlabels == conditions because conditions includes ALL terms,
  # but stimlabels only includes terms that generate AFNI stims
  # assert_that(length(stimlabels) == length(conditions(model$event_model)))
  
  ## extract all contrast matrices
  cons <- contrast_weights(model)
  cons <- unlist(cons, recursive=FALSE)
  
  ## convert to 'glt's
  glts <- lapply(cons, to_glt)
  
  gltfiles <- unlist(lapply(glts, function(x) paste0(x$name, ".txt")))
  gltnames <- unlist(lapply(glts, function(x) x$name))
  gltstr <- unlist(lapply(glts, function(x) x$glt_str))
  
  assert_that(sum(duplicated(gltnames))  == 0, msg="Cannot have two GLTs with the same name")
  
  afni_baseline_mats <- build_baseline_stims(model)
  
  purge_nulls <- function(A) {
    A[!sapply(A, is.null)]
  }
  
  opt_stim_labels <-  purge_nulls(lapply(seq_along(afni_stims), function(i) afni_command_switch(afni_stims[[i]], i, "label")))
  opt_stim_files  <-  purge_nulls(lapply(seq_along(afni_stims), function(i) afni_command_switch(afni_stims[[i]], i, "file")))
  opt_stim_times  <-  purge_nulls(lapply(seq_along(afni_stims), function(i) afni_command_switch(afni_stims[[i]], i, "times")))
  opt_stim_times_IM  <-  purge_nulls(lapply(seq_along(afni_stims), function(i) afni_command_switch(afni_stims[[i]], i, "times_IM")))
  opt_stim_ortvecs <- purge_nulls(lapply(seq_along(afni_baseline_mats), function(i) afni_command_switch.afni_stim_file(afni_baseline_mats[[i]], i, "ortvec")))
  opt_stim_iresp  <-  purge_nulls(lapply(seq_along(afni_stims), function(i) afni_command_switch(afni_stims[[i]], i, "iresp")))
  
  #browser()
  
  if ( (length(opt_stim_times) + length(opt_stim_times_IM)) > 0) {
    ## if we use `afni_hrf` that use -stim_times, then we use local times
    global_times <- FALSE
  } else {
    ## otherwise global_times is irrelevant, since values rather than times are provided.
    global_times <- TRUE
  }
  
  cmdlines <- list(input=paste0(dataset$scans),
                   mask=paste0(dataset$mask_file),
                   polort=if (opts[["polort"]] > 0) opts[["polort"]] else -1,
                   global_times=if (global_times) TRUE else NULL,
                   num_stimts=length(afni_stims),
                   num_glt=length(gltfiles),
                   stim_file=opt_stim_files,
                   stim_label=opt_stim_labels,
                   ortvec=opt_stim_ortvecs,
                   censor=if (!is.null(opts[["censor"]])) "censor.1D" else NULL,
                   stim_times=opt_stim_times,
                   stim_times_IM=opt_stim_times_IM,
                   TR_times=opts[["TR_times"]],
                   iresp=opt_stim_iresp,
                   gltsym=lapply(seq_along(gltfiles), function(i) paste(gltfiles[i], collapse=" ")),
                   glt_label=lapply(seq_along(gltnames), function(i) paste(i, gltnames[i], collapse=" ")),
                   nofullf_atall=opts[["nofullf_atall"]],
                   fout=opts[["fout"]],
                   rout=opts[["rout"]],
                   tout=opts[["tout"]],
                   bout=opts[["bout"]],
                   noFDR=opts[["noFDR"]],
                   cbucket=opts[["cbucket"]],
                   bucket=opts[["bucket"]],
                   nocond=opts[["nocond"]],
                   x1D_stop=opts[["x1D_stop"]],
                   jobs=opts[["jobs"]],
                   errts=if (!is.null(opts[["errts"]])) opts[["errts"]] else NULL,
                   float=TRUE)
  
  cmd <- .make_decon_command_str(cmdlines)
  
  list(cmd=cmd, cmdlines=cmdlines, afni_stims=afni_stims, afni_baseline_mats=afni_baseline_mats,
       gltfiles=gltfiles, gltnames=gltnames, glts=glts, gltstr=gltstr, censor=opts$censor)
}



#' Run an afni_lm_spec object
#'
#' This function runs the 3dDeconvolve command for the specified afni_lm_spec object.
#' It outputs the results to a specified directory and can either execute the command
#' or only output the shell '3dDeconvolve.sh' script.
#'
#' @param x An afni_lm_spec object containing the model, dataset, and options
#' @param outdir The output folder
#' @param execute Whether to execute the command or only output the shell '3dDeconvolve.sh' script (default is TRUE)
#' @param execfun Function used to execute external system command (default is system)
#' @param prepend Prepend string to command (default is an empty string)
#' @param ... Additional arguments passed to execfun
#'
#' @return NULL. The function is used for its side effects, such as writing output files.
#'
#' @examples
#' # Assuming you have created an afni_lm_spec object called alm
#' #run.afni_lm_spec(alm, outdir="results")
#' @export
run.afni_lm_spec <- function(x, outdir, execute=TRUE, execfun=system, prepend="",...) {
  start_dir <- getwd()
  res <- try({
    if (!file.exists(outdir)) {
      dir.create(outdir)
    } else {
      warning(paste("glm output directory: ", outdir, " already exists"))
      outdir <- next_dir_name(outdir)
      dir.create(outdir)
      warning(paste("outputting to: ", outdir))
    }
    print(paste("setting directory:", outdir))
    setwd(outdir)
    
    write_stim_files(x$cmd$afni_stims)
    
    if (!is.null(x$cmd$gltstr)) {
      write_glts(x$cmd$gltstr, x$cmd$gltfiles)
    }
    
    if (!is.null(x$cmd$afni_baseline_mats)) {
      write_baseline_mats(x$cmd$afni_baseline_mats)
    }
    
    if (!is.null(x$cmd$censor)) {
      write_censor_file(".", x$cmd$censor)
    }
    
    #if (reml) {
    #  x$cmd$cmd <- paste(x$cmd$cmd, "-x1D_stop")
    #}
    
    write(x$cmd$cmd, "3ddeconvolve.sh")
    
    if (execute) {
      execfun(paste(prepend, x$cmd$cmd))
      
      #if (reml) {
      #  execfun(paste0("./", x$options$bucket, ".REML_cmd"))
      #}
    }
  })
  
  setwd(start_dir)
}

#' convert a contrast to an AFNI 'GLT' 
#' 
#' @param x the contrast to convert
#' @param ... extra args
#' @export
to_glt <- function(x, ...) UseMethod("to_glt")


#' @export
to_glt.contrast <- function(x,...) {
  if (is.matrix(x$weights) && ncol(x$weights) > 1) {
    glts <- lapply(1:ncol(x$weights), function(i) {
      paste0(signif(x$weights[,i],4), "*", x$condnames, collapse=" ")
    })
    
    ret <- list(glt_str=glts,
                name=paste0("GLT_", x$name, "_", 1:ncol(x$weights)),
                con=x)
    
    class(ret) <- "glt_contrast_list"
    ret
  } else {
    glt <- paste0(signif(x$weights,4), "*", x$condnames, collapse=" ")
    ret <- list(glt_str=glt,
                name=paste0("GLT_", x$name),
                con=x)
    
    class(ret) <- "glt_contrast"
    ret
  }
}







#           
#   afni.stims <- unlist(lapply(funcTerms, function(term) { buildAFNIStims(term, opts$iresp, opts$TR_times ) }))
# 
#   purgeNulls <- function(A) {
#     A[!sapply(A, is.null)]
#   }
# 
# 
#   opt_stim_labels <-  purgeNulls(lapply(seq_along(afni.stims), function(i) buildCommandSwitch(afni.stims[[i]], i, "label")))
#   opt_stim_files  <-  purgeNulls(lapply(seq_along(afni.stims), function(i) buildCommandSwitch(afni.stims[[i]], i, "file")))
#   opt_stim_times  <-  purgeNulls(lapply(seq_along(afni.stims), function(i) buildCommandSwitch(afni.stims[[i]], i, "times")))
#   opt_stim_iresp  <-  purgeNulls(lapply(seq_along(afni.stims), function(i) buildCommandSwitch(afni.stims[[i]], i, "iresp")))
# 
# 
#   cmdlines <- list(input=filelist(x@design, full.names=T),
#                              mask=x@mask,
#                              polort=opts[["polort"]],
#                              num_stimts=length(afni.stims),
#                              num_glt=length(gltlist),
#                              stim_file=opt_stim_files,
#                              stim_label=opt_stim_labels,
#                              stim_times=opt_stim_times,
#                              TR_times=opts[["TR_times"]],
#                              iresp=opt_stim_iresp,
#                              gltsym=lapply(seq_along(gltfiles), function(i) paste(gltfiles[i], collapse=" ")),
#                              glt_label=lapply(seq_along(gltnames), function(i) paste(i, gltnames[i], collapse=" ")),
#                              nofullf_atall=opts[["nofullf_atall"]],
#                              fout=opts[["fout"]],
#                              rout=opts[["rout"]],
#                              tout=opts[["tout"]],
#                              bout=opts[["bout"]],
#                              noFDR=opts[["noFDR"]],
#                              cbucket=opts[["cbucket"]],
#                              bucket=opts[["bucket"]],
#                              jobs=opts[["jobs"]],
#                              float=TRUE)
# 
# 
#             cmdstr <- .makeCommandStr(cmdlines)
# 
#             ret <- list()
#             wd <- workingDir(x)
# 
#             nextDirName <- function(wd) {
#               nd <- paste(wd, "+", sep="")
#               if (!file.exists(nd)) {
#                 nd
#               } else {
#                 Recall(nd)
#               }
#             }
# 
#             writeStimFiles <- function() {
#               sapply(afni.stims, function(stim) {
#                 writeAFNIStim(stim, ".")
#               })
#             }
# 
#
#             writeGLTs <- function() {
#               lapply(seq_along(gltlist), function(i) {
#                 fout <- file(gltfiles[i], "w")
#                 .glt <- gltlist[[i]]
# 
#                 write(unlist(.glt), file=fout, sep="\n")
# 
#                 close(fout)
#               })
#             }
# 
#
</file>

<file path="R/baseline_model.R">
###############################################################################
## BASELINE_MODEL.R
##
## This file implements baseline model construction for fMRI analyses.
## It includes helper routines for:
##   - Extracting column indices from a list of matrices.
##   - Constructing baseline models that account for drift, block‐wise
##     intercepts, and nuisance regressors.
##   - Creating design matrices and terms for baseline models.
##   - Specifying block and nuisance terms.
##   - Printing and plotting baseline models.
##
## The file has been organized into sections with additional inline comments
## for clarity. Functionality is preserved exactly as in the original file.
###############################################################################

## ============================================================================
## Section 1: Helper Functions
## ============================================================================

# Helper to get number of columns, returning 0 for NULL
.nz <- function(x) if (is.null(x)) 0 else ncol(design_matrix(x))

#' Calculate column indices for a list of block matrices
#'
#' Given a list of matrices (e.g., one per block), this function calculates
#' the corresponding column indices for each matrix as they would appear
#' when combined into a block-diagonal structure.
#'
#' @param mat_list A list of matrices. Each element must be a matrix.
#' @return A list where each element is an integer vector of column indices
#'         corresponding to the matrix in the input list.
#' @noRd
#' @keywords internal
get_col_inds <- function(mat_list) {
  # mat_list must be a list containing only matrices
  if (!is.list(mat_list)) {
    stop("mat_list must be a list")
  }
  if (!all(vapply(mat_list, is.matrix, logical(1)))) {
    stop("All elements of mat_list must be matrices")
  }
  ncols_per_block <- vapply(mat_list, ncol, integer(1))
  if (any(ncols_per_block < 0)) {
      stop("Matrices in mat_list must have non-negative number of columns.")
  }
  
  # Cumulative sum of columns, starting from 0
  cum_ncols <- c(0, cumsum(ncols_per_block))
  
  # Generate sequences of column indices for each block
  lapply(seq_along(ncols_per_block), function(i) {
    if (ncols_per_block[i] > 0) {
      # Indices are from (cumulative cols before this block + 1) to (cumulative cols up to this block)
      (cum_ncols[i] + 1):cum_ncols[i + 1]
    } else {
      # Return an empty integer vector if a block has 0 columns
      integer(0)
    }
  })
}

#' Build a baseline_term from a list of block‑wise nuisance matrices
#'
#' @param nuisance_list list of numeric matrices, **one per run/block**.
#' @param sframe        the sampling_frame used in the model.
#' @param prefix        prefix used when auto‑naming the columns.
#'
#' @return a baseline_term object (class c("baseline_term","matrix_term",...))
#' @noRd
make_nuisance_term <- function(nuisance_list,
                               sframe,
                               prefix = "nuis") {

  stopifnot(is.list(nuisance_list),
            all(vapply(nuisance_list, is.matrix, logical(1))))
  nb      <- length(blocklens(sframe))
  bl_lens <- blocklens(sframe)

  ## --- sanity checks ------------------------------------------------------
  if (length(nuisance_list) != nb)
    stop("length(nuisance_list) must equal number of blocks in sframe.")

  if (!all(vapply(seq_along(nuisance_list),
                  function(i) nrow(nuisance_list[[i]]) == bl_lens[i],
                  logical(1))))
    stop("Each nuisance matrix must have nrow == block length for its block.")

  ## --- assemble block‑diagonal matrix ------------------------------------
  full_mat <- as.matrix(Matrix::bdiag(lapply(nuisance_list, unclass)))
  ncols    <- ncol(full_mat)

  ## names:  prefix#<block>_<col>
  colnames(full_mat) <-
    unlist(purrr::imap(nuisance_list, function(mat, i)
      sprintf("%s#%02d_%d",
              prefix, i, seq_len(ncol(mat)))))

  ## bookkeeping lists
  colind <- get_col_inds(lapply(nuisance_list, as.matrix))
  rowind <- split(seq_len(nrow(full_mat)), blockids(sframe))

  baseline_term("nuisance", full_mat, colind, rowind)
}


## ============================================================================
## Section 2: Baseline Model Construction and Specification
## ============================================================================

#' Construct a Baseline Model
#'
#' Builds a baseline model to account for noise and non–event-related variance.
#' This model may include a drift term, a block intercept term, and nuisance regressors.
#'
#' @param basis Character; type of basis function ("constant", "poly", "bs", or "ns").
#' @param degree Integer; degree of the spline/polynomial function.
#' @param sframe A sampling_frame object.
#' @param intercept Character; whether to include an intercept ("runwise", "global", or "none").
#'   Ignored when \code{basis == "constant"} because the drift term already
#'   provides the constant baseline.
#' @param nuisance_list Optional list of nuisance matrices (one matrix per fMRI block).
#'
#' @return An object of class "baseline_model".
#'
#' @examples 
#' sframe <- sampling_frame(blocklens = c(100, 100), TR = 2)
#' bmod <- baseline_model(basis = "bs", degree = 3, sframe = sframe)
#' bmod_global <- baseline_model(basis = "bs", degree = 3, sframe = sframe, intercept = "global")
#' bmod_nointercept <- baseline_model(basis = "bs", degree = 3, sframe = sframe, intercept = "none")
#' stopifnot(ncol(design_matrix(bmod)) == 8)
#' @export
#' @importFrom purrr compact
baseline_model <- function(basis = c("constant", "poly", "bs", "ns"), degree = 1, sframe, 
                           intercept = c("runwise", "global", "none"), nuisance_list = NULL) {
  
  basis <- match.arg(basis)
  intercept <- match.arg(intercept)
  
  if (basis %in% c("bs", "ns")) {
    assert_that(degree > 2, msg ="'bs' and 'ns' bases must have degree >= 3")
  }
  
  # Construct the drift term specification
  drift_spec <- baseline(degree = degree, basis = basis, intercept = intercept)
  
  # List potential terms, using compact later to remove NULLs
  terms_list <- list(
    # Drift term always constructed based on spec
    drift = construct(drift_spec, sframe),
    # Block term constructed only if intercept is needed and basis isn't constant
    block = if (intercept != "none" && basis != "constant") {
              construct_block_term("constant", sframe, intercept)
            },
    # Nuisance term constructed only if list provided
    nuisance = if (!is.null(nuisance_list)) {
                 make_nuisance_term(nuisance_list, sframe)
               }
  )

  # Remove NULL terms and store in the final list
  ret <- list(
    terms = purrr::compact(terms_list),
    # Keep drift_spec for potential inspection? (Optional, but consistent with review example)
    drift_spec = drift_spec, 
    sampling_frame = sframe
  )
  
  class(ret) <- c("baseline_model", "list")
  ret
}

#' Create a Baseline Specification
#'
#' Generates a baselinespec for modeling low-frequency drift in fMRI time series.
#'
#' @param degree Number of basis terms per image block (ignored for "constant").
#' @param basis Type of basis ("constant", "poly", "bs", or "ns").
#' @param name Optional name for the term.
#' @param intercept Type of intercept to include ("runwise", "global", or "none").
#'
#' @return A baselinespec list instance.
#' @examples
#' baseline(degree = 3, basis = "bs")
#' @export
baseline <- function(degree = 1, basis = c("constant", "poly", "bs", "ns"), name = NULL,
                     intercept = c("runwise", "global", "none")) {
  
  basis <- match.arg(basis)
  intercept <- match.arg(intercept)
  
  if (basis == "constant") {
    degree <- 1
  }
  
  bfun <- switch(basis,
                 bs = splines::bs,
                 ns = splines::ns,
                 poly = poly,
                 constant = function(x, degree) { matrix(rep(1, length(x))) })
  
  if (is.null(name)) {
    name <- paste0("baseline_", basis, "_", degree)
  }
  
  ret <- list(
    degree = degree,
    basis = basis,
    fun = bfun,
    intercept = intercept,
    name = name
  )
  
  class(ret) <- c("baselinespec", "nuisancespec")
  ret
}


## ============================================================================
## Section 3: Design Matrix and Term Functions for Baseline Models
## ============================================================================

#' Construct a Design Matrix for a Baseline Model
#'
#' Combines the drift term, block intercept term, and nuisance term (if any)
#' into a complete design matrix.
#'
#' @param x A baseline_model object.
#' @param blockid Optional block ID to extract a subset.
#' @param allrows Logical; if TRUE, returns all rows for the block.
#' @param ... Additional arguments passed to underlying term methods.
#' @return A tibble representing the design matrix.
#' @examples
#' sframe <- sampling_frame(blocklens = 10, TR = 1)
#' bmod <- baseline_model(sframe = sframe)
#' design_matrix(bmod)
#' @rdname design_matrix.baseline_model
#' @export
#' @importFrom purrr map
#' @importFrom dplyr bind_cols
design_matrix.baseline_model <- function(x, blockid = NULL, allrows = FALSE, ...) {
  # Map design_matrix over the terms list
  mats <- purrr::map(x$terms, design_matrix, blockid = blockid, allrows = allrows)
  # Combine the resulting matrices column-wise using bind_cols for safety and tibble output
  dplyr::bind_cols(mats)
}

#' Return the Terms of a Baseline Model
#'
#' @param x A baseline_model object.
#' @param ... Passed to underlying term constructors (unused here).
#' @rdname terms.baseline_model
#' @return A list of terms (drift, block, nuisance).
#' @examples
#' sframe <- sampling_frame(blocklens = 10, TR = 1)
#' bmod <- baseline_model(sframe = sframe)
#' terms(bmod)
#' @export
#' @importFrom purrr map_lgl
terms.baseline_model <- function(x, ...) {
  # Simply return the terms list
  x$terms
}

#' Retrieve Cells of a Baseline Model
#'
#' Combines the cells from all baseline terms into a tibble with an index.
#'
#' @param x A baseline_model object.
#' @param ... Currently unused.
#' @return A tibble with columns: term, level, basis, and index.
#' @examples
#' sframe <- sampling_frame(blocklens = 10, TR = 1)
#' bmod <- baseline_model(sframe = sframe)
#' cells(bmod)
#' @export
#' @importFrom dplyr mutate tibble
#' @importFrom stringr str_pad
#' @rdname cells
cells.baseline_model <- function(x, ...) {
  # Use lapply over x$terms
  cells_list <- lapply(x$terms, function(term) {
    conds <- conditions(term)
    ncond <- length(conds)
    # Handle case with zero conditions gracefully
    if (ncond == 0) return(dplyr::tibble(term = character(0), level = character(0), basis = character(0)))
    # Use str_pad for consistent zero-padding
    basis_names <- stringr::str_pad(1:ncond, width = ceiling(log10(ncond + 1e-6)), pad = "0")
    dplyr::tibble(term = term$varname, level = conds, basis = paste0("basis", basis_names))
  })
  # Use do.call(rbind, ...) to combine
  combined_cells <- do.call(rbind, cells_list)
  # Add index column if there are rows
  if(nrow(combined_cells) > 0) {
     dplyr::mutate(combined_cells, index = 1:dplyr::n())
  } else {
     dplyr::mutate(combined_cells, index = integer(0))
  }
}

## ============================================================================
## Section 4: Block and Nuisance Specification Helpers
## ============================================================================

#' Create a Block Variable
#'
#' Returns a block variable that is constant over the span of a scanning run.
#'
#' @param x The block variable.
#' @return An object of class "blockspec".
#' @examples
#' block(run)
#' @export
block <- function(x) {
  varname <- substitute(x)
  pterm <- parse_term(as.list(substitute(x)), "block")
  ret <- list(
    name = varname,
    label = pterm$label
  )
  class(ret) <- "blockspec"
  ret
}

#' Construct a Baseline Specification from a Sampling Frame
#'
#' Given a baselinespec object and a sampling frame, constructs the baseline
#' covariates for each block by applying the baseline function to each block.
#'
#' @param x A baselinespec object.
#' @param model_spec A model specification containing (or serving as) the sampling frame.
#' @return A baseline term object.
#' @noRd
construct.baselinespec <- function(x, model_spec, ...) {
  sampling_frame <- if (!is.null(model_spec$sampling_frame)) model_spec$sampling_frame else model_spec
  
  bl <- blocklens(sampling_frame) # Normalize block lengths usage
  
  # Compute baseline covariates for each block, passing correct argument name
  ret_list <- lapply(bl, function(block_len) {
    if (x$basis == "ns") {
      x$fun(seq(1, block_len), df = x$degree)
    } else if (x$basis %in% c("poly", "bs")) {
      x$fun(seq(1, block_len), degree = x$degree)
    } else { 
      x$fun(seq(1, block_len))
    }
  })
  
  # Simplified handling for global constant intercept
  if (x$basis == "constant" && x$intercept == "global") {
    mat <- matrix(1, nrow = sum(bl), ncol = 1)
    cnames <- paste0("base_", x$basis)
    colnames(mat) <- cnames
    # column index is a single value, but rows are tracked per block
    colind <- list(1)
    rowind <- split(seq_len(nrow(mat)), blockids(sampling_frame))
    return(baseline_term(x$name, mat, colind, rowind))
  }
  
  # Standard block-wise construction
  nc_per_block <- ncol(ret_list[[1]])
  total_cols <- length(ret_list) * nc_per_block
  mat <- matrix(0, sum(bl), total_cols)
  
  colind <- vector("list", length(ret_list))
  rowind <- vector("list", length(ret_list))
  all_cnames <- vector("character", total_cols)
  
  current_col <- 1
  current_row <- 1
  for (i in seq_along(ret_list)) {
    rows_this_block <- bl[i]
    cols_this_block <- nc_per_block
    
    row_indices <- current_row:(current_row + rows_this_block - 1)
    col_indices <- current_col:(current_col + cols_this_block - 1)
    
    mat[row_indices, col_indices] <- ret_list[[i]]
    colind[[i]] <- col_indices
    rowind[[i]] <- row_indices
    
    # Generate column names for this block
    cnames_block <- paste0("base_", x$basis, 1:cols_this_block, "_block_", i)
    all_cnames[col_indices] <- cnames_block
    
    current_row <- current_row + rows_this_block
    current_col <- current_col + cols_this_block
  }
  
  colnames(mat) <- all_cnames
  baseline_term(x$name, mat, colind, rowind)
}

#' Construct a Baseline Term
#'
#' Creates a baseline_term object given a covariate matrix and its associated
#' column and row indices.
#'
#' @param varname The name of the term.
#' @param mat A matrix (or data frame) of covariates.
#' @param colind A list of column indices.
#' @param rowind A list of row indices.
#' @return A baseline_term object.
#' @importFrom tibble as_tibble
#' @noRd
#' @keywords internal
baseline_term <- function(varname, mat, colind, rowind) {
  stopifnot(inherits(mat, "matrix") || is.data.frame(mat) || inherits(mat, "Matrix"))
  ret <- list(varname = varname, 
              design_matrix = suppressMessages(tibble::as_tibble(as.matrix(mat), .name_repair = "minimal")), 
              colind = colind, 
              rowind = rowind)
  class(ret) <- c("baseline_term", "matrix_term", "fmri_term", "list")
  ret
}

#' Design matrix for a baseline term
#'
#' Extract the design matrix from a single baseline term object.
#'
#' @param x A `baseline_term` object.
#' @param blockid Optional block identifier to subset rows.
#' @param allrows Logical; if `TRUE`, return all rows for the selected block.
#' @param ... Additional arguments (currently unused).
#' @return A tibble containing baseline regressors.
#' @examples
#' sframe <- sampling_frame(blocklens = 10, TR = 1)
#' bmod <- baseline_model(sframe = sframe)
#' dm <- design_matrix(baseline_terms(bmod)$drift)
#' @export
design_matrix.baseline_term <- function(x, blockid = NULL, allrows = FALSE, ...) {
  if (is.null(blockid)) {
    x$design_matrix
  } else {
    if (!allrows) {
      x$design_matrix[unlist(x$rowind[blockid]), unlist(x$colind[blockid]), drop = FALSE]
    } else {
      x$design_matrix[, unlist(x$colind[blockid]), drop = FALSE]
    }
  }
}

#' @export
conditions.baseline_term <- function(x, ...) {
  colnames(x$design_matrix)
}

#' Construct a Block Term.
#'
#' Constructs a constant block intercept term based on block IDs.
#'
#' @param vname The name of the block variable.
#' @param sframe A sampling_frame object.
#' @param intercept Type of intercept ("global" or "runwise").
#' @return A block_term object.
#' @noRd
construct_block_term <- function(vname, sframe, intercept = c("global", "runwise")) {
  intercept <- match.arg(intercept)
  blockids_vec <- blockids(sframe)
  blockord <- sort(unique(blockids_vec))
  n_total_scans <- length(blockids_vec)
  n_blocks <- length(blockord)
  
  if (n_blocks == 1 || intercept == "global") {
    # Simple global intercept: single column of 1s
    mat <- matrix(1, nrow = n_total_scans, ncol = 1)
    cnames <- paste0(vname, "_global")
    colnames(mat) <- cnames
    colind <- list(1)
    rowind <- list(1:n_total_scans)
  } else {
    # Runwise intercept: use model.matrix once
    # Create the factor directly for model.matrix
    expanded_blockids_fac <- factor(blockids_vec, levels = blockord) 
    mat <- model.matrix(~ expanded_blockids_fac - 1)
    cnames <- paste0(vname, "_", blockord)
    colnames(mat) <- cnames
    # colind and rowind reflect the block structure
    colind <- as.list(1:n_blocks) 
    rowind <- split(1:n_total_scans, blockids_vec)
  }
  
  # Use baseline_term constructor directly
  baseline_term(vname, mat, colind, rowind) 
}

#' @noRd
term_names.baseline_model <- function(x) {
  xt <- terms(x)
  unlist(lapply(xt, function(term) term$varname))
}

#' Create a Nuisance Specification
#'
#' Returns a nuisance term specification from a numeric matrix.
#'
#' @param x A matrix.
#' @return An object of class "nuisancespec".
#' @examples
#' mat <- matrix(rnorm(10), nrow = 5)
#' nuisance(mat)
#' @export
nuisance <- function(x) {
  varname <- substitute(x)
  ret <- list(name = varname)
  class(ret) <- "nuisancespec"
  ret
}

#' @export
construct.nuisancespec <- function(x, model_spec, ...) {
  expr <- rlang::parse_expr(as.character(x$varname))
  mat <- rlang::eval_tidy(expr, data = model_spec$aux_data, env = parent.frame())
  matrix_term(x$name, mat)
}

#' @export
construct.blockspec <- function(x, model_spec, ...) {
  construct_block_term(x$name, model_spec$sampling_frame)
}


## ============================================================================
## Section 4: Print and Plot Methods for Baseline Models
## ============================================================================

#' Print a Baseline Model
#'
#' Displays key information about the baseline model components and a preview
#' of the design matrix.
#'
#' @param x A baseline_model object.
#' @param ... Additional arguments (ignored).
#' @return The input object, invisibly.
#' @examples
#' sframe <- sampling_frame(blocklens = 5, TR = 1)
#' bmod <- baseline_model(sframe = sframe)
#' print(bmod)
#' @export
#' @rdname print
print.baseline_model <- function(x, ...) {
  # Extract component information using helper
  drift_cols <- .nz(x$terms$drift)
  const_cols <- .nz(x$terms$block)
  nuis_cols  <- .nz(x$terms$nuisance)
  total_cols <- sum(drift_cols, const_cols, nuis_cols) # Summing is safer now
  
  # Get drift spec details (assuming drift_spec is still stored, adjust if removed)
  basis_type <- if (!is.null(x$drift_spec)) x$drift_spec$basis else "N/A"
  degree     <- if (!is.null(x$drift_spec)) x$drift_spec$degree else "N/A"
  drift_name <- if (!is.null(x$terms$drift)) x$terms$drift$varname else "N/A"
  
  # Print header.
  cat("╔══════════════════════════════════════════╗\n")
  cat("║           Baseline Model                 ║\n")
  cat("╠══════════════════════════════════════════╣\n")
  
  # Drift term info.
  if (drift_cols > 0) {
      cat("║ Drift Components                         ║\n")
      cat(sprintf("║   • %-35s ║\n", paste("Name:", drift_name)))
      cat(sprintf("║   • %-35s ║\n", paste("Basis type:", basis_type)))
      cat(sprintf("║   • %-35s ║\n", paste("Degree:", degree)))
      cat(sprintf("║   • %-35s ║\n", paste("Drift columns:", drift_cols)))
  }
  
  # Additional components.
  # Use correct number of spaces (42) for blank lines
  cat("║                                          ║\n") 
  cat("║ Additional Components                    ║\n")
  cat(sprintf("║   • %-35s ║\n", paste("Constant columns:", const_cols)))
  cat(sprintf("║   • %-35s ║\n", paste("Nuisance columns:", nuis_cols)))
  
  # Summary.
  cat("║                                          ║\n") # Blank line
  cat("║ Model Summary                            ║\n")
  cat(sprintf("║   • %-35s ║\n", paste("Total columns:", total_cols)))
  
  # Preview design matrix.
  cat("║                                          ║\n") # Blank line
  cat("║ Design Matrix Preview                    ║\n")
  if (total_cols > 0) {
      dm <- head(design_matrix(x), 3)
      for (i in 1:min(3, nrow(dm))) {
        row_preview <- paste(sprintf("%6.3f", as.numeric(dm[i, 1:min(4, ncol(dm))])), collapse = " ")
        if (ncol(dm) > 4) row_preview <- paste0(row_preview, " ...")
        # Adjust padding to 37 for design matrix preview lines
        cat(sprintf("║   %-37s ║\n", row_preview)) 
      }
      # Adjust padding for '...' line
      if (nrow(dm) > 3) cat("║   ...                                    ║\n") 
  } else {
      # Adjust padding for 'no terms' line
      cat("║   (No baseline terms in model)           ║\n") 
  }
  
  cat("╚══════════════════════════════════════════╝\n")
}

#' Plot a Baseline Model
#'
#' Creates a detailed ggplot2 visualization of the baseline model design matrix.
#' Each non-constant term is plotted over time. The plot includes separate panels
#' for each block and supports customization of titles, axis labels, line size, and color palette.
#'
#' @param x A baseline_model object.
#' @param term_name Optional term name (a character string) specifying which term to plot.
#'   If omitted, the first non-constant term is plotted.
#' @param title Optional title for the plot. If not provided, a default title is generated.
#' @param xlab Label for the x-axis (default: "Time").
#' @param ylab Label for the y-axis (default: "Design Matrix Value").
#' @param line_size Numeric value for line thickness (default: 1).
#' @param color_palette A palette name for the line colors (default: "Set1").
#' @param ... Additional arguments passed to ggplot2::geom_line.
#' @return A ggplot2 plot object.
#' @examples
#' sframe <- sampling_frame(blocklens = 5, TR = 1)
#' bmod <- baseline_model(sframe = sframe)
#' if (requireNamespace("ggplot2", quietly = TRUE)) plot(bmod)
#'
#' @importFrom ggplot2 ggplot aes_string geom_line facet_wrap labs theme_minimal scale_color_brewer
#' @importFrom tidyr pivot_longer
#' @autoglobal
#' @export
plot.baseline_model <- function(x, term_name = NULL, title = NULL, 
                                xlab = "Time", ylab = "Design Matrix Value",
                                line_size = 1, color_palette = "Set1", ...) {
  # Extract terms and term names from the baseline model using the terms() S3 method
  all_terms <- terms(x)
  if (length(all_terms) == 0) {
      stop("Baseline model contains no terms.")
  }
  term_names <- names(all_terms)
  
  # Remove constant terms from plotting (e.g., block intercept)
  # Need a reliable way to identify constant terms - check varname? Or add a flag?
  # Let's assume terms named "constant" or similar are constant for now.
  # A more robust approach might be needed.
  const_idx <- grep("^constant", term_names, ignore.case = TRUE)
  if (length(const_idx) > 0) {
    plotting_terms <- all_terms[-const_idx]
    plotting_term_names <- term_names[-const_idx]
  } else {
    plotting_terms <- all_terms
    plotting_term_names <- term_names
  }
  
  # Check if any non-constant terms remain.
  if (length(plotting_terms) == 0) {
    stop("No non-constant baseline terms available for plotting.")
  }
  
  # Extract the sampling frame.
  sframe <- x$sampling_frame
  if (is.null(sframe$time) || is.null(sframe$blockids)) {
    stop("The sampling_frame in the baseline model must contain 'time' and 'blockids'.")
  }
  
  # For each term to plot, convert its design matrix into a long-format tibble.
  dflist <- lapply(plotting_terms, function(term) {
    dm <- design_matrix(term) # Get matrix for this specific term
    dm_tib <- suppressMessages(tibble::as_tibble(dm, .name_repair = "check_unique"))
    # Add block and time info - ensure dimensions match!
    if (nrow(dm_tib) != length(sframe$blockids)) {
        stop(paste("Row mismatch between design matrix for term", term$varname, "and sampling frame."))
    }
    dm_tib$.block <- sframe$blockids
    dm_tib$.time <- sframe$time
    tidyr::pivot_longer(dm_tib, cols = -c(.time, .block),
                        names_to = "condition", values_to = "value")
  })
  names(dflist) <- plotting_term_names
  
  # Select the term to plot, allowing for partial matching against plottable terms.
  if (is.null(term_name)) {
    plot_term_idx <- 1
    plot_term <- plotting_term_names[plot_term_idx]
    message(paste("No term_name specified, plotting the first available non-constant term:", plot_term))
  } else {
    exact_match <- which(plotting_term_names == term_name)
    if (length(exact_match) == 1) {
      plot_term_idx <- exact_match
      plot_term <- plotting_term_names[plot_term_idx]
    } else {
      # Try partial matching if no exact match
      partial_matches <- grep(term_name, plotting_term_names, ignore.case = TRUE)
      if (length(partial_matches) == 1) {
        plot_term_idx <- partial_matches
        plot_term <- plotting_term_names[plot_term_idx]
        message(paste("Found unique partial match for '", term_name, "': using term '", plot_term, "'", sep=""))
      } else if (length(partial_matches) == 0) {
        stop("Specified term_name '", term_name, "' not found among plottable terms. Available: ", 
             paste(plotting_term_names, collapse=", "))
      } else {
        # Multiple partial matches
        stop("Specified term_name '", term_name, "' matches multiple terms: ", 
             paste(plotting_term_names[partial_matches], collapse=", "), ". Please be more specific.")
      }
    }
  }
  
  # Get the data for the selected term
  dfx <- dflist[[plot_term]]
  n_cond <- length(unique(dfx$condition))
  
  # Define scale function outside the pipe
  scale_fn <- if (n_cond > 9) { 
                  ggplot2::scale_color_viridis_d 
              } else { 
                  function(...) ggplot2::scale_color_brewer(palette = color_palette, ...) 
              }
  
  # Create the ggplot.
  p <- ggplot2::ggplot(dfx, ggplot2::aes_string(x = ".time", y = "value", colour = "condition")) +
    ggplot2::geom_line(size = line_size, ...) +
    ggplot2::facet_wrap(~ .block, ncol = 1, scales = "free_x") + # Use scales="free_x"
    ggplot2::labs(title = if (!is.null(title)) title else paste("Baseline Model:", plot_term),
                  x = xlab, y = ylab, colour = "Condition") +
    scale_fn() + # Apply the chosen scale function
    ggplot2::theme_minimal(base_size = 14) +
    ggplot2::theme(legend.position = "bottom",
                   plot.title = ggplot2::element_text(face = "bold", hjust = 0.5),
                   axis.title = ggplot2::element_text(face = "bold"))
  
  p
}

#' correlation_map.baseline_model
#'
#' @description
#' Generates a correlation heatmap of the columns in a \code{baseline_model}'s design matrix.
#'
#' @param x A \code{baseline_model}.
#' @param method Correlation method (e.g., "pearson", "spearman").
#' @param half_matrix Logical; if TRUE, display only the lower triangle of the matrix.
#' @param absolute_limits Logical; if TRUE, set color scale limits from -1 to 1.
#' @param ... Additional arguments passed to internal plotting functions.
#' @return A ggplot2 plot object.
#' @examples
#' sframe <- sampling_frame(blocklens = 5, TR = 1)
#' bmod <- baseline_model(sframe = sframe)
#' if (requireNamespace("ggplot2", quietly = TRUE)) correlation_map(bmod)
#' @export
correlation_map.baseline_model <- function(x,
                                           method          = c("pearson", "spearman"),
                                           half_matrix     = FALSE,
                                           absolute_limits = TRUE,
                                           ...) {
  DM <- as.matrix(design_matrix(x))
  .correlation_map_common(DM, method=method, half_matrix=half_matrix,
                          absolute_limits=absolute_limits, ...)
}


#' Heatmap visualization of the baseline_model design matrix
#'
#' @description
#' Produces a heatmap of all columns in the design matrix for a `baseline_model` object,
#' with rows corresponding to scans and columns corresponding to regressors. By default,
#' it draws horizontal lines separating runs (blocks), and rotates the column labels diagonally.
#'
#' @param x A `baseline_model` object.
#' @param block_separators Logical; if `TRUE`, draw white horizontal lines between blocks.
#' @param rotate_x_text Logical; if `TRUE`, rotate x-axis labels by 45 degrees.
#' @param fill_midpoint Numeric or `NULL`; if not `NULL`, used as the `midpoint` in
#'   [ggplot2::scale_fill_gradient2()] to center the color scale (for example at 0).
#' @param fill_limits Numeric vector of length 2 or `NULL`; passed to the fill scale
#'   `limits` argument. Can clip or expand the color range.
#' @param ... Additional arguments forwarded to [ggplot2::geom_tile()].
#'
#' @import ggplot2
#' @importFrom tibble as_tibble
#' @importFrom tidyr pivot_longer
#' @return A ggplot2 plot object.
#' @examples
#' sframe <- sampling_frame(blocklens = 5, TR = 1)
#' bmod <- baseline_model(sframe = sframe)
#' if (requireNamespace("ggplot2", quietly = TRUE)) design_map(bmod)
#' @export
design_map.baseline_model <- function(x,
                                      block_separators = TRUE,
                                      rotate_x_text    = TRUE,
                                      fill_midpoint    = NULL,
                                      fill_limits      = NULL,
                                      ...) {
  # 1) Extract the design matrix
  DM <- design_matrix(x)
  n_scans <- nrow(DM)
  
  # 2) Convert to long format
  df_long <- tibble::as_tibble(DM, .name_repair = "unique")
  df_long$scan_number <- seq_len(n_scans)
  df_long <- tidyr::pivot_longer(
    df_long,
    cols      = -scan_number,
    names_to  = "Regressor",
    values_to = "Value"
  )
  
  # 3) Build the base ggplot
  plt <- ggplot(df_long, aes(x = Regressor, y = scan_number, fill = Value)) +
    geom_tile(...)
  
  # 4) Reverse the y-axis so that scan #1 is at top
  plt <- plt + scale_y_reverse()
  
  # 5) Decide on color scale
  #    - If fill_midpoint is set, use scale_fill_gradient2 to center the scale
  #    - Otherwise, use a default 3-color gradient
  if (is.null(fill_midpoint)) {
    plt <- plt + scale_fill_gradientn(
      colours = c("navy", "white", "firebrick"),
      limits  = fill_limits
    )
  } else {
    plt <- plt + scale_fill_gradient2(
      midpoint = fill_midpoint,
      low      = "navy",
      mid      = "white",
      high     = "firebrick",
      limits   = fill_limits
    )
  }
  
  # 6) Optionally draw white horizontal lines to separate blocks
  sframe <- x$sampling_frame
  if (block_separators && !is.null(sframe$blockids)) {
    block_ids  <- sframe$blockids
    run_info   <- rle(block_ids)             # lengths of each block
    row_breaks <- cumsum(run_info$lengths)   # boundary after each block
    ncols      <- ncol(DM)
    
    # Add horizontal lines
    for (rb in row_breaks[-length(row_breaks)]) {
      plt <- plt + 
        annotate("segment",
                 x    = 0.5,
                 xend = ncols + 0.5,
                 y    = rb + 0.5,
                 yend = rb + 0.5,
                 color = "white", size = 1)
    }
  }
  
  # 7) Clean up theme
  plt <- plt + 
    theme_minimal(base_size = 14) +
    labs(x = "Regressors", y = "Scan Number", fill = "Value") +
    theme(
      panel.grid  = element_blank(),
      axis.text.x = if (rotate_x_text) element_text(angle = 45, hjust = 1) else element_text()
    )
  
  plt
}


## ============================================================================
## Section 5: End of File
###############################################################################
</file>

<file path="R/contrast.R">
#' Translate legacy contrast regex patterns
#'
#' Convert older column-naming patterns to the current naming scheme.
#'
#' @param pattern Character string with the legacy regex.
#' @return Updated regex string.
#' @keywords internal
#' @export
#' @name translate_legacy_pattern
#' @rdname translate_legacy_pattern

translate_legacy_pattern <- function(pattern) {
  # 1. Replace Var[Level] -> Var.Level (Do this first)
  # Handles VarName[LevelName] -> VarName.LevelName
  pattern <- gsub("([A-Za-z0-9_\\.]+)\\[([^]]+)\\]", "\\1.\\2", pattern, perl = TRUE)

  # 2. Replace :basis[digits] -> _b<digits>
  # Handles :basis[3] -> _b3
  #pattern <- gsub(":basis\\[(\\d+)\\]", "_b\\1", pattern, perl = TRUE) # CORRECTED LINE
  pattern <- gsub(":basis\\[(\\d+)\\](\\$?)$", "_b\\1\\2", pattern, perl = TRUE)
  # 3. Replace standalone : -> _ (interaction separator)
  # Uses lookarounds to avoid replacing potential future :: syntax
  pattern <- gsub("(?<!:):(?!:)", "_", pattern, perl = TRUE)
  
  pattern
}

#' Get condition names for a term
#' Wraps conditions() with standard arguments for internal use.
#' @param term An event_term object.
#' @param expanded Logical, whether to return basis-expanded names.
#' @return Character vector of condition names.
#' @keywords internal
#' @noRd
.condnames <- function(term, expanded = TRUE) {
  # Assumes conditions() is robust and handles drop.empty=FALSE internally
  tryCatch(conditions(term, drop.empty = FALSE, expand_basis = expanded),
           error = function(e) {
             stop(paste("Error retrieving condition names for term '", 
                        term$varname %||% "<unknown>", # Use varname if available
                        "' (expanded=", expanded, "): ", e$message), call. = FALSE)
           })
}

#' Calculate contrast weights from logical masks
#' Returns a *named* numeric vector.
#' @param names Character vector of all condition names.
#' @param A_mask Logical vector (same length as names) indicating TRUE for conditions in group A.
#' @param B_mask Logical vector (same length as names) indicating TRUE for conditions in group B. Optional.
#' @param tol Tolerance for sum-to-zero check.
#' @return Named numeric vector of weights.
#' @keywords internal
#' @noRd
.mask_to_weights <- function(names, A_mask, B_mask = NULL, tol = 1e-8) {
  # Input validation
  stopifnot(is.character(names)) # names can be empty if upstream condnames is empty, but length checks handle this.
  stopifnot(is.logical(A_mask), length(A_mask) == length(names))
  
  nA <- sum(A_mask)
  nB <- 0 # Initialize nB for the case where B_mask is NULL

  if (!is.null(B_mask)) {
    stopifnot(is.logical(B_mask), length(B_mask) == length(names))
    if (any(A_mask & B_mask)) {
      stop(".mask_to_weights: Masks for group A and group B overlap.", call. = FALSE)
    }
    nB <- sum(B_mask)
  }

  # Check for completely empty selection: this should be an error.
  if (nA == 0 && (is.null(B_mask) || nB == 0)) {
    stop("Cannot calculate contrast weights: No conditions were selected by the provided mask(s). This usually indicates that the patterns or formulas used to define the contrast did not match any existing conditions. Please check your contrast specification.", call. = FALSE)
  }

  # Initialize weights vector
  w <- numeric(length(names))
  if (length(names) > 0) { # Only assign names if 'names' is not empty
      names(w) <- names
  }
  
  # Assign weights if masks are not empty
  if (nA > 0) {
    w[A_mask] <- 1 / nA
  }
  # Ensure B_mask is not NULL before checking nB for assignment
  if (!is.null(B_mask) && nB > 0) {
    w[B_mask] <- -1 / nB
  }
  
  # Warnings for partially defined A-vs-B contrasts (that won't sum to zero as expected)
  if (!is.null(B_mask)) { # These warnings only make sense for A-vs-B type contrasts
    if (nA == 0 && nB > 0) { # A empty, B not (and B_mask was provided)
      warning(".mask_to_weights: For A-vs-B contrast, Mask A is empty but Mask B is not. Weights will not sum to zero as expected for a balanced comparison.", call. = FALSE)
    } else if (nB == 0 && nA > 0) { # B empty, A not (and B_mask was provided)
      warning(".mask_to_weights: For A-vs-B contrast, Mask B is empty but Mask A is not. Weights will not sum to zero as expected for a balanced comparison.", call. = FALSE)
    } else if (nA > 0 && nB > 0) { # Both A and B are defined and non-empty for A-vs-B
        if (abs(sum(w)) > tol) {
           # This scenario (both non-empty, but sum != 0) should be rare with 1/nA and -1/nB
           warning(".mask_to_weights: Weights for A-vs-B contrast (both groups non-empty) do not sum to zero (Sum: ", sum(w), "). This is unexpected.", call. = FALSE)
        }
    }
  } 
  # If B_mask is NULL (single group contrast, e.g. from unit_contrast or pattern_A only column_contrast):
  # - If nA == 0, we would have errored out above.
  # - If nA > 0, weights are 1/nA for A_mask elements. Sum-to-zero is not expected here. No warning needed.
  
  w
}

#' Robust weight calculation using logical masks
#' Returns a *named* numeric vector (names are condition names)
#' @keywords internal
# makeWeights <- function(keepA, keepB=NULL) {
#   weights <- matrix(0, length(keepA), 1)
#   numA <- sum(keepA)
#   weights[keepA,1] <- rep(1/numA, numA)
#   
#   if (!is.null(keepB)) {
#     numB <- sum(keepB)
#     weights[keepB,1] <- -rep(1/numB, numB)
#   }
#   
#   weights
# }

#' Robust weight calculation using logical masks
#' Returns a *named* numeric vector (names are condition names)
#' @keywords internal
#' @noRd
.make_weights <- function(cond_names, mask_A, mask_B = NULL) {
  # Check inputs
  stopifnot(length(cond_names) == length(mask_A))
  stopifnot(is.logical(mask_A))
  if (!is.null(mask_B)) {
      stopifnot(length(cond_names) == length(mask_B))
      stopifnot(is.logical(mask_B))
      # Ensure no overlap between A and B masks
      if (any(mask_A & mask_B)) {
          stop(".make_weights: Masks A and B overlap.", call. = FALSE)
      }
  }
  
  w <- numeric(length(mask_A))
  names(w) <- cond_names
  
  numA <- sum(mask_A)
  if (numA > 0) {
      w[mask_A] <-  1 / numA
  }
  
  if (!is.null(mask_B)) {
    numB <- sum(mask_B)
    if (numB > 0) {
        w[mask_B] <- -1 / numB
    } 
  }
  
  # Handle cases where one mask is empty (weights should still sum to 0)
  if (numA == 0 && !is.null(mask_B) && numB > 0) {
      warning(".make_weights: Mask A is empty but Mask B is not. Weights will not sum to zero.", call. = FALSE)
  } else if (numB == 0 && !is.null(mask_B) && numA > 0) {
       warning(".make_weights: Mask B is empty but Mask A is not. Weights will not sum to zero.", call. = FALSE)
  } else if (numA == 0 && (is.null(mask_B) || numB == 0)) {
       warning(".make_weights: Both masks A and B are empty.", call. = FALSE)
  }
  
  w
}


#' Get Indices of Design Matrix Columns Matching a Pattern
#'
#' Retrieves the full list of potential design matrix column names for an
#' event_term (using `conditions(term, drop.empty = FALSE)`) and returns the
#' numeric indices of columns whose names match the provided regex pattern.
#' Handles translation of legacy patterns for backward compatibility.
#'
#' @param term An object of class `event_term`.
#' @param pattern A character string containing a regular expression (can use legacy syntax).
#' @param ... Additional arguments passed to `grep()`.
#' @return An integer vector of the indices of matching column names.
#'         Returns `integer(0)` if no names match or if the term has no conditions.
#' @keywords internal
#' @noRd
.col_index <- function(term, pattern, ...) {
  
  # --- Removed legacy pattern translation block ---
  
  # Ensure conditions function is available (Should be implicitly available if package loaded)
  # if (!exists("conditions") || !is.function(conditions)) {
  #     stop(".col_index requires the 'conditions' function.")
  # }
  
  # --- Removed duplicated basis expansion logic --- 
  # The caller should decide if expanded names are needed and pass them or call conditions appropriately.
  # For now, assume the core use case (column_contrast) needs expanded names.
  # TODO: Refactor later to use a condnames() helper or accept names directly.
  expand_basis <- TRUE # Default assumption for now, needs refinement
  hrfspec <- attr(term, "hrfspec")
  if (!is.null(hrfspec) && !is.null(hrfspec$hrf)) {
    hrf_fun <- hrfspec$hrf
    # Check nbasis generic exists and is applicable
    # We still need to know if *any* expansion is possible for the default
    if (exists("nbasis") && is.function(nbasis) && !inherits(try(nbasis(hrf_fun), silent=TRUE), "try-error") && nbasis(hrf_fun) > 1) { 
      # Expansion is possible, keep expand_basis = TRUE
    } else {
      expand_basis <- FALSE # No basis functions or only 1
    }
  } else {
     expand_basis <- FALSE # No HRF spec
  }

  # Get all potential column names (expanded or not)
  # Assume conditions() is robust and will stop() on genuine error
  all_colnames <- conditions(term, drop.empty = FALSE, expand_basis = expand_basis)

  # --- Removed try() wrapper and error check --- 
  # if (inherits(all_colnames, "try-error") || length(all_colnames) == 0) {
  #   # Stop if conditions() failed, return integer(0) if empty result (grep handles this)
  #   stop(paste("Could not retrieve column names via conditions() for term",
  #                 term$varname, "in .col_index.")) 
  # }

  # Perform grep using the pattern directly
  grep(pattern, all_colnames, value = FALSE, ...)
}

#' Contrast Specification
#'
#' @description
#' Define a linear contrast using a formula expression.
#'
#' @param form A formula describing the contrast.
#' @param name A character label for the contrast.
#' @param where An expression defining the subset over which the contrast is applied (default: NULL).
#'
#' @return A list containing the contrast specification.
#'
#' @examples
#' # A minus B contrast
#' contrast(~ A - B, name="A_B")
#'
#' @export
contrast <- function(form, name, where=NULL) {
  assert_that(rlang::is_formula(form))
  if (!is.null(where)) {
    assert_that(rlang::is_formula(where))
  }
  ret <- list(A=form,
              B=NULL,
              where=where,
              name=name)
  
  class(ret) <- c("contrast_formula_spec", "contrast_spec", "list")
  ret
  
}

#' Unit Contrast
#'
#' @description
#' Construct a contrast that sums to 1 and is used to define contrasts against the baseline.
#'
#' @param A A formula representing the contrast expression.
#' @param name A character string specifying the name of the contrast.
#' @param where An optional formula specifying the subset of conditions to apply the contrast to.
#'
#' @return A unit_contrast_spec object containing the contrast that sums to 1.
#'
#' @examples
#' con <- unit_contrast(~ Face, name="Main_face")
#'
#' @export
unit_contrast <- function(A, name, where=NULL) {
  assert_that(rlang::is_formula(A)) 
  
  if (!is.null(where)) {
    assert_that(rlang::is_formula(where))
  }
  
  structure(
    list(A=A,
         B=NULL,
         where=where,
         name=name),
    class=c("unit_contrast_spec", "contrast_spec", "list")
  )
  
}

#' One Against All Contrast
#'
#' @description
#' Construct contrasts comparing each factor level against the average of the other levels.
#'
#' @param levels A vector of factor levels to be compared.
#' @param facname A character string specifying the name of the factor containing the supplied levels.
#' @param where An optional formula specifying the subset over which the contrast is computed.
#'
#' @return A contrast_set object containing contrasts comparing each factor level against the average of the other levels.
#'
#' @examples
#' fac <- factor(rep(c("A", "B", "C"), 2))
#' con <- one_against_all_contrast(levels(fac), "fac")
#'
#' @export
one_against_all_contrast <- function(levels, facname, where=NULL) {
  if (!is.null(where)) {
    assert_that(rlang::is_formula(where))
  }
  
  ret <- lapply(1:length(levels), function(i) {
    lev1 <- levels[i]
    levother <- levels[-i]
    pair_contrast(as.formula(paste("~", facname, " == ", paste0('"', lev1, '"'))), 
                  as.formula(paste0("~", facname, "!= ", paste0('"', lev1, '"'))), 
                  where=where, name=paste0("con_", lev1, "_vs_", "other"))
  })
  
  do.call(contrast_set, ret)
  
}


#' Create a Set of Contrasts
#'
#' @description
#' Construct a list of contrast_spec objects.
#'
#' @param ... A variable-length list of contrast_spec objects.
#'
#' @return A list of contrast_spec objects with class "contrast_set".
#'
#' @examples
#' c1 <- contrast(~ A - B, name="A_B")
#' c2 <- contrast(~ B - C, name="B_C")
#' contrast_set(c1,c2)
#'
#' @export
#' @import assertthat
#' @importFrom purrr map_lgl
contrast_set <- function(...) {
  ret <- list(...)
  assertthat::assert_that(all(purrr::map_lgl(ret, inherits, "contrast_spec")))
  class(ret) <- c("contrast_set", "list")
  ret
}


#' Pairwise Contrasts
#'
#' @description
#' Construct pairwise contrasts for all combinations of factor levels.
#'
#' @param levels A vector of factor levels to be compared.
#' @param facname The name of the factor variable (column name in the design) these levels belong to.
#' @param where An optional formula specifying the subset over which the contrast is computed.
#' @param name_prefix A character string to prefix the generated contrast names (default: "con").
#'
#' @return A contrast_set object containing pairwise contrasts for all combinations of factor levels.
#'
#' @examples
#' # Assuming 'my_factor' is a column name
#' pairwise_contrasts(c("A", "B", "C"), facname = "my_factor")
#' pairwise_contrasts(c("A", "B", "C"), facname = "my_factor", name_prefix = "pair")
#'
#' @export
#' @importFrom utils combn
pairwise_contrasts <- function(levels, facname, where=NULL, name_prefix = "con") {
  assert_that(is.character(facname), length(facname) == 1, msg = "'facname' must be a single string.")
  if (!is.null(where)) {
    assert_that(rlang::is_formula(where))
  }
  
  if (length(levels) < 2) {
    stop("pairwise_contrasts requires at least two levels.")
  }
  
  cbns <- combn(length(levels), 2)
  ret <- lapply(1:ncol(cbns), function(i) {
    lev1 <- levels[cbns[1,i]]
    lev2 <- levels[cbns[2,i]]
    # Construct formulas using the factor name
    formula_A <- as.formula(paste("~", facname, "==", paste0('"', lev1, '"')))
    formula_B <- as.formula(paste("~", facname, "==", paste0('"', lev2, '"')))
    pair_contrast(formula_A, formula_B, 
                  where=where, name=paste0(name_prefix, "_", lev1, "_", lev2))
  })
  
  do.call(contrast_set, ret)
}




#' Pair Contrast
#'
#' @description
#' Construct a sum-to-zero contrast between two logical expressions. This function is
#' particularly useful for comparing specific conditions or combinations of conditions.
#'
#' @param A A formula representing the first logical expression in the contrast.
#' @param B A formula representing the second logical expression in the contrast.
#' @param name A character string specifying the name of the contrast (mandatory).
#' @param where An optional formula specifying the subset over which the contrast is computed.
#'
#' @return A pair_contrast_spec object containing:
#'   \item{A}{First logical expression}
#'   \item{B}{Second logical expression}
#'   \item{where}{Subsetting formula (if provided)}
#'   \item{name}{Contrast name}
#'
#' @details
#' The contrast is constructed as (A - B), where A and B are logical expressions that
#' evaluate to TRUE/FALSE for each observation. The resulting contrast weights sum to zero.
#'
#' @examples
#' # Compare faces vs scenes
#' pair_contrast(~ category == "face", ~ category == "scene", name = "face_vs_scene")
#'
#' # Compare with subsetting
#' pair_contrast(~ category == "face", ~ category == "scene",
#'              name = "face_vs_scene_block1",
#'              where = ~ block == 1)
#'
#' @seealso
#' \code{\link{pairwise_contrasts}} for all pairwise comparisons,
#' \code{\link{contrast_set}} for creating sets of contrasts
#'
#' @export
pair_contrast <- function(A, B, name, where = NULL) {
  assert_that(rlang::is_formula(A))
  assert_that(rlang::is_formula(B))
  

  if (!is.null(where)) {
    assert_that(rlang::is_formula(where))
  }
  
  ret <- list(A=A,
              B=B,
              where=where,
              name=name)
    
  class(ret) <- c("pair_contrast_spec", "contrast_spec", "list")
  ret
}


#' One-way Contrast
#'
#' @description
#' Create a one-way contrast specification
#'
#' @param A A formula specifying the contrast
#' @param name The name of the contrast
#' @param where Optional environment for evaluating the formula
#' @return A oneway_contrast_spec object that can be used to generate contrast weights
#' @examples
#' # Create a one-way contrast for a factor 'basis'
#' con <- oneway_contrast(~ basis, name = "Main_basis")
#'
#' # Create a one-way contrast with a specific environment
#' con <- oneway_contrast(~ basis, name = "Main_basis",
#'                       where = new.env())
#'
#' @seealso \code{\link{interaction_contrast}} for testing interactions,
#'          \code{\link{pair_contrast}} for pairwise comparisons
#' @export
oneway_contrast <- function(A, name, where = NULL) {
  assert_that(rlang::is_formula(A)) 
  
  if (!is.null(where)) {
    assert_that(rlang::is_formula(where))
  }
  
  structure(
    list(A=A,
         B=NULL,
         where=where,
         name=name),
    class=c("oneway_contrast_spec", "contrast_spec", "list")
  )
}

#' Interaction Contrast
#'
#' @description
#' Create an interaction contrast specification
#'
#' @param A A formula specifying the interaction contrast
#' @param name The name of the contrast
#' @param where Optional environment for evaluating the formula
#' @return An interaction_contrast_spec object containing the specification for
#'         generating interaction contrast weights
#' @examples
#' # Create an interaction contrast for factors A and B
#' con <- interaction_contrast(~ A * B, name = "A_by_B")
#'
#' # Create an interaction contrast with a specific environment
#' con <- interaction_contrast(~ A * B, name = "A_by_B",
#'                           where = new.env())
#'
#' @seealso \code{\link{oneway_contrast}} for main effects,
#'          \code{\link{pair_contrast}} for pairwise comparisons
#' @export
interaction_contrast <- function(A, name, where = NULL) {
  assert_that(rlang::is_formula(A)) 
  
  if (!is.null(where)) {
    assert_that(rlang::is_formula(where))
  }
  
  
  
  structure(
    list(A=A,
         B=NULL,
         where=where,
         name=name),
    class=c("interaction_contrast_spec", "contrast_spec", "list")
  )
}

#' Column Contrast Specification
#'
#' @description
#' Define a contrast by directly targeting design matrix columns using regex patterns.
#' This is useful for contrasts involving continuous variables or specific basis functions.
#'
#' @param pattern_A A character string containing a regex pattern to identify the
#'   columns for the positive (+) part of the contrast.
#' @param pattern_B Optional character string containing a regex pattern for the
#'   negative (-) part (for A-B type contrasts). If NULL, creates a contrast testing
#'   the average of columns matching `pattern_A` against baseline (0).
#' @param name A character string name for the contrast (mandatory).
#' @param where Currently unused for column_contrast, but kept for API consistency.
#'
#' @return A `column_contrast_spec` object containing the specification.
#'
#' @details
#' This contrast type operates by finding design matrix columns whose names match
#' the provided patterns (`pattern_A`, `pattern_B`). It calculates weights such that
#' the average effect of the 'A' columns is compared to the average effect of the
#' 'B' columns (or baseline if `pattern_B` is NULL). Weights are assigned as +1/nA
#' for 'A' columns and -1/nB for 'B' columns, ensuring the contrast sums to zero
#' if both A and B groups are present.
#'
#' Use standard R regex syntax for the patterns. Remember to escape special
#' characters (e.g., `\\[`, `\\.`, `\\*`).
#'
#' @examples
#' # Test the main effect of a continuous modulator 'RT'
#' # Assumes RT is a column name, e.g., from columns(Scale(RT))
#' cc1 <- column_contrast(pattern_A = "^z_RT$", name = "Main_RT")
#'
#' # Compare Condition.A vs Condition.B for the 'RT' modulator effect
#' # Assumes condition names like "Condition.A_z_RT", "Condition.B_z_RT"
#' cc2 <- column_contrast(pattern_A = "^Condition\\.A_z_RT$",
#'                        pattern_B = "^Condition\\.B_z_RT$",
#'                        name = "CondA_vs_CondB_for_RT")
#'
#' # Test a specific basis function (e.g., basis spline #3)
#' # Assumes column names like "TermName_Condition.Tag_b03"
#' cc3 <- column_contrast(pattern_A = "_b03$", name = "Basis_3_Effect")
#'
#' @export
column_contrast <- function(pattern_A, pattern_B = NULL, name, where = NULL) {
  assert_that(is.character(pattern_A), length(pattern_A) == 1)
  if (!is.null(pattern_B)) {
    assert_that(is.character(pattern_B), length(pattern_B) == 1)
  }
  assert_that(is.character(name), length(name) == 1)
  if (!is.null(where)) {
      warning("'where' argument is currently ignored for column_contrast.")
      # assert_that(rlang::is_formula(where)) # Keep structure if needed later
  }

  ret <- list(
    pattern_A = pattern_A,
    pattern_B = pattern_B,
    where = where, # Store it even if unused for now
    name = name
  )

  class(ret) <- c("column_contrast_spec", "contrast_spec", "list")
  ret
}

#' Polynomial Contrast
#'
#' @description
#' Create polynomial contrasts for testing trends across ordered factor levels. This is
#' particularly useful for analyzing factors with a natural ordering (e.g., time, dose).
#'
#' @param A A formula specifying the ordered factor.
#' @param name A character string identifying the contrast.
#' @param where An optional formula for subsetting the data.
#' @param degree An integer specifying the degree of the polynomial (default: 1).
#' @param value_map An optional list mapping factor levels to numeric values.
#'
#' @return A poly_contrast_spec object containing the specification for generating
#'   polynomial contrast weights.
#'
#' @details
#' The function creates orthogonal polynomial contrasts up to the specified degree.
#' These contrasts can test for linear, quadratic, cubic, and higher-order trends
#' in the data. The value_map parameter allows for non-uniform spacing between levels.
#'
#' @examples
#' # Linear trend across time points
#' pcon <- poly_contrast(~ time, name = "linear_time", degree = 1)
#'
#' # Cubic trend with custom spacing
#' pcon <- poly_contrast(~ dose, name = "dose_cubic",
#'                      degree = 3,
#'                      value_map = list("low" = 0, "med" = 2, "high" = 5))
#'
#' @seealso
#' \code{\link{oneway_contrast}} for categorical contrasts,
#' \code{\link{interaction_contrast}} for interaction effects
#'
#' @export
poly_contrast <- function(A, name, where = NULL, degree = 1, value_map = NULL) {
  assert_that(rlang::is_formula(A))
  
  if (!is.null(where)) {
    assert_that(rlang::is_formula(where))
  }

  ret <- list(
    A=A,
    B=NULL,
    where=where,
    degree=degree,
    value_map=value_map,
    name=name)
  
  class(ret) <- c("poly_contrast_spec", "contrast_spec", "list")
  ret
}

#' Unit Contrast Weights
#'
#' @description
#' Compute the contrast weights for a unit_contrast_spec object.
#'
#' @param x A unit_contrast_spec object.
#' @param term A term object.
#' @param ... Additional arguments (currently unused).
#'
#' @return A list containing the term, name, weights, condition names, and contrast specification.
#'
#' @export
contrast_weights.unit_contrast_spec <- function(x, term,...) {
  # Get cells (categorical only)
  term_cells <- cells(term)
  if (nrow(term_cells) == 0) {
       warning(paste("Contrast '", x$name, "': Term '", term$varname, "' has no categorical cells."), call. = FALSE)
       weights_out <- matrix(numeric(0), nrow = 0, ncol = 1)
       colnames(weights_out) <- x$name
       cell_names_out <- character(0)
  } else {
      # Apply 'where' clause
      keep <- if (!is.null(x$where)) {
        tryCatch(rlang::eval_tidy(rlang::f_rhs(x$where), data = term_cells), error = function(e) {
            warning(paste("Contrast '", x$name, "': Error evaluating 'where' clause: ", e$message), call. = FALSE)
            rep(FALSE, nrow(term_cells))
        })
      } else {
        rep(TRUE, nrow(term_cells))
      }
      
      relevant_cells <- term_cells[keep, , drop = FALSE]
      
      if (nrow(relevant_cells) == 0) {
          warning(paste("Contrast '", x$name, "' resulted in no relevant cells after applying the 'where' clause."), call. = FALSE)
          weights_out <- matrix(numeric(0), nrow = 0, ncol = 1)
          colnames(weights_out) <- x$name
          cell_names_out <- character(0)
      } else {
          # For unit_contrast, the formula A usually defines the set of cells to be averaged.
          # All cells within relevant_cells that are targeted by the formula should get a weight.
          # If x$A is ~MyFactor, all levels of MyFactor in relevant_cells are included.
          # Thus, keepA_rel should be TRUE for all rows in relevant_cells. 
          # If x$A is a logical expression, eval_tidy would handle it, but for unit_contrast 
          # the simple case implies averaging all specified cells.
          
          # The original eval_tidy might not be appropriate if x$A is just a variable name.
          # keepA_rel <- tryCatch(rlang::eval_tidy(rlang::f_rhs(x$A), data = relevant_cells), error = function(e) {
          #     warning(paste("Contrast '", x$name, "': Error evaluating formula A: ", e$message), call. = FALSE)
          #     rep(FALSE, nrow(relevant_cells))
          # })
          
          # For unit_contrast, we average all cells identified by the scope. 
          # The formula A in unit_contrast (e.g. ~Face) implicitly means all levels of Face.
          # Therefore, all `relevant_cells` (after `where` clause) should be included in the averaging.
          keepA_rel <- rep(TRUE, nrow(relevant_cells))
          
          # Create unique names/identifiers for the relevant cells
          cell_names_rel <- apply(relevant_cells, 1, paste, collapse = "_")
          
          # Calculate weights - average of cells identified by formula A
          # Use the new .mask_to_weights helper
          weights_rel_named <- .mask_to_weights(names = cell_names_rel, A_mask = keepA_rel, B_mask = NULL) 
          # .make_weights already averages (divides by nA). So weights_rel_named is correct.
          
          # Ensure output is matrix
          weights_out <- matrix(weights_rel_named, ncol = 1)
          rownames(weights_out) <- names(weights_rel_named)
          colnames(weights_out) <- x$name
          cell_names_out <- names(weights_rel_named)
      }
  }

  # Return structure focused on cell-based weights
  ret <- list(
    term=term,
    name=x$name,
    weights=weights_out, # Weights relative to relevant cells
    condnames=cell_names_out, # Names of relevant cells
    contrast_spec=x
  )
  
  class(ret) <- c("unit_contrast", "cell_contrast", "contrast", "list")
  ret
}


#' @export
`-.contrast_spec` <- function(e1, e2, ...){
  assert_that(inherits(e2, "contrast_spec"))
  structure(list(
    name=paste0(e1$name, ":", e2$name),
    con1=e1,
    con2=e2),
    class=c("contrast_diff_spec", "contrast_spec", "list")
  )
}


#' One-way Contrast Weights
#'
#' @description
#' Compute the contrast weights for an oneway_contrast_spec object.
#'
#' @param x An oneway_contrast_spec object.
#' @param term A term object.
#' @param ... Additional arguments (currently unused).
#'
#' @return A list containing the term, name, weights, condition names, and contrast specification.
#'
#' @export
contrast_weights.oneway_contrast_spec <- function(x, term,...) {
  # Get cells (categorical only)
  term_cells <- cells(term)
  if (nrow(term_cells) == 0) {
       warning(paste("Contrast '", x$name, "': Term '", term$varname, "' has no categorical cells."), call. = FALSE)
       weights_out <- matrix(numeric(0), nrow = 0, ncol = 0) # F-contrast, ncol unknown yet
       cell_names_out <- character(0)
  } else { 
      # Apply 'where' clause
      keep <- if (!is.null(x$where)) {
        tryCatch(rlang::eval_tidy(rlang::f_rhs(x$where), data = term_cells), error = function(e) {
            warning(paste("Contrast '", x$name, "': Error evaluating 'where' clause: ", e$message), call. = FALSE)
            rep(FALSE, nrow(term_cells))
        })
      } else {
        rep(TRUE, nrow(term_cells))
      }
      
      relevant_cells <- term_cells[keep, , drop = FALSE]
      
      if (nrow(relevant_cells) == 0) {
          warning(paste("Contrast '", x$name, "' resulted in no relevant cells after applying the 'where' clause."), call. = FALSE)
          weights_out <- matrix(numeric(0), nrow = 0, ncol = 0)
          cell_names_out <- character(0)
      } else {
          # Identify the factor for the main effect
          fac_name <- all.vars(rlang::f_rhs(x$A))
          if (length(fac_name) > 1) {
              warning(paste("Contrast '", x$name, "': one-way contrast has >1 factor specified (", 
                            paste(fac_name, collapse=", "), "), using first: ", fac_name[1]), call.=FALSE)
              fac_name <- fac_name[1]
          }
          if (!(fac_name %in% names(relevant_cells))){
               stop(paste("Contrast '", x$name, "': factor ", fac_name, " not found in relevant cells."), call.=FALSE)
          }
          
          # Generate contrast matrix relative to the levels of the factor in relevant_cells
          # Assuming generate_main_effect_contrast works on the cell structure
          # It should return a matrix where rows correspond to relevant_cells
          cmat <- tryCatch(generate_main_effect_contrast(relevant_cells, fac_name), error = function(e) {
              stop(paste("Contrast '", x$name, "': Error generating main effect contrast for factor ", fac_name, ": ", e$message), call.=FALSE)
          })
          
          # Ensure rownames match cell identifiers (if helper doesn't add them)
          # Create unique names/identifiers for the relevant cells 
          cell_names_rel <- apply(relevant_cells, 1, paste, collapse = "_")
          rownames(cmat) <- cell_names_rel
          colnames(cmat) <- paste(x$name, seq_len(ncol(cmat)), sep="_") # Name F-contrast columns
          
          weights_out <- cmat
          cell_names_out <- cell_names_rel
      }
  }

  # Return structure focused on cell-based weights
  ret <- list(
    term = term,
    name = x$name,
    weights = weights_out, # Weights matrix relative to relevant cells
    condnames = cell_names_out, # Names of relevant cells
    contrast_spec = x
  )
  
  # Classify as Fcontrast if multiple columns, otherwise simple contrast
  base_class <- if(ncol(weights_out) > 1) "Fcontrast" else "contrast"
  class(ret) <- c("oneway_contrast", base_class, "cell_contrast", "contrast", "list")
  ret
}

#' Interaction Contrast Weights
#'
#' @description
#' Compute the contrast weights for an interaction_contrast_spec object.
#'
#' @param x An interaction_contrast_spec object.
#' @param term A term object.
#' @param ... Additional arguments (currently unused).
#'
#' @return A list containing the term, name, weights, condition names, and contrast specification.
#'
#' @export
contrast_weights.interaction_contrast_spec <- function(x, term,...) {
  # Get cells (categorical only)
  term_cells <- cells(term)
  if (nrow(term_cells) == 0) {
       warning(paste("Contrast '", x$name, "': Term '", term$varname, "' has no categorical cells for interaction."), call. = FALSE)
       weights_out <- matrix(numeric(0), nrow = 0, ncol = 0)
       cell_names_out <- character(0)
  } else {
      # Apply 'where' clause
      keep <- if (!is.null(x$where)) {
        tryCatch(rlang::eval_tidy(rlang::f_rhs(x$where), data = term_cells), error = function(e) {
            warning(paste("Contrast '", x$name, "': Error evaluating 'where' clause: ", e$message), call. = FALSE)
            rep(FALSE, nrow(term_cells))
        })
      } else {
        rep(TRUE, nrow(term_cells))
      }
      
      relevant_cells <- term_cells[keep, , drop = FALSE]
      
      if (nrow(relevant_cells) == 0) {
          warning(paste("Contrast '", x$name, "' resulted in no relevant cells after applying the 'where' clause."), call. = FALSE)
          weights_out <- matrix(numeric(0), nrow = 0, ncol = 0)
          cell_names_out <- character(0)
      } else {
          # Identify factors for interaction
          factors <- all.vars(rlang::f_rhs(x$A))
          if (length(factors) < 2) {
              stop(paste("Contrast '", x$name, "': Interaction contrast requires at least two factors."), call.=FALSE)
          }
          if (!all(factors %in% names(relevant_cells))) {
              missing_facs <- factors[!factors %in% names(relevant_cells)]
              stop(paste("Contrast '", x$name, "': Factor(s)", paste(missing_facs, collapse=", "), "not found in relevant cells."), call.=FALSE)
          }
          
          # Generate interaction contrast matrix relative to relevant cells
          # Assuming generate_interaction_contrast works on cell structure
          cmat <- tryCatch(generate_interaction_contrast(relevant_cells, factors), error = function(e) {
              stop(paste("Contrast '", x$name, "': Error generating interaction contrast: ", e$message), call.=FALSE)
          })
          
          # Ensure rownames match cell identifiers
          cell_names_rel <- apply(relevant_cells, 1, paste, collapse = "_")
          rownames(cmat) <- cell_names_rel
          colnames(cmat) <- paste(x$name, seq_len(ncol(cmat)), sep="_") # Name F-contrast columns
          
          weights_out <- cmat
          cell_names_out <- cell_names_rel
      }
  }
  
  # Return structure focused on cell-based weights
  ret <- list(
    term = term,
    name = x$name,
    weights = weights_out, # Weights matrix relative to relevant cells
    condnames = cell_names_out, # Names of relevant cells
    contrast_spec = x
  )
  
  # Classify as Fcontrast (interactions usually are)
  base_class <- if(is.null(ncol(weights_out)) || ncol(weights_out) > 1) "Fcontrast" else "contrast"
  class(ret) <- c("interaction_contrast", base_class, "cell_contrast", "contrast", "list")
  ret
}

#' Polynomial Contrast Weights
#'
#' @description
#' Compute the contrast weights for a poly_contrast_spec object.
#'
#' @param x A poly_contrast_spec object.
#' @param term A term object.
#' @param ... Additional arguments (currently unused).
#'
#' @return A list containing the term, name, weights, condition names, and contrast specification.
#'
#' @export
contrast_weights.poly_contrast_spec <- function(x, term,...) {
  # Get cells (categorical only)
  term_cells <- cells(term)
  if (nrow(term_cells) == 0) {
       warning(paste("Contrast '", x$name, "': Term '", term$varname, "' has no categorical cells for poly contrast."), call. = FALSE)
       weights_out <- matrix(numeric(0), nrow = 0, ncol = x$degree)
       colnames(weights_out) <- paste(x$name, 1:x$degree, sep="_")
       cell_names_out <- character(0)
  } else {
      # Apply 'where' clause
      keep <- if (!is.null(x$where)) {
        tryCatch(rlang::eval_tidy(rlang::f_rhs(x$where), data = term_cells), error = function(e) {
            warning(paste("Contrast '", x$name, "': Error evaluating 'where' clause: ", e$message), call. = FALSE)
            rep(FALSE, nrow(term_cells))
        })
      } else {
        rep(TRUE, nrow(term_cells))
      }
      
      relevant_cells <- term_cells[keep, , drop = FALSE]

      if (nrow(relevant_cells) == 0) {
          warning(paste("Contrast '", x$name, "' resulted in no relevant cells after applying the 'where' clause."), call. = FALSE)
          weights_out <- matrix(numeric(0), nrow = 0, ncol = x$degree)
          colnames(weights_out) <- paste(x$name, 1:x$degree, sep="_")
          cell_names_out <- character(0)
      } else {
          # Evaluate the formula A on relevant cells to get the factor levels
          vals_fac <- tryCatch(rlang::eval_tidy(rlang::f_rhs(x$A), data = relevant_cells), error = function(e) {
              stop(paste("Contrast '", x$name, "': Error evaluating formula A: ", e$message), call.=FALSE)
          })
          
          # Convert factor levels to numeric values (using value_map or direct coercion)
          vals_num <- if (is.null(x$value_map)) {
              tryCatch(as.numeric(as.character(vals_fac)), warning = function(w){
                  stop(paste("Contrast '", x$name, "': Cannot coerce factor levels from formula A to numeric for poly contrast. Use value_map? Error: ", w$message), call.=FALSE)
              })
          } else {
              mapped_vals <- x$value_map[as.character(vals_fac)]
              if(anyNA(mapped_vals) || length(mapped_vals) != length(vals_fac)){
                  stop(paste("Contrast '", x$name, "': value_map does not cover all factor levels present in relevant cells."), call.=FALSE)
              }
              unlist(mapped_vals)
          }
          
          # Check for sufficient unique points for the polynomial degree
          if (length(unique(vals_num)) <= x$degree) {
               stop(paste("Contrast '", x$name, "': Polynomial degree (", x$degree, 
                           ") is too high for the number of unique points (", length(unique(vals_num)), ") in relevant cells."), call.=FALSE)
          }

          # Calculate orthogonal polynomial weights relative to relevant cells
          pvals_mat <- tryCatch(stats::poly(vals_num, degree = x$degree), error = function(e){
               stop(paste("Contrast '", x$name, "': Error calculating polynomial weights: ", e$message), call.=FALSE)
          })
          
          # Create unique names/identifiers for the relevant cells 
          cell_names_rel <- apply(relevant_cells, 1, paste, collapse = "_")
          rownames(pvals_mat) <- cell_names_rel
          colnames(pvals_mat) <- paste(x$name, 1:x$degree, sep="_")
          
          weights_out <- pvals_mat
          cell_names_out <- cell_names_rel
      }
  }
  
  # Return structure focused on cell-based weights
  ret <- list(
    term = term,
    name = x$name,
    weights = weights_out, # Weights matrix relative to relevant cells
    condnames = cell_names_out, # Names of relevant cells
    contrast_spec = x
  )
  
  # Classify as Fcontrast (poly usually has multiple columns)
  base_class <- if(is.null(ncol(weights_out)) || ncol(weights_out) > 1) "Fcontrast" else "contrast"
  class(ret) <- c("poly_contrast", base_class, "cell_contrast", "contrast", "list")
  ret
}

#' Pair Contrast Weights
#'
#' @description
#' Compute the contrast weights for a pair_contrast_spec object.
#'
#' @param x A pair_contrast_spec object.
#' @param term A term object.
#' @param ... Additional arguments (currently unused).
#'
#' @return A list containing the term, name, weights, condition names, and contrast specification.
#'
#' @export
contrast_weights.pair_contrast_spec <- function(x, term,...) {
  # Get cells (only categorical combinations) for evaluating formulas A & B
  term_cells <- cells(term)
  
  # Determine if basis expansion is needed
  expand_basis <- FALSE
  nbasis <- 1L
  hrfspec <- attr(term, "hrfspec")
  if (!is.null(hrfspec) && !is.null(hrfspec$hrf)) {
    hrf_fun <- hrfspec$hrf
    # Check nbasis using the nbasis generic
    if (!inherits(try(nbasis(hrf_fun), silent=TRUE), "try-error") && nbasis(hrf_fun) > 1) {
       nbasis <- nbasis(hrf_fun)
       expand_basis <- TRUE
    }
  }
  
  # Get base condition names (pre-expansion) - these are the targets for weights
  base_condnames_all <- try(conditions(term, drop.empty=FALSE, expand_basis=FALSE), silent=TRUE)
  if (inherits(base_condnames_all, "try-error") || length(base_condnames_all) == 0) {
      warning(paste("Contrast '", x$name, "': Failed to get base condition names for term '", term$varname, "'. Skipping."), call. = FALSE)
      return(NULL) # Return NULL if cannot proceed
  }
  
  if (nrow(term_cells) == 0) {
      # If term_cells is empty, we can still proceed if base_condnames_all exist,
      # but the contrast formulas A/B likely won't match anything.
      warning(paste("Contrast '", x$name, "': Term '", term$varname, "' has no observed categorical cells. Contrast weights might be all zero."), call. = FALSE)
  }
  
  # Evaluate 'where' clause on term_cells
  keep <- if (!is.null(x$where)) {
      tryCatch(rlang::eval_tidy(rlang::f_rhs(x$where), data = term_cells), error = function(e) {
          warning(paste("Contrast '", x$name, "': Error evaluating 'where' clause: ", e$message), call. = FALSE)
          rep(FALSE, nrow(term_cells)) # Default to FALSE on error
      })
  } else {
      rep(TRUE, nrow(term_cells)) # Keep all if no 'where'
  }
  relevant_cells <- term_cells[keep, , drop = FALSE]
  
  if (nrow(relevant_cells) == 0 && nrow(term_cells) > 0) {
       warning(paste("Contrast '", x$name, "' resulted in no relevant cells after applying the 'where' clause."), call. = FALSE)
       # Proceed, but weights will likely be zero
  }
  
  # Evaluate A and B formulas on the relevant cells
  keepA_rel <- if(nrow(relevant_cells) > 0) tryCatch(rlang::eval_tidy(rlang::f_rhs(x$A), data = relevant_cells), error = function(e) {
      warning(paste("Contrast '", x$name, "': Error evaluating formula A: ", e$message), call. = FALSE)
      logical(nrow(relevant_cells)) # Return all FALSE on error
  }) else logical(0)
  
  keepB_rel <- if (is.null(x$B) || nrow(relevant_cells) == 0) NULL else {
      tryCatch(rlang::eval_tidy(rlang::f_rhs(x$B), data = relevant_cells), error = function(e) {
          warning(paste("Contrast '", x$name, "': Error evaluating formula B: ", e$message), call. = FALSE)
          logical(nrow(relevant_cells)) # Return all FALSE on error
      })
  }
  
  # --- FIX: Map formula evaluation results to condition names --- 
  mask_A_full <- logical(length(base_condnames_all))
  mask_B_full <- if (!is.null(keepB_rel)) logical(length(base_condnames_all)) else NULL
  
  if (nrow(relevant_cells) > 0) {
    # Get the variable names involved in the term (must match cells colnames)
    term_vars <- names(relevant_cells)
    
    for (i in 1:nrow(relevant_cells)) {
      cell_row <- relevant_cells[i, , drop = FALSE]
      
      # Construct the corresponding condition name(s) for this cell row
      # This needs to handle interactions correctly.
      # For a single factor 'condition' with level 'a', it should produce 'condition.a'
      # For factors 'condition', 'task' with levels 'a', 'X', it should produce 'condition.a_task.X'
      tokens <- vector("character", length(term_vars))
      for (j in seq_along(term_vars)) {
         var_name <- term_vars[j]
         level_val <- cell_row[[var_name]] # Get the factor level value
         # Assume level_token handles sanitization if needed
         tokens[j] <- level_token(var_name, level_val)
      }
      target_cond_name <- make_cond_tag(tokens)
      
      # Find the index in the full list
      idx <- match(target_cond_name, base_condnames_all)
      
      if (!is.na(idx)) {
        if (i <= length(keepA_rel) && keepA_rel[i]) {
          mask_A_full[idx] <- TRUE
        }
        if (!is.null(mask_B_full) && i <= length(keepB_rel) && keepB_rel[i]) {
          mask_B_full[idx] <- TRUE
        }
      }
    }
  }
  # --- END FIX --- 

  # Calculate base weights relative to the full set of base conditions
  base_weights_named <- .make_weights(base_condnames_all, mask_A_full, mask_B_full)
  
  # --- Basis Expansion --- 
  if (expand_basis) {
     # Get expanded condition names
     expanded_condnames <- try(conditions(term, drop.empty = FALSE, expand_basis = TRUE), silent = TRUE)
     if (inherits(expanded_condnames, "try-error") || length(expanded_condnames) == 0) {
         warning(paste("Contrast '", x$name, "': Failed to get expanded condition names for term '", term$varname, "'. Skipping expansion."), call. = FALSE)
         weights_out <- matrix(base_weights_named, ncol = 1)
         rownames(weights_out) <- names(base_weights_named)
         colnames(weights_out) <- x$name
         cell_names_out <- names(base_weights_named)
     } else if (length(expanded_condnames) != length(base_weights_named) * nbasis) {
          warning(paste("Contrast '", x$name, "': Mismatch between expanded names (", length(expanded_condnames), 
                        ") and expected from base weights * nbasis (", length(base_weights_named) * nbasis, "). Skipping expansion."), call. = FALSE)
          weights_out <- matrix(base_weights_named, ncol = 1)
          rownames(weights_out) <- names(base_weights_named)
          colnames(weights_out) <- x$name
          cell_names_out <- names(base_weights_named)
     } else {
         # --- REMOVED MANUAL BROADCAST ---
         # weights_out_vec <- rep(base_weights_named, each = nbasis)
         # --- Instead, align using names ---
         weights_out <- matrix(0, nrow = length(expanded_condnames), ncol = 1)
         rownames(weights_out) <- expanded_condnames
         colnames(weights_out) <- x$name
         # Find expanded names corresponding to non-zero base weights
         base_names_with_weight <- names(base_weights_named)[base_weights_named != 0]
         # Create regex patterns to match expanded names
         # patterns_to_match <- paste0("^", base_names_with_weight, "(\_b\\d+)?$") # Match name + optional _b suffix
         
         for(i in seq_along(base_names_with_weight)){
             base_name <- base_names_with_weight[i]
             weight_val <- base_weights_named[base_name]
             # Find all expanded conditions that start with this base name
             # Use fixed=TRUE for exact match of base name part
             pattern <- paste0("^", base_name, "(_b\\d+)?$")   # note: _b\\d+
             matching_expanded_indices <- grep(pattern, expanded_condnames, perl = TRUE)
            if(length(matching_expanded_indices) > 0){
                 weights_out[matching_expanded_indices, 1] <- weight_val 
             }
         }
         # Ensure weights still sum to zero (or close to it)
         if (abs(sum(weights_out)) > 1e-8) {
              warning(paste("Contrast ", x$name, ": Weights do not sum to zero after basis expansion."), call.=FALSE)
         }
         cell_names_out <- expanded_condnames
     }
  } else {
     # No expansion needed
     weights_out <- matrix(base_weights_named, ncol = 1)
     rownames(weights_out) <- names(base_weights_named)
     colnames(weights_out) <- x$name
     cell_names_out <- names(base_weights_named)
  }

  # Return structure focused on cell-based weights
  ret <- list(
    term = term,
    name = x$name,
    weights = weights_out, # Weights relative to (potentially expanded) relevant cells
    condnames = cell_names_out, # Names of the relevant cells corresponding to rows of weights
    contrast_spec = x
  )
  
  class(ret) <- c("cell_contrast", "contrast", "list") 
  ret  
}

#' Column Contrast Weights
#'
#' @description
#' Compute contrast weights for a `column_contrast_spec` object by targeting
#' design matrix columns based on regex patterns.
#'
#' @param x A `column_contrast_spec` object.
#' @param term An `event_term` object.
#' @param ... Additional arguments (currently unused).
#'
#' @return A list containing the contrast details:
#'   \item{term}{The original `event_term` object.}
#'   \item{name}{The name of the contrast.}
#'   \item{weights}{A numeric matrix where rows correspond to the full design
#'                  matrix columns (from `.condnames(term, expanded = TRUE)`)
#'                  and columns represent the contrast(s). Usually one column.}
#'   \item{condnames}{Character vector of all potential *expanded* condition names from `term`.}
#'   \item{contrast_spec}{The original `column_contrast_spec` object.}
#'
#' @export
#' @import assertthat
contrast_weights.column_contrast_spec <- function(x, term, ...) {

  # --- Use .condnames helper to get expanded names --- 
  all_colnames <- .condnames(term, expanded = TRUE)
  # Note: .condnames() already includes error handling for conditions()
  if (length(all_colnames) == 0) {
      # It's possible conditions() returns empty if term has no levels/columns
      warning(paste("Column contrast '", x$name, "': Term '", term$varname %||% "<unknown>",
                    "' resulted in zero condition names. Weights will be empty."), call. = FALSE)
      # Return structure with empty weights
      weights_out <- matrix(numeric(0), nrow = 0, ncol = 1)
      colnames(weights_out) <- x$name
      ret <- list(
          term = term,
          name = x$name,
          weights = weights_out,
          condnames = character(0),
          contrast_spec = x
      )
      class(ret) <- c("column_contrast", "contrast", "list")
      return(ret)
  }
  num_all_conds <- length(all_colnames)

  # --- Find indices using grep directly --- 
  # No need for .col_index intermediary anymore if we have names
  idx_A <- grep(x$pattern_A, all_colnames, value = FALSE)
  nA <- length(idx_A)
  if (nA == 0) {
    warning(paste("Column contrast '", x$name, "': pattern_A ('", x$pattern_A,
                  "') did not match any design matrix columns for term '", term$varname %||% "<unknown>", "'."),
            call. = FALSE)
  }

  idx_B <- integer(0)
  nB <- 0
  if (!is.null(x$pattern_B)) {
    idx_B <- grep(x$pattern_B, all_colnames, value = FALSE)
    nB <- length(idx_B)
    if (nB == 0) {
      warning(paste("Column contrast '", x$name, "': pattern_B ('", x$pattern_B,
                    "') did not match any design matrix columns for term '", term$varname %||% "<unknown>", "'."),
              call. = FALSE)
    }
  }

  # --- Retain overlap check --- 
  if (nA > 0 && nB > 0 && any(idx_A %in% idx_B)) {
    stop(paste("Column contrast '", x$name, "': pattern_A and pattern_B match overlapping columns.",
               " Indices A: ", paste(idx_A, collapse=", "),
               "; Indices B: ", paste(idx_B, collapse=", ")), 
         call. = FALSE)
  }

  # --- Calculate weights using .mask_to_weights --- 
  mask_A <- seq_along(all_colnames) %in% idx_A
  mask_B <- if (!is.null(x$pattern_B)) seq_along(all_colnames) %in% idx_B else NULL
  
  # .mask_to_weights handles 1/nA, -1/nB, checks, and warnings
  weights_vec <- .mask_to_weights(all_colnames, mask_A, mask_B)
  
  # Ensure output is a matrix
  weights_mat <- matrix(weights_vec, ncol = 1)
  rownames(weights_mat) <- all_colnames
  colnames(weights_mat) <- x$name

  # Return structure
  ret <- list(
    term = term,
    name = x$name,
    weights = weights_mat,
    condnames = all_colnames, # These are the expanded names used for weights
    contrast_spec = x
  )

  # Classify appropriately
  class(ret) <- c("column_contrast", "contrast", "list")
  ret
}

#' Contrast Formula Weights
#'
#' @description
#' Compute the contrast weights for a contrast_formula_spec object.
#'
#' @param x A contrast_formula_spec object.
#' @param term A term object.
#' @param ... Additional arguments (currently unused).
#'
#' @return A list containing the term, name, weights, condition names, and contrast specification.
#'
#' @export
contrast_weights.contrast_formula_spec <- function(x, term,...) {

  term.cells <- cells(term)
  condnames <- shortnames(term)
  count <- attr(term.cells, "count")		
  term.cells <- subset(term.cells, count > 0)
  
  if (!is.null(x$where)) {
    keep <- rlang::eval_tidy(rlang::f_rhs(x$where), data=term.cells)
    assert_that(sum(keep) > 0)
    term.cells <- term.cells[keep,]
  } else {
    keep <- rep(TRUE, nrow(term.cells))
  }
  
  if (is_continuous(term)) {
    ## hack to handle contrasts with continuous terms
    facs <- !sapply(term$events, is_continuous)
    term.cells[,!facs] <- 1
  } 

  # Create a simple environment with shortnames as variables
  # Each shortname gets a vector with 1 in its position and 0 elsewhere
  weights <- matrix(0, NROW(term.cells), 1)
  eval_env <- new.env(parent = rlang::f_env(x$A))
  
  # Create indicator variables for each condition using shortnames
  for (i in seq_along(condnames)) {
    indicator <- rep(0, length(condnames))
    indicator[i] <- 1
    assign(condnames[i], indicator, envir = eval_env)
  }
  
  # Evaluate the contrast formula
  res <- tryCatch(rlang::eval_tidy(rlang::f_rhs(x$A), env=eval_env), error = function(e) {
       stop(paste("Contrast formula evaluation failed:", e$message, "\nAvailable names:", paste(condnames, collapse=", ")), call.=FALSE)
  })
  
  # Apply results to weights matrix
  weights[keep,1] <- as.vector(res)
  
  # Use longnames for rownames (the new format)
  row.names(weights) <- longnames(term)[keep]

  # Return structure
  ret <- list(
    term=term,
    name=x$name,
    weights=weights,
    condnames=longnames(term),
    contrast_spec=x)
  
  class(ret) <- c("contrast", "list")
  ret  
}

#' Contrast Difference Weights
#'
#' @description
#' Compute the contrast weights for a contrast_diff_spec object.
#'
#' @param x A contrast_diff_spec object.
#' @param term A term object.
#' @param ... Additional arguments (currently unused).
#'
#' @return A list containing the term, name, weights, condition names, and contrast specification.
#'
#' @export
contrast_weights.contrast_diff_spec <- function(x, term,...) {
  wts1 <- contrast_weights(x$con1, term)
  wts2 <- contrast_weights(x$con2, term)

  ret <- structure(
    list(
      term=term,
      name=x$name,
      weights=wts1$weights - wts2$weights,
      condnames=longnames(term),
      contrast_spec=x),
    class=c("contrast_diff", "contrast")
  )

  ret  
}

#' Convert Contrast to GLT
#'
#' @description
#' Convert a contrast to an AFNI 'GLT' format.
#'
#' @param x The contrast to convert.
#' @param ... Additional arguments (currently unused).
#'
#' @return A list containing the GLT string, name, and contrast specification.
#'
#' @export
to_glt.contrast <- function(x,...) {
  if (is.matrix(x$weights) && ncol(x$weights) > 1) {
    glts <- lapply(1:ncol(x$weights), function(i) {
      paste0(signif(x$weights[,i],4), "*", x$condnames, collapse=" ")
    })
    
    ret <- list(glt_str=glts,
                name=paste0("GLT_", x$name, "_", 1:ncol(x$weights)),
                con=x)
    
    class(ret) <- "glt_contrast_list"
    ret
  } else {
    glt <- paste0(signif(x$weights,4), "*", x$condnames, collapse=" ")
    ret <- list(glt_str=glt,
       name=paste0("GLT_", x$name),
       con=x)
  
    class(ret) <- "glt_contrast"
    ret
  }
}

#' Write GLT to File
#'
#' @description
#' Write a generic function for writing GLT contrast to a file.
#'
#' @param x The GLT contrast object
#' @param ... Additional arguments passed to methods
#' @export
write_glt <- function(x, ...) {
  UseMethod("write_glt")
}

#' Write GLT to File
#'
#' @description
#' Write a GLT contrast to a file.
#'
#' @param x The GLT contrast to write.
#' @param fname File path for the GLT specification
#'
#' @export
#' @rdname write_glt
write_glt.glt_contrast <- function(x, fname=NULL,...) {
  con <- if (is.null(fname)) {
    file(fname, "w")
  } else {
    file(paste0(x$name, ".txt"), "w")
  }
  
  writeLines(x$glt_str, con=con)
  close(con)
}

#' Estimated Contrast
#'
#' @description
#' Compute the estimated contrast for a given fit and indices.
#'
#' @param x The contrast to estimate.
#' @param fit The fit object.
#' @param indices The indices to use.
#' @param ... Additional arguments (currently unused).
#'
#' @return The estimated contrast.
#'
#' @noRd
#' @keywords internal
estcon.contrast <- function(x, fit, indices, ...) {
  wts <- numeric(length(fit$assign))
  wts[indices] <- x$weights
  
  gmodels::estimable(fit, wts)
}

#' Print Contrast Set
#'
#' @description
#' Print a contrast set.
#'
#' @param x The contrast set to print.
#' @param ... Additional arguments (currently unused).
#'
#' @export
#' @rdname print
print.contrast_set <- function(x, ...) {
  n_contrasts <- length(x)
  
  # Header
  cat("\n═══ Contrast Set ═══\n")
  
  # Summary
  cat("\n Overview:\n")
  cat("  • Number of contrasts:", n_contrasts, "\n")
  
  # Group contrasts by type
  types <- sapply(x, function(con) class(con)[1])
  type_table <- table(types)
  if (length(type_table) > 0) {
    cat("  • Types of contrasts:\n")
    for (type in names(type_table)) {
      cat("    -", type, ":", type_table[type], "\n")
    }
  }
  
  # List all contrasts
  cat("\n🔍 Individual Contrasts:\n")
  for (i in seq_along(x)) {
    cat("\n[", i, "] ", x[[i]]$name, " (", class(x[[i]])[1], ")\n", sep="")
    cat("    Formula: ")
    if (!is.null(x[[i]]$A)) cat(deparse(x[[i]]$A))
    if (!is.null(x[[i]]$B)) cat(" vs ", deparse(x[[i]]$B))
    cat("\n")
    if (!is.null(x[[i]]$where)) {
      cat("    Subset: ", deparse(x[[i]]$where), "\n")
    }
  }
  
  cat("\n")
  invisible(x)
}

#' Print Contrast Specification
#'
#' @description
#' Print a contrast specification.
#'
#' @param x The contrast specification to print.
#' @param ... Additional arguments (currently unused).
#'
#' @export
#' @rdname print
print.contrast_spec <- function(x,...) {
  cat("contrast:", x$name, "\n")
  cat(" A: ", Reduce(paste, deparse(x$A)), "\n")
  if (!is.null(x$B))
    cat(" B: ", Reduce(paste, deparse(x$B)), "\n")
  if (!is.null(x$where))
    cat(" where: ", Reduce(paste, deparse(x$where)), "\n")
  

}

#' Print Contrast
#'
#' @description
#' Print a contrast.
#'
#' @param x The contrast to print.
#' @param ... Additional arguments (currently unused).
#'
#' @export
#' @rdname print
print.contrast <- function(x,...) {
  print(x$contrast_spec)
  cat(" term: ", x$term$varname, "\n")
  cat(" weights: ", "\n")
  print(x$weights)
  cat(" conditions: ", x$condnames)
  
}

#' Print Polynomial Contrast Specification
#'
#' @description
#' Print a polynomial contrast specification.
#'
#' @param x The polynomial contrast specification to print.
#' @param ... Additional arguments (currently unused).
#'
#' @export
#' @rdname print
print.poly_contrast_spec <- function(x,...) {
  cat("poly contrast:", "\n")
  cat(" A: ", Reduce(paste, deparse(x$A)), "\n")
  cat(" degree: ", x$degree, "\n")
  if (!is.null(x$where)) {
    cat(" where: ", deparse(x$where), "\n")
  }
  
  if (!is.null(x$value_map)) {
    cat(" values: ", unlist(x$value_map), "\n")
  }
}

#' Print Contrast Difference Specification
#'
#' @description
#' Print a contrast difference specification.
#'
#' @param x The contrast difference specification to print.
#' @param ... Additional arguments (currently unused).
#'
#' @export
#' @rdname print
print.contrast_diff_spec <- function(x,...) {
  cat("contrast difference:", "\n")
  cat("  ", x$con1$name, "-", x$con2$name, "\n")
}

#' plot_contrasts
#'
#' @description
#' Generic function for plotting contrasts.
#'
#' @param x Object containing contrast information
#' @param ... Additional arguments passed to methods
#' @export
plot_contrasts <- function(x, ...) {
  UseMethod("plot_contrasts")
}

#' plot_contrasts.event_model
#'
#' @description
#' Produces a heatmap of all contrasts defined for an \code{event_model}.
#' Rows = each contrast (or column of an F-contrast), columns = each regressor in
#' the full design matrix, and the fill color = the contrast weight.
#'
#' @param x An \code{event_model} with (lazily) defined contrasts.
#' @param absolute_limits Logical; if \code{TRUE}, the color scale is fixed at (-1,1).
#'   If \code{FALSE}, the range is set to (min, max) of the weights.
#' @param rotate_x_text Logical; if \code{TRUE}, rotate x-axis labels for readability.
#' @param scale_mode Character; 'auto', 'diverging', or 'one_sided' color scaling.
#' @param coord_fixed Logical; if TRUE, use fixed aspect ratio.
#' @param ... Further arguments passed to \code{geom_tile}, e.g. \code{color="grey80"}.
#'
#' @return A \code{ggplot2} object (a heatmap).
#' @import ggplot2
#' @export
plot_contrasts.event_model <- function(
    x,
    absolute_limits = FALSE,
    rotate_x_text   = TRUE,
    scale_mode      = c("auto", "diverging", "one_sided"),
    coord_fixed     = TRUE,
    ...
) {
  # 1) Extract all the design-matrix column names
  dm <- design_matrix(x)
  regressor_names <- colnames(dm)
  
  # 2) Gather contrast weights (the nested list by term, then by contrast)
  cws <- contrast_weights(x)
  
  # Flatten everything into one big matrix of contrast weights
  big_mat  <- NULL
  rownames <- character(0)
  
  add_contrast_row <- function(vec, row_name) {
    if (is.null(big_mat)) {
      big_mat <<- matrix(vec, nrow = 1)
      colnames(big_mat) <<- regressor_names
      rownames <<- row_name
    } else {
      big_mat <<- rbind(big_mat, vec)
      rownames <<- c(rownames, row_name)
    }
  }
  
  for (term_nm in names(cws)) {
    term_level <- cws[[term_nm]]
    if (is.null(term_level)) next
    
    for (contrast_nm in names(term_level)) {
      cw_obj <- term_level[[contrast_nm]]
      # By default, we store offset_weights in cw_obj$offset_weights
      W <- cw_obj$offset_weights
      if (is.null(W)) next  # skip if no offset_weights
      
      # (#designCols x #contrastCols)
      ncols <- ncol(W)
      for (k in seq_len(ncols)) {
        this_col <- W[, k]
        if (ncols > 1) {
          row_label <- paste0(contrast_nm, "_component", k)
        } else {
          row_label <- contrast_nm
        }
        add_contrast_row(this_col, row_label)
      }
    }
  }
  
  if (is.null(big_mat)) {
    stop("No contrasts found in this event_model.")
  }
  
  rownames(big_mat) <- rownames
  
  # 3) Convert big_mat to a long data frame using modern base R approach
  # Create indices for row and column positions
  row_indices <- rep(seq_len(nrow(big_mat)), ncol(big_mat))
  col_indices <- rep(seq_len(ncol(big_mat)), each = nrow(big_mat))
  
  # Create the long format data frame
  df_long <- data.frame(
    ContrastName = rownames(big_mat)[row_indices],
    Regressor = colnames(big_mat)[col_indices],
    Weight = as.vector(big_mat),
    stringsAsFactors = FALSE
  )
  
  # 4) Build the ggplot
  plt <- ggplot2::ggplot(
    df_long,
    ggplot2::aes(
      x    = ReorderFactor(Regressor),
      y    = ReorderFactor(ContrastName, reverse = TRUE),
      fill = Weight
    )
  ) +
    ggplot2::geom_tile(...)
  
  # Decide on color scale
  scale_mode <- match.arg(scale_mode)
  wmin <- min(df_long$Weight, na.rm = TRUE)
  wmax <- max(df_long$Weight, na.rm = TRUE)
  
  # If user set absolute_limits=TRUE, we might forcibly use [-1,1] or [0,1]
  # but let's allow scale_mode to override as well.
  if (scale_mode == "diverging") {
    # Diverging scale, centered on 0
    lim_low  <- if (absolute_limits) -1 else wmin
    lim_high <- if (absolute_limits)  1 else wmax
    midpt <- 0
    
    plt <- plt + ggplot2::scale_fill_gradient2(
      limits   = c(lim_low, lim_high),
      midpoint = midpt,
      low      = "blue",
      mid      = "white",
      high     = "red"
    )
    
  } else if (scale_mode == "one_sided") {
    # One-sided scale for 0..1 or 0..something
    lim_low  <- if (absolute_limits) 0 else wmin
    lim_high <- if (absolute_limits) 1 else wmax
    
    plt <- plt + ggplot2::scale_fill_gradient(
      limits = c(lim_low, lim_high),
      low    = "white",
      high   = "red"
    )
    
  } else {
    # scale_mode == "auto"
    # If we detect any negative weight, do diverging; otherwise do one-sided
    if (wmin < 0) {
      # diverging
      lim_low  <- if (absolute_limits) -1 else wmin
      lim_high <- if (absolute_limits)  1 else wmax
      plt <- plt + ggplot2::scale_fill_gradient2(
        limits   = c(lim_low, lim_high),
        midpoint = 0,
        low      = "blue",
        mid      = "white",
        high     = "red"
      )
    } else {
      # one-sided
      lim_low  <- if (absolute_limits) 0 else wmin
      lim_high <- if (absolute_limits) 1 else wmax
      plt <- plt + ggplot2::scale_fill_gradient(
        limits = c(lim_low, lim_high),
        low    = "white",
        high   = "red"
      )
    }
  }
  
  # 5) Theming
  plt <- plt +
    ggplot2::theme_minimal(base_size = 14) +
    ggplot2::labs(
      x    = "Regressor",
      y    = "Contrast",
      fill = "Weight"
    ) +
    ggplot2::theme(
      panel.grid  = ggplot2::element_blank(),
      axis.ticks  = ggplot2::element_blank()
    )
  
  if (rotate_x_text) {
    plt <- plt + ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, hjust = 1))
  }
  
  # 6) Optionally fix the coordinate ratio to keep tiles square
  if (coord_fixed) {
    plt <- plt +
      ggplot2::scale_x_discrete(expand = c(0, 0)) +
      ggplot2::scale_y_discrete(expand = c(0, 0)) +
      ggplot2::coord_fixed()
  }
  
  plt
}

#' A small utility to preserve factor order in ggplot
#' 
#' Makes a factor from a character vector but preserves the order of appearance.
#' If `reverse=TRUE`, it reverses that order.
#' @keywords internal
#' @noRd
ReorderFactor <- function(x, reverse=FALSE) {
  levs <- unique(as.character(x))
  if (reverse) levs <- rev(levs)
  factor(x, levels=levs)
}

#' Contrast Weights for a Contrast Set
#'
#' @description
#' Compute the contrast weights for each contrast specification within a contrast_set object.
#'
#' @param x A contrast_set object (a list of contrast_spec objects).
#' @param term A term object against which weights should be computed.
#' @param ... Additional arguments passed to individual contrast_weights methods.
#'
#' @return A named list where each element is the result of calling contrast_weights 
#'         on the corresponding contrast_spec in the set. The list names are the 
#'         names of the individual contrasts.
#'
#' @export
#' @importFrom purrr map set_names
contrast_weights.contrast_set <- function(x, term, ...) {
  # Ensure x is a list (contrast_set inherits from list)
  if (!is.list(x)) {
    stop("Input 'x' must be a contrast_set (list).")
  }
  
  # Iterate through each contrast spec in the set
  results_list <- purrr::map(x, function(contrast_spec) {
    # Check if the element is actually a contrast_spec
    if (!inherits(contrast_spec, "contrast_spec")) {
      warning(paste("Element", contrast_spec$name, "is not a contrast_spec object, skipping."))
      return(NULL)
    }
    # Compute weights for the individual contrast spec
    contrast_weights(contrast_spec, term, ...)
  })
  
  # Filter out any NULL results (if any elements weren't contrast_spec)
  results_list <- results_list[!sapply(results_list, is.null)]
  
  # Set the names of the results list based on the names of the contrasts
  contrast_names <- purrr::map_chr(results_list, "name")
  results_list <- purrr::set_names(results_list, contrast_names)
  
  return(results_list)
}
</file>

<file path="R/all_generic.R">
#' @noRd
#' @keywords internal
get_methods <- function(obj) {
  unique(purrr::map_chr(class(obj), ~ methods(class= . )))
}


#' @noRd
#' @keywords internal
with_package <- function(name) {
  if (!requireNamespace(name, quietly=TRUE)) {
    stop(paste("Please install the", name, "package to use this functionality"))
  }
}
  


#' @noRd
#' @keywords internal
as_vectors <- function(x) { UseMethod("as_vectors") }

#' @importFrom methods setGeneric 
setGeneric("as_vectors") 


#' Construct an event model
#' 
#' This function creates an event-based fMRI regression model, represented as a data structure.
#' 
#' @importFrom lazyeval f_eval
#' @param formula_or_list The model specification, typically a `formula`. The formula should have the following format:
#'    response ~ predictor1 + predictor2 + ... + predictorN
#' where `response` is a numeric vector of fMRI signal values, and `predictor1` to `predictorN` are
#' predictor variables. Each predictor variable should be specified as a function of categorical
#' variables (factors) and/or continuous variables. The functions should have the prefix "hrf", and can
#' be defined using the `hrf()` function (see `hrf` documentation for details).
#' @param data A data frame containing the experimental design, with one row per time point and
#' one column per variable used in the model formula. If a categorical variable is used in the formula,
#' it should be a factor in the data frame. The data frame should also contain a column with the fMRI
#' signal values (the response variable).
#' @param block A formula specifying the block structure of the design. This formula should have
#' the format `block_var1 + block_var2 + ...`, where each `block_var` is a categorical variable (factor)
#' used to define blocks of time points. The block structure is used to estimate the baseline fMRI
#' signal level separately for each block.
#' @param sampling_frame A sampling frame defining the temporal and block structure of the design.
#' This should be an object of class `sampling_frame` (see `sampling_frame` documentation for details).
#' @param drop_empty Logical value indicating whether to drop empty factor levels in the model.
#' If `TRUE` (default), any factor levels with no observations will be dropped from the model. If `FALSE`,
#' empty levels will be retained and will receive a coefficient of zero in the model.
#' @param durations A numeric vector specifying the duration (in seconds) of each event in the model.
#' If the model contains block variables, the duration of each block should be specified as well.
#' The length of this vector should be equal to the number of events/blocks in the design.
#' Default value is 0 (no duration).
#' @param ... Additional arguments to be passed to methods. Currently not used.
#' 
#' @export
#' 
#' @return A list containing the following elements:
#' \describe{
#'   \item{formula}{The formula used to create the model.}
#'   \item{design}{The design matrix for the model, with one row per time point and one column per predictor variable.}
#'   \item{block_indices}{A list of indices defining the start and end time points of each block.}
#'   \item{baseline}{A vector containing the estimated baseline fMRI signal level for each block.}
#'   \item{dur}{A vector containing the duration (in seconds) of each event or block in the design.}
#' }
#' 
#' @examples 
#' # Create a data frame with experimental design
#' event_data <- data.frame(fac=c("a", "B", "A", "B"), onsets=c(1,10,20,80), run=c(1,1,1,1))
#' 
#' # Create a sampling frame with 50-second blocks and a TR of 2 seconds
#' sframe <- sampling_frame(blocklens=50, TR=2)
#' 
#' # Create an event model using the `onsets` variable as a predictor, 
#' #  with a separate baseline for each run
#' evmodel <- event_model(onsets ~ hrf(onsets), data=event_data, block=~run, sampling_frame=sframe)
#' dmat <- design_matrix(evmodel)
event_model <- function(formula_or_list, data, block, sampling_frame, drop_empty=TRUE, durations=0, ...) { UseMethod("event_model") }



#' get_data
#' 
#' @param x the dataset
#' @param ... extra args
#' @keywords internal
#' @noRd
get_data <- function(x, ...) UseMethod("get_data")


#' Extract data matrix
#'
#' Return the BOLD time series from a dataset as a numeric matrix. Rows
#' correspond to voxels and columns to scans.
#'
#' @param x The dataset object.
#' @param ... Additional arguments passed to methods.
#'
#' @return A numeric matrix containing the data values.
#'
#' @examples
#' X <- matrix(rnorm(20), 4, 5)
#' dset <- matrix_dataset(X, TR = 1, run_length = 5)
#' mat <- get_data_matrix(dset)
#' dim(mat)
#'
#' @export
get_data_matrix <- function(x, ...) UseMethod("get_data_matrix")


#' get_mask
#' 
#' get the binary inclusion mask associated with a dataset
#' 
#' @param x the dataset
#' @param ... extra args
#' @keywords internal
#' @noRd
get_mask <- function(x, ...) UseMethod("get_mask")


#' get_formula
#' 
#' @param x the object
#' @param ... extra args
#' @keywords internal
#' @noRd
get_formula <- function(x, ...) UseMethod("get_formula")


#' term_matrices
#' 
#' @param x the object
#' @param ... extra args
#' @keywords internal
#' @export
term_matrices <- function(x, ...) UseMethod("term_matrices")



#' design_env
#' 
#' return regression design as a set of matrices stored in an environment
#' 
#' @param x the object
#' @param ... extra args
#' @keywords internal
#' @noRd
design_env <- function(x, ...) UseMethod("design_env")


#' Calculate contrast weights for a given contrast specification and term.
#'
#' @description
#' This function calculates the contrast weights based on the contrast specification
#' provided by the user. It is a generic function that dispatches to the appropriate
#' method depending on the class of the contrast specification (e.g., unit_contrast_spec,
#' pair_contrast_spec, poly_contrast_spec, etc.).
#'
#' @param x The contrast specification object
#' @param ... Extra arguments passed to specific methods
#' @return A list containing:
#' \describe{
#'     \item{term}{The model term the contrast is applied to}
#'     \item{name}{The name of the contrast}
#'     \item{weights}{A matrix of contrast weights}
#'     \item{condnames}{The condition names associated with the weights}
#'     \item{contrast_spec}{The original contrast specification}
#' }
#' @examples
#' # Create a data frame with experimental design
#' event_data <- data.frame(
#'   condition = factor(c("A", "B", "A", "B")),
#'   onsets = c(1, 10, 20, 80),
#'   run = c(1, 1, 1, 1)
#' )
#' 
#' # Create a sampling frame
#' sframe <- sampling_frame(blocklens = 50, TR = 2)
#' 
#' # Create an event model
#' evmodel <- event_model(
#'   onsets ~ hrf(condition),
#'   data = event_data,
#'   block = ~run,
#'   sampling_frame = sframe
#' )
#' 
#' # Create a contrast comparing conditions A and B
#' con <- pair_contrast(
#'   ~condition == "A",
#'   ~condition == "B",
#'   name = "A_vs_B"
#' )
#' 
#' # Calculate the contrast weights
#' weights <- contrast_weights(con, evmodel)
#' @export
#' @family contrast_weights
#' @seealso [pair_contrast()], [unit_contrast()], [poly_contrast()]
contrast_weights <- function(x, ...) UseMethod("contrast_weights")


#' parent_terms
#' 
#' @param x the object
#' @keywords internal
#' @noRd
parent_terms <- function(x) UseMethod("parent_terms")


#' term_names
#' @param x the object to extra term names from
#' @noRd
#' @keywords internal
term_names <- function(x) UseMethod("term_names")



#' The experimental cells of a design
#' 
#' Return the experimental cells that are in a model term as a table. Experimental cells 
#' represent unique combinations of factor levels in the design. For example, if a design 
#' has factors A (levels: a1, a2) and B (levels: b1, b2), the cells would be: a1:b1, 
#' a1:b2, a2:b1, a2:b2.
#' 
#' @param x The object (typically an event_term or event_model)
#' @param ... Additional arguments passed to methods. Common arguments include:
#' \describe{
#'     \item{drop.empty}{Logical; if TRUE, cells with no events are removed (default)}
#'     \item{exclude_basis}{Logical; if TRUE, basis functions are excluded from cell names}
#' }
#' @return A tibble containing the experimental cells with attributes:
#' \describe{
#'     \item{count}{Number of events in each cell}
#'     \item{rownames}{Cell names when cells have multiple factors}
#' }
#' @examples
#' # Create a simple factorial design
#' evlist <- list(
#'   fac1 = factor(c("A", "B", "A", "B")),
#'   fac2 = factor(c("1", "1", "2", "2"))
#' )
#' 
#' # Create an event term
#' eterm <- event_term(
#'   evlist,
#'   onsets = 1:4,
#'   blockids = rep(1, 4)
#' )
#' 
#' # Get the experimental cells
#' cells(eterm)  # Returns cells: A:1, A:2, B:1, B:2
#' 
#' # Create an event model
#' event_data <- data.frame(
#'   fac = c("a", "B", "A", "B"),
#'   onsets = c(1, 10, 20, 80),
#'   run = c(1, 1, 1, 1)
#' )
#' sframe <- sampling_frame(blocklens = 50, TR = 2)
#' evmodel <- event_model(
#'   onsets ~ hrf(fac),
#'   data = event_data,
#'   block = ~run,
#'   sampling_frame = sframe
#' )
#' 
#' # Get cells from the model
#' cells(evmodel)
#' @export
#' @family cells
#' @seealso [event_term()], [event_model()]
cells <- function(x, ...) UseMethod("cells")



#' Conditions
#' 
#' Return the set of condition labels associated with a model term. Conditions represent 
#' the unique experimental conditions in the design, typically formed from factor levels 
#' and/or basis functions. For example, a term with factor "stimulus" (levels: face, house) 
#' and two basis functions would have conditions: `"stimulus[face]:basis1"`, `"stimulus[face]:basis2"`, 
#' `"stimulus[house]:basis1"`, `"stimulus[house]:basis2"`.
#' 
#' @param x The model term (typically an event_term, event_model, or convolved_term)
#' @param ... Additional arguments passed to methods. Common arguments include:
#' \itemize{
#'   \item{drop.empty}{Logical; if TRUE, conditions with no events are dropped}
#'   \item{exclude_basis}{Logical; if TRUE, basis function labels are excluded}
#' }
#' @return A character vector of condition labels
#' @examples
#' # Create a simple event model with a categorical predictor
#' event_data <- data.frame(
#'   stimulus = factor(c("face", "house", "face", "house")),
#'   onsets = c(1, 10, 20, 30),
#'   run = c(1, 1, 1, 1)
#' )
#' 
#' # Create a sampling frame
#' sframe <- sampling_frame(blocklens = 50, TR = 2)
#' 
#' # Create an event model with canonical HRF
#' evmodel <- event_model(
#'   onsets ~ hrf(stimulus),
#'   data = event_data,
#'   block = ~run,
#'   sampling_frame = sframe
#' )
#' 
#' # Get condition labels
#' conditions(evmodel)  # Returns: c("stimulus[face]", "stimulus[house]")
#' 
#' # Create model with multiple basis functions
#' evmodel2 <- event_model(
#'   onsets ~ hrf(stimulus, basis = "fourier", nbasis = 2),
#'   data = event_data,
#'   block = ~run,
#'   sampling_frame = sframe
#' )
#' 
#' # Get conditions with basis functions
#' conditions(evmodel2)  # Returns conditions with basis labels
#' @export
#' @family conditions
#' @seealso [cells()], [event_model()], [hrf()]
conditions <- function(x, ...) UseMethod("conditions")



#' Convolve a term with a hemodynamic response function
#'
#' @description
#' This function convolves an event sequence with a hemodynamic response function (HRF) 
#' over a specified time series grid. The convolution models the expected BOLD response 
#' to the events. For event-related designs, each event is convolved with the HRF and 
#' the results are summed. For block designs, the duration of each event is taken into 
#' account during convolution.
#'
#' @param x The event sequence (typically an event_term or event_model)
#' @param hrf The hemodynamic response function to use for convolution
#' @param sampling_frame The time series grid over which to sample the convolved function
#' @param ... Additional arguments passed to methods. Common arguments include:
#'   \itemize{
#'     \item{drop.empty}{Logical; if TRUE, empty events are dropped}
#'     \item{summate}{Logical; if TRUE, sum the convolved HRF over event durations}
#'     \item{precision}{Numeric; precision of HRF sampling (default: 0.3)}
#'   }
#' @return A tibble containing the convolved design matrix, with columns for each condition
#' @examples
#' # Create a simple event-related design
#' event_data <- data.frame(
#'   condition = factor(c("A", "B", "A", "B")),
#'   onsets = c(1, 10, 20, 30),
#'   run = c(1, 1, 1, 1)
#' )
#' 
#' # Create a sampling frame
#' sframe <- sampling_frame(blocklens = 50, TR = 2)
#' 
#' # Create an event term
#' eterm <- event_term(
#'   list(condition = event_data$condition),
#'   onsets = event_data$onsets,
#'   blockids = event_data$run
#' )
#' 
#' # Convolve with canonical HRF
#' convolved <- convolve(eterm, HRF_SPMG1, sframe)
#' 
#' # Convolve with multiple basis functions
#' convolved_fourier <- convolve(
#'   eterm, 
#'   getHRF("fourier", nbasis = 2),
#'   sframe
#' )
#' @export
#' @family convolution
#' @seealso [HRF_SPMG1()], [event_term()], [sampling_frame()]
convolve <- function(x, hrf, sampling_frame, ...) UseMethod("convolve")


#' Check if a variable is continuous
#' 
#' @description
#' Determines if a variable represents continuous (numeric) rather than categorical data.
#' For event terms, continuous variables are those that have numeric values (like amplitudes 
#' or modulators) rather than discrete factor levels. For example, reaction times would be 
#' continuous, while trial types would be categorical.
#' 
#' @param x The object to check (typically an event_term, event_seq, or event_matrix)
#' @return Logical; TRUE if the variable is continuous (numeric), FALSE if categorical
#' @examples
#' # Create event terms with different types
#' 
#' # Categorical event (factor)
#' event_data <- data.frame(
#'   condition = factor(c("A", "B", "A", "B")),
#'   onsets = c(1, 10, 20, 30),
#'   run = c(1, 1, 1, 1)
#' )
#' cat_term <- event_term(
#'   list(condition = event_data$condition),
#'   onsets = event_data$onsets,
#'   blockids = event_data$run
#' )
#' is_continuous(cat_term)  # Returns: FALSE
#' 
#' # Continuous event (numeric)
#' event_data$rt <- c(0.8, 1.2, 0.9, 1.1)  # reaction times
#' cont_term <- event_term(
#'   list(rt = event_data$rt),
#'   onsets = event_data$onsets,
#'   blockids = event_data$run
#' )
#' is_continuous(cont_term)  # Returns: TRUE
#' @export
#' @family variable_type
#' @seealso [is_categorical()], [event_term()]
is_continuous <- function(x) UseMethod("is_continuous")



#' Check if a variable is categorical
#' 
#' @description
#' Determines if a variable represents categorical (factor-based) rather than continuous data.
#' For event terms, categorical variables are those that have discrete factor levels (like 
#' trial types or conditions) rather than numeric values. For example, stimulus types 
#' ("face", "house") would be categorical, while reaction times would be continuous.
#' This function is complementary to [is_continuous()].
#' 
#' @param x The object to check (typically an event_term, event_seq, or event_matrix)
#' @return Logical; TRUE if the variable is categorical (factor-based), FALSE if continuous
#' @examples
#' # Create event terms with different types
#' 
#' # Categorical event (factor)
#' event_data <- data.frame(
#'   condition = factor(c("face", "house", "face", "house")),
#'   onsets = c(1, 10, 20, 30),
#'   run = c(1, 1, 1, 1)
#' )
#' cat_term <- event_term(
#'   list(condition = event_data$condition),
#'   onsets = event_data$onsets,
#'   blockids = event_data$run
#' )
#' is_categorical(cat_term)  # Returns: TRUE
#' 
#' # Continuous event (numeric)
#' event_data$intensity <- c(0.8, 1.2, 0.9, 1.1)  # stimulus intensity
#' cont_term <- event_term(
#'   list(intensity = event_data$intensity),
#'   onsets = event_data$onsets,
#'   blockids = event_data$run
#' )
#' is_categorical(cont_term)  # Returns: FALSE
#' @export
#' @family variable_type
#' @seealso [is_continuous()], [event_term()]
is_categorical <- function(x) UseMethod("is_categorical")

#' levels
#' 
#' Extract the levels of a term. For categorical terms (event_factor), this returns the 
#' factor levels. For continuous terms (event_variable), this returns the variable name. 
#' For matrix terms, this returns the column names. For event terms with multiple factors, 
#' this returns the interaction of all factor levels.
#' 
#' @param x The term (typically an event_factor, event_variable, event_matrix, or event_term)
#' @return A character vector containing:
#'   \itemize{
#'     \item For event_factor: The factor levels
#'     \item For event_variable: The variable name
#'     \item For event_matrix: The column names
#'     \item For event_term: The interaction of factor levels for categorical variables
#'   }
#' @examples
#' # Factor event
#' event_data <- data.frame(
#'   stimulus = factor(c("face", "house", "face", "house")),
#'   onsets = c(1, 10, 20, 30),
#'   run = c(1, 1, 1, 1)
#' )
#' fac_term <- event_term(
#'   list(stimulus = event_data$stimulus),
#'   onsets = event_data$onsets,
#'   blockids = event_data$run
#' )
#' levels(fac_term)  # Returns: c("face", "house")
#' 
#' # Multiple factor event
#' event_data$location <- factor(c("left", "right", "left", "right"))
#' multi_term <- event_term(
#'   list(
#'     stimulus = event_data$stimulus,
#'     location = event_data$location
#'   ),
#'   onsets = event_data$onsets,
#'   blockids = event_data$run
#' )
#' levels(multi_term)  # Returns: c("face:left", "house:left", "face:right", "house:right")
#' @export
#' @family term_properties
#' @seealso [event_term()], [event_factor()], [event_variable()]
levels <- function(x) UseMethod("levels")



#' columns
#' 
#' return the column labels associated with the elements of a term.
#' 
#' @param x the term
#' @keywords internal
#' @noRd
columns <- function(x) UseMethod("columns")



#' Extract event table from a term or model
#'
#' @description
#' Extract the event table from a term or model as a data frame. The event table contains 
#' the experimental design information, with one row per event and columns for different 
#' variables (e.g., conditions, onsets, durations). For event terms, this returns the raw 
#' event data. For convolved terms, this includes any basis function expansions.
#'
#' @param x The object to extract events from (typically an event_term, convolved_term, or event_model)
#' @return A tibble containing the event information with columns for:
#'   \itemize{
#'     \item Factor variables (e.g., condition, stimulus type)
#'     \item Continuous variables (e.g., reaction times, intensities)
#'     \item Basis function expansions (if applicable)
#'   }
#' @examples
#' # Create an event term with multiple variables
#' event_data <- data.frame(
#'   condition = factor(c("face", "house", "face", "house")),
#'   rt = c(0.8, 1.2, 0.9, 1.1),
#'   onsets = c(1, 10, 20, 30),
#'   run = c(1, 1, 1, 1)
#' )
#' 
#' # Create event term
#' eterm <- event_term(
#'   list(
#'     condition = event_data$condition,
#'     rt = event_data$rt
#'   ),
#'   onsets = event_data$onsets,
#'   blockids = event_data$run
#' )
#' 
#' # Extract event table
#' etable <- event_table(eterm)
#' 
#' # Create and extract from convolved term
#' sframe <- sampling_frame(blocklens = 50, TR = 2)
#' evmodel <- event_model(
#'   onsets ~ hrf(condition) + hrf(rt),
#'   data = event_data,
#'   block = ~run,
#'   sampling_frame = sframe
#' )
#' 
#' # Get event table with basis expansions
#' model_events <- event_table(evmodel)
#' @export
#' @family events
#' @seealso [event_term()], [event_model()]
event_table <- function(x) UseMethod("event_table")



#' Extract event terms from a model
#'
#' @description
#' Extract the event-related terms from a model object, separating them from baseline 
#' or nuisance terms. Event terms represent the experimental conditions and parametric 
#' modulators in an fMRI design. For example, in a model with both task events 
#' (e.g., stimulus presentations) and baseline components (e.g., drift terms, motion 
#' parameters), this function returns only the task-related terms.
#'
#' @param x The model object (typically an fmri_model)
#' @return A list of event_term objects. Each event_term represents a different 
#' component of the experimental design and contains:
#'   \itemize{
#'     \item varname: Name of the term (e.g., "stimulus", "rt")
#'     \item events: List of event objects (factors or continuous variables)
#'     \item event_table: Data frame of event information
#'     \item onsets: Event onset times in seconds
#'     \item blockids: Run/block identifiers
#'     \item durations: Event durations in seconds
#'   }
#' @examples
#' # Create a model with both event and baseline terms
#' event_data <- data.frame(
#'   stimulus = factor(c("face", "house", "face", "house")),
#'   rt = c(0.8, 1.2, 0.9, 1.1),
#'   onsets = c(1, 10, 20, 30),
#'   run = c(1, 1, 1, 1)
#' )
#' 
#' # Create sampling frame
#' sframe <- sampling_frame(blocklens = 50, TR = 2)
#' 
#' # Create event model
#' evmodel <- event_model(
#'   onsets ~ hrf(stimulus) + hrf(rt),
#'   data = event_data,
#'   block = ~run,
#'   sampling_frame = sframe
#' )
#' 
#' # Create baseline model for drift
#' bmodel <- baseline_model(
#'   basis = "bs",
#'   degree = 3,
#'   sframe = sframe
#' )
#' 
#' # Combine into full model
#' fmodel <- fmri_model(evmodel, bmodel)
#' 
#' # Extract only the event terms
#' event_terms(fmodel)  # Returns list of stimulus and rt terms
#' @export
#' @family model_components
#' @seealso [baseline_terms()], [fmri_model()]
event_terms <- function(x) UseMethod("event_terms")



#' Extract baseline terms from a model
#'
#' @description
#' Extract the baseline and nuisance terms from a model object, separating them from 
#' experimental event terms. Baseline terms represent non-experimental components of the 
#' fMRI signal, such as:
#' \itemize{
#'   \item Drift terms (modeling scanner drift)
#'   \item Block terms (modeling run-specific baselines)
#'   \item Nuisance terms (e.g., motion parameters, physiological noise)
#' }
#'
#' @param x The model object (typically an fmri_model)
#' @return A list of baseline_term objects. Each baseline_term represents a different 
#' component of the non-experimental signal and contains:
#'   \itemize{
#'     \item varname: Name of the term (e.g., "drift", "block", "motion")
#'     \item design_matrix: Matrix of baseline regressors
#'     \item term_type: Type of baseline term ("drift", "block", or "nuisance")
#'   }
#' @examples
#' # Create a model with both event and baseline terms
#' event_data <- data.frame(
#'   stimulus = factor(c("face", "house", "face", "house")),
#'   onsets = c(1, 10, 20, 30),
#'   run = c(1, 1, 1, 1)
#' )
#' 
#' # Create sampling frame
#' sframe <- sampling_frame(blocklens = 50, TR = 2)
#' 
#' # Create event model
#' evmodel <- event_model(
#'   onsets ~ hrf(stimulus),
#'   data = event_data,
#'   block = ~run,
#'   sampling_frame = sframe
#' )
#' 
#' # Create baseline model with drift and block terms
#' bmodel <- baseline_model(
#'   basis = "bs",    # B-spline basis for drift
#'   degree = 3,      # Cubic drift model
#'   sframe = sframe
#' )
#' 
#' # Combine into full model
#' fmodel <- fmri_model(evmodel, bmodel)
#' 
#' # Extract only the baseline terms
#' baseline_terms(fmodel)  # Returns list with drift and block terms
#' @export
#' @family model_components
#' @seealso [event_terms()], [fmri_model()], [baseline_model()]
baseline_terms <- function(x) UseMethod("baseline_terms")


#' Get term indices from a model or term
#'
#' @description
#' Get the indices that map between model terms and their corresponding columns in the 
#' design matrix. These indices are essential for:
#' \itemize{
#'   \item Extracting coefficients for specific terms
#'   \item Computing contrasts for specific model components
#'   \item Mapping between event terms and baseline terms
#'   \item Identifying which design matrix columns belong to which terms
#' }
#'
#' @param x The model or term object (typically an fmri_model, event_model, or convolved_term)
#' @param ... Additional arguments passed to methods
#' @return A named list where each element contains the column indices in the design matrix 
#' corresponding to that term. For example:
#' \itemize{
#'   \item For event terms: Indices for each experimental condition
#'   \item For baseline terms: Indices for drift and block terms
#'   \item For convolved terms: Indices for each basis function
#' }
#' @examples
#' # Create a model with multiple terms
#' event_data <- data.frame(
#'   stimulus = factor(c("face", "house", "face", "house")),
#'   rt = c(0.8, 1.2, 0.9, 1.1),
#'   onsets = c(1, 10, 20, 30),
#'   run = c(1, 1, 1, 1)
#' )
#' 
#' # Create sampling frame
#' sframe <- sampling_frame(blocklens = 50, TR = 2)
#' 
#' # Create event model with multiple terms
#' evmodel <- event_model(
#'   onsets ~ hrf(stimulus) + hrf(rt, basis = "fourier", nbasis = 2),
#'   data = event_data,
#'   block = ~run,
#'   sampling_frame = sframe
#' )
#' 
#' # Get indices for each term
#' indices <- term_indices(evmodel)
#' # Returns list with:
#' #  - Indices for stimulus conditions
#' #  - Indices for rt basis functions
#' 
#' # Create full model with baseline
#' bmodel <- baseline_model(basis = "bs", degree = 3, sframe = sframe)
#' fmodel <- fmri_model(evmodel, bmodel)
#' 
#' # Get indices for full model
#' full_indices <- term_indices(fmodel)
#' # Returns indices for both event and baseline terms
#' @export
#' @family model_components
#' @seealso [event_terms()], [baseline_terms()], [design_matrix()]
term_indices <- function(x, ...) UseMethod("term_indices")

#' @export
term_indices.event_model <- function(x, ...) {
  # Extract col_indices from the design matrix attribute
  col_indices <- attr(x$design_matrix, "col_indices")
  if (is.null(col_indices)) {
    warning("Event model design matrix missing 'col_indices' attribute.")
    return(NULL)
  }
  return(col_indices)
}




#' run
#'
#' Run a command or analysis step.
#'
#' @description
#' This function runs a command `x` with the provided extra arguments.
#'
#' @param x the command to run
#' @param ... extra args
#' @noRd
run <- function(x,...) UseMethod("run")


#' design_matrix
#' 
#' Extract or construct the design matrix from a model term or object. The design matrix
#' contains the predictor variables used in the model, with one row per time point and
#' one column per predictor. For event-related designs, the design matrix typically
#' contains the convolved HRF responses. For baseline terms, it contains drift and
#' nuisance regressors.
#' 
#' @details
#' ### Column Naming (Post-Refactor)
#' As of version X.Y.Z, column names in the final design matrix generated by 
#' `event_model` follow the structure: 
#' `term_tag` + `_` + `condition_tag` + `_b##` basis suffix
#' 
#' Refer to `event_model` documentation for details on `term_tag` and `condition_tag` generation.
#' The `design_matrix` methods for individual term types (like `design_matrix.event_term`)
#' return unconvolved predictors whose names may *not* yet follow this final structure.
#' The final naming is applied by `convolve.event_term` and assembled by 
#' `build_event_model_design_matrix`.
#' 
#' @param x The term or model object (typically an event_term, event_model, baseline_model, or fmri_model)
#' @param ... Additional arguments passed to methods. Common arguments include:
#' \itemize{
#'   \item{blockid}{Numeric vector specifying which blocks/runs to include}
#' }
#' 
#' @return A tibble containing the design matrix, where:
#' \itemize{
#'   \item Rows represent time points (scans)
#'   \item Columns represent predictor variables
#'   \item Column names indicate the condition or regressor (see Details)
#' }
#' @export
#' @rdname design_matrix
#' @family design_matrices
#' @seealso [event_model()], [baseline_model()], [fmri_model()]
design_matrix <- function(x, ...) { UseMethod("design_matrix") }

#' elements
#' 
#' Return the ordered elements of a term or variable.
#' 
#' @description
#' Extract the unique elements from a term or variable in their natural order. For 
#' categorical variables (factors), this returns the factor levels. For continuous 
#' variables, this returns the unique values in ascending order. For event terms with 
#' multiple variables, this returns the combined elements.
#' 
#' @param x The term or variable object (typically an event_term, event_factor, or event_variable)
#' @param ... Additional arguments passed to methods
#' @return A vector containing the ordered elements:
#'   \itemize{
#'     \item For factors: The factor levels in their defined order
#'     \item For numeric variables: Unique values in ascending order
#'     \item For event terms: Combined elements from all variables
#'   }
#' @examples
#' # Create event terms with different types
#' 
#' # Categorical variable
#' event_data <- data.frame(
#'   condition = factor(c("A", "B", "A", "B"), levels = c("B", "A")),
#'   onsets = c(1, 10, 20, 30),
#'   run = c(1, 1, 1, 1)
#' )
#' cat_term <- event_term(
#'   list(condition = event_data$condition),
#'   onsets = event_data$onsets,
#'   blockids = event_data$run
#' )
#' elements(cat_term)  # Returns: c("B", "A")
#' 
#' # Continuous variable
#' event_data$rt <- c(1.2, 0.8, 1.1, 0.9)
#' cont_term <- event_term(
#'   list(rt = event_data$rt),
#'   onsets = event_data$onsets,
#'   blockids = event_data$run
#' )
#' elements(cont_term)  # Returns: c(0.8, 0.9, 1.1, 1.2)
#' @export
#' @family term_properties
#' @seealso [levels()], [event_term()]
elements <- function(x, ...) UseMethod("elements")


#' correlation_map
#'
#' Create a correlation heatmap for an fMRI design matrix.
#'
#' @description
#' Generate a correlation heatmap showing the relationships between columns in a design 
#' matrix. This visualization helps identify potential collinearity between regressors 
#' in the model. For event models, it shows correlations between different conditions. 
#' For baseline models, it shows correlations between drift and nuisance terms.
#'
#' @param x The model object (event_model, baseline_model, or fmri_model)
#' @param ... Additional arguments passed to methods. Common arguments include:
#'   \describe{
#'     \item{method}{Correlation method ("pearson" or "spearman")}
#'     \item{half_matrix}{Logical; if TRUE, show only lower triangle}
#'     \item{absolute_limits}{Logical; if TRUE, set color limits to \[-1,1\]}
#'   }
#' @return A ggplot2 object containing the correlation heatmap, where:
#'   \itemize{
#'     \item Rows and columns represent model terms
#'     \item Colors indicate correlation strength (-1 to 1)
#'     \item Darker colors indicate stronger correlations
#'   }
#' @examples
#' # Create event data
#' event_data <- data.frame(
#'   condition = factor(c("face", "house", "face", "house")),
#'   rt = c(0.8, 1.2, 0.9, 1.1),
#'   onsets = c(1, 10, 20, 30),
#'   run = c(1, 1, 1, 1)
#' )
#' 
#' # Create sampling frame
#' sframe <- sampling_frame(blocklens = 50, TR = 2)
#' 
#' # Create event model
#' evmodel <- event_model(
#'   onsets ~ hrf(condition) + hrf(rt),
#'   data = event_data,
#'   block = ~run,
#'   sampling_frame = sframe
#' )
#' 
#' # Plot correlation map for event model
#' correlation_map(evmodel)
#' 
#' # Create baseline model
#' bmodel <- baseline_model(
#'   basis = "bs",
#'   degree = 3,
#'   sframe = sframe
#' )
#' 
#' # Plot correlation map for baseline model
#' correlation_map(bmodel)
#' 
#' # Create full model and plot combined correlations
#' fmodel <- fmri_model(evmodel, bmodel)
#' correlation_map(fmodel, method = "pearson", half_matrix = TRUE)
#' @export
#' @family visualization
#' @seealso [event_model()], [baseline_model()]
correlation_map <- function(x, ...) {
  UseMethod("correlation_map")
}



#' Evaluate a regressor object over a time grid
#' 
#' Generic function to evaluate a regressor object over a specified time grid.
#' Different types of regressors may have different evaluation methods.
#'
#' @param x The regressor object to evaluate
#' @param grid A numeric vector specifying the time points at which to evaluate the regressor
#' @param ... Additional arguments passed to specific methods
#' @return A numeric vector or matrix containing the evaluated regressor values
#' @seealso [single_trial_regressor()], [regressor()]
#' @export
evaluate <- function(x, grid, ...) {
  UseMethod("evaluate")
}


#' fitted_hrf
#'
#' This generic function computes the fitted hemodynamic response function (HRF) for an object.
#' The method needs to be implemented for specific object types.
#'
#' @description
#' Compute and return the fitted hemodynamic response function (HRF) for a model object. 
#' The HRF represents the expected BOLD response to neural activity. For models with 
#' multiple basis functions, this returns the combined HRF shape.
#'
#' @param x An object for which the fitted HRF should be computed
#' @param sample_at A vector of time points at which the HRF should be sampled
#' @param ... Additional arguments passed to methods
#' @return A numeric vector containing the fitted HRF values at the requested time points
#' @examples
#' # Create a simple dataset with two conditions
#' X <- matrix(rnorm(100 * 100), 100, 100)  # 100 timepoints, 100 voxels
#' event_data <- data.frame(
#'   condition = factor(c("A", "B", "A", "B")),
#'   onsets = c(1, 25, 50, 75),
#'   run = c(1, 1, 1, 1)
#' )
#' 
#' # Create dataset and sampling frame
#' dset <- matrix_dataset(X, TR = 2, run_length = 100, event_table = event_data)
#' sframe <- sampling_frame(blocklens = 100, TR = 2)
#' 
#' # Create event model with canonical HRF
#' evmodel <- event_model(
#'   onsets ~ hrf(condition),
#'   data = event_data,
#'   block = ~run,
#'   sampling_frame = sframe
#' )
#' 
#' # Fit model
#' fit <- fmri_lm(
#'   onsets ~ hrf(condition),
#'   block = ~run,
#'   dataset = dset
#' )
#' 
#' # Get fitted HRF at specific timepoints
#' times <- seq(0, 20, by = 0.5)  # Sample from 0-20s every 0.5s
#' hrf_values <- fitted_hrf(fit, sample_at = times)
#' @export
#' @family hrf
#' @seealso [HRF_SPMG1()], [fmri_lm()]
fitted_hrf <- function(x, sample_at, ...) UseMethod("fitted_hrf")


#' Extract regressor set
#' 
#' @description
#' Extract a set of regressors from a model object. Regressors represent the predicted 
#' BOLD response for different experimental conditions or model components. For event-related 
#' designs, each regressor is typically a convolution of event onsets with an HRF. For 
#' baseline terms, regressors might represent drift or nuisance components.
#' 
#' @param x A model object that contains regressors (or can generate them)
#' @param ... Additional arguments passed to methods. Common arguments include:
#'   \describe{
#'     \item{condition}{Character; specific condition to extract regressors for}
#'     \item{block}{Numeric; specific block/run to extract regressors from}
#'     \item{basis}{Character; type of basis functions to use}
#'   }
#' @return A list of regressor objects, where each regressor contains:
#'   \itemize{
#'     \item values: Numeric vector of regressor values over time
#'     \item onsets: Original event onset times
#'     \item condition: Associated experimental condition
#'     \item block: Associated run/block number
#'   }
#' @examples
#' # Create event data with two conditions
#' event_data <- data.frame(
#'   condition = factor(c("face", "house", "face", "house")),
#'   onsets = c(1, 10, 20, 30),
#'   run = c(1, 1, 1, 1)
#' )
#' 
#' # Create sampling frame
#' sframe <- sampling_frame(blocklens = 50, TR = 2)
#' 
#' # Create event model with canonical HRF
#' evmodel <- event_model(
#'   onsets ~ hrf(condition),
#'   data = event_data,
#'   block = ~run,
#'   sampling_frame = sframe
#' )
#' 
#' # Extract all regressors
#' reg_list <- regressors(evmodel)
#' 
#' # Create model with multiple basis functions
#' evmodel2 <- event_model(
#'   onsets ~ hrf(condition, basis = "fourier", nbasis = 2),
#'   data = event_data,
#'   block = ~run,
#'   sampling_frame = sframe
#' )
#' 
#' # Extract regressors with basis functions
#' reg_list2 <- regressors(evmodel2)
#' @export
#' @family regressors
#' @seealso [event_model()], [HRF_SPMG1()], [convolve()]
regressors <- function(x, ...) UseMethod("regressors")

#' Shift a time series object
#'
#' @description
#' Apply a temporal shift to a time series object. This function shifts the values in time 
#' while preserving the structure of the object. Common uses include:
#' \describe{
#'   \item{alignment}{Aligning regressors with different temporal offsets}
#'   \item{derivatives}{Applying temporal derivatives to time series}
#'   \item{correction}{Correcting for timing differences between signals}
#' }
#'
#' @param x An object representing a time series or a time-based data structure
#' @param ... Additional arguments passed to methods. Common arguments include:
#'   \describe{
#'     \item{offset}{Numeric; amount to shift by (positive = forward, negative = backward)}
#'     \item{pad}{Value to use for padding shifted regions (default = 0)}
#'   }
#' @return An object of the same class as the input, with values shifted in time:
#'   \describe{
#'     \item{Values}{Values are moved by the specified offset}
#'     \item{Structure}{Object structure and dimensions are preserved}
#'     \item{Padding}{Empty regions are filled with padding value}
#'   }
#' @examples
#' # Create a simple time series with events
#' event_data <- data.frame(
#'   onsets = c(1, 10, 20, 30),
#'   run = c(1, 1, 1, 1)
#' )
#' 
#' # Create sampling frame
#' sframe <- sampling_frame(blocklens = 50, TR = 2)
#' 
#' # Create regressor from events
#' reg <- regressor(
#'   onsets = event_data$onsets,
#'   sampling_frame = sframe
#' )
#' 
#' # Shift regressor forward by 2 seconds
#' reg_forward <- shift(reg, offset = 2)
#' 
#' # Shift regressor backward by 1 second
#' reg_backward <- shift(reg, offset = -1)
#' 
#' # Evaluate original and shifted regressors
#' times <- seq(0, 50, by = 2)
#' orig_values <- evaluate(reg, times)
#' shifted_values <- evaluate(reg_forward, times)
#' @export
#' @family time_series
#' @seealso [regressor()], [evaluate()]
shift <- function(x, ...) {
  UseMethod("shift")
}




#' Return the global onsets of an object
#' 
#' @description
#' Convert relative onset times to global (cumulative) onset times across runs. Global onsets 
#' are defined as cumulative time over runs, meaning they do not reset to zero for each run. 
#' This is useful for:
#' \itemize{
#'   \item Converting run-specific onsets to experiment-wide timings
#'   \item Aligning events across multiple runs
#'   \item Computing temporal distances between events in different runs
#' }
#'
#' @param x The object containing timing information (typically a sampling_frame)
#' @param onsets A numeric vector of relative onset times within each run/block
#' @param ... Additional arguments passed to methods. Common arguments include:
#' \describe{
#'   \item{blockids}{Numeric vector specifying which block/run each onset belongs to}
#'   \item{TR}{Numeric; repetition time in seconds}
#' }
#' @return A numeric vector of global onset times where:
#'   \itemize{
#'     \item Each onset is adjusted by the cumulative duration of previous runs
#'     \item Times are in the same units as the input onsets (typically seconds)
#'     \item NA is returned for onsets that exceed their block duration
#'   }
#' @examples
#' # Create a sampling frame with three runs
#' sframe <- sampling_frame(
#'   blocklens = c(100, 100, 100),  # 100 scans per run
#'   TR = 2                         # 2 seconds per scan
#' )
#' 
#' # Define events in each run
#' run_onsets <- c(10, 20, 30)     # Events at 10s, 20s, 30s
#' run_ids <- c(1, 2, 3)           # One event per run
#' 
#' # Convert to global onsets
#' global_times <- global_onsets(
#'   sframe,
#'   onsets = run_onsets,
#'   blockids = run_ids
#' )
#' # Returns: c(10, 220, 430)
#' # Because:
#' #  - Run 1: 10s
#' #  - Run 2: 20s + (100 scans * 2s) = 220s
#' #  - Run 3: 30s + (200 scans * 2s) = 430s
#' @export
#' @family timing
#' @seealso [sampling_frame()], [event_model()]
global_onsets <- function(x, onsets, ...) UseMethod("global_onsets")



#' Return number of basis functions associated with HRF
#' 
#' @description
#' Get the number of basis functions used in a hemodynamic response function (HRF) or 
#' model term. For canonical HRFs (like SPM's canonical HRF), this returns 1. For 
#' flexible basis sets (like Fourier or B-spline bases), this returns the number of 
#' basis functions used to model the response shape.
#' 
#' @param x The object to query (typically an HRF, hrfspec, or convolved_term)
#' @param ... Additional arguments passed to methods
#' @return An integer indicating the number of basis functions:
#'   \itemize{
#'     \item 1 for canonical HRFs (e.g., SPM gamma)
#'     \item >1 for flexible basis sets (e.g., Fourier, B-spline)
#'     \item For convolved terms: number of basis functions per condition
#'   }
#' @examples
#' # Check basis functions for different HRF types
#' 
#' # Canonical HRF (single basis)
#' canonical_hrf <- HRF_SPMG1
#' nbasis(canonical_hrf)  # Returns: 1
#' 
#' # Fourier basis set
#' fourier_hrf <- getHRF("fourier", nbasis = 3)
#' nbasis(fourier_hrf)  # Returns: 3
#' 
#' # Create event model with multiple basis functions
#' event_data <- data.frame(
#'   condition = factor(c("A", "B", "A", "B")),
#'   onsets = c(1, 10, 20, 30),
#'   run = c(1, 1, 1, 1)
#' )
#' sframe <- sampling_frame(blocklens = 50, TR = 2)
#' 
#' # Model with Fourier basis
#' evmodel <- event_model(
#'   onsets ~ hrf(condition, basis = "fourier", nbasis = 3),
#'   data = event_data,
#'   block = ~run,
#'   sampling_frame = sframe
#' )
#' 
#' # Get number of basis functions for model term
#' nbasis(evmodel)  # Returns: 3 (basis functions per condition)
#' @export
#' @family hrf
#' @seealso [HRF_SPMG1()], [event_model()]
nbasis <- function(x, ...) UseMethod("nbasis")


#' Generate penalty matrix for regularization
#'
#' @description
#' Generate a penalty matrix for regularizing HRF basis coefficients. The penalty matrix
#' encodes shape priors that discourage implausible or overly wiggly HRF estimates.
#' Different HRF types use different penalty structures:
#' 
#' \itemize{
#'   \item{FIR/B-spline bases: Roughness penalties based on discrete derivatives}
#'   \item{SPM canonical + derivatives: Differential shrinkage of derivative terms}
#'   \item{Fourier bases: Penalties on high-frequency components}
#'   \item{Default: Identity matrix (ridge penalty)}
#' }
#'
#' @param x The HRF object or basis specification
#' @param ... Additional arguments passed to specific methods
#' @return A symmetric positive definite penalty matrix of dimension nbasis(x) × nbasis(x)
#' @details
#' The penalty matrix R is used in regularized estimation as λ * h^T R h, where h are
#' the basis coefficients and λ is the regularization parameter. Well-designed penalty
#' matrices can significantly improve HRF estimation by encoding smoothness or other
#' shape constraints.
#' 
#' @examples
#' # FIR basis with smoothness penalty
#' fir_hrf <- HRF_FIR
#' R_fir <- penalty_matrix(fir_hrf)
#' 
#' # B-spline basis with second-order smoothness
#' bspline_hrf <- HRF_BSPLINE  
#' R_bspline <- penalty_matrix(bspline_hrf, order = 2)
#' 
#' # SPM canonical with derivative shrinkage
#' spmg3_hrf <- HRF_SPMG3
#' R_spmg3 <- penalty_matrix(spmg3_hrf, shrink_deriv = 4)
#' 
#' @export
#' @family hrf
#' @seealso [nbasis()], [HRF_objects]
penalty_matrix <- function(x, ...) UseMethod("penalty_matrix")


 
#' Return a set of data chunks
#' 
#' @description
#' Split a dataset into manageable chunks for processing. This is particularly useful 
#' for parallel processing of large fMRI datasets. Chunks can be created either by run 
#' (runwise=TRUE) or by dividing the data into a specified number of pieces. Each chunk 
#' contains a subset of the data and metadata about its position in the full dataset.
#' 
#' @param x The dataset to chunk (typically an fmri_dataset or matrix_dataset)
#' @param nchunks Integer; number of chunks to create (ignored if runwise=TRUE)
#' @param ... Additional arguments passed to methods. Common arguments include:
#'   \describe{
#'     \item{runwise}{Logical; if TRUE, create one chunk per run}
#'     \item{parallel}{Logical; if TRUE, prepare chunks for parallel processing}
#'   }
#' @return An iterator object that yields data chunks, where each chunk contains:
#'   \describe{
#'     \item{data}{Matrix of data values for this chunk}
#'     \item{chunk_num}{Index of this chunk}
#'     \item{voxel_ind}{Indices of voxels in this chunk}
#'     \item{row_ind}{Indices of timepoints in this chunk}
#'   }
#' @examples
#' # Create a simple matrix dataset
#' X <- matrix(rnorm(100 * 1000), 100, 1000)  # 100 timepoints, 1000 voxels
#' dset <- matrix_dataset(
#'   X, 
#'   TR = 2,
#'   run_length = c(50, 50)  # Two runs of 50 timepoints each
#' )
#' 
#' # Create chunks by run
#' run_chunks <- data_chunks(dset, runwise = TRUE)
#' 
#' # Process each run chunk
#' foreach::foreach(chunk = run_chunks) %do% {
#'   # chunk$data contains the data for one run
#'   # chunk$row_ind shows which timepoints are included
#'   mean_signal <- colMeans(chunk$data)
#' }
#' 
#' # Create arbitrary number of chunks
#' vox_chunks <- data_chunks(dset, nchunks = 4)
#' 
#' # Process chunks in parallel
#' foreach::foreach(chunk = vox_chunks) %dopar% {
#'   # chunk$data contains subset of voxels
#'   # chunk$voxel_ind shows which voxels are included
#'   apply(chunk$data, 2, sd)
#' }
#' @export
#' @family iterators
#' @seealso [matrix_dataset()], [fmri_dataset()], [foreach::foreach()]
data_chunks <- function(x, nchunks, ...) UseMethod("data_chunks")


#' Get event onsets from an object
#' 
#' @description
#' Extract the onset times of events from a model object. Onsets represent the timing of 
#' experimental events in an fMRI design, typically in seconds from the start of each run. 
#' These times are used to:
#' \itemize{
#'   \item Create regressors by convolving with HRF
#'   \item Verify event timing in the design
#'   \item Analyze temporal patterns of events
#' }
#'
#' @param x The object containing event information (typically an event_term or event_model)
#' @return A numeric vector of onset times in seconds, where:
#'   \itemize{
#'     \item Each value represents the start time of an event
#'     \item Times are relative to the start of each run
#'     \item Order matches the original event sequence
#'   }
#' @examples
#' # Create event data with multiple conditions
#' event_data <- data.frame(
#'   condition = factor(c("face", "house", "face", "house")),
#'   onsets = c(1, 10, 20, 30),
#'   run = c(1, 1, 1, 1)
#' )
#' 
#' # Create sampling frame
#' sframe <- sampling_frame(blocklens = 50, TR = 2)
#' 
#' # Create event term
#' eterm <- event_term(
#'   list(condition = event_data$condition),
#'   onsets = event_data$onsets,
#'   blockids = event_data$run
#' )
#' 
#' # Get onsets from term
#' onset_times <- onsets(eterm)  # Returns: c(1, 10, 20, 30)
#' 
#' # Create and get onsets from event model
#' evmodel <- event_model(
#'   onsets ~ hrf(condition),
#'   data = event_data,
#'   block = ~run,
#'   sampling_frame = sframe
#' )
#' 
#' model_onsets <- onsets(evmodel)
#' @export
#' @family timing
#' @seealso [event_term()], [event_model()], [global_onsets()]
onsets <- function(x) UseMethod("onsets")


#' Get event durations from an object
#' 
#' @description
#' Extract the duration of events from a model object. Durations represent how long each 
#' event lasts in an fMRI design, typically in seconds. These are important for:
#' \itemize{
#'   \item Modeling block designs where stimuli have non-zero duration
#'   \item Creating accurate HRF convolutions for extended events
#'   \item Distinguishing between brief and sustained neural activity
#' }
#'
#' @param x The object containing event information (typically an event_term or event_model)
#' @return A numeric vector of durations in seconds, where:
#'   \itemize{
#'     \item Each value represents how long an event lasts
#'     \item Zero values indicate instantaneous events
#'     \item Order matches the corresponding event sequence
#'   }
#' @examples
#' # Create event data with varying durations
#' event_data <- data.frame(
#'   condition = factor(c("block", "event", "block", "event")),
#'   onsets = c(1, 10, 20, 30),
#'   durations = c(8, 0, 8, 0),  # 8s blocks and instantaneous events
#'   run = c(1, 1, 1, 1)
#' )
#' 
#' # Create event term
#' eterm <- event_term(
#'   list(condition = event_data$condition),
#'   onsets = event_data$onsets,
#'   durations = event_data$durations,
#'   blockids = event_data$run
#' )
#' 
#' # Get durations from term
#' dur <- durations(eterm)  # Returns: c(8, 0, 8, 0)
#' @export
#' @family timing
#' @seealso [onsets()], [event_term()]
durations <- function(x) UseMethod("durations")

#' Get event amplitudes from an object
#' 
#' @description
#' Extract the amplitude or intensity values associated with each event. Amplitudes 
#' represent the strength or magnitude of events and can be used to:
#' \itemize{
#'   \item Model parametric modulation of neural responses
#'   \item Weight events by their intensity or importance
#'   \item Create amplitude-modulated regressors
#' }
#'
#' @param x The object containing event information (typically an event_term or event_model)
#' @return A numeric vector of amplitude values, where:
#'   \itemize{
#'     \item Each value represents the intensity of an event
#'     \item Default value of 1 indicates unmodulated events
#'     \item Order matches the corresponding event sequence
#'   }
#' @examples
#' # Create event data with varying amplitudes
#' event_data <- data.frame(
#'   condition = factor(c("stim", "stim", "stim", "stim")),
#'   onsets = c(1, 10, 20, 30),
#'   intensity = c(0.5, 1.0, 1.5, 2.0),  # Parametrically varying intensity
#'   run = c(1, 1, 1, 1)
#' )
#' 
#' # Create event term with amplitudes
#' eterm <- event_term(
#'   list(condition = event_data$condition),
#'   onsets = event_data$onsets,
#'   amplitudes = event_data$intensity,
#'   blockids = event_data$run
#' )
#' 
#' # Get amplitudes from term
#' amp <- amplitudes(eterm)  # Returns: c(0.5, 1.0, 1.5, 2.0)
#' @export
#' @family event_properties
#' @seealso [event_term()], [onsets()]
amplitudes <- function(x) UseMethod("amplitudes")

#' Extract sampling times
#' 
#' @description
#' Get the sampling times for a regressor or sampling frame. These times represent when 
#' fMRI data was acquired and can be either relative (within each run) or global 
#' (cumulative across runs). Sampling times are used to:
#' \itemize{
#'   \item Evaluate regressors at scan acquisition times
#'   \item Align model predictions with data collection
#'   \item Convert between TR-based and time-based representations
#' }
#'
#' @param x The object containing timing information (typically a sampling_frame or regressor)
#' @param ... Additional arguments passed to methods. Common arguments include:
#'   \describe{
#'     \item{blockids}{Numeric vector specifying which blocks/runs to include}
#'     \item{global}{Logical; if TRUE, return cumulative times across runs}
#'   }
#' @return A numeric vector of sampling times in seconds, where:
#'   \itemize{
#'     \item Each value represents a scan acquisition time
#'     \item Times account for TR (repetition time) spacing
#'     \item If global=FALSE, times reset at the start of each run
#'     \item If global=TRUE, times accumulate across runs
#'   }
#' @examples
#' # Create a sampling frame with multiple runs
#' sframe <- sampling_frame(
#'   blocklens = c(100, 100, 100),  # 100 scans per run
#'   TR = 2,                        # 2 seconds per scan
#'   start_time = 0                 # Start at time 0
#' )
#' 
#' # Get relative sampling times (reset each run)
#' rel_times <- samples(sframe)
#' # First few times: 0, 2, 4, 6, ... (resets each run)
#' 
#' # Get global sampling times (cumulative)
#' glob_times <- samples(sframe, global = TRUE)
#' # Shows: 0, 2, 4, ..., 198, 200, 202, ..., 598
#' 
#' # Get times for specific runs
#' run2_times <- samples(sframe, blockids = 2)
#' # Times for second run only
#' 
#' # Create regressor and get its sampling times
#' event_data <- data.frame(
#'   onsets = c(1, 10, 20),
#'   run = c(1, 1, 1)
#' )
#' reg <- regressor(
#'   onsets = event_data$onsets,
#'   sampling_frame = sframe
#' )
#' reg_times <- samples(reg)
#' @export
#' @family timing
#' @seealso [sampling_frame()], [regressor()], [global_onsets()]
samples <- function(x, ...) UseMethod("samples")

#' Split variables by block ID
#' 
#' @description
#' Split a vector or matrix of values into separate pieces based on block/run IDs. 
#' This function is useful for:
#' \itemize{
#'   \item Separating data into individual runs
#'   \item Processing blocks independently
#'   \item Analyzing run-specific patterns
#' }
#'
#' @param x The object containing data to split (typically a sampling_frame or dataset)
#' @param ... Additional arguments passed to methods
#' @return A list where each element contains data from one block:
#'   \itemize{
#'     \item List length equals number of blocks
#'     \item Each element contains values from one block
#'     \item Order matches the original block sequence
#'   }
#' @examples
#' # Create a sampling frame with multiple runs
#' sframe <- sampling_frame(
#'   blocklens = c(50, 50, 50),  # 3 runs of 50 scans each
#'   TR = 2
#' )
#' 
#' # Create some example data
#' data_values <- rnorm(150)  # 150 values (50 per run)
#' 
#' # Split data by run
#' run_data <- split_by_block(sframe, data_values)
#' # Returns list with 3 elements, each containing 50 values
#' 
#' # Create matrix dataset
#' X <- matrix(rnorm(150 * 10), 150, 10)  # 150 timepoints, 10 voxels
#' dset <- matrix_dataset(
#'   X,
#'   TR = 2,
#'   run_length = c(50, 50, 50)
#' )
#' 
#' # Split matrix data by run
#' run_matrices <- split_by_block(dset)
#' # Returns list with 3 matrices, each 50 x 10
#' @export
#' @family block_operations
#' @seealso [sampling_frame()], [blockids()], [blocklens()]
split_by_block <- function(x, ...) UseMethod("split_by_block")

#' Get block/run indices
#' 
#' @description
#' Get the block or run number associated with each scan/timepoint in the dataset. 
#' Block indices are used to:
#' \itemize{
#'   \item Track which scans belong to which runs
#'   \item Split data by experimental blocks
#'   \item Align events with their corresponding runs
#'   \item Apply run-specific processing
#' }
#'
#' @param x The object containing block information (typically a sampling_frame or dataset)
#' @return A numeric vector where:
#'   \itemize{
#'     \item Each element is the block/run ID for that scan
#'     \item IDs are sequential integers starting from 1
#'     \item Length matches the total number of scans
#'   }
#' @examples
#' # Create a sampling frame with multiple runs
#' sframe <- sampling_frame(
#'   blocklens = c(50, 75, 50),  # Different length runs
#'   TR = 2
#' )
#' 
#' # Get block IDs for all scans
#' block_ids <- blockids(sframe)
#' # Returns: c(1,1,...,1, 2,2,...,2, 3,3,...,3)
#' # 50 ones, 75 twos, 50 threes
#' 
#' # Create a matrix dataset
#' X <- matrix(rnorm(175 * 10), 175, 10)  # 175 timepoints (50+75+50), 10 voxels
#' dset <- matrix_dataset(
#'   X,
#'   TR = 2,
#'   run_length = c(50, 75, 50)
#' )
#' 
#' # Get block IDs from dataset
#' dataset_blocks <- blockids(dset)
#' 
#' # Use block IDs to split data by run
#' run_data <- split(1:nrow(X), dataset_blocks)
#' # Returns list with indices for each run
#' @export
#' @family block_operations
#' @seealso [blocklens()], [split_by_block()], [sampling_frame()]
blockids <- function(x) UseMethod("blockids")

#' Get block/run lengths
#' 
#' @description
#' Get the number of scans or timepoints in each block/run of the dataset. Block lengths 
#' are used to:
#' \itemize{
#'   \item Define the temporal structure of the experiment by specifying scan counts and timing per run
#'   \item Allocate memory for data matrices by pre-allocating arrays based on scan counts
#'   \item Validate data dimensions across runs by checking against expected lengths
#'   \item Calculate global timing information by computing cumulative timing across runs
#' }
#'
#' @param x The object containing block information (typically a sampling_frame or dataset)
#' @param ... Additional arguments passed to methods
#' @return A numeric vector where:
#' \itemize{
#'   \item Each element is the number of scans in a block or run
#'   \item Length equals the number of blocks/runs 
#'   \item Values are positive integers
#' }
#' @examples
#' # Create a sampling frame with varying run lengths
#' sframe <- sampling_frame(
#'   blocklens = c(100, 150, 100),  # Different length runs
#'   TR = 2
#' )
#' 
#' # Get number of scans per run
#' run_lengths <- blocklens(sframe)  # Returns: c(100, 150, 100)
#' 
#' # Use block lengths to create a dataset
#' total_scans <- sum(run_lengths)  # 350 total timepoints
#' X <- matrix(rnorm(total_scans * 10), total_scans, 10)  # 10 voxels
#' dset <- matrix_dataset(
#'   X,
#'   TR = 2,
#'   run_length = run_lengths
#' )
#' 
#' # Verify block lengths in dataset
#' dset_lengths <- blocklens(dset)
#' 
#' # Use lengths to create time vectors for each run
#' time_vectors <- lapply(run_lengths, function(len) seq(0, by = 2, length.out = len))
#' @export
#' @family block_operations
#' @seealso [blockids()], [split_by_block()], [sampling_frame()]
blocklens <- function(x, ...) UseMethod("blocklens")

#' Generate F-contrasts for a model term
#' 
#' @description
#' Create F-contrasts to test for overall effects of model terms. F-contrasts are used to:
#'\describe{
#'   \item{categorical}{Test for any effect of a categorical predictor}
#'   \item{basis}{Compare multiple basis functions simultaneously}
#'   \item{nonlinear}{Test for nonlinear effects of continuous predictors}
#'   \item{overall}{Evaluate overall significance of model terms}
#'}
#'
#' @param x The model term to generate contrasts for (typically an event_term or event_model)
#' @param ... Additional arguments passed to methods. Common arguments include:
#'\describe{
#'     \item{basis}{Character; type of basis functions used}
#'     \item{nbasis}{Integer; number of basis functions} 
#'     \item{exclude}{Character vector of conditions to exclude}
#'}
#' @return A list of contrast specifications where each contains:
#'\describe{
#'     \item{weights}{Matrix of contrast weights}
#'     \item{term}{The model term being tested}
#'     \item{name}{Descriptive name for the contrast}
#'     \item{df}{Degrees of freedom for the contrast}
#'}
#' @examples
#' # Create event data with multiple conditions
#' event_data <- data.frame(
#'   condition = factor(c("A", "B", "C", "A", "B", "C")),
#'   rt = c(0.8, 1.2, 0.9, 1.1, 0.7, 1.3),
#'   onsets = c(1, 10, 20, 30, 40, 50),
#'   run = c(1, 1, 1, 1, 1, 1)
#' )
#' 
#' # Create sampling frame
#' sframe <- sampling_frame(blocklens = 60, TR = 2)
#' 
#' # Create event model with multiple terms
#' evmodel <- event_model(
#'   onsets ~ hrf(condition) + hrf(rt),
#'   data = event_data,
#'   block = ~run,
#'   sampling_frame = sframe
#' )
#' 
#' # Get F-contrast for main effect of condition
#' cond_contrast <- Fcontrasts(evmodel)
#' 
#' # Create model with multiple basis functions
#' evmodel2 <- event_model(
#'   onsets ~ hrf(condition, basis = "fourier", nbasis = 3),
#'   data = event_data,
#'   block = ~run,
#'   sampling_frame = sframe
#' )
#' 
#' # Get F-contrasts testing all basis functions
#' basis_contrasts <- Fcontrasts(evmodel2)
#' @export
#' @family contrasts
#' @seealso [event_model()], [contrast_weights()]
Fcontrasts <- function(x, ...) UseMethod("Fcontrasts")

#' estcon
#' 
#' @param x the object
#' @param fit the model fit
#' @param ... extra args
#' @noRd
#' @keywords internal
estcon <- function(x, fit, ...) UseMethod("estcon")

#' construct
#' 
#' construct a term given a an hrf spec and model specification
#' 
#' @param x the object
#' @param model_spec the model specification
#' @param ... extra args
#' @noRd
#' @keywords internal
construct <- function(x, model_spec,...) UseMethod("construct")




#' generate an AFNI linear model command from a configuration file
#' 
#' @param x the config file
#' @param ... extra args
#' @export
gen_afni_lm <- function(x, ...) UseMethod("gen_afni_lm")

#' generate a set of AFNI stimuli for '3dDeconvolve'
#' 
#' @param x the term
#' @param ... extra args
#' @keywords internal
#' @rdname build_afni_stims
build_afni_stims <- function(x, ...) UseMethod("build_afni_stims")

#' Split Event Onsets into Lists by Factor Levels or Blocks
#'
#' Split a vector of event onsets into separate lists based on factor levels and/or block IDs.
#' This is useful for:
#' 
#' \describe{
#'   \item{separation}{Separating events by experimental conditions}
#'   \item{organization}{Organizing onsets by scanning runs/blocks}
#'   \item{preparation}{Preparing onset times for AFNI analysis}
#'   \item{analysis}{Analyzing timing patterns within conditions}
#' }
#'
#' @param x The object containing onset information (typically an event_term or event_model)
#' @param ... Additional arguments passed to methods. Common arguments include:
#' \describe{
#'     \item{sframe}{A sampling_frame object defining the temporal structure}
#'     \item{global}{Logical; if TRUE, convert to global onset times}
#'     \item{blocksplit}{Logical; if TRUE, further split by block IDs}
#' }
#' @return A list of numeric vectors where:
#' \describe{
#'     \item{Elements}{Each element contains onsets for one condition/block}
#'     \item{Names}{Names correspond to condition labels}
#'     \item{Nested Structure}{If blocksplit=TRUE, each condition contains a nested list of blocks}
#' }
#' @examples
#' # Create example data with multiple conditions and blocks
#' event_data <- data.frame(
#'   condition = factor(c("A", "B", "A", "B", "A", "B")),
#'   onsets = c(1, 10, 30, 40, 70, 80),
#'   run = c(1, 1, 2, 2, 3, 3)
#' )
#' 
#' # Create sampling frame
#' sframe <- sampling_frame(blocklens = c(25, 25, 25), TR = 2)
#' 
#' # Create event term
#' eterm <- event_term(
#'   list(condition = event_data$condition),
#'   onsets = event_data$onsets,
#'   blockids = event_data$run
#' )
#' 
#' # Split onsets by condition
#' split_by_cond <- split_onsets(eterm, sframe)
#' # Returns list with onsets for conditions A and B
#' 
#' # Split by condition and block
#' split_by_block <- split_onsets(eterm, sframe, blocksplit = TRUE)
#' # Returns nested list: conditions -> blocks -> onsets
#' 
#' # Get global onset times
#' split_global <- split_onsets(eterm, sframe, global = TRUE)
#' # Returns onsets adjusted for block timing
#' @family timing_functions
#' @seealso [event_term()], [sampling_frame()], [global_onsets()]
#' @export
split_onsets <- function(x, ...) UseMethod("split_onsets")



#' estimate contrast
#' 
#' @param x the contrast
#' @param fit the model fit
#' @param colind the subset of column indices in the design matrix
#' @param ... extra args
#' @noRd 
#' @keywords internal
estimate_contrast <- function(x, fit, colind, ...) UseMethod("estimate_contrast")


#' estimate a linear model sequentially for each "chunk" (a matrix of time-series) of data
#' 
#' @param x the dataset 
#' @param ... extra args
#' @noRd
#' @keywords internal
chunkwise_lm <- function(x, ...) UseMethod("chunkwise_lm")



#' Extract Standard Errors from a Model Fit
#'
#' Extract standard errors of parameter estimates from a fitted model object.
#' This is part of a family of functions for extracting statistical measures.
#'
#' @param x The fitted model object
#' @param ... Additional arguments passed to methods. Common arguments include:
#'   \describe{
#'     \item{type}{The type of standard errors to extract (e.g., "estimates" or "contrasts")}
#'   }
#' @return A tibble or matrix containing standard errors of parameter estimates
#' @examples
#' # Create example data
#' event_data <- data.frame(
#'   condition = factor(c("A", "B", "A", "B")),
#'   onsets = c(1, 10, 20, 30),
#'   run = c(1, 1, 1, 1)
#' )
#' 
#' # Create sampling frame and dataset
#' sframe <- sampling_frame(blocklens = 50, TR = 2)
#' dset <- matrix_dataset(
#'   matrix(rnorm(100 * 2), 100, 2),
#'   TR = 2,
#'   run_length = 50,
#'   event_table = event_data
#' )
#' 
#' # Fit model
#' fit <- fmri_lm(
#'   onsets ~ hrf(condition),
#'   block = ~run,
#'   dataset = dset
#' )
#' 
#' # Extract standard errors
#' se <- standard_error(fit)
#' @family statistical_measures
#' @export
standard_error <- function(x, ...) UseMethod("standard_error")

#' Extract Test Statistics from a Model Fit
#'
#' Extract test statistics (e.g., t-statistics, F-statistics) from a fitted model object.
#' This is part of a family of functions for extracting statistical measures.
#'
#' @param x The fitted model object
#' @param ... Additional arguments passed to methods. Common arguments include:
#'   \describe{
#'     \item{type}{The type of statistics to extract (e.g., "estimates", "contrasts", or "F")}
#'   }
#' @return A tibble or matrix containing test statistics
#' @examples
#' # Create example data
#' event_data <- data.frame(
#'   condition = factor(c("A", "B", "A", "B")),
#'   onsets = c(1, 10, 20, 30),
#'   run = c(1, 1, 1, 1)
#' )
#' 
#' # Create sampling frame and dataset
#' sframe <- sampling_frame(blocklens = 50, TR = 2)
#' dset <- matrix_dataset(
#'   matrix(rnorm(100 * 2), 100, 2),
#'   TR = 2,
#'   run_length = 50,
#'   event_table = event_data
#' )
#' 
#' # Fit model
#' fit <- fmri_lm(
#'   onsets ~ hrf(condition),
#'   block = ~run,
#'   dataset = dset
#' )
#' 
#' # Extract test statistics
#' tstats <- stats(fit)
#' @family statistical_measures
#' @export
stats <- function(x, ...) UseMethod("stats")

#' Extract P-values from a Model Fit
#'
#' Extract p-values associated with parameter estimates or test statistics from a fitted model object.
#' This is part of a family of functions for extracting statistical measures.
#'
#' @param x The fitted model object
#' @param ... Additional arguments passed to methods. Common arguments include:
#'   \describe{
#'     \item{type}{The type of p-values to extract (e.g., "estimates" or "contrasts")}
#'   }
#' @return A tibble or matrix containing p-values
#' @examples
#' # Create example data
#' event_data <- data.frame(
#'   condition = factor(c("A", "B", "A", "B")),
#'   onsets = c(1, 10, 20, 30),
#'   run = c(1, 1, 1, 1)
#' )
#' 
#' # Create sampling frame and dataset
#' sframe <- sampling_frame(blocklens = 50, TR = 2)
#' dset <- matrix_dataset(
#'   matrix(rnorm(100 * 2), 100, 2),
#'   TR = 2,
#'   run_length = 50,
#'   event_table = event_data
#' )
#' 
#' # Fit model
#' fit <- fmri_lm(
#'   onsets ~ hrf(condition),
#'   block = ~run,
#'   dataset = dset
#' )
#' 
#' # Extract p-values
#' pvals <- p_values(fit)
#' @family statistical_measures
#' @export
p_values <- function(x, ...) UseMethod("p_values")

#' Extract Long Names of Variable Levels
#'
#' Get the extended names of variable levels, which include the term prefix and any basis function 
#' information. Long names provide the complete specification of each condition in the model.
#' For example, if a term has conditions "level1" and "level2" with basis functions "basis1" and "basis2",
#' the long names would be "term#level1:basis1", "term#level1:basis2", "term#level2:basis1", "term#level2:basis2".
#'
#' @param x The object to extract names from (typically an event_term, event_model, or convolved_term)
#' @param ... Additional arguments passed to methods. Common arguments include:
#' \describe{
#'     \item{exclude_basis}{Logical; if TRUE, exclude basis function labels from names}
#'     \item{drop_empty}{Logical; if TRUE, drop empty condition levels}
#' }
#' @return A character vector containing the full condition names with term prefixes and basis functions
#' @examples
#' # Create example data with multiple conditions
#' event_data <- data.frame(
#'   condition = factor(c("A", "B", "C", "A", "B", "C")),
#'   rt = c(0.8, 1.2, 0.9, 1.1, 0.7, 1.3),
#'   onsets = c(1, 10, 20, 30, 40, 50),
#'   run = c(1, 1, 1, 1, 1, 1)
#' )
#' 
#' # Create sampling frame
#' sframe <- sampling_frame(blocklens = 60, TR = 2)
#' 
#' # Create event model with multiple basis functions
#' evmodel <- event_model(
#'   onsets ~ hrf(condition, basis = "fourier", nbasis = 2),
#'   data = event_data,
#'   block = ~run,
#'   sampling_frame = sframe
#' )
#' 
#' # Get long names including basis functions
#' lnames <- longnames(evmodel)
#' # Returns: c("condition#A:basis1", "condition#A:basis2",
#' #           "condition#B:basis1", "condition#B:basis2",
#' #           "condition#C:basis1", "condition#C:basis2")
#' 
#' # Create simple event term
#' eterm <- event_term(
#'   list(condition = event_data$condition),
#'   onsets = event_data$onsets,
#'   blockids = event_data$run
#' )
#' 
#' # Get long names for term
#' term_names <- longnames(eterm)
#' # Returns: c("condition#A", "condition#B", "condition#C")
#' @family variable_names
#' @seealso [shortnames()], [event_model()], [event_term()]
#' @export
longnames <- function(x, ...) UseMethod("longnames")

#' @export
#' @rdname longnames
longnames.event_term <- function(x, ...) {
  # Get the cells (factor level combinations) for this term
  term.cells <- cells(x)
  
  # Create long names by combining variable names with their levels
  # Format: varname#level for each variable, joined with ":"
  apply(as.matrix(sapply(1:ncol(term.cells), 
                         function(i) {
                           paste0(names(term.cells)[i], "#", term.cells[[i]], sep="")
                         })), 1, paste, collapse=":")
}

#' @export
#' @rdname longnames
longnames.event_seq <- function(x, ...) {
  # Delegate to event_term method since event_term inherits from event_seq
  longnames.event_term(x, ...)
}

#' @export
#' @rdname longnames
longnames.afni_hrf_convolved_term <- function(x, ...) {
  # For AFNI terms, use the longnames of the underlying event term
  longnames(x$evterm, ...)
}

#' @export
#' @rdname longnames
longnames.afni_trialwise_convolved_term <- function(x, ...) {
  # For AFNI trialwise terms, use the longnames of the underlying event term
  longnames(x$evterm, ...)
}

#' @export
#' @rdname longnames
longnames.convolved_term <- function(x, ...) {
  # For convolved terms, delegate to the underlying event term
  longnames(x$evterm, ...)
}

#' Estimate Beta Coefficients for fMRI Data
#'
#' @description
#' Estimate beta coefficients (regression parameters) from fMRI data using various methods.
#' This function supports different estimation approaches for:
#' \describe{
#'   \item{single}{Single-trial beta estimation}
#'   \item{effects}{Fixed and random effects}
#'   \item{regularization}{Various regularization techniques}
#'   \item{hrf}{Optional HRF estimation}
#' }
#'
#' @param x The dataset object (fmri_dataset, matrix_dataset, or latent_dataset)
#' @param progress Logical; show progress bar.
#' @param ... Additional arguments passed to specific methods. Common arguments include:
#' \describe{
#'   \item{fixed}{Formula specifying fixed effects (constant across trials)}
#'   \item{ran}{Formula specifying random effects (varying by trial)}
#'   \item{block}{Formula specifying the block/run structure}
#'   \item{method}{Estimation method (e.g., "mixed", "r1", "lss", "pls")}
#'   \item{basemod}{Optional baseline model to regress out}
#'   \item{hrf_basis}{Basis functions for HRF estimation}
#'   \item{hrf_ref}{Reference HRF for initialization}
#' }
#'
#' @return A list of class "fmri_betas" containing:
#' \describe{
#'     \item{betas_fixed}{Fixed effect coefficients}
#'     \item{betas_ran}{Random (trial-wise) coefficients}
#'     \item{design_ran}{Design matrix for random effects}
#'     \item{design_fixed}{Design matrix for fixed effects}
#'     \item{design_base}{Design matrix for baseline model}
#'     \item{method_specific}{Additional components specific to the estimation method used}
#' }
#'
#' @details
#' This is a generic function with methods for different dataset types:
#' \describe{
#'   \item{fmri_dataset}{For volumetric fMRI data}
#'   \item{matrix_dataset}{For matrix-format data}
#'   \item{latent_dataset}{For dimensionality-reduced data}
#' }
#'
#' Available estimation methods include:
#' \describe{
#'   \item{mixed}{Mixed-effects model using rrBLUP}
#'   \item{r1}{Rank-1 GLM with joint HRF estimation}
#'   \item{lss}{Least-squares separate estimation}
#'   \item{pls}{Partial least squares regression}
#'   \item{ols}{Ordinary least squares}
#' }
#'
#' @examples
#' # Create example data
#' event_data <- data.frame(
#'   condition = factor(c("A", "B", "A", "B")),
#'   onsets = c(1, 10, 20, 30),
#'   run = c(1, 1, 1, 1)
#' )
#' 
#' # Create sampling frame and dataset
#' sframe <- sampling_frame(blocklens = 50, TR = 2)
#' dset <- matrix_dataset(
#'   matrix(rnorm(100 * 2), 100, 2),
#'   TR = 2,
#'   run_length = 50,
#'   event_table = event_data
#' )
#' 
#' # Estimate betas using mixed-effects model
#' betas <- estimate_betas(
#'   dset,
#'   fixed = onset ~ hrf(condition),
#'   ran = onset ~ trialwise(),
#'   block = ~run,
#'   method = "mixed"
#' )
#'
#' @references
#' Mumford, J. A., et al. (2012). Deconvolving BOLD activation in event-related designs for multivoxel pattern classification analyses. NeuroImage, 59(3), 2636-2643.
#'
#' Pedregosa, F., et al. (2015). Data-driven HRF estimation for encoding and decoding models. NeuroImage, 104, 209-220.
#'
#' @seealso 
#' \code{\link{fmri_dataset}}, \code{\link{matrix_dataset}}, \code{\link{latent_dataset}}
#' @family model_estimation
#' @export
estimate_betas <- function(x, ...) UseMethod("estimate_betas")

#' Generate Neural Input Function from Event Timing
#'
#' Converts event timing information into a neural input function representing the underlying
#' neural activity before HRF convolution. This function is useful for:
#' 
#' \describe{
#'   \item{stimulus}{Creating stimulus functions for fMRI analysis}
#'   \item{modeling}{Modeling sustained vs. transient neural activity}
#'   \item{inputs}{Generating inputs for HRF convolution}
#'   \item{visualization}{Visualizing the temporal structure of experimental designs}
#' }
#'
#' @param x A regressor object containing event timing information
#' @param ... Additional arguments passed to methods. Common arguments include:
#' \describe{
#'     \item{start}{Numeric; start time of the input function}
#'     \item{end}{Numeric; end time of the input function} 
#'     \item{resolution}{Numeric; temporal resolution in seconds (default: 0.33)}
#' }
#'
#' @return A list containing:
#' \describe{
#'     \item{time}{Numeric vector of time points}
#'     \item{neural_input}{Numeric vector of input amplitudes at each time point}
#' }
#'
#' @examples
#' # Create a regressor with multiple events
#' reg <- regressor(
#'   onsets = c(10, 30, 50),
#'   duration = c(2, 2, 2),
#'   amplitude = c(1, 1.5, 0.8),
#'   hrf = HRF_SPMG1
#' )
#' 
#' # Generate neural input function
#' input <- neural_input(reg, start = 0, end = 60, resolution = 0.5)
#' 
#' # Plot the neural input function
#' plot(input$time, input$neural_input, type = "l",
#'      xlab = "Time (s)", ylab = "Neural Input",
#'      main = "Neural Input Function")
#' 
#' # Create regressor with varying durations
#' reg_sustained <- regressor(
#'   onsets = c(10, 30),
#'   duration = c(5, 10),  # sustained activity
#'   amplitude = c(1, 1),
#'   hrf = HRF_SPMG1
#' )
#' 
#' # Generate and compare neural inputs
#' input_sustained <- neural_input(
#'   reg_sustained,
#'   start = 0,
#'   end = 60,
#'   resolution = 0.5
#' )
#'
#' @family regressor_functions
#' @seealso 
#' \code{\link{regressor}}, \code{\link{evaluate.Reg}}, \code{\link{HRF_SPMG1}}
#' @export
neural_input <- function(x, ...) UseMethod("neural_input")

#' Visualize the entire design matrix as a heatmap
#'
#' Generate a heatmap visualization of a design matrix, showing regressor values over time.
#' This is useful for inspecting the temporal structure of fMRI design matrices.
#'
#' @param x The model object (event_model, baseline_model, or fmri_model)
#' @param ... Additional arguments passed to methods. Common arguments include:
#'   \describe{
#'     \item{rescale_cols}{Logical; if TRUE, columns are rescaled to (-1,1)}
#'     \item{block_separators}{Logical; if TRUE, draw white lines between blocks}
#'     \item{rotate_x_text}{Logical; if TRUE, rotate x-axis labels by 45 degrees}
#'   }
#' @return A ggplot2 object containing the design matrix heatmap
#' @export
#' @family visualization
#' @seealso [correlation_map()], [event_model()], [baseline_model()]
design_map <- function(x, ...) {
  UseMethod("design_map")
}

#' @export
#' @rdname conditions
conditions.afni_hrf_convolved_term <- function(x, ...) {
  # For AFNI terms, use the conditions of the underlying event term
  conditions(x$evterm, ...)
}

#' @export
#' @rdname conditions
conditions.afni_trialwise_convolved_term <- function(x, ...) {
  # For AFNI trialwise terms, use the conditions of the underlying event term
  conditions(x$evterm, ...)
}

#' @export
#' @rdname conditions
conditions.convolved_term <- function(x, ...) {
  # For regular convolved terms, use the conditions of the underlying event term
  conditions(x$evterm, ...)
}

#' @export
#' @rdname event_table
event_table.convolved_term <- function(x) {
  # For convolved terms, delegate to the underlying event term
  event_table(x$evterm)
}

#' @export
#' @rdname nbasis
nbasis.convolved_term <- function(x, ...) {
  # Get nbasis from the HRF object in the hrfspec
  hrfspec <- x$hrfspec
  if (!is.null(hrfspec) && !is.null(hrfspec$hrf)) {
    nbasis(hrfspec$hrf)
  } else {
    1L # Default fallback
  }
}

#' Short Names
#'
#' @description
#' Generate short names for model terms and conditions.
#'
#' @param x The object to generate short names for.
#' @param ... Additional arguments.
#' @return A character vector of short names.
#' @export
shortnames <- function(x, ...) UseMethod("shortnames")

#' @export
#' @rdname shortnames
shortnames.event_term <- function(x, ...) {
  # Get the cells (factor level combinations) for this term
  term.cells <- cells(x)
  
  # Create short names by combining levels with ":" separator (legacy format)
  apply(as.matrix(sapply(1:ncol(term.cells), 
                         function(i) {
                           term.cells[[i]]
                         })), 1, paste, collapse=":")
}

#' @export
#' @rdname shortnames
shortnames.event_model <- function(x, ...) {
  unlist(lapply(terms(x), shortnames))
}

#' @export
#' @rdname longnames
longnames.convolved_term <- function(x, ...) {
  # For convolved terms, delegate to the underlying event term
  longnames(x$evterm, ...)
}

#' @export
#' @rdname design_matrix
design_matrix.convolved_term <- function(x, blockid=NULL, ...) {
  if (is.null(blockid)) {
    x$design_matrix
  } else {
    keep <- blockids(x$sampling_frame) %in% blockid
    x$design_matrix[keep,]
  } 
}

#' @describeIn design_matrix Design matrix for AFNI-convolved terms
#'
#' AFNI-convolved terms rely on AFNI software for design matrix
#' construction. This method stops with an informative message.
#'
#' @export
design_matrix.afni_hrf_convolved_term <- function(x, blockid=NULL, ...) {
  stop("afni_hrf_convolved_term delegates design matrix construction to AFNI")
}
</file>

<file path="DESCRIPTION">
Package: fmrireg
Type: Package
Title: R package for the anlysis of fmri data
Version: 0.1.0
LinkingTo: Rcpp,RcppArmadillo, roptim, RcppParallel
Date: 2023-03-07
Authors@R: person("Bradley", "Buchsbaum",, role = c("aut", "cre"), email = "brad.buchsbaum@gmail.com")
License: GPL (>= 2)
Maintainer: Bradley Buchsbaum <brad.buchsbaum@gmail.com>
Description: fmrireg is a package for the analysis of functional magnetic resonance imaging (fMRI) data. Facilities are provided to construct flexible hemodynamic response functions, experimental regressors, and conduct univariate fMRI analyses.
Encoding: UTF-8
LazyData: false
Depends:
    R (>= 4.0.0)
Imports:
    stats,
    Matrix,
    RANN,
    assertthat,
    stringr,
    tibble,
    purrr,
    foreach,
    dplyr,
    ggplot2,
    gmodels,
    lazyeval,
    tidyr,
    iterators,
    robustbase,
    memoise,
    pracma,
    furrr,
    rlang,
    neuroim2,
    Rcpp,
    methods,
    numDeriv,
    RcppArmadillo (>= 0.10.1.0),
    splines,
    crayon,
    plotly,
    cli,
    colorplane
RoxygenNote: 7.3.2.9000
Roxygen: list(
    markdown = TRUE,
    roclets = c("collate", "namespace", "rd", "roxyglobals::global_roclet"))
Suggests: 
    testthat,
    pls,
    fmristore,
    knitr,
    rmarkdown,
    roxygen2,
    covr,
    multivarious,
    rrBLUP,
    care,
    glmnet,
    proxy,
    cowplot,
    forecast,
    shiny,
    mgcv,
    progressr,
    ggforce,
    roxyglobals (>= 0.2.1),
    bidser
Remotes:
    bbuchsbaum/neuroim2,
    bbuchsbaum/multivarious,
    bbuchsbaum/fmristore,
    anthonynorth/roxyglobals
VignetteBuilder: knitr
URL: https://github.com/bbuchsbaum/fmrireg
BugReports: https://github.com/bbuchsbaum/fmrireg/issues
Collate: 
    'RcppExports.R'
    'afni.R'
    'all_generic.R'
    'autoplot-methods.R'
    'ar_utils.R'
    'baseline_model.R'
    'basis.R'
    'benchmark_datasets.R'
    'beta_utils.R'
    'bootstrap.R'
    'con_stats.R'
    'contrast.R'
    'covariate.R'
    'data_fmri_benchmark_datasets.R'
    'design_plot.R'
    'evaluate-helpers.R'
    'utils-internal.R'
    'event-classes.R'
    'event_model_helpers.R'
    'event_model.R'
    'event_vector.R'
    'fmri_betas.R'
    'fmri_dataset.R'
    'fmri_latent_lm.R'
    'fmri_model.R'
    'fmrilm.R'
    'fmrireg.R'
    'fmrirlm.R'
    'gen_contrast.R'
    'globals.R'
    'hrf-afni.R'
    'hrf-formula.R'
    'hrf-functions.R'
    'hrf.R'
    'hrf_decorators.R'
    'hrf_smoothing_kernel.R'
    'lss.R'
    'metafuns.R'
    'mixed_solve.R'
    'naming-utils.R'
    'penalty_matrix.R'
    'reg-constructor.R'
    'reg-methods.R'
    'regressor.R'
    'sampling_frame.R'
    'simulate.R'
    'zzz.R'
</file>

<file path="R/fmrilm.R">
#' Get the formula representation of an fMRI model
#'
#' This function extracts the formula from an \code{fmri_model} object.
#'
#' @return A formula representing the model.
#' @param x An \code{fmri_model} object.
#' @param ... Additional arguments.
#' @rdname get_formula
#' @export
get_formula.fmri_model <- function(x,...) {
  assert_that(inherits(x, "fmri_model"), msg = "'x' must be an 'fmri_model' object")
  term_names <- names(terms(x))
  form <- paste(".y ~", paste(term_names, collapse = " + "), "-1")
  return(as.formula(form))
}

#' Extract Term Matrices from an fMRI Model
#'
#' This function extracts the term matrices from an \code{fmri_model}, which consists of event-related terms
#' and baseline-related terms. These matrices are used to build the design matrix in fMRI data analysis.
#'
#' @param x An \code{fmri_model} object containing the event and baseline models.
#' @param blocknum (Optional) A numeric vector specifying the block numbers to include. Defaults to all blocks.
#' @return A named list of term matrices, with event terms followed by baseline terms.
#'         Attributes \code{"event_term_indices"} and \code{"baseline_term_indices"} store the indices of event and baseline terms,
#'         \code{"blocknum"} stores the block numbers, and \code{"varnames"} stores the variable names.
#' @export
#' @rdname term_matrices
term_matrices.fmri_model <- function(x, blocknum = NULL,...) {
  assert_that(inherits(x, "fmri_model"), msg = "'x' must be an 'fmri_model' object")
  
  if (is.null(blocknum)) {
    blocknum <- sort(unique(x$event_model$blockids))
  }
  
  # Get the full convolved design matrix from the event model
  event_dm <- design_matrix(x$event_model, blockid = blocknum)
  
  # Get the baseline design matrix
  baseline_dm <- design_matrix(x$baseline_model, blockid = blocknum)
  
  # Extract individual term matrices using the col_indices attribute
  col_indices <- attr(x$event_model$design_matrix, "col_indices")
  if (is.null(col_indices)) {
    stop("Event model design matrix missing 'col_indices' attribute needed to extract individual term matrices.")
  }
  
  # Extract event term matrices from the full convolved design matrix
  eterms <- lapply(names(col_indices), function(term_name) {
    indices <- col_indices[[term_name]]
    as.matrix(event_dm[, indices, drop = FALSE])
  })
  names(eterms) <- names(col_indices)
  
  # Extract baseline term matrices (baseline terms are simpler, one per term)
  bterms <- lapply(baseline_terms(x), function(term) as.matrix(design_matrix(term, blockid = blocknum)))
  
  # Compute indices for event and baseline terms
  num_event_cols <- ncol(event_dm)
  num_baseline_cols <- ncol(baseline_dm)
  
  eterm_indices <- 1:num_event_cols
  bterm_indices <- (num_event_cols + 1):(num_event_cols + num_baseline_cols)
  
  # Combine term matrices
  term_matrices <- c(eterms, bterms)
  names(term_matrices) <- names(terms(x))
  
  # Collect variable names
  vnames <- c(colnames(event_dm), colnames(baseline_dm))
  
  # Set attributes
  attr(term_matrices, "event_term_indices") <- eterm_indices
  attr(term_matrices, "baseline_term_indices") <- bterm_indices
  attr(term_matrices, "blocknum") <- blocknum
  attr(term_matrices, "varnames") <- vnames
  
  return(term_matrices)
}



#' @keywords internal
#' @noRd
is.formula <- function(x) {
  inherits(x, "formula")
}

#' @keywords internal
#' @noRd
.fast_preproject <- function(X) {
  # Ensure X is a matrix
  if (!is.matrix(X)) {
    X <- as.matrix(X)
  }
  XtX   <- crossprod(X)        # p × p
  # Add small ridge for stability if needed, but try direct first
  # Rchol <- tryCatch(chol(XtX), error = function(e) chol(XtX + diag(ncol(XtX)) * 1e-10))
  Rchol <- chol(XtX)           # p × p  upper‑triangular
  Pinv  <- backsolve(Rchol, t(X), transpose = TRUE)  # (Rchol^-1)' Xᵀ = (Rchol'^-1) Xᵀ = (XtX)^-1 Xᵀ -> p x n
                                                    # backsolve solves R'y = x for y if transpose=TRUE
                                                    # We want to solve R z = t(X) for z, where R is upper.
                                                    # Let R = chol(XtX). We want z = R^-1 t(X)
                                                    # Pinv should be (XtX)^-1 X^T = (R'R)^-1 X^T = R^-1 R'^-1 X^T
                                                    # Let's use solve(R) %*% solve(t(R)) %*% t(X) ? No.
                                                    # Let's use chol2inv(Rchol) %*% t(X) ? Yes.
  
  # Revisit Pinv calculation based on user's note: Pinv = backsolve(Rchol, t(X)) # (R⁻¹) Xᵀ  →  p × n
  # This assumes R is upper triangular. backsolve solves R x = b.
  # We want (XtX)^-1 Xt = (R'R)^-1 Xt = R^-1 R'^-1 Xt
  # Let's test:
  # X <- matrix(rnorm(30*5), 30, 5); XtX <- crossprod(X); Rchol <- chol(XtX)
  # Pinv_chol2inv <- chol2inv(Rchol) %*% t(X)
  # Pinv_backsolve <- backsolve(Rchol, t(X)) # solves R z = t(X) -> z = R^-1 t(X) - This is NOT (XtX)^-1 Xt
  # Pinv_correct <- solve(XtX, t(X))
  # Let's stick to chol2inv for clarity and correctness
  
  XtXinv <- chol2inv(Rchol)
  Pinv   <- XtXinv %*% t(X) # p x n : (X'X)^-1 X'
  
  list(Pinv = Pinv,           # (X'X)^-1 X'
       XtXinv = XtXinv,       # (X'X)^-1
       Rchol = Rchol,         # For potential future use
       dfres = nrow(X) - ncol(X)) # rank issue not handled here, assumes full rank
}

#' @keywords internal
#' @noRd
.fast_lm_matrix <- function(X, Y, proj, return_fitted = FALSE) {
  # X : n × p design matrix
  # Y : n × V data matrix
  # proj$Pinv : (X'X)^-1 X'

  if (!is.matrix(Y)) {
    Y <- as.matrix(Y)
  }
  if (!is.matrix(X)) {
    X <- as.matrix(X)
  }

  if (ncol(X) != nrow(proj$Pinv) || nrow(X) != nrow(Y)) {
    stop(".fast_lm_matrix: X and Y dimensions do not match projection matrix")
  }

  Betas <- proj$Pinv %*% Y

  if (return_fitted) {
    Fitted <- X %*% Betas
    rss <- colSums((Y - Fitted)^2)
  } else {
    yTy <- colSums(Y^2)
    XtX <- solve(proj$XtXinv)
    XtX_Betas <- XtX %*% Betas
    beta_XtX_beta <- colSums(Betas * XtX_Betas)
    rss <- yTy - beta_XtX_beta
    rss[rss < 0 & rss > -1e-10] <- 0
    if (any(rss < -1e-10)) {
      warning("Negative residual sum of squares computed in .fast_lm_matrix")
    }
    Fitted <- NULL
  }

  sigma2 <- rss / proj$dfres
  sigma <- sqrt(sigma2)

  list(
    betas = Betas,
    rss   = rss,
    sigma = sigma,
    sigma2 = sigma2,
    fitted = Fitted
  )
}

#' Create an fMRI Model
#'
#' This function creates an \code{fmri_model} by combining an event model and a baseline model.
#' If a baseline model is not provided, a default one is created based on the dataset.
#'
#' @param formula The model formula for experimental events.
#' @param block The model formula for block structure.
#' @param baseline_model (Optional) A \code{baseline_model} object. If \code{NULL}, a default baseline model is created.
#' @param dataset An \code{fmri_dataset} containing the event table and sampling frame.
#' @param drop_empty Logical. Whether to remove factor levels with zero size. Default is \code{TRUE}.
#' @param durations A vector of event durations. Default is \code{0}.
#' @return An \code{fmri_model} object.
#' @keywords internal
create_fmri_model <- function(formula, block, baseline_model = NULL, dataset, drop_empty = TRUE, durations = 0) {
  assert_that(is.formula(formula), msg = "'formula' must be a formula")
  assert_that(is.formula(block), msg = "'block' must be a formula")
  assert_that(inherits(dataset, "fmri_dataset"), msg = "'dataset' must be an 'fmri_dataset'")
  assert_that(is.numeric(durations), msg = "'durations' must be numeric")
  
  if (is.null(baseline_model)) {
    baseline_model <- baseline_model(
      basis = "bs",
      degree = max(ceiling(median(dataset$sampling_frame$blocklens) / 100), 3),
      sframe = dataset$sampling_frame
    )
  } else {
    assert_that(inherits(baseline_model, "baseline_model"),
                msg = "'baseline_model' must have class 'baseline_model'")
  }
  
  ev_model <- event_model(
    formula_or_list = formula,
    block = block,
    data = dataset$event_table,
    sampling_frame = dataset$sampling_frame,
    drop_empty = drop_empty,
    durations = durations
  )
  
  fmri_model(ev_model, baseline_model)
}



#' Fit a Linear Regression Model for fMRI Data Analysis
#'
#' This function fits a linear regression model for fMRI data analysis using the specified model formula,
#' block structure, and dataset. The model can be fit using either a runwise or chunkwise data splitting strategy,
#' and robust fitting can be enabled if desired. When \code{cor_struct} is set to
#' one of the AR options (\code{"ar1"}, \code{"ar2"}, \code{"arp"}), the function
#' performs fast AR prewhitening to account for temporal autocorrelation in the
#' residuals.
#'
#' @param formula The model formula for experimental events.
#' @param block The model formula for block structure.
#' @param baseline_model (Optional) A \code{baseline_model} object. Default is \code{NULL}.
#' @param dataset An \code{fmri_dataset} object containing the time-series data.
#' @param durations A vector of event durations. Default is \code{0}.
#' @param drop_empty Logical. Whether to remove factor levels with zero size. Default is \code{TRUE}.
#' @param robust Logical. Whether to use robust fitting. Default is \code{FALSE}.
#' @param strategy The data splitting strategy, either \code{"runwise"} or \code{"chunkwise"}. Default is \code{"runwise"}.
#' @param nchunks Number of data chunks when strategy is \code{"chunkwise"}. Default is \code{10}.
#' @param use_fast_path Logical. If \code{TRUE}, use matrix-based computation for speed. Default is \code{FALSE}.
#' @param progress Logical. Whether to display a progress bar during model fitting. Default is \code{FALSE}.
#' @param cor_struct Error correlation structure. One of \code{"iid"}, \code{"ar1"},
#'   \code{"ar2"}, or \code{"arp"}. The \code{"arp"} option models an autoregressive
#'   process of order \code{ar_p}. Only AR components are currently supported
#'   (no moving-average terms).
#' @param cor_iter Number of GLS iterations for AR prewhitening. A value of
#'   \code{1} performs one OLS fit followed by one GLS fit.
#' @param cor_global Logical. If \code{TRUE}, AR coefficients are estimated from
#'   all runs combined and applied globally; otherwise they are estimated per
#'   run.
#' @param ar_p Integer order for \code{cor_struct = "arp"}.
#' @param ar1_exact_first Logical. If \code{TRUE} applies exact AR(1) scaling to
#'   the first sample when \code{cor_struct = "ar1"}.
#' @param ... Additional arguments.
#' @return A fitted linear regression model for fMRI data analysis.
#' @export
#' @seealso \code{\link{fmri_dataset}}, \code{\link{fmri_lm_fit}}
#' @examples
#' 
#' facedes <- subset(read.table(system.file("extdata", "face_design.txt", package = "fmrireg"), 
#' header=TRUE), face_gen != "n/a")
#' facedes$face_gen <- droplevels(factor(facedes$face_gen))
#' sframe <- sampling_frame(rep(430/2,6), TR=2)
#' ev <- event_model(onset ~ hrf(face_gen, basis="gaussian"), data=facedes, 
#' block= ~ run, sampling_frame=sframe)
#' globonsets <- global_onsets(sframe, facedes$onset, blockids(ev))
#' reg1_signal <- regressor(globonsets[facedes$face_gen == "male"], hrf=HRF_GAUSSIAN)
#' reg2_signal <- regressor(globonsets[facedes$face_gen == "female"], hrf=HRF_GAUSSIAN)
#' time <- samples(sframe, global=TRUE)
#' y1 <- evaluate(reg1_signal, time)*1.5
#' y2 <- evaluate(reg2_signal, time)*3.0
#' y <- y1+y2
#' ys1 <- y + rnorm(length(y), sd=.02)
#' ys2 <- y + rnorm(length(y), sd=.02)
#' 
#' h <<- gen_hrf(hrf_bspline, N=7, span=25)
#' dset <- matrix_dataset(cbind(ys1,ys2), TR=2, run_length=sframe$blocklens, event_table=facedes)
#' flm <- fmri_lm(onset ~ hrf(face_gen, basis=gen_hrf(hrf_bspline, N=7, span=25)), block = ~ run, 
#' strategy="chunkwise", nchunks=1, dataset=dset)
#' 
fmri_lm <- function(formula, block, baseline_model = NULL, dataset, durations = 0, drop_empty = TRUE, robust = FALSE,
                    strategy = c("runwise", "chunkwise"), nchunks = 10, use_fast_path = FALSE, progress = FALSE,
                    cor_struct = c("iid", "ar1", "ar2", "arp"), cor_iter = 1L, cor_global = FALSE,
                    ar_p = NULL, ar1_exact_first = FALSE, ...) {
  
  strategy <- match.arg(strategy)
  
  # Error checking
  assert_that(is.formula(formula), msg = "'formula' must be a formula")
  assert_that(is.formula(block), msg = "'block' must be a formula")
  assert_that(inherits(dataset, "fmri_dataset"), msg = "'dataset' must be an 'fmri_dataset'")
  assert_that(is.numeric(durations), msg = "'durations' must be numeric")
  assert_that(is.logical(drop_empty), msg = "'drop_empty' must be logical")
  assert_that(is.logical(robust), msg = "'robust' must be logical")
  assert_that(is.logical(use_fast_path), msg = "'use_fast_path' must be logical")
  cor_struct <- match.arg(cor_struct)
  assert_that(is.numeric(cor_iter) && cor_iter >= 1, msg = "'cor_iter' must be >= 1")
  assert_that(is.logical(cor_global), msg = "'cor_global' must be logical")
  if (cor_struct == "arp") {
    assert_that(!is.null(ar_p) && ar_p > 0, msg = "'ar_p' must be positive when cor_struct='arp'")
  }
  assert_that(is.logical(ar1_exact_first), msg = "'ar1_exact_first' must be logical")
  if (strategy == "chunkwise") {
    assert_that(is.numeric(nchunks) && nchunks > 0, msg = "'nchunks' must be a positive number")
  }
  if (robust && use_fast_path) {
      warning("Robust fitting ('robust=TRUE') is not currently implemented with 'use_fast_path=TRUE'. Ignoring 'robust=TRUE'.")
      robust <- FALSE # Force robust to FALSE if fast path is used
  }
  
  model <- create_fmri_model(formula, block, baseline_model, dataset, durations = durations, drop_empty = drop_empty)
  # Pass use_fast_path down
  ret <- fmri_lm_fit(model, dataset, strategy, robust, nchunks,
                     use_fast_path = use_fast_path, progress = progress,
                     cor_struct = cor_struct, cor_iter = cor_iter,
                     cor_global = cor_global, ar_p = ar_p,
                     ar1_exact_first = ar1_exact_first, ...)
  return(ret)
}


#' Fit an fMRI Linear Regression Model with a Specified Fitting Strategy
#'
#' This function fits an fMRI linear regression model using the specified \code{fmri_model} object, dataset,
#' and data splitting strategy (either \code{"runwise"} or \code{"chunkwise"}). It is primarily an internal function
#' used by the \code{fmri_lm} function.
#'
#' @param fmrimod An \code{fmri_model} object.
#' @param dataset An \code{fmri_dataset} object containing the time-series data.
#' @param strategy The data splitting strategy, either \code{"runwise"} or \code{"chunkwise"}. Default is \code{"runwise"}.
#' @param robust Logical. Whether to use robust fitting. Default is \code{FALSE}.
#' @param nchunks Number of data chunks when strategy is \code{"chunkwise"}. Default is \code{10}.
#' @param use_fast_path Logical. If \code{TRUE}, use matrix-based computation for speed. Default is \code{FALSE}.
#' @param progress Logical. Whether to display a progress bar during model fitting. Default is \code{FALSE}.
#' @param cor_struct Error correlation structure. One of \code{"iid"}, \code{"ar1"},
#'   \code{"ar2"}, or \code{"arp"}. The \code{"arp"} option models an AR process of
#'   order \code{ar_p}. Only AR terms are currently supported.
#' @param cor_iter Number of GLS iterations to run.
#' @param cor_global Logical. If \code{TRUE}, a single AR model is estimated from
#'   all runs and applied globally; otherwise a separate model is estimated per
#'   run.
#' @param ar_p Integer order used when \code{cor_struct = "arp"}.
#' @param ar1_exact_first Logical. Apply exact AR(1) scaling to the first sample
#'   when \code{cor_struct = "ar1"}.
#' @param ... Additional arguments.
#' @return A fitted fMRI linear regression model with the specified fitting strategy.
#' @keywords internal
#' @seealso \code{\link{fmri_lm}}, \code{\link{fmri_model}}, \code{\link{fmri_dataset}}
fmri_lm_fit <- function(fmrimod, dataset, strategy = c("runwise", "chunkwise"),
                        robust = FALSE, nchunks = 10, use_fast_path = FALSE, progress = FALSE,
                        cor_struct = c("iid", "ar1", "ar2", "arp"), cor_iter = 1L,
                        cor_global = FALSE, ar_p = NULL, ar1_exact_first = FALSE, ...) {
  strategy <- match.arg(strategy)
  
  # Error checking
  assert_that(inherits(fmrimod, "fmri_model"), msg = "'fmrimod' must be an 'fmri_model' object")
  assert_that(inherits(dataset, "fmri_dataset"), msg = "'dataset' must be an 'fmri_dataset' object")
  assert_that(is.logical(robust), msg = "'robust' must be logical")
  assert_that(is.logical(use_fast_path), msg = "'use_fast_path' must be logical")
  cor_struct <- match.arg(cor_struct)
  assert_that(is.numeric(cor_iter) && cor_iter >= 1, msg = "'cor_iter' must be >= 1")
  assert_that(is.logical(cor_global), msg = "'cor_global' must be logical")
  if (cor_struct == "arp") {
    assert_that(!is.null(ar_p) && ar_p > 0, msg = "'ar_p' must be positive when cor_struct='arp'")
  }
  assert_that(is.logical(ar1_exact_first), msg = "'ar1_exact_first' must be logical")
  if (strategy == "chunkwise") {
    assert_that(is.numeric(nchunks) && nchunks > 0, msg = "'nchunks' must be a positive number")
  }
  if (robust && use_fast_path) {
      # Warning already issued in fmri_lm, but double check
      warning("Robust fitting ('robust=TRUE') is not currently implemented with 'use_fast_path=TRUE'. Ignoring 'robust=TRUE'.")
      robust <- FALSE
  }
  
  # Get contrast info grouped by term
  contrast_info_by_term <- contrast_weights(fmrimod$event_model)
  full_design_colnames <- colnames(design_matrix(fmrimod))
  processed_conlist <- list()
  
  # Process contrasts term by term to correctly assign column indices
  for (term_name in names(contrast_info_by_term)) {
      term_contrasts <- contrast_info_by_term[[term_name]]
      
      # Get col_indices from design matrix instead of term_indices from event model
      col_indices <- attr(fmrimod$event_model$design_matrix, "col_indices")
      
      if (length(term_contrasts) > 0 && !is.null(col_indices) && !is.null(col_indices[[term_name]])) {
          # Get the column indices directly from col_indices instead of trying to match names
          # The col_indices already contains the correct indices for this term
          colind <- col_indices[[term_name]]
          
          if (length(colind) == 0) {
              warning(paste("No column indices found for term:", term_name))
              next # Skip contrasts for this term if columns can't be found
          }
          
          # Apply colind attribute to each contrast spec within this term
          processed_term_contrasts <- lapply(term_contrasts, function(con_spec) {
              if (inherits(con_spec, "contrast") || inherits(con_spec, "Fcontrast")) {
                  # Set the colind attribute on the contrast weights for the slow path
                  attr(con_spec$weights, "colind") <- colind
                  # Also set it directly on the contrast object for estimate_contrast
                  attr(con_spec, "colind") <- colind
                  # Add term name attribute for potential future use/debugging
                  # attr(con_spec$weights, "term") <- term_name 
              } else {
                  warning(paste("Item in contrast list for term", term_name, "is not a contrast or Fcontrast object."))
              }
              con_spec # Return modified or original con_spec
          })
          processed_conlist <- c(processed_conlist, processed_term_contrasts)
      } else if (length(term_contrasts) > 0 && (is.null(col_indices) || is.null(col_indices[[term_name]]))) {
           warning(paste("Contrasts found for term '", term_name, "' but col_indices are missing in the event model design matrix."))
      }
  }

  # Now processed_conlist contains all valid contrasts with the colind attribute added
  
  # Separate simple and F contrasts (full objects) for the standard path
  simple_conlist_objects <- Filter(function(x) inherits(x, "contrast"), processed_conlist)
  fconlist_objects <- Filter(function(x) inherits(x, "Fcontrast"), processed_conlist)
  # Combine for standard path (fit_lm_contrasts expects a single list)
  standard_path_conlist <- c(simple_conlist_objects, fconlist_objects)
  
  # Pass the full processed contrast objects list down.
  # The fitting function (chunkwise/runwise) will decide whether to use the objects (slow path)
  # or extract weights (fast path).
  phi_global <- NULL
  if (cor_global && match.arg(cor_struct) != "iid") {
    ar_order <- switch(match.arg(cor_struct),
                       ar1 = 1L,
                       ar2 = 2L,
                       arp = ar_p)

    run_chunks <- exec_strategy("runwise")(dataset)
    form <- get_formula(fmrimod)
    resid_vec <- numeric(0)
    for (rch in run_chunks) {
      tmats_run <- term_matrices(fmrimod, rch$chunk_num)
      data_env_run <- list2env(tmats_run)
      n_time_run <- nrow(tmats_run[[1]])
      data_env_run[[".y"]] <- rep(0, n_time_run)
      X_run <- model.matrix(form, data_env_run)
      proj_run <- .fast_preproject(X_run)
      Y_run <- as.matrix(rch$data)
      ols <- .fast_lm_matrix(X_run, Y_run, proj_run, return_fitted = TRUE)
      resid_vec <- c(resid_vec, rowMeans(Y_run - ols$fitted))
    }
    phi_global <- .estimate_ar(resid_vec, ar_order)
    cor_iter <- 1L
  }

  result <- switch(strategy,
                   "runwise" = runwise_lm(dataset, fmrimod, standard_path_conlist, # Pass full objects
                                         robust = robust, use_fast_path = use_fast_path,
                                         progress = progress,
                                         cor_struct = cor_struct, cor_iter = cor_iter,
                                         cor_global = cor_global, ar_p = ar_p,
                                         ar1_exact_first = ar1_exact_first,
                                         phi_fixed = phi_global, ...),
                   "chunkwise" = {
                    if (inherits(dataset, "latent_dataset")) {
                      chunkwise_lm(dataset, fmrimod, standard_path_conlist, # Pass full objects
                                   nchunks, robust = robust, progress = progress,
                                   cor_struct = cor_struct, cor_iter = cor_iter,
                                   cor_global = cor_global, ar_p = ar_p,
                                   ar1_exact_first = ar1_exact_first,
                                   phi_fixed = phi_global, ...) # Do not pass use_fast_path
                    } else {
                      chunkwise_lm(dataset, fmrimod, standard_path_conlist, # Pass full objects
                                   nchunks, robust = robust, use_fast_path = use_fast_path,
                                   progress = progress,
                                   cor_struct = cor_struct, cor_iter = cor_iter,
                                   cor_global = cor_global, ar_p = ar_p,
                                   ar1_exact_first = ar1_exact_first,
                                   phi_fixed = phi_global, ...)
                    }
                  })
  
  ret <- list(
    result = result,
    model = fmrimod,
    strategy = strategy,
    bcons = processed_conlist,
    dataset = dataset
  )
  
  class(ret) <- "fmri_lm"
  
  return(ret)
}


#' Compute Fitted Hemodynamic Response Functions for an fmri_lm Object
#'
#' This method computes the fitted hemodynamic response functions (HRFs) for an \code{fmri_lm} object.
#'
#' @param x An \code{fmri_lm} object for which the fitted HRFs should be computed.
#' @param sample_at A numeric vector of time points at which the HRFs should be sampled. Default is \code{seq(0, 24, by = 1)}.
#' @param ... Additional arguments (currently unused).
#' @return A list where each element corresponds to an event term in the \code{fmri_lm} object. Each element contains:
#' \describe{
#'   \item{\code{pred}}{A matrix of predicted HRF values.}
#'   \item{\code{design}}{A tibble containing the design matrix for the HRFs.}
#' }
#' @export
fitted_hrf.fmri_lm <- function(x, sample_at = seq(0, 24, by = 1), ...) {
  # Error checking
  assert_that(inherits(x, "fmri_lm"), msg = "'x' must be an 'fmri_lm' object")
  assert_that(is.numeric(sample_at), msg = "'sample_at' must be numeric")
  
  eterms <- terms(x$model$event_model)
  betas <- coef(x)
  tind <- x$model$event_model$term_indices
  
  pred <- lapply(seq_along(tind), function(i) {
    ind <- tind[[i]]
    hrf_spec <- eterms[[i]]$hrfspec
    hrf <- hrf_spec$hrf
    nb <- attr(hrf, "nbasis")
    G <- as.matrix(hrf(sample_at))
    
    excond <- cells(eterms[[i]], exclude_basis = TRUE)
    ncond <- nrow(excond)
    Gex <- do.call(Matrix::bdiag, replicate(ncond, G, simplify = FALSE))
    
    B <- t(betas[, ind, drop = FALSE])
    yh <- Gex %*% B
    
    excond_expanded <- excond %>% dplyr::slice(rep(1:dplyr::n(), each = length(sample_at)))
    design <- cbind(
      dplyr::tibble(time = rep(sample_at, ncond)),
      excond_expanded
    )
    
    list(pred = as.matrix(yh), design = tibble::as_tibble(design))
  })
  
  names(pred) <- names(eterms)
  return(pred)
}



#' Reshape Coefficient Data
#'
#' This function reshapes coefficient data from wide to long format and merges it with design information.
#'
#' @param df A data frame containing coefficient estimates.
#' @param des A data frame containing design information.
#' @param measure The name of the value column in the reshaped data. Default is \code{"value"}.
#' @return A data frame in long format with merged design information.
#' @keywords internal
#' @autoglobal
reshape_coef <- function(df, des, measure = "value") {
  # Create a unique identifier for each row
  df <- df %>% dplyr::mutate(row_id = dplyr::row_number())
  
  des <- des %>% dplyr::mutate(key = do.call(paste, c(.[, colnames(des)], sep = ":")))
  
  colnames(df)[-ncol(df)] <- des$key  # assign new column names excluding the last column (row_id)
  
  df_long <- df %>%
    tidyr::pivot_longer(-row_id, names_to = "col_name", values_to = measure)
  
  # Match the long dataframe with the design dataframe
  df_long <- dplyr::left_join(df_long, des, by = c("col_name" = "key"))
  
  return(df_long)
}


#' Extract Statistical Measures from an fmri_lm Object
#'
#' This function extracts statistical measures (e.g., estimates, standard errors) from an \code{fmri_lm} object.
#'
#' @param x An \code{fmri_lm} object.
#' @param type The type of statistic to extract: \code{"betas"}, \code{"contrasts"}, or \code{"F"}.
#' @param element The specific element to extract, such as \code{"estimate"}, \code{"se"}, \code{"stat"}, or \code{"prob"}.
#' @return A tibble containing the requested statistical measures.
#' @keywords internal
pull_stat_revised <- function(x, type, element) {
  if (type == "betas") {
    # Ensure we access the matrix correctly from the list structure
    beta_matrix <- x$result$betas$data[[1]]$estimate[[1]]
    ret <- beta_matrix[, x$result$event_indices, drop = FALSE]
    colnames(ret) <- conditions(x$model$event_model)
    suppressMessages(tibble::as_tibble(ret, .name_repair = "check_unique"))
  } else if (type == "contrasts") {
    ret <- x$result$contrasts %>% dplyr::filter(type == "contrast")
    if (nrow(ret) == 0) {
      stop("No simple contrasts for this model.")
    }
    cnames <- ret$name
    # Extract the specific element (e.g., estimate), which is a list(vector)
    # Then extract the vector itself (element [[1]]) before binding
    out <- lapply(ret$data, function(inner_tibble) inner_tibble[[element]][[1]]) %>% 
             dplyr::bind_cols()
    names(out) <- cnames
    out
  } else if (type == "F") {
    ret <- x$result$contrasts %>% dplyr::filter(type == "Fcontrast")
    if (nrow(ret) == 0) {
      stop("No F contrasts for this model.")
    }
    cnames <- ret$name
    # Extract the specific element (e.g., estimate), which is list(vector)
    # Then extract the vector itself (element [[1]]) before binding
    out <- lapply(ret$data, function(inner_tibble) inner_tibble[[element]][[1]]) %>% 
             dplyr::bind_cols()
    names(out) <- cnames
    out
  } else {
    stop("Invalid type specified. Must be 'betas', 'contrasts', or 'F'.")
  }
}

pull_stat <- function(x, type, element) {
  if (type == "betas") {
    ret <- x$result$betas$data[[1]][[element]][[1]]
    
    # Check bounds and filter valid indices
    max_col <- ncol(ret)
    valid_event_indices <- x$result$event_indices[x$result$event_indices <= max_col]
    
    if (length(valid_event_indices) == 0) {
      warning("No valid event indices found in pull_stat. Using all available columns.")
      valid_event_indices <- 1:max_col
    }
    
    ret <- ret[, valid_event_indices, drop = FALSE]
    
    # Use the actual column names from the design matrix instead of conditions()
    # This avoids duplicate names when multiple terms have the same variables
    dm <- design_matrix(x$model)
    if (!is.null(dm) && ncol(dm) >= max(valid_event_indices)) {
      actual_colnames <- colnames(dm)[valid_event_indices]
      colnames(ret) <- actual_colnames
    } else {
      # Fallback: use conditions but make them unique
      condition_names <- conditions(x$model$event_model)[1:length(valid_event_indices)]
      colnames(ret) <- make.names(condition_names, unique = TRUE)
    }
    
    # Ensure tibble output for consistency with original behavior
    res <- suppressMessages(tibble::as_tibble(ret, .name_repair = "check_unique"))
  } else if (type == "contrasts") {
    ret <- x$result$contrasts %>% dplyr::filter(type == "contrast")
    if (nrow(ret) == 0) {
      stop("No simple contrasts for this model.")
    }
    cnames <- ret$name
    out <- lapply(ret$data, function(x) x[[element]]) %>% dplyr::bind_cols()
    names(out) <- cnames
    out
  } else if (type == "F") {
    ret <- x$result$contrasts %>% dplyr::filter(type == "Fcontrast")
    if (nrow(ret) == 0) {
      stop("No F contrasts for this model.")
    }
    cnames <- ret$name
    out <- lapply(ret$data, function(x) x[[element]]) %>% dplyr::bind_cols()
    names(out) <- cnames
    out
  } else {
    stop("Invalid type specified. Must be 'betas', 'contrasts', or 'F'.")
  }
}

#' Extract Model Coefficients from an fmri_lm Object
#'
#' This function extracts model coefficients (estimates) from an `fmri_lm` object.
#'
#' @param object An `fmri_lm` object.
#' @param type The type of coefficients to extract: `"betas"` or `"contrasts"`. Default is `"betas"'.
#' @param include_baseline Logical. If `TRUE`, include coefficients for baseline regressors along with event regressors.
#'                         If `FALSE` (default), only event regressors are returned.
#' @param recon Logical. If `TRUE`, reconstructs the coefficients into a neuroimaging volume. Default is `FALSE`.
#' @param ... Additional arguments (currently unused).
#' @return A tibble or matrix of coefficients.
#' @export
coef.fmri_lm <- function(object, type = c("betas", "contrasts"), include_baseline = FALSE, recon = FALSE, ...) {
  type <- match.arg(type)
  
  if (type == "contrasts") {
    # Contrast handling remains the same
    res <- pull_stat(object, "contrasts", "estimate")
  } else if (type == "betas") {
    # Get all beta estimates first
    all_betas <- object$result$betas$data[[1]]$estimate[[1]]
    
    if (include_baseline) {
      # Return all betas, ensure correct names from the full design matrix
      res <- all_betas
      colnames(res) <- colnames(design_matrix(object$model))
      # Convert back to tibble for consistency if needed, though matrix might be better here
      # res <- as_tibble(res)
    } else {
      # Default: return only event betas
      # Check bounds and filter valid indices
      max_col <- ncol(all_betas)
      valid_event_indices <- object$result$event_indices[object$result$event_indices <= max_col]
      
      if (length(valid_event_indices) == 0) {
        warning("No valid event indices found in coef.fmri_lm. Using all available columns.")
        valid_event_indices <- 1:max_col
      }
      
      res <- all_betas[, valid_event_indices, drop = FALSE]
      
      # Use the actual column names from the design matrix instead of conditions()
      # This avoids duplicate names when multiple terms have the same variables
      dm <- design_matrix(object$model)
      if (!is.null(dm) && ncol(dm) >= max(valid_event_indices)) {
        actual_colnames <- colnames(dm)[valid_event_indices]
        colnames(res) <- actual_colnames
      } else {
        # Fallback: use conditions but make them unique
        condition_names <- conditions(object$model$event_model)[1:length(valid_event_indices)]
        colnames(res) <- make.names(condition_names, unique = TRUE)
      }
      
      # Ensure tibble output for consistency with original behavior
      res <- suppressMessages(tibble::as_tibble(res, .name_repair = "check_unique"))
    }
  } else {
    # Should not happen due to match.arg, but defensive coding
    stop("Invalid type specified.")
  }
  
  # Reconstruction functionality can be added here if necessary (applies to the 'res' matrix/tibble)
  # if (recon && inherits(object$dataset, "fmri_dataset")) { ... }
  
  return(res)
}

#' Extract Statistical Values from an fmri_lm Object
#'
#' This function extracts statistical values (e.g., t-statistics, F-statistics) from an \code{fmri_lm} object.
#'
#' @param x An \code{fmri_lm} object.
#' @param type The type of statistics to extract: \code{"estimates"}, \code{"contrasts"}, or \code{"F"}.
#' @param ... Additional arguments (currently unused).
#' @return A tibble containing the requested statistical values.
#' @export
stats.fmri_lm <- function(x, type = c("estimates", "contrasts", "F"), ...) {
  type <- match.arg(type)
  if (type == "estimates") {
    pull_stat(x, "betas", "stat")
  } else if (type == "contrasts") {
    pull_stat(x, "contrasts", "stat")
  } else if (type == "F") {
    pull_stat(x, "F", "stat")
  }
}

#' Extract Standard Errors from an fmri_lm Object
#'
#' This function extracts standard errors from an \code{fmri_lm} object.
#'
#' @rdname standard_error
#'
#' @param x An \code{fmri_lm} object.
#' @param type The type of standard errors to extract: \code{"estimates"} or
#'   \code{"contrasts"}.
#' @return A tibble containing the standard errors.
#' @export
standard_error.fmri_lm <- function(x, type = c("estimates", "contrasts"),...) {
  type <- match.arg(type)
  if (type == "estimates") {
    pull_stat(x, "betas", "se")
  } else if (type == "contrasts") {
    pull_stat(x, "contrasts", "se")
  }
}



#' Fit Linear Model Contrasts
#'
#' This function computes contrasts and beta statistics for a fitted linear model.
#'
#' @param fit A fitted linear model object.
#' @param conlist A list of contrast matrices.
#' @param fcon A list of F-contrasts.
#' @param vnames Variable names corresponding to the model coefficients.
#' @param se Logical. Whether to compute standard errors. Default is \code{TRUE}.
#' @return A list containing contrasts, beta statistics, and the fitted model.
#' @keywords internal
fit_lm_contrasts <- function(fit, conlist, fcon, vnames, se = TRUE) {
  conres <- if (!is.null(conlist)) {
    ret <- lapply(conlist, function(con) {
      # Extract colind from the contrast object's attributes
      colind <- attr(con, "colind")
      if (is.null(colind)) {
        warning(paste("Missing colind attribute for contrast:", con$name %||% "unnamed"))
        return(NULL) # Skip this contrast
      }
      estimate_contrast(con, fit, colind)
    })
    # Filter out NULL results
    ret <- ret[!sapply(ret, is.null)]
    names(ret) <- sapply(conlist[!sapply(ret, is.null)], function(x) x$name %||% "unnamed")
    ret
  } else {
    list()
  }
  
  bstats <- beta_stats(fit, vnames, se = se)
  list(contrasts = conres, bstats = bstats, fit = fit)
}




#' Fit Multiresponse Linear Model
#'
#' This function fits a linear model to multiple responses in an fMRI dataset.
#'
#' @param form The formula used to define the linear model.
#' @param data_env The environment containing the data to be used in the linear model.
#' @param conlist The list of contrasts used in the analysis.
#' @param vnames The names of the variables used in the linear model.
#' @param fcon The F-contrasts used in the analysis.
#' @param modmat The model matrix (default is \code{NULL}, which will calculate the model matrix using the formula).
#' @return A list containing the results from the multiresponse linear model analysis.
#' @keywords internal
multiresponse_lm <- function(form, data_env, conlist, vnames, fcon, modmat = NULL) {
  lm_fit <- if (is.null(modmat)) {
    lm(as.formula(form), data = data_env)
  } else {
    lm.fit(modmat, data_env$.y)
  }
  
  # Use the actual column names from the model matrix instead of vnames
  # This ensures the dimensions match correctly
  actual_vnames <- if (is.null(modmat)) {
    names(coef(lm_fit))
  } else {
    colnames(modmat)
  }
  
  fit_lm_contrasts(lm_fit, conlist, fcon, actual_vnames)
}





unpack_chunkwise <- function(cres, event_indices, baseline_indices) {
  # --- Beta Processing (Seems OK) ---
  cbetas <- lapply(cres, function(x) x$bstats) %>% dplyr::bind_rows()
  dat_beta <- cbetas$data %>% dplyr::bind_rows()
  
  # Check validity (assuming estimate column now correctly holds matrices)
  valid_estimates_idx <- sapply(dat_beta$estimate, function(x) !is.null(x) && is.matrix(x) && nrow(x) > 0)
  if (!any(valid_estimates_idx)) {
      stop("No valid beta estimates found across chunks in unpack_chunkwise.")
  }
  dat_beta_valid <- dat_beta[valid_estimates_idx, , drop = FALSE]

  # Concatenate beta results across chunks
  estimate_beta <- do.call(rbind, dat_beta_valid$estimate)
  se_beta <- do.call(rbind, dat_beta_valid$se)
  stat_beta <- do.call(rbind, dat_beta_valid$stat)
  prob_beta <- do.call(rbind, dat_beta_valid$prob)
  sigma_beta <- do.call(c, dat_beta_valid$sigma)
  
  # Re-package combined beta results
  cbetas_out <- dplyr::tibble(
    type = cbetas$type[1],
    stat_type = cbetas$stat_type[1],
    df.residual = cbetas$df.residual[1],
    conmat = list(NULL),
    colind = list(NULL),
    data = list(
      dplyr::tibble(
        estimate = list(estimate_beta),   
        se = list(se_beta),               
        stat = list(stat_beta),            
        prob = list(prob_beta),            
        sigma = list(sigma_beta)          
      )
    )
  )

  # --- Contrast Processing --- 
  ncon <- if (length(cres) > 0 && !is.null(cres[[1]]$contrasts) && length(cres[[1]]$contrasts) > 0) {
      length(cres[[1]]$contrasts)
  } else { 0 }

  if (ncon > 0) {
    contab <- lapply(cres, function(x) { 
        # Ensure contrasts is a list of tibbles, even if only one contrast
        cons <- x$contrasts 
        if (!is.list(cons)) cons <- list(cons) # Handle single contrast case if needed
        if (length(cons) > 0 && !is.null(names(cons))) { # Ensure names exist
             dplyr::bind_rows(cons, .id = "contrast_internal_name") # Requires names
        } else if (length(cons) > 0) {
             # Fallback if names are missing, might need adjustment based on actual structure
             warning("Contrast list per chunk lacks names, attempting bind_rows without .id")
             dplyr::bind_rows(cons)
        } else {
             dplyr::tibble() # Return empty tibble for chunks with no contrasts
        }
    }) %>% dplyr::bind_rows() # Bind results from all chunks

    # Check if contab is empty after binding
    if (nrow(contab) == 0) {
        con <- dplyr::tibble()
    } else {
        # Group by original contrast name and type
        # Use 'name' column if it exists, otherwise fallback might be needed
        grouping_vars <- intersect(c("name", "type"), names(contab))
        if (length(grouping_vars) == 0) stop("Cannot group contrasts: 'name' or 'type' column missing.")
        
        gsplit <- contab %>% dplyr::group_by(dplyr::across(dplyr::all_of(grouping_vars))) %>% dplyr::group_split()

        # Process each contrast group (combine results across chunks)
        con <- lapply(gsplit, function(g) {
            dat <- g$data %>% dplyr::bind_rows() 
            
            # Both paths now produce the same structure, so no conditional logic needed.
            # Simply assign the vectors directly.
            estimate_full <- dat$estimate
            se_full <- dat$se
            stat_full <- dat$stat
            prob_full <- dat$prob
            sigma_full <- if ("sigma" %in% names(dat)) dat$sigma else NULL
            
            # Re-package combined data for this contrast
            combined_data_tibble <- dplyr::tibble(
                estimate = list(estimate_full), 
                se = list(se_full),             
                stat = list(stat_full),          
                prob = list(prob_full)           
            )
            if (!is.null(sigma_full)) {
                combined_data_tibble$sigma = list(sigma_full)
            }

            # Take metadata from the first chunk's entry for this contrast
            g %>% dplyr::select(-data) %>% dplyr::slice_head() %>% 
                dplyr::mutate(data = list(combined_data_tibble))
                
        }) %>% dplyr::bind_rows() 
    }
  } else {
    con <- dplyr::tibble() # Return empty tibble if no contrasts
  }

  # --- DEBUG FINAL CONTRAST TIBBLE ---
  # message("Structure of final 'con' tibble before returning from unpack_chunkwise:")
  # print(str(con))
  # --- END DEBUG ---

  list(
    betas = cbetas_out,
    contrasts = con,
    event_indices = event_indices,
    baseline_indices = baseline_indices
  )
}




#' Perform Chunkwise Linear Modeling on fMRI Dataset
#'
#' This function performs a chunkwise linear model analysis on an fMRI dataset,
#' splitting the dataset into chunks and running the linear model on each chunk.
#'
#' @param dset An \code{fmri_dataset} object.
#' @param model The \code{fmri_model} used for the analysis.
#' @param contrast_objects The list of full contrast objects.
#' @param nchunks The number of chunks to divide the dataset into.
#' @param robust Logical. Whether to use robust linear modeling (default is \code{FALSE}).
#' @param verbose Logical. Whether to display progress messages (default is \code{FALSE}).
#' @param use_fast_path Logical. If \code{TRUE}, use matrix-based computation for speed. Default is \code{FALSE}.
#' @param progress Logical. Display a progress bar for chunk processing. Default is \code{FALSE}.
#' @return A list containing the unpacked chunkwise results.
#' @keywords internal
chunkwise_lm.fmri_dataset <- function(dset, model, contrast_objects, nchunks, robust = FALSE,
                                      verbose = FALSE, use_fast_path = FALSE, progress = FALSE,
                                      cor_struct = c("iid", "ar1", "ar2", "arp"), cor_iter = 1L,
                                      cor_global = FALSE, ar_p = NULL, ar1_exact_first = FALSE,
                                      phi_fixed = NULL) {
  chunks <- exec_strategy("chunkwise", nchunks = nchunks)(dset)
  if (progress) {
    pb <- cli::cli_progress_bar("Fitting chunks", total = length(chunks), clear = FALSE)
    on.exit(cli::cli_progress_done(id = pb), add = TRUE)
  }
  form <- get_formula(model)
  tmats <- term_matrices(model)
  vnames <- attr(tmats, "varnames")
  event_indices = attr(tmats, "event_term_indices")
  baseline_indices = attr(tmats, "baseline_term_indices")

  # Common setup for both paths
  ym <- NULL # Define ym for R CMD check

  
  
  if (!use_fast_path) {
   
      # -------- Original Slow Path --------
      # Slow path uses lmfun which calls fit_lm_contrasts, expects full contrast objects
      # contrast_objects should already be the correct list structure here
      data_env <- list2env(tmats)
      data_env[[ ".y"]] <- rep(0, nrow(tmats[[1]])) # Corrected [[ ]] indexing
      modmat <- model.matrix(as.formula(form), data_env)
      Qr_global <- qr(modmat)
      Vu <- chol2inv(Qr_global$qr)
      
      lmfun <- if (robust) multiresponse_rlm else multiresponse_lm
      
      cres <- vector("list", length(chunks))
      for (i in seq_along(chunks)) {
        ym <- chunks[[i]]
        if (verbose) message("Processing chunk ", ym$chunk_num)
        data_env[[".y"]] <- as.matrix(ym$data)

        ret <- lmfun(form, data_env, contrast_objects, vnames, fcon = NULL, modmat = modmat)

        rss <- colSums(as.matrix(ret$fit$residuals^2))
        rdf <- ret$fit$df.residual
        resvar <- rss / rdf
        sigma <- sqrt(resvar)

        cres[[i]] <- list(bstats = ret$bstats, contrasts = ret$contrasts,
                          rss = rss, rdf = rdf, sigma = sigma)
        if (progress) cli::cli_progress_update(id = pb)
      }

  } else {
      # -------- New Fast Path --------
      # Fast path needs weights extracted from contrast_objects
      simple_conlist <- Filter(function(x) inherits(x, "contrast"), contrast_objects)
      fconlist <- Filter(function(x) inherits(x, "Fcontrast"), contrast_objects)
      simple_conlist_weights <- lapply(simple_conlist, `[[`, "weights")
      names(simple_conlist_weights) <- names(simple_conlist) 
      fconlist_weights <- lapply(fconlist, `[[`, "weights")
      names(fconlist_weights) <- names(fconlist) 
      
      if (robust) {
          warning("Robust fitting not implemented for fast path, using standard OLS.")
          robust <- FALSE
      }
      
      message("Using fast path for chunkwise LM...")

      data_env <- list2env(tmats)
      data_env[[ ".y"]] <- rep(0, nrow(tmats[[1]])) # Placeholder for model.matrix
      modmat_orig <- model.matrix(as.formula(form), data_env)

      ar_modeling <- match.arg(cor_struct) != "iid"
      ar_order <- switch(match.arg(cor_struct),
                         ar1 = 1L,
                         ar2 = 2L,
                         arp = ar_p,
                         iid = 0L)

      run_chunks <- exec_strategy("runwise")(dset)
      run_row_inds <- lapply(run_chunks, `[[`, "row_ind")

      if (ar_modeling && cor_iter > 1L) {
          warning("cor_iter > 1 not supported in chunkwise fast path; using 1")
          cor_iter <- 1L
      }

      phi_hat_list <- vector("list", length(run_chunks))

      if (ar_modeling) {
          X_w_list <- vector("list", length(run_chunks))
          for (ri in seq_along(run_chunks)) {
              rch <- run_chunks[[ri]]

              tmats_run <- term_matrices(model, rch$chunk_num)
              data_env_run <- list2env(tmats_run)
              n_time_run <- nrow(tmats_run[[1]])
              data_env_run[[".y"]] <- rep(0, n_time_run)
              X_run <- model.matrix(as.formula(form), data_env_run)
              proj_run <- .fast_preproject(X_run)
              Y_run <- as.matrix(rch$data)

              if (is.null(phi_fixed)) {
                  ols <- .fast_lm_matrix(X_run, Y_run, proj_run, return_fitted = TRUE)
                  resid_ols <- Y_run - ols$fitted
                  phi_hat_run <- .estimate_ar(rowMeans(resid_ols), ar_order)
              } else {
                  phi_hat_run <- phi_fixed
              }
              dummyY <- matrix(0, nrow(X_run), 0)
              ar_whiten_inplace(dummyY, X_run, phi_hat_run, ar1_exact_first)

              phi_hat_list[[ri]] <- phi_hat_run
              X_w_list[[ri]] <- X_run
          }
          modmat <- do.call(rbind, X_w_list)
      } else {
          modmat <- modmat_orig
      }
      proj <- .fast_preproject(modmat)
      Vu <- proj$XtXinv

      cres <- vector("list", length(chunks))
      for (i in seq_along(chunks)) {
          ym <- chunks[[i]]
          if (verbose) message("Processing chunk (fast path) ", ym$chunk_num)
          Ymat <- as.matrix(ym$data)

          if (ar_modeling) {
              for (ri in seq_along(run_chunks)) {
                  rows <- run_row_inds[[ri]]
                  phi <- phi_hat_list[[ri]]
                  if (!is.null(phi)) {
                      dummyX <- matrix(0, length(rows), 0)
                      subY <- Ymat[rows, , drop = FALSE]
                      ar_whiten_inplace(subY, dummyX, phi, ar1_exact_first)
                      Ymat[rows, ] <- subY
                  }
              }
          }

          if (verbose) message("  Chunk ", ym$chunk_num, ": ncol(Ymat) = ", ncol(Ymat))

          res <- .fast_lm_matrix(modmat, Ymat, proj)

          actual_vnames <- colnames(modmat)
          bstats <- beta_stats_matrix(res$betas, proj$XtXinv, res$sigma, proj$dfres, actual_vnames)

          contrasts <- fit_lm_contrasts_fast(res$betas, res$sigma2, proj$XtXinv,
                                             simple_conlist_weights, fconlist_weights, proj$dfres)

          cres[[i]] <- list(bstats = bstats,
                            contrasts = contrasts,
                            rss = res$rss,
                            rdf = proj$dfres,
                            sigma = res$sigma)
          if (progress) cli::cli_progress_update(id = pb)
      }
      # -------- End New Fast Path --------
  }
  
  # Unpack results (expects specific structure from cres)
  out <- unpack_chunkwise(cres, event_indices, baseline_indices)
  # Add cov.unscaled to the output
  out$cov.unscaled <- Vu 
  out
}



#' Perform Runwise Linear Modeling on fMRI Dataset
#'
#' This function performs a runwise linear model analysis on an fMRI dataset by
#' running the linear model for each data run and combining the results.
#'
#' @param dset An \code{fmri_dataset} object.
#' @param model The \code{fmri_model} used for the analysis.
#' @param contrast_objects The list of full contrast objects.
#' @param robust Logical. Whether to use robust linear modeling (default is \code{FALSE}).
#' @param verbose Logical. Whether to display progress messages (default is \code{FALSE}).
#' @param progress Logical. Display a progress bar for run processing. Default is \code{FALSE}.
#' @return A list containing the combined results from runwise linear model analysis.
#' @keywords internal
#' @autoglobal
runwise_lm <- function(dset, model, contrast_objects, robust = FALSE, verbose = FALSE,
                       use_fast_path = FALSE, progress = FALSE,
                       cor_struct = c("iid", "ar1", "ar2", "arp"), cor_iter = 1L,
                       cor_global = FALSE, ar_p = NULL, ar1_exact_first = FALSE,
                       phi_fixed = NULL) {
  # Get an iterator of data chunks (runs)
  chunks <- exec_strategy("runwise")(dset)
  if (progress) {
    pb <- cli::cli_progress_bar("Fitting runs", total = length(chunks), clear = FALSE)
    on.exit(cli::cli_progress_done(id = pb), add = TRUE)
  }
  form <- get_formula(model)
  # Global design matrix needed for pooling compatibility? Or just for Vu?
  modmat_global <- design_matrix(model)
  Qr_global <- qr(modmat_global)
  Vu <- chol2inv(Qr_global$qr)
  
  # Define ym for R CMD check
  ym <- NULL
  
  if (!use_fast_path) {
      # -------- Original Slow Path --------
      # Slow path uses lmfun which calls fit_lm_contrasts, expects full contrast objects
      lmfun <- if (robust) multiresponse_rlm else multiresponse_lm
      
      cres <- vector("list", length(chunks))
      for (i in seq_along(chunks)) {
        ym <- chunks[[i]]
        if (verbose) message("Processing run ", ym$chunk_num)
        tmats <- term_matrices(model, ym$chunk_num)
        vnames <- attr(tmats, "varnames")
        event_indices <- attr(tmats, "event_term_indices")
        baseline_indices <- attr(tmats, "baseline_term_indices")

        data_env <- list2env(tmats)
        data_env$.y <- as.matrix(ym$data)
        ret <- lmfun(form, data_env, contrast_objects, vnames, fcon = NULL)

        rss <- colSums(as.matrix(ret$fit$residuals^2))
        rdf <- ret$fit$df.residual
        resvar <- rss / rdf
        sigma <- sqrt(resvar)

        cres[[i]] <- list(
          conres = ret$contrasts,
          bstats = ret$bstats,
          event_indices = event_indices,
          baseline_indices = baseline_indices,
          rss = rss,
          rdf = rdf,
          resvar = resvar,
          sigma = sigma
        )
        if (progress) cli::cli_progress_update(id = pb)
      }
      # -------- End Original Slow Path --------
      
  } else {
      # -------- New Fast Path --------
      # Fast path needs weights extracted from contrast_objects
      simple_conlist <- Filter(function(x) inherits(x, "contrast"), contrast_objects)
      fconlist <- Filter(function(x) inherits(x, "Fcontrast"), contrast_objects)
      simple_conlist_weights <- lapply(simple_conlist, `[[`, "weights")
      names(simple_conlist_weights) <- names(simple_conlist) 
      fconlist_weights <- lapply(fconlist, `[[`, "weights")
      names(fconlist_weights) <- names(fconlist) 
      
      if (robust) {
          warning("Robust fitting not implemented for fast path, using standard OLS.")
          robust <- FALSE
      }
      

      message("Using fast path for runwise LM...")

      ar_modeling <- match.arg(cor_struct) != "iid"
      ar_order <- switch(match.arg(cor_struct),
                         ar1 = 1L,
                         ar2 = 2L,
                         arp = ar_p,
                         iid = 0L)
      
      # .export needed? conlist, fcon, model should be available.
      # Add functions from this package? .packages = c("dplyr", "purrr", "fmrireg")? Or rely on namespace?
      cres <- vector("list", length(chunks))
      for (i in seq_along(chunks)) {
        ym <- chunks[[i]]
        if (verbose) message("Processing run (fast path) ", ym$chunk_num)

        tmats <- term_matrices(model, ym$chunk_num)
        vnames <- attr(tmats, "varnames")
        event_indices <- attr(tmats, "event_term_indices")
        baseline_indices <- attr(tmats, "baseline_term_indices")

        data_env_run <- list2env(tmats)
        n_timepoints_run <- nrow(tmats[[1]])
        if (n_timepoints_run == 0) {
            warning(paste("Skipping empty run:", ym$chunk_num))
            next
        }
        data_env_run[[".y"]] <- rep(0, n_timepoints_run)
        X_run <- model.matrix(form, data_env_run)

        proj_run <- .fast_preproject(X_run)

        Y_run <- as.matrix(ym$data)

        if (nrow(X_run) != nrow(Y_run)) {
            stop(paste("Dimension mismatch in run", ym$chunk_num, ": X_run rows (", nrow(X_run), ") != Y_run rows (", nrow(Y_run), ")"))
        }

        phi_hat_run <- NULL
        if (ar_modeling) {
            if (is.null(phi_fixed)) {
                ols <- .fast_lm_matrix(X_run, Y_run, proj_run, return_fitted = TRUE)
                resid_ols <- Y_run - ols$fitted
                phi_hat_run <- .estimate_ar(rowMeans(resid_ols), ar_order)
            } else {
                phi_hat_run <- phi_fixed
            }
        }

        gls <- NULL
        proj_iter <- proj_run
        X_iter <- X_run
        Y_iter <- Y_run
        for (iter in seq_len(cor_iter)) {
            if (ar_modeling) {
                X_iter <- X_run
                Y_iter <- Y_run
                ar_whiten_inplace(Y_iter, X_iter, phi_hat_run, ar1_exact_first)
                proj_iter <- .fast_preproject(X_iter)
            }
            gls <- .fast_lm_matrix(X_iter, Y_iter, proj_iter)
            if (ar_modeling && is.null(phi_fixed) && iter < cor_iter) {
                resid_gls <- Y_iter - X_iter %*% gls$betas
                phi_hat_run <- .estimate_ar(rowMeans(resid_gls), ar_order)
            }
        }

        actual_vnames <- colnames(X_iter)
        bstats <- beta_stats_matrix(gls$betas, proj_iter$XtXinv, gls$sigma, proj_iter$dfres, actual_vnames)

        conres <- fit_lm_contrasts_fast(gls$betas, gls$sigma2, proj_iter$XtXinv,
                                         simple_conlist_weights, fconlist_weights, proj_iter$dfres)

        cres[[i]] <- list(
          conres = conres,
          bstats = bstats,
          event_indices = event_indices,
          baseline_indices = baseline_indices,
          rss = gls$rss,
          rdf = proj_iter$dfres,
          resvar = gls$sigma2,
          sigma = gls$sigma
        )
        if (progress) cli::cli_progress_update(id = pb)
      }
      
      # Filter out NULL results from skipped empty runs
      cres <- Filter(Negate(is.null), cres)
      if (length(cres) == 0) {
          stop("No valid run results found in runwise fast path.")
      }
      # -------- End New Fast Path --------
  }
  
  # Combine results (Pooling logic assumes specific structure in cres[[i]]$bstats and cres[[i]]$conres)
  bstats_list <- lapply(cres, `[[`, "bstats")
  conres_list <- lapply(cres, `[[`, "conres")
  
  # Compute overall statistics (these seem independent of fast/slow path)
  sigma <- colMeans(do.call(rbind, lapply(cres, function(x) as.matrix(x$sigma)))) # Make sure sigma is matrix/vector
  rss <- colSums(do.call(rbind, lapply(cres, function(x) as.matrix(x$rss))))
  rdf <- sum(unlist(lapply(cres, `[[`, "rdf")))
  resvar <- rss / rdf # Overall residual variance
  
  # Pool over runs
  if (length(cres) > 1) {
    # meta_contrasts expects a list of lists (runs) of lists (contrasts) of tibbles?
    # Or list (runs) of lists (contrasts) where elements are the tibbles?
    # Current: conres_list is list (runs) of lists (contrasts are named elements, values are tibbles)
    # Need to check meta_contrasts implementation.
    # Assuming meta_contrasts can handle the list of lists structure from fit_lm_contrasts_fast.
    
    # meta_betas expects a list of bstats tibbles and event_indices from the first run.
    # Assuming beta_stats_matrix output is compatible.
    meta_con <- meta_contrasts(conres_list)
    meta_beta <- meta_betas(bstats_list, cres[[1]]$event_indices)
    
    list(
      contrasts = meta_con,
      betas = meta_beta,
      event_indices = cres[[1]]$event_indices,
      baseline_indices = cres[[1]]$baseline_indices,
      cov.unscaled = Vu, # Using Vu from global design matrix
      sigma = sigma, # Pooled sigma
      rss = rss,     # Pooled rss
      rdf = rdf,     # Pooled rdf
      resvar = resvar # Pooled resvar
    )
  } else {
    # If only one run, return its results directly
    list(
      contrasts = conres_list[[1]], # This is the list of contrast tibbles for the single run
      betas = bstats_list[[1]], # This is the bstats tibble for the single run
      event_indices = cres[[1]]$event_indices,
      baseline_indices = cres[[1]]$baseline_indices,
      cov.unscaled = Vu,
      sigma = cres[[1]]$sigma, # Use run sigma
      rss = cres[[1]]$rss,
      rdf = cres[[1]]$rdf,
      resvar = cres[[1]]$resvar
    )
  }
}


#' Print an fmri_lm_result object
#'
#' Provides a colorful and informative printout.
#'
#' @param x An fmri_lm_result object.
#' @param ... Additional arguments (unused).
#' @export
#' @rdname print
print.fmri_lm <- function(x, ...) {
  # optional: check if crayon is installed
  if (!requireNamespace("crayon", quietly = TRUE)) {
    # fallback to standard cat if crayon is missing
    cat("fmri_lm_result object (install 'crayon' for color)\n\n")
    
    cat("Model formula:\n",
        as.character(x$model$event_model$model_spec$formula), "\n")
    cat("Strategy: ", x$strategy, "\n")
    cat("Baseline parameters: ",
        ncol(design_matrix(x$model$baseline_model)), "\n")
    cat("Design parameters: ",
        ncol(design_matrix(x$model$event_model)), "\n")
    cat("Contrasts: ",
        paste(names(x$bcons), collapse = ", "), "\n\n")
    return(invisible(x))
  }
  
  # If we do have crayon, let's color it up:
  cat(crayon::blue$bold("\n╔════════════════════════════════╗\n"))
  cat(crayon::blue$bold("║        fmri_lm_result          ║\n"))
  cat(crayon::blue$bold("╚════════════════════════════════╝\n\n"))
  
  # Print the model formula
  cat(crayon::green("Model formula:\n  "))
  cat(crayon::silver(as.character(x$model$event_model$model_spec$formula)), "\n\n")
  
  # Print strategy
  cat(crayon::green("Fitting strategy:  "))
  cat(crayon::silver(x$strategy), "\n\n")
  
  # Some stats about baseline, design, and contrasts
  bdim <- ncol(design_matrix(x$model$baseline_model))
  ddim <- ncol(design_matrix(x$model$event_model))
  
  cat(crayon::green("Baseline parameters: "), crayon::silver(bdim), "\n")
  cat(crayon::green("Design parameters:   "), crayon::silver(ddim), "\n")
  
  # If you have some # of simple contrasts
  c_names <- names(x$bcons)
  if (length(c_names) > 0) {
    cat(crayon::green("Contrasts:          "), crayon::silver(paste(c_names, collapse = ", ")), "\n\n")
  } else {
    cat(crayon::green("Contrasts:          "), crayon::silver("None\n\n"))
  }
  
  cat(crayon::yellow("Use coef(...), stats(...), etc. to extract results.\n\n"))
  
  invisible(x)
}
</file>

</files>
