% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/benchmark_datasets.R
\name{evaluate_method_performance}
\alias{evaluate_method_performance}
\title{Evaluate Method Performance on Benchmark Dataset}
\usage{
evaluate_method_performance(
  dataset_name,
  estimated_betas,
  method_name = "Unknown"
)
}
\arguments{
\item{dataset_name}{Character string specifying which dataset to use}

\item{estimated_betas}{Matrix of estimated beta values (conditions x voxels)}

\item{method_name}{Character string describing the method used}
}
\value{
A list with performance metrics
}
\description{
Helper function to evaluate the performance of beta estimation methods
on benchmark datasets by comparing estimated betas to ground truth.
}
\examples{
\dontrun{
# Load dataset and create design matrix
dataset <- load_benchmark_dataset("BM_Canonical_HighSNR")
X <- create_design_matrix_from_benchmark("BM_Canonical_HighSNR", HRF_SPMG1)

# Fit simple linear model
betas <- solve(t(X) \%*\% X) \%*\% t(X) \%*\% dataset$Y_noisy

# Evaluate performance
performance <- evaluate_method_performance("BM_Canonical_HighSNR", 
                                          betas[-1, ], # Remove intercept
                                          "OLS")
}

}
